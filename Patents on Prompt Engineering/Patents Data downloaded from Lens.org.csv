#,Jurisdiction,Kind,Display Key,Lens ID,Publication Date,Publication Year,Application Number,Application Date,Priority Numbers,Earliest Priority Date,Title,Abstract,Applicants,Inventors,Owners,URL,Document Type,Has Full Text,Cites Patent Count,Cited by Patent Count,Simple Family Size,Simple Family Members,Simple Family Member Jurisdictions,Extended Family Size,Extended Family Members,Extended Family Member Jurisdictions,Sequence Count,CPC Classifications,IPCR Classifications,US Classifications,NPL Citation Count,NPL Resolved Citation Count,NPL Resolved Lens ID(s),NPL Resolved External ID(s),NPL Citations,Legal Status
1,US,A1,US 2025/0117672 A1,173-786-334-266-046,4/10/2025,2025,US 202418893972 A,9/24/2024,US 202418893972 A;;US 202363588298 P,10/6/2023,CONSTRAINT-BASED PROMPTING FOR LANGUAGE MODELS TO REASON ON COMMONSENSE KNOWLEDGE BASES,"Provided herein is a method of improved commonsense knowledge bases reasoning through constraint-based prompting. A novel dual-module constraint-based prompt engineering system named ConstraintChecker is involved, which employs a first rule-based module to produce a list of constraints and a second zero-shot learning module to check whether the knowledge instance satisfies all constraints. The acquired constraint-checking result is then aggregated with the output of the main prompting backbone to produce the final output. This present method is more effective in commonsense knowledge bases reasoning then that by employing the prompting backbone alone, and also significantly reduces computational costs.",UNIV HONG KONG SCIENCE & TECH,DO VAN QUYET;;FANG TIANQING;;WANG ZHAOWEI;;SONG YANGQIU,THE HONG KONG UNIVERSITY OF SCIENCE AND TECHNOLOGY (2024-08-09),https://lens.org/173-786-334-266-046,Patent Application,yes,0,0,2,121-683-542-535-652;;173-786-334-266-046,US;;CN,2,121-683-542-535-652;;173-786-334-266-046,US;;CN,0,G06N5/04;;G06N5/022;;G06N5/04,G06N5/04,,0,0,,,,PENDING
2,US,A1,US 2025/0200294 A1,076-992-618-318-830,6/19/2025,2025,US 202318541030 A,12/15/2023,US 202318541030 A,12/15/2023,System And Methods For Multi-User Large Language Model Execution,"Disclosures are provided for execution of large-language models (LLMs), including systems and methods that allow for increased multi-user efficiency within an execution framework. For example, LLM queries provided by a plurality of users of an LLM may be combined together into a batched prompt that can be received by an LLM. In addition, the LLM receiving the batched prompt may be configured to provide an output that is segmented in accordance with each user's query. Configuration of the LLM may include providing the LLM with prompt-engineering inputs in connection with the batched prompt.",GOOGLE LLC,SHIN DONGEEK,GOOGLE LLC (2023-12-14),https://lens.org/076-992-618-318-830,Patent Application,yes,0,0,2,076-992-618-318-830;;006-445-361-614-551,US;;EP,2,076-992-618-318-830;;006-445-361-614-551,US;;EP,0,G06F16/3331;;G06F16/334;;G06F40/284;;G06F40/40,G06F40/40;;G06F40/284,,0,0,,,,PENDING
3,EP,A1,EP 4553646 A1,003-315-892-122-172,5/14/2025,2025,EP 24166863 A,3/27/2024,US 202318504451 A,11/8/2023,PROMPT ENGINEERING ENGINE,"A system and method including receiving a prompt specifying at least one task type; determining a system prompt based on the received prompt, the system prompt including artificial intelligence (Al) system configuration details corresponding to the at least one task type; pre-processing the system prompt to generate a pre-processed prompt including code referenced in the system prompt; transmitting, as an input prompt, the pre-processed prompt to an Al system; receiving, in response to the Al system executing the pre-processed prompt, a result from the AI system; and storing a record of the result from the AI system in a data repository.",SAP SE,MATHIS CHRISTIAN,,https://lens.org/003-315-892-122-172,Patent Application,yes,2,0,3,060-529-669-782-048;;144-184-060-305-254;;003-315-892-122-172,US;;EP;;CN,3,060-529-669-782-048;;144-184-060-305-254;;003-315-892-122-172,US;;EP;;CN,0,G06F8/30;;G06F8/36;;G06F8/423;;G06N20/00;;G06N3/0475;;G06F40/30;;G06F9/453;;G06F16/3322,G06F8/36;;G06F8/30;;G06F8/41;;G06F9/451;;G06F40/30;;G06N3/0475;;G06N20/00,,1,1,125-326-827-944-505,10.1145/3555041.3589678,"JOHN ROGERS JEFFREY LEO ET AL: ""DataChat: An Intuitive and Collaborative Data Analytics Platform"", PROCEEDINGS OF THE 23RD INTERNATIONAL MIDDLEWARE CONFERENCE DOCTORAL SYMPOSIUM, ACMPUB27, NEW YORK, NY, USA, 4 June 2023 (2023-06-04), pages 203 - 215, XP059055423, ISBN: 978-1-4503-9942-5, DOI: 10.1145/3555041.3589678",PENDING
4,US,A1,US 2023/0252224 A1,021-075-414-187-273,8/10/2023,2023,US 202318115365 A,2/28/2023,US 202318115365 A;;US 202217582852 A;;US 202163140774 P,1/22/2021,SYSTEMS AND METHODS FOR MACHINE CONTENT GENERATION,"Computerized systems and methods are disclosed to generate a document with a transformer by prompt-engineering the transformer with a title and a summary to generate a description of the document; displaying a set of claims and allowing user editing of the set of claims; receiving one or more figures; receiving a part list with a plurality of element names for each figure; generating an expanded description of each element name through prompt engineering based on prior text in the document; selecting one or more boilerplate texts for major sections of the document; and organizing the document with the title, a background, the summary, a brief description of the drawings, and a detailed description.",TRAN BAO,TRAN BAO,,https://lens.org/021-075-414-187-273,Patent Application,yes,0,60,1,021-075-414-187-273,US,5,021-075-414-187-273;;181-771-812-896-957;;159-757-006-132-460;;108-243-339-916-468;;078-327-594-521-449,US,0,G06F3/04845;;G06F40/166;;G06F40/56;;G06Q10/10;;G06Q50/184;;G06F40/151;;G06F3/0482;;G06F3/04845;;G06F40/166;;G06F40/40,G06F40/151;;G06F3/0482;;G06F3/04845;;G06F40/166;;G06F40/40,,0,0,,,,PENDING
5,US,A1,US 2024/0274125 A1,087-222-028-903-640,8/15/2024,2024,US 202318167127 A,2/10/2023,US 202318167127 A,2/10/2023,ADAPTABLE ACOUSTIC MODEL BUILT WITH LIMITED LABELING DATA,"According to one embodiment, a method, computer system, and computer program product for building an acoustic model is provided. The present invention may include performing contrastive pre-training of the acoustic model; building a dataset classifier using prompt engineering; performing a prediction process; and performing zero-shot audio prediction using the pre-trained acoustic model.",IBM,YUAN ZHONG FANG;;ZHAO SI TONG;;LIU TONG;;ZHONG YI CHEN;;DING YUAN YUAN,INTERNATIONAL BUSINESS MACHINES CORPORATION (2023-02-08),https://lens.org/087-222-028-903-640,Patent Application,yes,0,0,1,087-222-028-903-640,US,1,087-222-028-903-640,US,0,G10L15/063;;G10L2015/0638;;G10L2015/0638;;G10L15/063,G10L15/06,,0,0,,,,PENDING
6,US,A1,US 2025/0045411 A1,135-711-245-498-983,2/6/2025,2025,US 202318230253 A,8/4/2023,US 202318230253 A,8/4/2023,SYSTEM AND METHOD FOR CONTINUOUS AUTOMATED THREAT MODELING,"A system and method for continuous automated threat modeling which is based on prompt engineering using large language models includes a threat modeling engine, a threat prompt generator, and a continuous automation module configured to retrieve a threat prompt from the threat prompt generator and to perform a security assessment of the threat prompt on a continuous, automatic basis. In addition, the system and method each include integration with a large language model for generating threat models and mitigations pertaining to those threat models.",GUARDIAN LIFE INSURANCE COMPANY OF AMERICA,SINGH MANAS;;SINGH KARAN PRATAP;;S NAVEEN KUMAR;;JOHNSON DANIEL;;KYRYTSCHENKO GREG;;NOVACK MICHAEL;;VUTTARAPALLY SRINI,GUARDIAN LIFE INSURANCE COMPANY OF AMERICA (2023-07-27),https://lens.org/135-711-245-498-983,Patent Application,yes,0,0,1,135-711-245-498-983,US,1,135-711-245-498-983,US,0,G06F21/577;;G06F21/552;;G06F21/552;;G06F21/577,G06F21/57;;G06F21/55,,0,0,,,,PENDING
7,WO,A1,WO 2025/059465 A1,128-347-174-786-344,3/20/2025,2025,US 2024/0046614 W,9/13/2024,US 202363582390 P,9/13/2023,CLINICAL TRIAL OPERATIONAL PLAN GENERATION,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating operational plans. The method includes grounding a natural language processing (NLP) model in clinical trial context documents containing information related to execution of clinical trials, receiving a request to generate a. clinical trial operational plan; by the NLP model and responsive to the received request, generating the clinical trial operational plan such that the generated plan includes content based on the clinical trial context documents; providing the generated clinical trial operational plan as an output; receiving revisions to the generated clinical trial operational plan, wherein the revisions applied to the generated clinical trial operational plan correspond to a revised clinical trial operational plan; and grounding the NLP model in the revised clinical trial operational plan.",IQVIA INC,BONAGERI VIRUPAXKUMAR;;PATIL RAJNEESH,,https://lens.org/128-347-174-786-344,Patent Application,yes,5,0,3,128-347-174-786-344;;166-079-104-860-596;;123-843-917-489-326,US;;WO,3,128-347-174-786-344;;123-843-917-489-326;;166-079-104-860-596,US;;WO,0,G16H10/20;;G16H40/20;;G06Q10/06313;;G16H10/20;;G06Q10/06313;;G16H40/20,G16H10/20;;G06N20/00;;G16H40/20;;G16H50/20;;G16H50/30,,0,0,,,,PENDING
8,US,B1,US 12051205 B1,179-434-440-907-782,7/30/2024,2024,US 202318475722 A,9/27/2023,US 202318475722 A,9/27/2023,Systems and methods for interacting with a large language model,"Disclosed embodiments may include a method of interacting with a multimodal machine learning model; the method may include providing a graphical user interface associated with a multimodal machine learning model. The method may further include displaying an image to a user in the graphical user interface. The method may also include receiving a textual prompt from the user and then generating input data using the image and the textual prompt. The method may further include generating an output at least in part by applying the input data to the multimodal machine learning model, the multimodal machine learning model configured using prompt engineering to identify a location in the image conditioned on the image and the textual prompt, wherein the output includes a first location indication. The method may also include displaying, in the graphical user interface, an emphasis indicator at the indicated first location in the image.",OPENAI OPCO LLC,DEUTSCH NOAH;;ZWEIG BENJAMIN,OPENAI OPCO LLC (2024-01-16),https://lens.org/179-434-440-907-782,Granted Patent,yes,24,3,3,151-646-719-346-124;;179-434-440-907-782;;102-518-796-837-644,US;;WO,3,151-646-719-346-124;;179-434-440-907-782;;102-518-796-837-644,US;;WO,0,G06V10/82;;G06T2200/24;;G06T7/10,G06T7/10,,1,1,142-801-763-486-272,10.1109/tpami.2023.3275156;;37167049,"Peng Xu et al., Multimodal Learning with Transformers: A Survey, arXiv:2206.06488, May 10, 2023.",ACTIVE
9,US,A1,US 2025/0149169 A1,077-313-361-162-971,5/8/2025,2025,US 202318504649 A,11/8/2023,US 202318504649 A,11/8/2023,LEARNABLE VISUAL PROMPT ENGINEERING,"Systems or techniques for facilitating learnable visual prompt engineering are provided. In various embodiments, a system can access a medical image and a pre-trained machine learning model that is configured to perform a diagnostic or prognostic inferencing task. In various aspects, the system can apply a pre-processing transformation to one or more pixels or voxels of the medical image, thereby yielding a transformed version of the medical image, wherein the pre-processing transformation can convert an input pixel or voxel intensity value to an output pixel or voxel intensity value via one or more parameters that are iteratively learned. In various instances, the system can perform the diagnostic or prognostic inferencing task, by executing the pre-trained machine learning model on the transformed version of the medical image.",GE PREC HEALTHCARE LLC,ANAND DEEPA;;SHANBHAG DATTESH;;RAVISHANKAR HARIHARAN;;JOEL SURESH EMMANUEL DEVADOSS;;MULLICK RAKESH;;SATHISH RACHANA;;VENKATARAMANI RAHUL;;SHRIRAM KRISHNA SEETHARAM;;MURTHY PRASAD SUDHAKARA,GE PRECISION HEALTHCARE LLC (2023-09-01),https://lens.org/077-313-361-162-971,Patent Application,yes,0,0,2,129-029-290-017-860;;077-313-361-162-971,US;;CN,2,129-029-290-017-860;;077-313-361-162-971,US;;CN,0,G06T2207/30004;;G06T2207/20084;;G16H50/20;;G16H30/40;;G06T7/0012;;G06T2207/20081;;G16H50/20;;G06T7/0012;;G06T2207/30004;;G06T2207/20084;;G16H30/40,G16H50/20;;G06T7/00;;G16H30/40,,0,0,,,,PENDING
10,US,A1,US 2025/0209389 A1,120-482-453-571-064,6/26/2025,2025,US 202318395104 A,12/22/2023,US 202318395104 A,12/22/2023,AI-ASSISTED SCHEDULE PLANNER,"A data processing system implements receiving, via a first software application on a client device, a call requesting a schedule to be generated for a user by a generative model. The system further implements identifying online and/or offline data source(s) indicating activities specific to the user, the online and/or offline data source(s) including software application(s) within a workspace; constructing a first prompt by a prompt construction unit as an input to the generative model, the prompt construction unit constructing the first prompt by appending the activities and context data to an instruction string, the instruction string comprising instructions to the generative model to schedule the activities based on the context data, and to assign the scheduled activities into the schedule, the context data being associated with the user and/or the activities; providing the schedule to the client device; and causing a user interface of the client device to present the schedule.",MICROSOFT TECHNOLOGY LICENSING LLC,WOULFE MUIRIS;;AYDEMIR ATA TANER;;KAMATHAM CHAITANYA KUMAR;;GOYAL SHEETAL PRASAD;;RAMAMOORTHY VIGNESH;;POLYVANYI IEVGEN;;MOWATT DAVID,MICROSOFT TECHNOLOGY LICENSING LLC (2023-12-12),https://lens.org/120-482-453-571-064,Patent Application,yes,0,0,1,120-482-453-571-064,US,1,120-482-453-571-064,US,0,G06Q10/06311;;G06Q10/06311,G06Q10/0631,,0,0,,,,PENDING
11,WO,A1,WO 2024/213989 A1,181-077-100-187-247,10/17/2024,2024,IB 2024053425 W,4/8/2024,IN 202341026577 A,4/10/2023,A SYSTEM AND A METHOD FOR PARENTAL CONTROL IN A GENERATIVE ARTIFICIAL INTELLIGENCE GOVERNANCE PLATFORM,"A system (10) for a parental control in a generative artificial intelligence governance platform is disclosed The core modules include the parental requirement capture module to allow a parent to specify prerequisite conditions, harm identification, regulatory requirements, acceptable automated risk mitigation and alert services. A context based query assessment module to understand the context of a prompt, compare it against the configured parental requirement and quantify risk by interacting with subsequent questions. The query treatment module to identify risks associated with the prompt. Further, the query treatment module is configured to mitigate the risks from the child perspective based on a context of the intended action and parental requirement defined. The child prompt engineering module is configured to monitor the query, review the response and modify or block the response based on the policy defined. A parental alert module to alert the parent of the risk thereby ensuring parental control.",PRIVASAPIEN TECH PRIVATE LIMITED,SOUNDARARAJAN ABILASH,,https://lens.org/181-077-100-187-247,Patent Application,yes,2,1,1,181-077-100-187-247,WO,1,181-077-100-187-247,WO,0,G06F16/335;;G06F40/30;;G06N20/00;;H04N21/4542;;H04N21/251;;G06F2221/2149;;G06F21/6245;;G06N3/08;;G06N3/045;;G06N3/044,G06F16/335;;G06F18/20;;G06F21/62;;G06F40/30;;G06N20/00;;H04N21/258,,0,0,,,,PENDING
12,WO,A2,WO 2024/254361 A2,150-117-208-445-497,12/12/2024,2024,US 2024/0032887 W,6/6/2024,US 202363471420 P,6/6/2023,AUTOMATICALLY DETECTING DISCREPANCIES BETWEEN PRIVACY POLICIES AND PRIVACY LABELS,"Computer systems and computer-implemented methods identify potential discrepancies between data practice disclosures made in a data practice policy and a data practice label for a data system. The data system collects or captures data about or for a user of the data system or any other person The method can also comprise the step of comparing, by the computer system, the prediction for the given data practice with an entry in the data practice label for the data system to identify a possible discrepancy between the prediction and the data practice label. The classifier can be trained via machine learning to make the predictions. The classifier could comprise a classifier for each data practice covered by the data label or a foundation model, such as large language model, that is adapted to make the predictions about a data system's data practice label.",UNIV CARNEGIE MELLON,JAIN AKSHATH;;SADEH NORMAN,,https://lens.org/150-117-208-445-497,Patent Application,yes,0,0,2,150-117-208-445-497;;048-538-654-264-862,WO,2,150-117-208-445-497;;048-538-654-264-862,WO,0,G06N20/00;;G06N20/20,,,0,0,,,,PENDING
13,US,A1,US 2025/0054615 A1,134-973-664-047-232,2/13/2025,2025,US 202418798721 A,8/8/2024,US 202418798721 A;;US 202363518241 P,8/8/2023,Information Management System and Method,"A computer-implemented method, computer program product and computing system for: monitoring one or more operations within a medical environment; generating an operations management report based, at least in part, upon the one or more operations monitored within the medical environment; and providing the operations management report to a user, wherein the operations management report includes one or more of: an operations management score, an explanation of the operations management score, and a justification for the operations management score.",CALMWAVE INC,RONEN OPHIR;;KEARNS JUSTIN;;GRUZYNSKI MICHAEL;;BAUER CHRISTIAN;;PILON MARGARET;;FALCON SETH;;DZIEDZIC THOMAS;;DE GROOT CEES;;EULAU KURT;;BOUDREAU KEITH;;CASIA DAVEN,CALMWAVE INC (2024-08-08),https://lens.org/134-973-664-047-232,Patent Application,yes,0,0,21,073-846-139-486-840;;189-713-109-318-843;;058-651-426-412-955;;130-719-579-284-103;;039-312-291-471-142;;176-295-212-904-241;;083-808-051-770-367;;008-187-780-173-096;;140-873-988-812-761;;174-207-032-441-205;;187-043-879-134-044;;072-930-705-533-45X;;072-482-967-325-937;;019-957-312-432-074;;030-596-391-598-028;;157-946-106-383-582;;134-973-664-047-232;;156-370-626-803-127;;194-799-736-480-71X;;138-145-293-628-928;;011-455-717-061-610,US;;WO,21,073-846-139-486-840;;189-713-109-318-843;;058-651-426-412-955;;130-719-579-284-103;;039-312-291-471-142;;176-295-212-904-241;;083-808-051-770-367;;008-187-780-173-096;;140-873-988-812-761;;174-207-032-441-205;;187-043-879-134-044;;072-930-705-533-45X;;072-482-967-325-937;;019-957-312-432-074;;030-596-391-598-028;;157-946-106-383-582;;134-973-664-047-232;;156-370-626-803-127;;194-799-736-480-71X;;138-145-293-628-928;;011-455-717-061-610,US;;WO,0,G16H40/67;;G16H40/40;;G16H10/60;;G16H50/70;;G16H50/20;;G16H40/60;;G16H80/00;;G16H15/00;;G16H40/20;;G16H40/63;;G16H50/30;;A61B5/746;;G16H80/00;;G16H40/60;;G16H50/20;;G16H15/00;;G16H50/70;;G16H40/67;;G16H40/20;;G16H10/60;;A61B5/746;;G16H40/40,G16H40/20;;G16H15/00,,0,0,,,,PENDING
14,WO,A1,WO 2025/080406 A1,134-172-954-577-266,4/17/2025,2025,US 2024/0048040 W,9/24/2024,US 202318380113 A,10/13/2023,SOFTWARE DEVELOPMENT LANGUAGE MODEL PROMPT ENGINEERING,"Some embodiments engineer a prompt for submission to a language model, such as a software development large language model. Some embodiments ascertain a relationship between code development information and potential context. Code development information includes static analysis results, project settings, development tool history or status data, and other software development data which augments training data previously embedded in the language model. Some embodiments compute a prompt inclusion score of the potential context, based on at least the relationship, and use the inclusion score to determine whether to include the potential context in the language model prompt. In some scenarios, an embodiment determines where to place the context in the prompt. Scoring is performed by a formula, statistical scoring model, or machine learning scoring model. Some embodiments reduce context inclusion false positives and false negatives that were based on the use of embedding similarity scores alone.",MICROSOFT TECHNOLOGY LICENSING LLC,MCMORRAN BENJAMIN JOHN;;TODIREL ION;;MIHALCEA BOGDAN LONUT,,https://lens.org/134-172-954-577-266,Patent Application,yes,1,0,2,074-968-022-225-614;;134-172-954-577-266,US;;WO,2,074-968-022-225-614;;134-172-954-577-266,US;;WO,0,G06F40/166;;G06F40/284;;G06F40/30;;G06F8/33;;G06N20/00;;G06F40/279;;G06F8/71;;G06F8/33;;G06F8/75,G06F8/33;;G06F40/166;;G06F40/284;;G06F40/30;;G06N20/00,,0,0,,,,PENDING
15,WO,A1,WO 2025/160186 A1,104-424-334-816-190,7/31/2025,2025,US US2025/012608,1/22/2025,"US 63/6/023,712",1/22/2024,ENHANCED OCR DATA PROCESSING THROUGH DATA ENRICHMENT AND CONTEXTUAL TAGGING FOR LLMS,"A method and system are disclosed for improving the accuracy, efficiency, and scalability of data interpretation and extraction of structured data from unstructured documents utilizing Large Language Models (LLMs). Applicable in finance, healthcare, legal, and government contexts, the disclosed invention addresses limitations of conventional Optical Character Recognition (OCR), machine learning, and LLM-based methods. In particular, the system and method incorporate feedback loops for continuous learning and leverage pre-processing, contextual tagging, customized prompt engineering, and post-processing to achieve robust data extraction. By integrating data enrichment techniques, the invention manages the inherent complexities of multilingual documents and evolving content standards.","ETON SOLUTIONS, L.P.","NADARAJAH, Muralidhran",,https://lens.org/104-424-334-816-190,Patent Application,yes,0,0,1,104-424-334-816-190,WO,1,104-424-334-816-190,WO,0,,G06F40/30;;G06F16/33;;G06F16/36;;G06F40/20,,0,0,,,,UNKNOWN
16,US,A1,US 2024/0362476 A1,160-843-729-530-59X,10/31/2024,2024,US 202318398050 A,12/27/2023,US 202318398050 A;;US 202363543503 P;;US 202363527534 P;;US 202363463049 P,4/30/2023,GENERATING A LARGE LANGUAGE MODEL PROMPT BASED ON COLLABORATION ACTIVITIES OF A USER,"Methods, systems, and computer program products for managing interactions between a content management system (CMS) and a large language model (LLM) system. The semantics of user questions can be considered before prompting an LLM, or alternatively, before querying datasets that are local to the CMS. Given a user question to be answered, the embedding of the user question can be matched against preconfigured sample question embeddings to determine a best match. A prompt corresponding to the determined best match is then configured based on identification of the class or classes that correspond to the matched question. Prompts for provision to LLMs can be synthesized based on a particular user's identity and/or based on the particular user's historical collaboration activities over objects of the CMS. The LLM can be hosted by a third-party provider. Alternatively all or portions of a large language model system can be hosted within the CMS.",BOX INC,GRENADER DENIS;;KUS BENJAMIN JOHN,BOX INC (2023-12-21),https://lens.org/160-843-729-530-59X,Patent Application,yes,0,2,5,088-011-995-027-697;;160-843-729-530-59X;;003-620-165-625-065;;160-066-196-031-873;;100-607-359-543-623,US;;WO,8,160-066-196-031-873;;104-422-345-292-266;;088-011-995-027-697;;160-843-729-530-59X;;129-965-524-229-48X;;003-620-165-625-065;;061-122-977-680-555;;100-607-359-543-623,US;;WO,0,G06N3/0455;;G06F40/40;;G06F16/24522;;G06N5/01;;G06N3/08;;G06F16/24573;;G06F16/22;;G06F40/186;;G06F16/3329;;G06N3/0455;;G06N5/01;;G06N3/08;;G06F16/24573;;G06F16/22;;G06F16/24522;;G06F40/40,G06N3/08,,0,0,,,,PENDING
17,US,A1,US 2025/0095802 A1,035-999-885-938-836,3/20/2025,2025,US 202418829651 A,9/10/2024,US 202418829651 A;;US 202363582936 P,9/15/2023,SYSTEMS AND METHODS TO GENERATE PERSONAL DOCUMENTATION FROM AUDIO DATA,"Systems and methods for generating personal documentation from audio data are disclosed. Meeting audio of a meeting between a person and a professional is received and transcribed, generating a transcription. A text string corresponding to a prompt is generated from the transcription, and is used to generate a document by a generative language model trained to take a string corresponding to the prompt as input and generate a string corresponding to the document as output. When the professional is a health professional and the person is a patient, the generated document can be a medical document such as a clinical note. Therefore, the systems and methods can be used as part of an electronic health records system.",LABORATOIRE COEURWAY INC,GADOURY BASTIEN;;GAGNON JEAN-PHILLIPE;;VAIL MARIANE;;GRAVEL PIERRE-OLIVIER,LABORATOIRE COEURWAY INC (2023-09-20),https://lens.org/035-999-885-938-836,Patent Application,yes,0,0,1,035-999-885-938-836,US,1,035-999-885-938-836,US,0,G06F40/40;;G06F40/197;;G06F40/174;;G06F40/186;;G16H10/60;;G16H15/00;;G16H10/60;;G06F40/186;;G06F40/174;;G06F40/40;;G06F40/197,G16H10/60;;G06F40/174;;G06F40/186;;G06F40/197;;G06F40/40,,0,0,,,,PENDING
18,US,A1,US 2025/0078343 A1,076-983-528-704-063,3/6/2025,2025,US 202318457521 A,8/29/2023,US 202318457521 A,8/29/2023,CONTROL FONT GENERATION CONSISTENCY,Systems and methods for generating custom art fonts with consistent style include receiving user input that identifies a base font style for a custom font and includes descriptive text that defies one or more text effects to use for the custom font. Depth maps are selected for characters to be included in the custom font. The depth maps are preprocessed to add noise to the depth maps. A generative model generates custom font images conditioned with the text prompt and the depth maps. The custom font images are then used to render text on a display screen of a computing device.,MICROSOFT TECHNOLOGY LICENSING LLC,CHEN LI;;LI JI,MICROSOFT TECHNOLOGY LICENSING LLC (2023-08-28),https://lens.org/076-983-528-704-063,Patent Application,yes,0,2,1,076-983-528-704-063,US,1,076-983-528-704-063,US,0,G06T2200/24;;G06F40/40;;G06T11/203;;G06F40/109;;G06T5/70;;G06T11/203;;G06T2200/24;;G06F40/40;;G06T7/50;;G06T5/70,G06T11/20;;G06F40/40;;G06T5/00;;G06T7/50,,0,0,,,,PENDING
19,US,A1,US 2025/0245577 A1,150-895-486-615-661,7/31/2025,2025,US 19030087,1/17/2025,,,SYSTEM AND METHOD FOR GENERATING TRAINING DATA FOR FINE TUNING A MODEL IN A DATA SCARCE SETTING,"System and methods for generating training data for fine tuning a model in a data scarce setting are disclosed. In some embodiments, a disclosed method includes: receiving, from a user interface, an indication of a customer's interaction with a website, the indication including a customer query, generating, using a first model, a plurality of synthetic queries, generating, using the first model, a plurality of synthetic responses to each of the plurality of synthetic queries, the plurality of synthetic responses being generated based on one or more rules and each synthetic response of the plurality of responses having a positive response and a negative response, aggregating, using a second model, the plurality of responses to generate training data, and training a third model using the training data, the third model configured to generate a response to the customer query in real-time.","Walmart Apollo, LLC",Ashkan Esmaeili;;Yushang Lai;;Arpit Sharma;;Komal Arvind Dhuri,,https://lens.org/150-895-486-615-661,Patent Application,yes,0,0,1,150-895-486-615-661,US,1,150-895-486-615-661,US,0,G06N20/20,G06N20/20,,0,0,,,,UNKNOWN
20,US,B2,US 12299404 B2,077-160-578-799-776,5/13/2025,2025,US 202318343683 A,6/28/2023,US 202318343683 A;;US 202318190791 A;;US 202263399932 P,8/22/2022,"Computer-generated content based on text classification, semantic relevance, and activation of deep learning large language models","The disclosure relates to systems and methods of automatically generating unique content including natural language text based on a corpus of previously generated response documents and discrete requirements defined in a requirements specification. The system may use generative stitching that includes multi-layer processes that execute to influence the generation of unique content including natural language text through an artificial intelligence (AI) language transformer model trained to output the content based on previously written material that is semantically relevant to the discrete requirements and is weighted against labeled attributes. The labeled attributes may determine the influence asserted against the language transformer, thereby generating unique on-target content that may be combined to create a computer-generated response document.",ROHIRRIM INC,ABERLE STEVEN THOMAS,ROHIRRIM INC (2022-08-19),https://lens.org/077-160-578-799-776,Granted Patent,yes,16,1,5,182-856-102-564-527;;046-749-966-763-211;;046-913-270-759-689;;176-795-255-128-028;;077-160-578-799-776,US;;GB;;CA,12,167-952-184-433-323;;067-080-768-671-463;;176-795-255-128-028;;077-160-578-799-776;;048-995-946-983-686;;183-531-797-707-467;;182-856-102-564-527;;046-749-966-763-211;;062-165-840-690-839;;194-725-746-693-602;;130-863-944-657-956;;046-913-270-759-689,US;;GB;;WO;;EP;;AU;;CA,0,G06F40/56;;G06F40/30;;G06F40/169;;G06F40/284;;G06N3/0475;;G06N3/09;;G06N3/0455;;G06F40/131;;G06F16/3329;;G06F16/3344;;G06F40/30;;G06F40/56;;G06N20/00;;G06F40/169;;G06F40/40;;G06F40/30,G06F17/00;;G06F40/169;;G06F40/30;;G06F40/40;;G06N20/00,,2,0,,,"Combined Search and Examination Report issued in corresponding UK Patent Application No. 2312620.4, dated Mar. 7, 2024.;;International Preliminary Report on Patentability dated Feb. 25, 2025, issued in corresponding International Application No. PCT/US2023/028732 (7 pgs.).",ACTIVE
21,US,A1,US 2025/0182478 A1,141-767-126-811-201,6/5/2025,2025,US 202318529541 A,12/5/2023,US 202318529541 A,12/5/2023,GENERATING VIDEOS USING A CENTRALIZED SYSTEM,The present disclosure describes techniques for generating videos using a centralized system. Text is received by the centralized system via a user interface. The text indicates instructions for creating a video. A script for the video is generated based on the text by a machine learning model of the centralized system. The script indicates a series of scenes in the video. A plurality of tasks associated with creating the video is generated based on the script. The plurality of tasks are dispatched to a plurality of tools. The plurality of tools are associated with the centralized system. The centralized system enables the plurality of tools to simultaneously implement the plurality of tasks. Data indicating results of the plurality of tasks is collected from the plurality of tools. Information is displayed on the user interface for accessing the video generated based on the collected data.,LEMON INC,OUYANG ZHIHAO;;JIANG ZHE;;CHEN BIN;;LIU BAOMAN;;GUO DONG,,https://lens.org/141-767-126-811-201,Patent Application,yes,0,0,2,141-767-126-811-201;;005-130-097-898-491,US;;WO,2,141-767-126-811-201;;005-130-097-898-491,US;;WO,0,G06V20/41;;G06V20/35;;G06V20/35;;G06V20/41,G06V20/40;;G06V20/00,,0,0,,,,PENDING
22,WO,A1,WO 2024/178294 A1,148-084-960-145-88X,8/29/2024,2024,US 2024/0017020 W,2/23/2024,US 202363486617 P,2/23/2023,THREAT MITIGATION SYSTEM AND METHOD,"A computer-implemented method, computer program product and computing system for establishing connectivity with a plurality of security-relevant subsystems within a computing platform; receiving an initial notification of a security event from one of the security-relevant subsystems, wherein the initial notification includes a computer-readable language portion that defines one or more specifics of the security event; and iteratively processing the initial notification using a generative AI model and a formatting script to produce a summarized human-readable report for the initial notification.",RELIAQUEST HOLDINGS LLC,MURPHY BRIAN P;;PARTLOW JOE;;O'CONNOR COLIN;;PFEIFFER JASON;;MURPHY BRIAN PHILIP;;ECHAVARRIA JONATHAN R,,https://lens.org/148-084-960-145-88X,Patent Application,yes,5,0,26,112-945-747-892-451;;146-663-507-673-215;;094-413-612-537-593;;168-931-052-940-749;;075-645-293-083-478;;148-084-960-145-88X;;124-908-424-054-747;;112-056-866-769-800;;130-303-811-054-670;;119-120-615-831-743;;027-715-128-377-923;;155-420-535-049-751;;094-603-584-400-692;;174-511-857-314-741;;149-650-160-073-929;;061-835-424-316-286;;147-047-264-402-345;;049-936-659-265-784;;045-581-318-805-089;;019-901-571-374-013;;071-206-154-817-769;;066-434-018-948-063;;112-318-137-924-927;;089-978-359-291-602;;041-614-493-399-818;;188-876-200-895-959,US;;WO,26,112-945-747-892-451;;146-663-507-673-215;;094-413-612-537-593;;168-931-052-940-749;;075-645-293-083-478;;148-084-960-145-88X;;124-908-424-054-747;;112-056-866-769-800;;130-303-811-054-670;;119-120-615-831-743;;027-715-128-377-923;;155-420-535-049-751;;094-603-584-400-692;;174-511-857-314-741;;149-650-160-073-929;;061-835-424-316-286;;147-047-264-402-345;;049-936-659-265-784;;045-581-318-805-089;;019-901-571-374-013;;071-206-154-817-769;;066-434-018-948-063;;112-318-137-924-927;;089-978-359-291-602;;041-614-493-399-818;;188-876-200-895-959,US;;WO,0,G06N3/0475;;H04L63/1425;;G06F40/103;;G06F21/554;;H04L41/16;;H04L63/1416;;H04L63/1441;;G06F40/56;;G06F21/566;;G06F21/552;;G06F16/345;;G06F40/154;;H04L63/1441;;G06F16/345;;H04L63/1416;;G06F21/552;;G06F21/554;;H04L63/1425;;G06F40/103;;G06F40/154;;G06F2221/034;;G06N3/0475;;G06F21/566;;G06F40/56;;H04L41/16,G06F21/55;;G06F40/169;;G06F40/56;;G06N3/0475;;G06N20/00;;H04L9/40;;H04L51/224,,0,0,,,,PENDING
23,US,A1,US 2025/0095807 A1,182-810-270-216-202,3/20/2025,2025,US 202418883782 A,9/12/2024,US 202418883782 A;;US 202363583224 P,9/15/2023,AUTOMATIC PROMPT ENGINEERING USING A LARGE LANGUAGE MODEL,"Techniques are disclosed for automatically generating prompts. A method comprises accessing first prompts, wherein each of the first prompts is a prompt for generating a portion of a SOAP note using a machine-learning model. For each respective first prompt of the first prompts: (i) using the respective first prompt to obtain a first result from a first machine-learning model, (ii) using the respective first prompt and the first result to obtain a second result from a second machine-learning model, the second result including an assessment of the first result, (iii) using the second result to obtain a third result from a third machine-learning model, the third result including a second prompt, (iv) setting the second prompt as the respective first prompt, (v) repeating steps (i)-(iv) a number of times to obtain a production prompt, (vi) adding the production prompt to a collection of prompts; and storing the collection of prompts.",ORACLE INT CORP,ZAIDI SYED NAJAM ABBAS;;ZAREMOODI POORYA;;YANG SHIQUAN;;MATHUR NITIKA;;SHAH SHUBHAM PAWANKUMAR;;SHAMAEI ARASH;;GOLLAMUDI SAGAR KALYAN,ORACLE INTERNATIONAL CORPORATION (2024-09-26),https://lens.org/182-810-270-216-202,Patent Application,yes,0,0,8,008-549-423-008-776;;010-001-453-775-069;;044-596-459-933-450;;144-225-715-144-454;;182-810-270-216-202;;196-732-266-920-157;;147-406-515-283-865;;008-106-433-123-61X,US;;WO,8,008-549-423-008-776;;010-001-453-775-069;;044-596-459-933-450;;182-810-270-216-202;;196-732-266-920-157;;144-225-715-144-454;;147-406-515-283-865;;008-106-433-123-61X,US;;WO,0,G16H15/00;;G06F40/295;;G06F40/205;;G06F40/30;;G06F40/56;;G16H10/60;;G06N3/045;;G06N3/0475;;G16H50/20;;G06N20/00;;G16H10/60;;G10L15/26;;G06F40/205;;G06F40/295;;G06N20/20;;G16H10/00;;G06N20/00,G16H10/60;;G10L15/26,,0,0,,,,PENDING
24,WO,A1,WO 2024/213995 A1,017-882-646-625-179,10/17/2024,2024,IB 2024053433 W,4/8/2024,IN 202341026640 A,4/10/2023,A SYSTEM FOR PRESCRIPTIVE AND PROTECTED PROMPT ENGINEERING AND A METHOD THEREOF,"A system (100) for prescriptive and protected prompt engineering for a generative artificial intelligence is disclosed The system includes processing subsystem (108) which includes a user requirement input module (114) to receive one or more first queries prompt from a user, an interactive query module (116) suggests a plurality of second queries prompt to the user, a context gathering module (120) collects information related to a context of the input query, an objective gathering module (122) collect objectives of the first input queries, an assumption validation module (124) validates the selected option for the prompts, a prompt creation module (126), an expected utility validation module (128) validates the utility of the prompt, a risk assessment and mitigation module (130) understands risk of the input prompts and mitigation related to the prompts, and a prompt translation module (132) translates the selected prompt based on user's language preference.",PRIVASAPIEN TECH PRIVATE LIMITED,SOUNDARARAJAN ABILASH,,https://lens.org/017-882-646-625-179,Patent Application,yes,3,0,1,017-882-646-625-179,WO,1,017-882-646-625-179,WO,0,G06F40/30;;H04L51/02;;G06N3/0475;;G06F40/253;;G06F16/3329;;G06F16/3337;;G06F16/3332;;G06F21/6245;;G06N20/00,G06N3/0475;;G06F16/335;;G06F21/62;;G06F40/30;;H04L51/02,,0,0,,,,PENDING
25,US,A1,US 2025/0117976 A1,060-127-426-174-003,4/10/2025,2025,US 202318480623 A,10/4/2023,US 202318480623 A,10/4/2023,SYSTEMS AND METHODS FOR GENERATING IMAGES OF LOCATIONS AFFECTED BY WEATHER CONDITIONS,"In some implementations, the techniques described herein relate to a method including: (i) identifying, by a processor, a geographic location and a current time, (ii) retrieving, by the processor from a database, a weather condition of the geographic location at the current time, (iii) retrieving, by the processor from an image database, an image based on the geographic location, (iv) creating, via a generative machine learning model executed by the processor that takes the image of the geographic location and the weather condition as input, a digital image depicting the geographic location being visibly affected by the weather condition, and (v) causing display, by the processor, of the digital image in an application.",YAHOO ASSETS LLC,RUGHWANI DIPEN;;SOARES JOAO VITOR BALDINI,YAHOO ASSETS LLC (2023-09-28),https://lens.org/060-127-426-174-003,Patent Application,yes,6,0,1,060-127-426-174-003,US,1,060-127-426-174-003,US,0,G06F16/587;;G06T11/001;;G06T13/80;;G06T11/001;;G06F16/587;;G06T13/80,G06T11/00;;G06F16/587;;G06T13/80,,0,0,,,,PENDING
26,US,A1,US 2025/0078972 A1,100-316-582-059-797,3/6/2025,2025,US 202318240269 A,8/30/2023,US 202318240269 A,8/30/2023,PROMPT ENGINEERING AND GENERATIVE AI FOR GOAL-BASED IMAGERY,"An example operation may include one or more of storing a generative artificial intelligence (GenAI) model configured to create images, displaying a plurality of prompts on a user interface of a software application, receiving an identifier of a goal of the user and attributes of the goal via the plurality of prompts on the user interface, executing the GenAI model on the identifier of the goal of the user and the attributes of the goal to generate a custom image of the goal for the user, and displaying the custom image of the goal via the user interface of the software application.",TORONTO DOMINION BANK,GORMLEY BREENA PATRICIA,THE TORONTO-DOMINION BANK (2023-09-08),https://lens.org/100-316-582-059-797,Patent Application,yes,2,0,1,100-316-582-059-797,US,1,100-316-582-059-797,US,0,G16H50/20;;G16H20/00;;G16H50/20;;G16H20/00,G16H20/00;;G16H50/20,,0,0,,,,PENDING
27,US,A1,US 2025/0165648 A1,091-219-526-864-338,5/22/2025,2025,US 202318513334 A,11/17/2023,US 202318513334 A,11/17/2023,PRIVACY-PRESERVING PROMPT ENGINEERING FOR GENERATIVE ARTIFICIAL INTELLIGENCE,"Certain aspects of the disclosure concern a computer-implemented method for improved data security when interacting with a large language model. The method includes receiving a prompt query entered through a user interface, detecting sensitive data in the prompt query that violates a security protocol, generating a modified prompt query which anonymizes the sensitive data, submitting the modified prompt query to a large language model, and receiving a reply generated by the large language model. The reply contains anonymized sensitive data. The method further includes generating a modified reply which deanonymizes the anonymized sensitive data and presenting the modified reply on the user interface.",SAP SE,GOMEZ LAURENT,SAP SE (2023-11-17),https://lens.org/091-219-526-864-338,Patent Application,yes,7,0,1,091-219-526-864-338,US,1,091-219-526-864-338,US,0,G06F21/6254;;G06F21/606;;G06F21/6227;;G06F21/6227;;G06F21/6254;;G06F21/606,G06F21/62,,0,0,,,,PENDING
28,US,A1,US 2025/0094729 A1,127-004-636-977-129,3/20/2025,2025,US 202318522709 A,11/29/2023,KR 20230123130 A,9/15/2023,METHOD AND DEVICE FOR STEPWISE PURIFICATION OF SENTENCES WITH GENERATIVE ARTIFICIAL INTELLIGENCE,"Provided is a method of generating stepwise purified sentences using a deep learning-based interactive model. The method includes receiving input sentences by a user's terminal, detecting malicious words in the input sentences, and generating a plurality of stagewise purified sentences using a plurality of types of purification including purification of the malicious words according to stepwise sentence purification, by a language purification model part of a stepwise purified sentence generation system, and presenting, by the terminal, the plurality of stepwise purified sentences to a user to allow the user to select one of the plurality of stepwise purified sentences, and transmitting, by the terminal, the selected stepwise purified sentence to the stepwise purified sentence generation system to determine a final purified sentence.",UNIV SANGMYUNG INDUSTRY ACADEMY COOPERATION FOUNDATION,KIM MANSEO;;KIM JONGHAN;;AHN SUNGCHAN;;JUNG WOOSUNG;;JO SUHWAN;;PARK SUNG JUN,SANGMYUNG UNIVERSITY INDUSTRY - ACADEMY COOPERATION FOUNDATION (2023-11-21),https://lens.org/127-004-636-977-129,Patent Application,yes,0,0,2,127-004-636-977-129;;046-608-714-280-791,US;;KR,2,127-004-636-977-129;;046-608-714-280-791,US;;KR,0,G06F16/338;;G06F16/3326;;G06F40/40;;G06F40/30;;G06F40/289;;G06F40/205;;G06F40/263;;G06F40/279;;G06F40/30;;G06F16/31;;G06F16/3329;;G06F16/338;;G06F16/3334;;G06N3/09;;G06N3/092;;G06N3/096;;G06N3/0985;;G06N3/0475;;G06N3/045;;G06F40/40;;G06F16/3326;;G06F16/338,G06F40/40;;G06F16/332;;G06F16/338,,0,0,,,,PENDING
29,US,A1,US 2024/0403005 A1,110-464-155-490-31X,12/5/2024,2024,US 202418677796 A,5/29/2024,US 202418677796 A;;US 202363504767 P;;US 202463554642 P,5/29/2023,SYSTEMS AND METHODS OF PROMPT ENGINEERING FOR NEURAL NETWORK INTERACTIONS,"A self-improving code/prompt system (e.g., an operating system or a process layer) for generating and/or reusing code/prompt processes is provided. Code/prompt processes include a sequence of prompts for a model, such as an LLM and traditional logic (code) which augments the input/output to the LLM and orchestrates interaction with other third party processes. The system includes an interpreter for managing the execution of code/prompt processes and corresponding interactions with external models, system processes, a process database (e.g., of existing code/prompt processes), and other sources.",FRIDDLE TYLER,FRIDDLE TYLER,,https://lens.org/110-464-155-490-31X,Patent Application,yes,0,3,1,110-464-155-490-31X,US,1,110-464-155-490-31X,US,0,G06F8/35;;G06F8/35,G06F8/35,,0,0,,,,PENDING
30,CN,A,CN 118364801 A,164-151-379-261-892,7/19/2024,2024,CN 202410572237 A,5/10/2024,CN 202410572237 A,5/10/2024,Automatic prompt engineering optimization method for large model,"The invention provides an automatic prompt engineering optimization method for a large model, which belongs to the field of artificial intelligence, and comprises the following steps: firstly, collecting and analyzing a large number of prompt statements in practical application, constructing a template library containing rich statistical characteristics, and establishing a matching model between a template and input data characteristics by using a machine learning technology; in the actual operation process, the system receives user task input and extracts key features to select an optimal prompt template to guide the large model to work, and then feedback opinions of a user on an output result are collected, so that the template library and the matching strategy are continuously iterated and optimized. According to the method, automation and individuation of large model prompting are realized, the response efficiency and the output quality of the large model in various application scenes are improved, and development and application practice of a natural language processing technology in the field of artificial intelligence are powerfully promoted.",SHANDONG INSPUR SCIENCE RESEARCH INSTITUTE CO LTD,ZHAN ENHAO;;LI XUE;;DUAN QIANG,,https://lens.org/164-151-379-261-892,Patent Application,no,0,2,1,164-151-379-261-892,CN,1,164-151-379-261-892,CN,0,G06F40/186;;G06F40/216;;G06F18/23;;G06F16/35;;G06F18/24323;;G06F16/334,G06F40/186;;G06F16/33;;G06F16/35;;G06F18/23;;G06F18/243;;G06F40/216,,0,0,,,,PENDING
31,US,A1,US 2025/0139108 A1,129-870-352-509-693,5/1/2025,2025,US 202419004302 A,12/28/2024,US 202419004302 A,12/28/2024,Design Strategies to Prevent Data Hallucination in Large Language Models for the Medical Field,"This invention proposes novel prompt engineering strategies to ensure the accuracy of large language models in medical applications, effectively mitigating the risk of data hallucination. The methods include stepwise database search designs, reference-providing mechanisms to enhance operational transparency and facilitate manual verification, and the integration of multilingual support schemes. These innovative prompt engineering designs significantly improve the reliability, transparency, and clinical applicability of information generated by natural language models.",CUI MIAO,CUI MIAO,,https://lens.org/129-870-352-509-693,Patent Application,yes,0,0,1,129-870-352-509-693,US,1,129-870-352-509-693,US,0,G16H50/70;;G06F16/2471;;G16H50/70;;G06F16/2471,G06F16/2458;;G16H50/70,,0,0,,,,PENDING
32,US,A1,US 2025/0131101 A1,067-094-819-814-194,4/24/2025,2025,US 202418921759 A,10/21/2024,US 202418921759 A;;US 202363592036 P,10/20/2023,AI-DRIVEN AUTONOMOUS COMMAND FILTERING,"A method and system to enable autonomous processing of a command line string prevent risky operations. After receiving a command, a session control service and holds the command in a queue while the command is parsed and risk analyzed. The parsed command and its parameters are sent to an AI-driven command risk analyzer trained on the types of commands that represent risks and generate a risk score. The risk score is used to inform the session control service to allow the command to be presented to the asset for execution if the risk has a low score and if the risk has a high score, either a) block the command execution or b) send the command and risk analysis to an admin user or approval team for review and either approval or rejection of the command.",DELINEA INC,MCNEELY DAVID;;HAIBACH NOAH,DELINEA INC (2024-10-19),https://lens.org/067-094-819-814-194,Patent Application,yes,0,0,1,067-094-819-814-194,US,1,067-094-819-814-194,US,0,G06F21/577;;G06N5/04;;G06F2221/034;;G06F21/577;;G06F2221/034;;G06N5/04,G06F21/57;;G06N5/04,,0,0,,,,PENDING
33,WO,A1,WO 2025/136374 A1,085-888-985-142-562,6/26/2025,2025,US 2023/0084977 W,12/20/2023,US 202318544949 A,12/19/2023,METHOD OF GENERATING PROMPTS FOR AN INDUSTRY-SPECIFIC LARGE LANGUAGE MODEL RECOMMENDATION SYSTEM,"A system and method for modifying operation of a drilling platform controller. A prompt generator receives drilling operations data relevant to drilling platform controller operation, wherein the drilling operations data includes current drilling parameters of a selected drilling platform controller. The prompt generator generates a prompt for recommended changes in operation of the selected drilling platform controller and applies the prompt to a large language model (LLM) trained with drilling operations domain knowledge. The LLM generates a recommendation for one or more changes in operation of the selected drilling platform controller. Feedback on efficacy of the recommendation is received from the selected drilling platform controller and is used to modify operation of the prompt generator.",HALLIBURTON ENERGY SERVICES INC,ANTONIO DANIEL;;CHRETIEN ALEXANDER SIMON;;SADLIER ANDREAS,,https://lens.org/085-888-985-142-562,Patent Application,yes,0,0,2,085-888-985-142-562;;153-420-872-160-116,US;;WO,2,085-888-985-142-562;;153-420-872-160-116,US;;WO,0,E21B2200/22;;E21B2200/20;;E21B44/00;;E21B44/00;;E21B2200/22;;E21B2200/20,E21B44/00;;G06N5/04;;G06N20/00,,0,0,,,,PENDING
34,US,A1,US 2025/0103746 A1,151-304-399-651-866,3/27/2025,2025,US 202418899600 A,9/27/2024,US 202418899600 A;;US 202363540779 P,9/27/2023,SYSTEM AND METHOD FOR PROVIDING A PRIVACY-AWARE PROMPT ENGINEERING SYSTEM,"Systems and methods are disclosed for providing a privacy aware semantic searching system. A system can include at least one memory; and at least one processor coupled to the at least one memory and configured to receive a prompt to a target machine learning model and generate, via a semantic search machine learning model, a sensitivity score for the prompt based on a relevant of the prompt to a sensitive enterprise data. The system can use the score to redact sensitive data from the prompt. The system also can augment the prompt based on enterprise data to improve the prompt for processing by the machine leaning model. The system can include a pre-processing model for redacting and/or augmenting the prompt and a post-processing model for inserting or modifying the output of the machine learning model.",GHARIBI GHARIB;;GENTRY CRAIG;;GORDON SAMUEL DOV;;HO NATHAN;;DAS RIDDHIMAN,GHARIBI GHARIB;;GENTRY CRAIG;;GORDON SAMUEL DOV;;HO NATHAN;;DAS RIDDHIMAN,,https://lens.org/151-304-399-651-866,Patent Application,yes,0,3,1,151-304-399-651-866,US,1,151-304-399-651-866,US,0,G06F21/6227;;G06F21/6227,G06F21/62,,0,0,,,,PENDING
35,US,A1,US 2025/0085688 A1,125-618-946-503-790,3/13/2025,2025,US 202318462626 A,9/7/2023,US 202318462626 A,9/7/2023,INDUSTRIAL AUTOMATION DESIGN ENVIRONMENT PROMPT ENGINEERING FOR GENERATIVE AI,"An integrated development environment (IDE) for designing, programming, and configuring aspects of an industrial automation system uses a generative artificial intelligence (AI) model and associated neural networks to generate portions of an industrial automation project in accordance with functional requirements provided to the industrial IDE system in intuitive formats, such as spoken or written plain language text. The system uses generative AI to translate plain language requests or functional specifications into industrial control code, human-machine interface (HMI) applications, device configuration settings, or other aspects of an industrial control project.",ROCKWELL AUTOMATION TECH INC,CARRARA ANTHONY;;PATEL RAHUL P;;ANAND ASHISH;;GREGORY ADAM J;;WENGATZ JUSTIN;;RICHTER DANIEL T;;BAHADER OMAR A;;MAJEWSKI LORENZO;;FERNANDES FABIANO;;JOSIPOVIC SRDJAN,ROCKWELL AUTOMATION TECHNOLOGIES INC (2023-08-21),https://lens.org/125-618-946-503-790,Patent Application,yes,0,0,1,125-618-946-503-790,US,1,125-618-946-503-790,US,0,G05B19/408;;G05B19/4063;;G05B19/409;;G05B19/408;;G05B19/4063;;G05B19/409,G05B19/408;;G05B19/4063;;G05B19/409,,0,0,,,,PENDING
36,US,A1,US 2025/0117410 A1,180-717-041-120-38X,4/10/2025,2025,US 202418736351 A,6/6/2024,US 202418736351 A;;US 202363588279 P;;US 202363588285 P,10/5/2023,SYSTEMS AND METHODS OF CHAINED CONVERSATIONAL PROMPT ENGINEERING FOR INFORMATION RETRIEVAL,"A system is provided for processing user queries by using an automated agent and a workflow. The system comprises reusable components that include states, tools, and/or data sources. Based on analysis of a query's content and goals, the system generates a workflow comprising a sequence of states, each state optimized for a subtask and dynamically bound to a selected tool(s) for that specific query. The workflow can provide a structured high-level control, while allowing for flexible selection of the tool(s) for each state of the workflow for that given query. The system produces a result using the structured workflow and selected tools, answering a user's original query.",NASDAQ INC,AGHAJANYAN VIKTOR;;STILLER MICHAEL;;BORNACINI EUGENIA,NASDAQ INC (2024-06-25),https://lens.org/180-717-041-120-38X,Patent Application,yes,13,0,2,029-365-994-406-677;;180-717-041-120-38X,US,6,029-365-994-406-677;;069-350-584-208-183;;112-183-619-800-091;;103-846-503-462-156;;180-717-041-120-38X;;116-253-303-398-004,US;;EP,0,G06V30/412;;G06F16/3326;;G06V30/413;;G06F16/3322;;G06F16/3326;;G06V30/412;;G06V30/413;;G06F16/3322,G06F16/332;;G06V30/412;;G06V30/413,,0,0,,,,ACTIVE
37,US,A1,US 2024/0289560 A1,061-349-534-364-875,8/29/2024,2024,US 202418589179 A,2/27/2024,US 202418589179 A;;US 202363487037 P,2/27/2023,PROMPT ENGINEERING AND AUTOMATED QUALITY ASSESSMENT FOR LARGE LANGUAGE MODELS,"Various embodiments of the present disclosure provide prompt engineering and text quality assessment techniques for improving generative text outputs. The techniques may include identifying an initial document subset for a generative text request that includes a request to generate a generative text document based on one or more request text fields. The techniques may include generating a contextual classification for the one or more request text fields and identifying a refined document subset based on the contextual classification. The techniques may include generating one or more request field embeddings respectively corresponding to the one or more request text fields and identifying a prompt document subset based on the one or more request field embeddings. The techniques may include generating, using a large language model, one or more generative text fields using a generative model prompt based on the prompt document subset and the one or more request text fields.",UNITEDHEALTH GROUP INC,KELLY DAMIAN;;BHADAURIA VIVEK;;VOLOZIN ANDREY;;FERNANDO SANJEEVA L,UNITEDHEALTH GROUP INCORPORATED (2023-02-27),https://lens.org/061-349-534-364-875,Patent Application,yes,0,4,1,061-349-534-364-875,US,1,061-349-534-364-875,US,0,G06F16/35;;G06F40/40;;G06F16/35;;G06F40/40,G06F40/40;;G06F16/35,,0,0,,,,PENDING
38,CN,A,CN 116958700 A,080-982-751-325-461,10/27/2023,2023,CN 202310955757 A,8/1/2023,CN 202310955757 A,8/1/2023,Image classification method based on prompt engineering and contrast learning,"The invention discloses an image classification method based on prompt engineering and comparative learning, and the method achieves the adaptation of a downstream task through employing Soft Prompt Tuning in a visual mode and a text mode, and achieves a cross-mode dual-path multilayer perceptron. According to the method, based on text and image features, high image classification accuracy can be achieved on 11 public data sets, and the average recognition accuracy is 82.5% or above; the method is based on a large-scale pre-training model and prompt fine tuning technology, only a small number of model parameters need to be adjusted in the training process, and computing resources are saved; according to the method, in the training process of the multi-modal model CLIP, the loss of comparative learning and the loss of few-label learning are combined, and the model convergence speed is increased on the basis of the prior art.",UNIV NANJING POSTS & TELECOMMUNICATIONS,LI BING;;GAO SHAOKUN;;LU YUCHEN,,https://lens.org/080-982-751-325-461,Patent Application,no,0,1,1,080-982-751-325-461,CN,1,080-982-751-325-461,CN,0,G06V10/765;;G06V10/811;;G06V10/82;;G06N3/0455;;G06N3/0895;;Y02D10/00,G06V10/764;;G06N3/0455;;G06N3/0895;;G06V10/80;;G06V10/82,,0,0,,,,PENDING
39,EP,A1,EP 4535189 A1,116-253-303-398-004,4/9/2025,2025,EP 24204027 A,10/1/2024,US 202363588285 P;;US 202418736351 A,10/5/2023,SYSTEMS AND METHODS OF CHAINED CONVERSATIONAL PROMPT ENGINEERING FOR INFORMATION RETRIEVAL,"A system is provided for processing user queries by using an automated agent and a workflow. The system comprises reusable components that include states, tools, and/or data sources. Based on analysis of a query's content and goals, the system generates a workflow comprising a sequence of states, each state optimized for a subtask and dynamically bound to a selected tool(s) for that specific query. The workflow can provide a structured high-level control, while allowing for flexible selection of the tool(s) for each state of the workflow for that given query. The system produces a result using the structured workflow and selected tools, answering a user's original query.",NASDAQ INC,AGHAJANYAN VIKTOR;;STILLER MICHAEL;;BORNACINI EUGENIA,,https://lens.org/116-253-303-398-004,Patent Application,yes,1,0,1,116-253-303-398-004,EP,6,029-365-994-406-677;;069-350-584-208-183;;112-183-619-800-091;;103-846-503-462-156;;180-717-041-120-38X;;116-253-303-398-004,US;;EP,0,G06F16/33295;;G06F40/56;;G06F40/30,G06F16/3329,,1,0,,,"LEWISPATRICK ET AL.: ""Retrieval-augmented generation for knowledge-intensive nlp tasks."", ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS, vol. 33, 2020, pages 9459 - 9474",PENDING
40,US,A1,US 2025/0245731 A1,189-205-207-916-184,7/31/2025,2025,US 19025793,1/16/2025,,,SYSTEMS AND METHODS FOR CONVERSATION BASED PRODUCT SEARCH,"Systems and methods for performing product search based on conversations with customers are disclosed. In some embodiments, a disclosed method includes: receiving, from a computing device, a search request identifying a query and contextual information; determining, using a natural language model, at least one query entity based on the query and the contextual information; generating at least one enhanced query based on the at least one query entity and an enhancement phrase; searching a database to identify a set of items using at least one machine learning model based on the at least one enhanced query; generating a ranked list of items based on the set of items; and transmitting, to the computing device, the ranked list of items in response to the search request.","Walmart Apollo, LLC",Ali Arsalan Yaqoob;;Rahul Radhakrishnan Iyer;;Shubham Gupta;;Hyun Duk Cho;;Praveenkumar Kanumala;;Sushant Kumar;;Kannan Achan,,https://lens.org/189-205-207-916-184,Patent Application,yes,0,0,1,189-205-207-916-184,US,1,189-205-207-916-184,US,0,G06Q30/0633;;G06Q30/0625;;G06Q30/0641,G06Q30/0601,,0,0,,,,UNKNOWN
41,US,A1,US 2024/0330589 A1,039-526-187-790-454,10/3/2024,2024,US 202318326666 A,5/31/2023,US 202318326666 A;;US 202363493594 P,3/31/2023,ADAPTING FOUNDATION MODELS FOR INFORMATION SYNTHESIS OF WIRELESS COMMUNICATION SPECIFICATIONS,"Existing approaches to understanding, developing, and researching modern wireless communication technologies involve time intensive and arduous processes of sifting through numerous webpages and technical specification documents, gathering the required information and synthesizing it. The present disclosure describes a conversational artificial intelligence tool for information synthesis of wireless communication specifications. The system builds on recent advancements in foundation large language models (LLMs) and consists of three key additional components: a domain-specific database, a context extractor, and a feedback mechanism. The system appends user queries with concise contextual information extracted from a database of wireless technical specifications and incorporates tools for expert feedback and data contribution. On evaluation using a benchmark dataset of expert queries and responses, the system provided more relevant and accurate answers on topics related to modern wireless communication specifications with a BLEU (BiLingual Evaluation Understudy) score of 0.28 compared to 0.03 achieved by current state-of-the-art LLM-based systems.",MICROSOFT TECHNOLOGY LICENSING LLC,KOTARU MANIKANTA,MICROSOFT TECHNOLOGY LICENSING LLC (2023-06-22),https://lens.org/039-526-187-790-454,Patent Application,yes,9,3,1,039-526-187-790-454,US,3,025-131-786-876-474;;039-526-187-790-454;;127-722-322-663-094,US;;WO,0,G06F40/284;;H04W24/02;;G06F40/205;;G06F40/30;;G06F40/284;;G06F40/205;;H04W24/02,G06F40/284;;G06F40/205;;H04W24/02,,3,1,066-122-043-803-541,10.24963/ijcai.2019/706,"Holm, Henrik. ""Bidirectional encoder representations from transformers (bert) for question answering in the telecom domain.: Adapting a bert-like language model to the telecom domain using the electra pre-training approach."" (2021). (Year: 2021);;Lian, Rongzhong, et al. ""Learning to select knowledge for response generation in dialog systems."" arXiv preprint arXiv:1902.04911 (2019). (Year: 2019);;Lewis, Patrick, et al. ""Retrieval-augmented generation for knowledge-intensive nlp tasks."" Advances in neural information processing systems 33 (2020): 9459-9474. (Year: 2020)",PENDING
42,US,A1,US 2025/0194978 A1,195-753-920-615-365,6/19/2025,2025,US 202318540775 A,12/14/2023,US 202318540775 A,12/14/2023,LARGE LANGUAGE MODEL WITH BRAIN PROCESSING TOOLS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for determining a mental state of a patient based on a natural language input and determining whether a relevant subset of brain data is anomalous. One of the methods includes receiving a natural language input describing at least one aspect of a mental state or of a behavior of an individual; generating a prompt based on at least in part the natural language input; submitting the prompt to a large language model; receiving at least one functional network that influences the at least one aspect of a mental state or of a behavior; for each network of the at least one functional network, analyzing MRI data for the individual to determine whether the network is anomalous; displaying to a user each network and whether it is anomalous; and taking an action in response to the displaying.",OMNISCIENT NEUROTECHNOLOGY PTY LTD,DOYEN STEPHANE PHILIPPE;;SUGHRUE MICHAEL EDWARD,OMNISCIENT NEUROTECHNOLOGY PTY LIMITED (2025-04-10),https://lens.org/195-753-920-615-365,Patent Application,yes,8,0,2,195-753-920-615-365;;150-927-039-280-357,US;;WO,2,195-753-920-615-365;;150-927-039-280-357,US;;WO,0,G06T2207/30016;;G06T2200/24;;G06T2207/10088;;G16H50/20;;G06F40/40;;G16H20/70;;G16H40/67;;A61B5/055;;G16H10/20;;G06T7/0012;;A61B5/4803;;A61B5/165;;A61B5/165;;G06T7/0012;;G06F40/40;;G16H40/67;;G06T2200/24;;G16H50/20;;A61B5/4803;;G06T2207/10088;;G06T2207/30016;;G16H20/70,A61B5/16;;A61B5/00;;G06F40/40;;G06T7/00;;G16H20/70;;G16H40/67;;G16H50/20,,0,0,,,,PENDING
43,US,A1,US 2025/0245081 A1,061-613-991-362-963,7/31/2025,2025,US 19036732,1/24/2025,,,SYSTEMS AND METHODS FOR ARTIFICIAL INTELLIGENCE INTEGRATION IN A COMPLIANCE ENVIRONMENT,"An artificial intelligence integration system comprising a client system; an artificial intelligence large language model system; a middleware system connected to the client system and the artificial intelligence large language model system, the middleware system comprising an application programming interface integration layer; a data privacy filter; a prompt engineering module; a response processing module; and a use-case library. The middleware system packages data received from the client system before providing it to the artificial intelligence large language model in order to address confidentiality, governmental compliance, and other risk compliance.","Cential AI, Inc.",Andrew Gunter;;David Ponder;;Jannie Wentzel,,https://lens.org/061-613-991-362-963,Patent Application,yes,0,0,1,061-613-991-362-963,US,1,061-613-991-362-963,US,0,G06F9/546;;G06F40/30;;G06F2209/547,G06F9/54;;G06F40/30,,0,0,,,,UNKNOWN
44,CN,A,CN 119810234 A,150-015-051-940-862,4/11/2025,2025,CN 202411877322 A,12/18/2024,CN 202411877322 A,12/18/2024,"Information processing method, device and system for image generation, and related equipment","The invention provides an information processing method, device and system for image generation and related equipment, relates to the technical field of artificial intelligence, in particular to the technical fields of computer vision, deep learning, large models and the like, and can be applied to scenes such as AIGC content generation based on artificial intelligence. According to the specific implementation scheme, the method comprises the steps of obtaining image generation demand information, used for generating an image, of a target object; and inputting the image generation demand information into a prompt engineering system so as to convert the image generation demand information into image generation parameters adopted by an image generation system based on the prompt engineering system.",BEIJING BAIDU NETCOM SCI & TECH CO LTD,XIA JUN;;LIU JIACHEN;;XIAO XINYAN;;HU WENHAO;;LIN YANZHENG,,https://lens.org/150-015-051-940-862,Patent Application,no,0,0,1,150-015-051-940-862,CN,1,150-015-051-940-862,CN,0,,G06T11/00;;G06N5/04,,0,0,,,,PENDING
45,US,A1,US 2025/0004428 A1,178-069-975-099-057,1/2/2025,2025,US 202318343374 A,6/28/2023,US 202318343374 A,6/28/2023,PROMPT ENGINEERING FOR ARTIFICIAL INTELLIGENCE ASSISTED INDUSTRIAL AUTOMATION DEVICE CONFIGURATION,"The present technology relates to artificial intelligence assisted device configuration. In an implementation, an interface service of a device design application receives an input comprising an association between a device and a controller of an automation system design. The interface service then generates a first prompt requesting an application type associated with the device. The interface service next transmits the first prompt to a large language model and receives a first response to the first prompt from the large language model, wherein the first response includes the application type. The interface service then generates a second prompt requesting configuration settings for the device based on the system information and the application type. The interface service next transmits the second prompt to the large language model and receives a second response to the second prompt that includes configuration settings for the device. The interface service then displays the second response.",ROCKWELL AUTOMATION TECH INC,ANTHONY MICHAEL J;;CASE CLARK L;;D'AMICO MICHAEL P;;JASPER TARYL J;;MANELA ERYN AMARA DANIELLE;;MAZUR DAVID C;;MILLS JONATHAN A;;SANDLER NATHANIEL S;;SNEEN KURT D;;SNYDER DAVID A,ROCKWELL AUTOMATION TECHNOLOGIES INC (2023-06-13),https://lens.org/178-069-975-099-057,Patent Application,yes,0,0,1,178-069-975-099-057,US,1,178-069-975-099-057,US,0,G05B13/0265;;G05B13/0265,G05B13/02,,0,0,,,,PENDING
46,US,A1,US 2025/0005224 A1,151-361-689-420-952,1/2/2025,2025,US 202318343481 A,6/28/2023,US 202318343481 A,6/28/2023,PROMPT ENGINEERING FOR ARTIFICIAL INTELLIGENCE ASSISTED INDUSTRIAL AUTOMATION SYSTEM DESIGN,"Technology disclosed herein includes a prompt engineering service that integrates artificial intelligence with the programming systems of an industrial automation environment to design a system of the industrial automation environment. The interface service leverages the capabilities of a large language model (LLM) trained on industrial automation workflows to provide accurate and relevant system design information. For example, the interface service receives system configuration data and generates a first prompt requesting a category associated with the system configuration data. The interface service uses the first prompt to generate a response from the LLM. The interface service generates a second prompt requesting a user interface message for offering assistance to configure the system based on the category. The interface service uses the second prompt to generate the user interface message and displays the message in a user interface.",ROCKWELL AUTOMATION TECH INC,ANTHONY MICHAEL J;;CASE CLARK L;;D'AMICO MICHAEL P;;JASPER TARYL J;;MANELA ERYN AMARA DANIELLE;;MAZUR DAVID C;;MILLS JONATHAN A;;SANDLER NATHANIEL S;;SNEEN KURT D;;SNYDER DAVID A,ROCKWELL AUTOMATION TECHNOLOGIES INC (2023-06-13),https://lens.org/151-361-689-420-952,Patent Application,yes,0,1,1,151-361-689-420-952,US,1,151-361-689-420-952,US,0,G06F30/20;;G06F30/20,G06F30/20,,0,0,,,,PENDING
47,US,A1,US 2025/0004450 A1,081-314-780-904-609,1/2/2025,2025,US 202318343551 A,6/28/2023,US 202318343551 A,6/28/2023,PROMPT ENGINEERING FOR ARTIFICIAL INTELLIGENCE ASSISTED INDUSTRIAL AUTOMATION DEVICE TROUBLESHOOTING,"The present technology relates to artificial intelligence assisted device troubleshooting. In an implementation, an interface service of a human machine interface application trains a machine learning model on the content of an embeddings database. The interface service then receives an input comprising a context of an automation system design. The interface service generates a prompt that includes an instruction for the ML model to identify an anomaly type associated with the context of the automation system design and to generate a solution that addresses the anomaly type. The interface service transmits the prompt to the ML model and receives a response from the ML model that includes the anomaly type and the requested solution. After receiving a response, the interface service may modify the automation system design based on the content of the response and surface a graphical user interface that includes the modified design.",ROCKWELL AUTOMATION TECH INC,ANTHONY MICHAEL J;;CASE CLARK L;;D'AMICO MICHAEL P;;JASPER TARYL J;;MANELA AARON D;;MAZUR DAVID C;;MILLS JONATHAN A;;SANDLER NATHANIEL S;;SNEEN KURT D;;SNYDER DAVID A,ROCKWELL AUTOMATION TECHNOLOGIES INC (2023-06-13),https://lens.org/081-314-780-904-609,Patent Application,yes,0,1,1,081-314-780-904-609,US,1,081-314-780-904-609,US,0,G05B2219/31449;;G05B19/4184;;G05B2219/31449;;G05B19/4184,G05B19/418,,0,0,,,,PENDING
48,CN,A,CN 117933360 A,094-761-192-695-130,4/26/2024,2024,CN 202410077118 A,1/19/2024,CN 202311073641 A,8/24/2023,Model generation method and system based on knowledge distillation and prompt engineering,"The invention discloses a model generation method and system based on knowledge distillation and prompt engineering, and the method comprises the steps: designing a training target suitable for a downstream task according to a vertical domain data set, optimizing a base large model according to the training target, and obtaining a vertical domain large model; regarding the vertical domain large model as a teacher model, and generating a network structure as a student model according to the downstream task; wherein the network structure scale of the student model is smaller than that of the vertical domain large model; at least one piece of batch data is extracted from the downstream task data set to serve as input of the teacher model and the student model, and the intermediate features are distilled layer by layer based on the cue project, so that after the intermediate features of the student model and the teacher model are aligned with output results, a small-scale model suitable for downstream tasks is obtained. According to the method, the model scale can be compressed as much as possible under the condition of realizing good alignment with downstream tasks, and the deployment and reasoning efficiency of the vertical domain model is improved.",INST INF ENG CAS,LI JIAN;;LI JIAOYANG;;LIN ZHENG;;LIU YONG;;WANG WEIPING,,https://lens.org/094-761-192-695-130,Patent Application,no,0,1,1,094-761-192-695-130,CN,1,094-761-192-695-130,CN,0,G06N3/096;;G06N5/02,G06N3/096;;G06N5/02,,0,0,,,,PENDING
49,CN,A,CN 118394422 A,188-273-636-480-639,7/26/2024,2024,CN 202410287661 A,3/13/2024,CN 202410287661 A,3/13/2024,"Prompt engineering method, system and equipment for cooperative control of intelligent hardware","The invention provides a prompt engineering method, system and equipment for cooperative control of intelligent hardware, and the method comprises the steps: determining an equipment state based on environment perception data, and determining an area where a user is located based on a user position and user activity information; under the condition that at least one of equipment state change, user area change and user command sending exists, inputting the environment perception data into a large language model to obtain an environment information analysis text, and inputting user historical data into the large language model to obtain a user demand text and a behavior analysis text; and generating a control instruction based on the environment information analysis text, the user demand text and the behavior analysis text, obtaining first feedback information of the user, executing the control instruction based on the first feedback information, and obtaining second feedback information of the user after the control instruction is executed. According to the method, the flexibility and adaptability of the hardware cooperative control method are improved, and the advantages of the hardware cooperative control method can be better reflected under the condition that the hardware relates to human-computer interaction.",INST AUTOMATION CAS,XIN MIAO;;WANG PEISONG;;YOU ZHONGRUI;;CHENG JIAN;;ZHANG YIFAN;;LIANG HAOTIAN,,https://lens.org/188-273-636-480-639,Patent Application,no,3,0,1,188-273-636-480-639,CN,1,188-273-636-480-639,CN,0,G05B19/04;;G06F9/4451;;G06Q10/04;;G06F40/30;;G06F18/25,G06F9/445;;G05B19/04;;G06F18/25;;G06F40/30;;G06Q10/04,,0,0,,,,PENDING
50,CN,A,CN 117931985 A,056-796-824-087-275,4/26/2024,2024,CN 202410338158 A,3/25/2024,CN 202410338158 A,3/25/2024,Advanced prompt engineering system and method for international engineering specification question and answer assistant and electronic equipment,"The invention discloses an advanced prompt engineering system and method for an international engineering specification question and answer assistant and electronic equipment, and belongs to the technical field of data processing. Comprising a user interface layer I, a multi-round prompt engineering layer II, a standard library search layer III, a database layer IV and a large language model layer V, the method comprises the following steps: collecting text data of international engineering specification book directories and multi-specialty question-answer cases; and constructing a first round of prompt project information template. And constructing a standard library search layer III based on the first-round prompt project information template. And constructing a second round of prompt project information template. Aiming at the technical level, the limitation of a processing object is made up. Aiming at an application level, the advanced prompt engineering method of the multi-round prompt information based on the GPT skillfully and effectively distinguishes and parameterizes the functional links of question asking, keyword recognition and extraction, an engineering specification database, database search logic and an international engineering specification question and answer assistant and forms series connection; and the overall performance and the application value of the international engineering specification consultation assistant system are improved.",UNIV BEIJING TECHNOLOGY,GAO WEN;;DU XIULI;;LIN BORONG;;WU CHENGLIN;;ZHANG XUANMING;;WANG YANG,,https://lens.org/056-796-824-087-275,Patent Application,no,9,0,2,056-796-824-087-275;;160-131-884-557-092,CN,2,056-796-824-087-275;;160-131-884-557-092,CN,0,G06F16/31;;G06F16/3329;;G06F16/335;;G06F16/338;;G06F40/186,G06F16/31;;G06F16/332;;G06F16/335;;G06F16/338;;G06F40/186,,0,0,,,,ACTIVE
51,WO,A1,WO 2024/213993 A1,043-219-838-777-822,10/17/2024,2024,IB 2024053431 W,4/8/2024,IN 202341026568 A,4/10/2023,A SYSTEM FOR MULTI MODAL AGGREGATION IN A GOVERNANCE PLATFORM AND A METHOD THEREOF,"A system (100) for multi modal aggregation and governance platform is provided The system includes an identity protection module (114) providing a plurality of identities of a user at a plurality of downstream modules, convert them into a unified user identity and proxy the unified identity, a query receiving module (116) receives a plurality of queries from the user and classify them into one or more categories, a governance module (118) understands a context of the multimodal queries, control user prompt or chain of thought prompts, execute the multimodal queries via a responsible artificial intelligence model (120), control the queries or prompts, generate reports related to the risks involved in the input query and the response outputs, query and response distribution module (122) distributes executed the plurality of multimodal queries to the plurality of downstream generative AI modules (140), including translation and select a foremost response.",PRIVASAPIEN TECH PRIVATE LIMITED,SOUNDARARAJAN ABILASH,,https://lens.org/043-219-838-777-822,Patent Application,yes,1,0,1,043-219-838-777-822,WO,1,043-219-838-777-822,WO,0,G06N3/02;;G06Q10/06;;G06F18/20;;G06Q50/26;;G06Q10/10;;G06F21/6218;;G06N20/00,G06F11/30;;G06F3/048;;G06F18/20;;G06F21/60;;G06F40/30;;G06N3/02;;G06Q10/06,,1,0,,,"DIGNUM VIRGINIA: ""Responsible AI: Ways to Avoid the Dark Side of AI Use"", ALTEXSOFT, 12 April 2022 (2022-04-12), XP093224142, Retrieved from the Internet <URL:https://www.altexsoft.com/blog/responsible-ai>",PENDING
52,CN,A,CN 119719136 A,001-170-120-206-328,3/28/2025,2025,CN 202411797530 A,12/9/2024,CN 202411797530 A,12/9/2024,Method for converting medical congruent variable text into SQL (Structured Query Language) based on large model and fine tuning technology,"The invention discloses a large model and fine tuning technology-based medical confusable variable text-to-SQL (structured query language) conversion method, which is characterized by comprising the following steps of: constructing and processing a confusable variable text; a Prompt engineering step is carried out; a model training step; generating an SQL (Structured Query Language) query; and integrating the system. Based on the NLP (Natural Language Processing) technology, the SQL query statement for the medical database can be automatically generated according to the data analysis requirement of a doctor. By using Prompt engineering, efficient parameter fine tuning (PEFT) and fine tuning (Fine-Tuning) technologies, data analysis requirements of doctors can be accurately understood, and then complex SQL query statements are accurately generated, so that the working efficiency and the data processing capability of the doctors are improved.",WONDERS INFORMATION CO LTD,TONG QING;;ZHANG TIANCHI;;CHEN CHENG;;XIONG YANGWU;;ZHAO XIAOJING;;REN LINKUN;;ZHANG LINMENG;;WANG XU,,https://lens.org/001-170-120-206-328,Patent Application,no,0,0,1,001-170-120-206-328,CN,1,001-170-120-206-328,CN,0,,G06F16/242;;G06F16/2452;;G06F16/28;;G06N3/0455;;G06N5/04,,0,0,,,,PENDING
53,US,A1,US 2024/0185099 A1,169-382-576-409-841,6/6/2024,2024,US 202218073386 A,12/1/2022,US 202218073386 A,12/1/2022,USER RESPONSE COLLECTION INTERFACE GENERATION AND MANAGEMENT USING MACHINE LEARNING TECHNOLOGIES,"Various embodiments described herein support or provide generation and management operations of user response collection interfaces using machine learning technologies, including receiving a user input from a user interface of a device, the user input including data content that describes context of a media asset; using a machine learning model to generate analysis of the context of the media asset based on the data content; dynamically generating a question based on the analysis of the context of the media asset; and causing display of the question and the plurality of answers on the user interface of the device.",SPHEREX INC,PHILLIPS TERESA ANN;;JOSHI PRANAV ANAND;;MCSTAY KIRA MICHELLE,SPHEREX INC (2022-11-21),https://lens.org/169-382-576-409-841,Patent Application,yes,0,0,1,169-382-576-409-841,US,1,169-382-576-409-841,US,0,G06N5/04;;G06N5/04,G06N5/04,,0,0,,,,PENDING
54,CN,A,CN 119006635 A,087-566-102-276-42X,11/22/2024,2024,CN 202411112586 A,8/14/2024,CN 202411112586 A,8/14/2024,"Simple and safe visual generation prompt engineering method, equipment, medium and product","The invention discloses a simple and safe visual generation prompt engineering method, equipment, a medium and a product, and belongs to the technical field of visual generation. The method comprises the following steps: creating an original cue word set based on three public data sets; classifying the original cue word set and configuring an optimal camera for each category; performing camera description mapping on each original cue word in the original cue word set to generate an optimized cue word; and generating visual generation content based on comparison of the original cue word and the optimized cue word. According to the method, the optimal camera description is provided for different types of image cues, so that the problem that original contents are changed or unsafe factors are introduced into the cues is avoided; meanwhile, different generation models are used for visual generation, it can be more widely verified that optimization prompts can improve the generation quality in different dimensions, the consistency from texts to images is kept, and compared with other methods, higher prompt word safety is achieved.",UNIV ELECTRONIC SCI & TECH CHINA,REN FUJI;;CHENG WEIJIN;;DENG JIAWEN;;LIU JIANZHI,,https://lens.org/087-566-102-276-42X,Patent Application,no,0,0,1,087-566-102-276-42X,CN,1,087-566-102-276-42X,CN,0,G06T11/00;;G06V20/70;;G06F16/353;;G06N20/00;;Y02T10/40,G06T11/00;;G06F16/35;;G06N20/00;;G06V20/70,,0,0,,,,PENDING
55,US,A1,US 2025/0095185 A1,193-068-998-499-829,3/20/2025,2025,US 202318466970 A,9/14/2023,US 202318466970 A,9/14/2023,ARTIFICIAL INTELLIGENCE SMOOTHED OBJECT DETECTION AND TRACKING IN VIDEO,Methods and systems for object detection and tracking in video that use at least two different AI-assisted object detection algorithms. A first AI-assisted object detection algorithm selected to be used to detect an object in a video frame and determine a mask defining location of the object on the basis that the video frame is a keyframe. A second AI-assisted object detection algorithm may be used to track location of the mask in temporally subsequent frames until the next keyframe is detected.,SHOPIFY INC,PADGETT NEIL LEONARD;;MASCHMEYER RUSS;;FLORENZANO ERIC ANDREW;;LETKEMAN BRENNAN;;LEPP JAMES;;BELLO DIEGO MACARIO,SHOPIFY (USA) INC (2023-10-04);;SHOPIFY QUEBEC INC (2023-09-21);;SHOPIFY INC (2023-09-21),https://lens.org/193-068-998-499-829,Patent Application,yes,0,0,2,127-315-579-620-227;;193-068-998-499-829,US;;WO,2,127-315-579-620-227;;193-068-998-499-829,US;;WO,0,H04N19/159;;G06T7/20;;G06T7/70;;G06T2207/10016;;G06T2207/20084;;G06T2207/20081;;G06T7/70;;H04N19/159;;G06T7/20,G06T7/70;;G06T7/20;;H04N19/159,,0,0,,,,PENDING
56,US,B1,US 12182144 B1,136-601-029-797-355,12/31/2024,2024,US 202418774195 A,7/16/2024,US 202418774195 A,7/16/2024,Innovative disclosure document evaluation and compliance system and method,"In one or more implementations, a computer-implemented system and method are provided for assessing relevance and accuracy of confirmation documents with respect to disclosure materials associated with completed activity.",MORGAN STANLEY SERVICES GROUP INC,BEHERA ANSHUMAN;;EAPEN SUJIT;;DHAGAI VIDHAN;;HOTA DEBI;;PATIL SHRIKANT;;RAJANIGANDHA RAKA,MORGAN STANLEY SERVICES GROUP INC (2024-07-01),https://lens.org/136-601-029-797-355,Granted Patent,yes,0,0,1,136-601-029-797-355,US,1,136-601-029-797-355,US,0,G06F16/24578;;G06F16/24578,G06F16/2457,,0,0,,,,ACTIVE
57,CN,A,CN 119443246 A,021-490-497-498-656,2/14/2025,2025,CN 202411468381 A,10/21/2024,CN 202411468381 A,10/21/2024,Multi-modal landslide event entity extraction method,"The invention provides a multi-modal landslide event entity extraction method, which comprises the following steps of: firstly, constructing a landslide entity expression model taking'feature expression and relation expression 'as a core, and then, providing an instruction prompt driven cross-platform multi-modal landslide event data set construction method. And constructing a multi-modal landslide event data set. Then, a multi-modal landslide event entity extraction model based on prompt engineering is constructed, the model is based on the prompt engineering concept, deep understanding of the landslide event is achieved by fusing an instruction prompt statement set of structured knowledge, and finally comprehensive description of a landslide event entity is conducted through a classification fusion strategy. According to the invention, the problems of low landslide event data processing efficiency, low entity extraction accuracy, difficulty in multi-modal data fusion and the like in the prior art are effectively solved, and powerful support is provided for landslide disaster early warning and emergency management.",HUBEI PROVINCE NATURAL RESOURCES DEPT INFORMATION CENTER;;UNIV WUHAN,LI RUI;;LI JIANG;;LIU LEI;;SHEN YUN;;CHENG SI;;WANG JUNHAO,,https://lens.org/021-490-497-498-656,Patent Application,no,0,0,1,021-490-497-498-656,CN,1,021-490-497-498-656,CN,0,G06N5/025;;G06F18/24,G06N5/025;;G06F18/24,,0,0,,,,PENDING
58,US,A1,US 2024/0419702 A1,158-546-726-922-544,12/19/2024,2024,US 202418817441 A,8/28/2024,US 202418817441 A;;US 202218082745 A,12/16/2022,METHODS AND SYSTEMS FOR AUTOMATIC APPEAL AUTHORIZATION USING MACHINE LEARNING ALGORITHM,"Methods and systems for selecting a deep learning/machine learning model are described. In one embodiment, a plurality of models are optimized by addressing class imbalances among a first subset of records, each of the plurality of models are trained using the first subset of records, each of the plurality of models are implemented to predict a value of respective known target columns in each of a second subset of records, respective success rates for each of the plurality of models at predicting the respective known target columns for each of the second subset of records are determined, a first of the plurality of models having a highest success rate is selected, and the first of the plurality of models is implemented to decide a target column of a received authorization request based on predictor columns in the received authorization request.",EXPRESS SCRIPTS STRATEGIC DEV INC,ADABOINA MALLA REDDY;;KAUR RAMANDEEP,EXPRESS SCRIPTS STRATEGIC DEVELOPMENT INC (2024-08-27),https://lens.org/158-546-726-922-544,Patent Application,yes,0,0,1,158-546-726-922-544,US,3,054-549-969-242-706;;053-391-358-981-848;;158-546-726-922-544,US,0,G16H20/10;;G16H50/20;;G16H50/70;;G06F16/3329;;G06F16/3347;;G06Q40/08;;G16H40/20;;G16H70/40;;G06F16/3329;;G06Q40/08;;G06F16/3347,G06F16/332;;G06F16/33;;G06Q40/08,,0,0,,,,PENDING
59,US,A1,US 2025/0168198 A1,017-033-714-653-168,5/22/2025,2025,US 202418748461 A,6/20/2024,US 202418748461 A;;US 202363524296 P,6/30/2023,METHODS AND SYSTEMS FOR AI-DRIVEN POLICY GENERATION,"In one aspect, a method of an managing policies in a multi-cloud governance platform comprising: implementing AI-driven policy generation in the multi-cloud governance platform by: providing at least one large language model (LLM) with sufficient size to have near or better than human reasoning abilities as an emergent property of the LLM; providing a plurality of cloud-computing platform dynamically updated documentations; with the LLM, interpreting an existing policy of a cloud-computing platform as provided in the plurality of cloud-computing platform dynamically updated documentations; with the by the LLM, generating executable check, for a compliance with a policy of the cloud-computing platform; and with the LLM, creating and maintaining a plurality of resources or activities associated with the policy for at least one cloud instance of the cloud-computing platform.",TUCKER STEPHEN;;ARUMUGAM RATHINASABAPATHY;;CHANDRASHEKAR SRIDHAR,TUCKER STEPHEN;;ARUMUGAM RATHINASABAPATHY;;CHANDRASHEKAR SRIDHAR,,https://lens.org/017-033-714-653-168,Patent Application,yes,0,0,1,017-033-714-653-168,US,1,017-033-714-653-168,US,0,G06F40/30;;H04L63/20;;G06F40/30;;H04L63/20,H04L9/40;;G06F40/30,,0,0,,,,PENDING
60,CN,A,CN 118214932 A,044-395-173-308-229,6/18/2024,2024,CN 202410440770 A,4/12/2024,CN 202410440770 A,4/12/2024,Video information auxiliary creation method and creation system,"The invention discloses a video information auxiliary creation method and creation system, and relates to the technical field of auxiliary creation. The method comprises the following steps of 1, analyzing audio information and picture information by using a language model technology based on Prompt engineering; 2, generating titles, keywords, brief introductions and classifications by using a language model according to an analysis result, and filling video information needing to be uploaded with the titles, the keywords, the brief introductions and the classifications; and step 3, aiming at the characteristics of the website uploaded by the video, unifying the searching and recommending processes into rough calling, sorting and restructuring by using a searching and pushing integrated algorithm. According to the system, on the basis of traditional audio information and picture information, a set of process for automatically constructing video information by using a language large model through Prompt engineering is designed, corresponding content can be produced according to the style of a current hot platform, the video content putting convenience of a user is improved, and the user experience is improved. And the influence of the description capability on excellent video content delivery is reduced.",ZHEJIANG XINLAN NETWORK MEDIA CO LTD,LUO LIEYI;;HUANG JIQI;;REN YIBIN;;ZHAO YINGCHUAN;;CHEN TENGYANG;;CHENG SHAOXI;;GUO JUNNAN,,https://lens.org/044-395-173-308-229,Patent Application,no,0,0,1,044-395-173-308-229,CN,1,044-395-173-308-229,CN,0,H04N21/816;;H04N21/8153;;H04N21/8113;;G06F16/7867;;G06F16/75,H04N21/81;;G06F16/75;;G06F16/78,,0,0,,,,PENDING
61,CN,A,CN 117390153 A,184-670-127-249-82X,1/12/2024,2024,CN 202311305240 A,10/10/2023,CN 202311305240 A,10/10/2023,Session content analysis method and device applied to customer service system and storage medium,"The invention relates to a session content analysis method and device applied to a customer service system, computer equipment and a storage medium. The method comprises the following steps: receiving session content of a user terminal; based on a large language model and a prompt engineering technology, any one of flow guide analysis, knowledge guide analysis and work order tutoring analysis is carried out on the session content, and based on an analysis result, recommended content is displayed on a front-end page of the customer service system; and any one of intention detection, emotion detection and customer service quality detection is performed based on the context of the session content, and a detection result is displayed on a front-end page of the customer service system. According to the method, multi-item analysis guidance and multi-item detection can be carried out on the session content of the customer service system by fully utilizing a large language model and a prompt engineering technology, the recommended content and the detection result are displayed on the front-end page of the customer service system, and intelligent customer analysis service is provided for the customer service system.",SHANGHAI SHUHE INFORMATION TECH CO LTD,LI PENGFEI,,https://lens.org/184-670-127-249-82X,Patent Application,no,0,1,1,184-670-127-249-82X,CN,1,184-670-127-249-82X,CN,0,G06F16/3329;;G06Q30/0613;;G06F40/30;;G06Q30/0631;;G10L15/22,G06F16/332;;G06F40/30;;G06Q30/0601;;G10L15/22,,0,0,,,,PENDING
62,US,A1,US 2025/0095096 A1,151-520-477-967-433,3/20/2025,2025,US 202418885192 A,9/13/2024,US 202418885192 A;;US 202363538760 P,9/15/2023,OFFICER-IN-THE-LOOP CRIME REPORT GENERATION USING LARGE LANGUAGE MODELS AND PROMPT ENGINEERING,"The present disclosure relates to utilizing large language models (LLMs) to facilitate generation of incident reports or similar documents. One or more initial inputs may be received from a user, and one or more example incident reports may be identified. The one or more example incident reports and the one or more initial inputs may be sent to an LLM. A reviewable version of an incident report may be accessed that is based on output that the LLM generated based on the example incident reports and the one or more initial inputs. The reviewable version of the incident report may be presented in a human readable format via a graphical user interface (GUI). A modification corresponding to the reviewable version of the incident report may be received via the GUI. The modification and the reviewable version of the incident report may be sent to the LLM to cause the LLM to generate an updated version of the incident report.",ORACLE INT CORP,ZADEH IMAN;;GERARD CHRISTOPHE J;;QIN QIU;;YE ZIQUN;;BANERJEE ADITYA;;QIAN JUN;;HESS NICOLE E,ORACLE INTERNATIONAL CORPORATION (2024-09-13),https://lens.org/151-520-477-967-433,Patent Application,yes,0,0,1,151-520-477-967-433,US,1,151-520-477-967-433,US,0,G06Q50/265;;G06F40/40;;G06F40/197;;G06F40/30;;G06F40/56;;G06Q50/265;;G06F40/40;;G06F40/197,G06Q50/26;;G06F40/197;;G06F40/40,,0,0,,,,PENDING
63,CN,A,CN 119783655 A,142-301-844-929-441,4/8/2025,2025,CN 202411848216 A,12/16/2024,CN 202411848216 A,12/16/2024,Similar law judgment document matching method based on prompt engineering and judgment prediction,"The invention discloses a similar law judgment document matching method based on prompt engineering and judgment prediction, belongs to the field of text matching, aims to solve the problem of inaccurate case matching in case retrieval of law case handling personnel, and is characterized by comprising the following steps: S10, acquiring a training data set; wherein the data set comprises case serial numbers, judgment texts and legal elements; s20, training a class case matching model by using the training data set, wherein the class case matching model comprises a plurality of Bert models sharing weights; wherein the class case matching model is trained by adopting a joint learning method; and S30, performing similarity prediction on the judgment text contents of a plurality of input judgment documents by using the trained class case matching model.",UNIV DALIAN TECH,SUN YUANYUAN;;LI WENWEI,,https://lens.org/142-301-844-929-441,Patent Application,no,0,1,1,142-301-844-929-441,CN,1,142-301-844-929-441,CN,0,,G06F40/194;;G06F18/22;;G06F40/211;;G06F40/284;;G06F40/30;;G06Q50/18,,0,0,,,,PENDING
64,CN,A,CN 117456183 A,058-404-951-839-908,1/26/2024,2024,CN 202311467948 A,11/7/2023,CN 202311467948 A,11/7/2023,Medical image segmentation method based on multi-level feature extraction and attention mechanism fusion,"The invention discloses a medical image segmentation method based on multi-level feature extraction and an attention mechanism, and the method comprises the steps: constructing a multi-type medical image data set coding process, carrying out the manual marking of a medical image, and inserting an extra training layer for feature extraction; a generated feature extraction data set is obtained and is embedded into convolution processing, and global analysis is carried out by using an attention mechanism; performing prompt engineering processing according to sparse prompt in the image, and performing contrast learning and training alignment by using CLIP and ALIGN algorithms; a data set of prompt engineering and convolution processing is obtained for attention mechanism processing, and self-attention and cross-attention of tokens can be carried out; according to the activation function and optimizer accelerated medical image detection method, an optimizer and a new activation function module are introduced, and the model detection speed is increased. According to the embodiment of the invention, the medical image segmentation detection model with high accuracy and wide application range can be efficiently trained, and the efficiency of medical image segmentation detection is improved.",GUANGZHOU HUOLANG MEDICAL TECH CO LTD,ZHANG LI;;NA YANG-HEUM;;LIN JING,,https://lens.org/058-404-951-839-908,Patent Application,no,0,4,1,058-404-951-839-908,CN,1,058-404-951-839-908,CN,0,G06V10/26;;G06V10/764;;G06V10/774;;G06V10/7715;;G06V10/806;;G06V10/82,G06V10/26;;G06V10/764;;G06V10/77;;G06V10/774;;G06V10/80;;G06V10/82,,0,0,,,,PENDING
65,KR,B1,KR 102613358 B1,011-811-549-519-749,12/13/2023,2023,KR 20230061179 A,5/11/2023,KR 20230061179 A,5/11/2023,APPARATUS AND METHOD FOR BUILDING ATTRIBUTE DATA USING MULTI PERSONA,"The present invention provides a device and method for constructing attribute data using multi-persona which processes and constructs data so as to provide an optimal response to a prompt input in order to improve the prompt engineering performance of an interactive artificial intelligence system. The device for constructing attribute data using multi-persona includes: a data collection unit (110) which collects arbitrary customer data from an administrator terminal (1000) or a database (2000); a data analysis unit (120) that generates a plurality of cluster data through clustering based on vector location coordinate values of vectorized characteristic data; a persona setting unit (130) that extracts keywords of cluster data, extracts clustering attributes of cluster data corresponding to the extracted keywords as text data, and sets the extracted text data as a persona of the corresponding cluster data; and an attribute construction unit (140) that matches the generated metadata and customer attribute data with the customer data and stores them. The present invention can provide an optimal response to a prompt input in order to improve the prompt engineering performance of an interactive artificial intelligence system.",AGILESODA INC,CHOI KEON WOO;;KIM CHAE JEONG;;JEONG HYO YONG,,https://lens.org/011-811-549-519-749,Granted Patent,no,5,1,1,011-811-549-519-749,KR,1,011-811-549-519-749,KR,0,,G06F16/9535;;G06F16/332;;G06F16/901;;G06F16/9032;;G06F16/9035;;G06F16/906,,0,0,,,,ACTIVE
66,CN,A,CN 117079809 A,169-399-492-856-362,11/17/2023,2023,CN 202311351953 A,10/19/2023,CN 202311351953 A,10/19/2023,"Method, system and equipment for constructing medical guide scene assistant based on generative model","The invention provides a method and a system for constructing a medical guide scene assistant based on a generative model, a method for performing intelligent hospital guide by using the medical guide scene assistant, electronic equipment and a storage medium, and relates to the technical field of artificial intelligence. According to the method for constructing the medical guide scene assistant based on the generative model, a prompt engineering template for interactive medical guide is developed based on medical guide path information and the generative model; medical guide reasoning control logic is established based on the medical guide path information; and constructing a medical guide scene assistant by combining the generative model, the prompt engineering template and the medical guide reasoning control logic. The medical guide scene assistant constructed in the embodiment guides the user to provide more description information of diseases and/or symptoms, and more accurate information for medical guide is collected; meanwhile, the medical guide service has very high medical specialty, the precision of the medical guide process is achieved in a mode of combining medical guide reasoning control logic and a generative model in the aspect of medical specialty information, and the purpose of efficient and accurate medical guide is achieved.",CHINA MERCHANTS XINNUO HEALTH MAN CO LTD,WAN BIJUN;;ZHANG YAZHOU;;SUN JIANLI,,https://lens.org/169-399-492-856-362,Patent Application,no,6,2,2,169-399-492-856-362;;175-595-533-940-655,CN,2,169-399-492-856-362;;175-595-533-940-655,CN,0,G16H50/20;;G06N5/04;;G06N7/02;;G06F40/186;;G16H40/20;;Y02A90/10,G16H50/20;;G06F40/186;;G06N5/04;;G06N7/02;;G16H40/20,,4,1,160-097-308-354-08X,37071280;;10.1007/s10439-023-03206-0,"YONGBIN HE: ""“Will ChatGPT/GPT‑4 be a Lighthouse to Guide Spinal Surgeons?”"", 《BMES》;;吴英华 等: ""“迈入人工智能新时代: ChatGPT 在智慧医疗应用场 景研究与思考”"", 《数据通信》, no. 4;;柳庆莉: ""“背景信息辅助SEQ2SEQ导医台自动问答系统”"", 《知网硕士电子期刊》, no. 1;;王永鹏: ""“基于深度学习的智能导诊系统的设计与实现”"", 《知网硕士电子期刊》, no. 8",ACTIVE
67,CN,A,CN 118505652 A,054-126-664-295-394,8/16/2024,2024,CN 202410651059 A,5/24/2024,CN 202410651059 A,5/24/2024,Panoramic film decayed tooth segmentation method based on prompt engineering and thinking chain reasoning technology,"The invention discloses a panoramic film decayed tooth segmentation method based on prompt engineering and a thinking chain reasoning technology, and the method comprises the steps: firstly obtaining the structural segmentation data of a tooth panoramic film, and carrying out the preprocessing, and obtaining the thinking chain data; secondly, constructing a panoramic film decayed tooth segmentation network model, wherein the panoramic film decayed tooth segmentation network model comprises an image encoder, a prompt encoder and a mask decoder which are sequentially constructed; and inputting the thinking chain data into the panoramic film decayed tooth segmentation network model to obtain a segmentation result, designing a loss function, carrying out reverse training, and optimizing parameters of the panoramic film decayed tooth segmentation network model. And finally, predicting a panoramic film decayed tooth segmentation result by using the trained panoramic film decayed tooth segmentation network model. According to the method, complex tasks are decoupled, step-by-step reasoning of the model is realized by using prompt engineering and thinking chain reasoning technologies, and the visual segmentation model is guided to perform accurate segmentation.",UNIV HANGZHOU DIANZI,LI JINHUI;;ZHU SUGUO;;YU JUN,,https://lens.org/054-126-664-295-394,Patent Application,no,0,1,1,054-126-664-295-394,CN,1,054-126-664-295-394,CN,0,G06T7/0012;;G06T7/11;;G06N5/04;;G06N3/084;;G06T2207/30036;;G06T2207/20081;;G06T2207/20084,G06T7/00;;G06N3/084;;G06N5/04;;G06T7/11,,0,0,,,,PENDING
68,WO,A9,WO 2024/205919 A9,127-722-322-663-094,3/6/2025,2025,US 2024/0019820 W,3/14/2024,US 202363493594 P;;US 202318326666 A,3/31/2023,ADAPTING FOUNDATION MODELS FOR INFORMATION SYNTHESIS OF WIRELESS COMMUNICATION SPECIFICATIONS,"Existing approaches to understanding, developing, and researching modern wireless communication technologies involve time intensive and arduous processes of sifting through numerous webpages and technical specification documents, gathering the required information and synthesizing it. The present disclosure describes a conversational artificial intelligence tool for information synthesis of wireless communication specifications. The system builds on recent advancements in foundation large language models (LLMs) and consists of three key additional components: a domain-specific database, a context extractor, and a feedback mechanism. The system appends user queries with concise contextual information extracted from a database of wireless technical specifications and incorporates tools for expert feedback and data contribution. On evaluation using a benchmark dataset of expert queries and responses, the system provided more relevant and accurate answers on topics related to modern wireless communication specifications with a BLEU (BiLingual Evaluation Understudy) score of 0.28 compared to 0.03 achieved by current state-of-the-art LLM-based systems.",MICROSOFT TECHNOLOGY LICENSING LLC,KOTARU MANIKANTA,,https://lens.org/127-722-322-663-094,Search Report,yes,0,0,2,025-131-786-876-474;;127-722-322-663-094,WO,3,025-131-786-876-474;;039-526-187-790-454;;127-722-322-663-094,US;;WO,0,G06F16/3329;;G06F40/30,G06F16/332;;G06F40/30,,0,0,,,,PENDING
69,US,A1,US 2025/0156288 A1,162-061-843-156-26X,5/15/2025,2025,US 202418440713 A,2/13/2024,US 202418440713 A;;US 202363599362 P,11/15/2023,PROTOCOL TESTING USING LARGE LANGUAGE MODELS,"The present disclosure relates to utilizing resources provided by large language models (LLMs) to generate models to be used in model-based testing of a variety of protocols. In particular, systems described herein utilize a vasty body of protocol knowledge defined in RFCs and standards, networking forums, blogs, and other online resources and documents to extract this knowledge in generating models that can be used for testing one or more components of a variety of protocols. The features and functionalities described herein provide a framework for utilizing LLMs to generate a protocol model while providing constraints for a harness (e.g., a symbolic harness) that will guide a symbolic execution engine in generating any number of protocol tests that may be used in determining whether a given application, hardware, and/or software implementation will perform as designed for a given protocol.",MICROSOFT TECHNOLOGY LICENSING LLC,KAKARLA SIVA KESAVA REDDY;;BECKETT RYAN ANDREW,MICROSOFT TECHNOLOGY LICENSING LLC (2024-02-09),https://lens.org/162-061-843-156-26X,Patent Application,yes,2,0,1,162-061-843-156-26X,US,1,162-061-843-156-26X,US,0,G06F11/28;;G06F11/28,G06F11/28,,2,1,109-989-647-556-166,10.1109/tse.2014.2323977,"K. Kanazawa. ""Prompt Engineering Learn how to use AI models with prompt engineering"". Blog post [online]. Microsoft Corporation, 25 June, 2022. Retrieved from the Internet: <URL:https://web.archive.org/web/20220625141111/https://microsoft.github.io/prompt-engineering/> (Year: 2022);;J. Song, C. Cadar and P. Pietzuch, ""SymbexNet: Testing Network Protocol Implementations with Symbolic Execution and Rule-Based Specifications,"" in IEEE Transactions on Software Engineering, vol. 40, no. 7, pp. 695-709, 1 July 2014, doi: 10.1109/TSE.2014.2323977. (Year: 2014)",PENDING
70,EP,A1,EP 4524709 A1,022-475-899-575-31X,3/19/2025,2025,EP 23198068 A,9/18/2023,EP 23198068 A,9/18/2023,COMPUTER-IMPLEMENTED METHOD OF GENERATING IMAGES FOR PRODUCT DESIGN,"The disclosed method and apparatus offer a mostly visual approach through an intuitive graphical user interface, e. g. presented in a web browser, that can be implemented with latent diffusion models. It presents a seemingly endless feed of images to the user that are pre-generated as variations from existing images with a fine-tuned model, also ensuring technical requirements by prompt engineering. The users select images from the feed to work on in boards, especially by successively generating new images (12) that resemble a first image (10) and a second image (11). The resemblance can be steered with a control element (9) (cf. Fig. 5 and Fig. 6). The resulting paths of modifications can be modified and re-used and consistently track and visualize the design process. Collaboration of many users is possible as well as the tailoring to preferences, such as corporate identities.",CRE[AI]TION GMBH,DORNDORF NIK;;LIMM MARCO;;SCHÜTZ MARC,,https://lens.org/022-475-899-575-31X,Patent Application,yes,2,0,1,022-475-899-575-31X,EP,1,022-475-899-575-31X,EP,0,G06F30/17;;G06F30/12;;G06F2111/20;;G06F2111/16;;G06F3/04845;;G06F2113/12;;G06F30/27,G06F3/04845;;G06F30/12;;G06F30/17;;G06F30/27;;G06F111/16;;G06F111/20;;G06F113/12,,9,4,088-212-506-091-278;;078-499-617-647-812;;091-925-670-210-249;;095-227-728-605-081,10.1145/3544548.3581377;;10.1109/iccv51070.2023.02138;;10.1111/cgf.13552;;10.1145/3478513.3480537,"WU DI ET AL: ""StyleMe: Towards Intelligent Fashion Generation with Designer Style"", PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, ACMPUB27, NEW YORK, NY, USA, 19 April 2023 (2023-04-19), pages 1 - 16, XP059018721, ISBN: 978-1-4503-9422-2, DOI: 10.1145/3544548.3581377;;ALBERTO BALDRATI ET AL: ""Multimodal Garment Designer: Human-Centric Latent Diffusion Models for Fashion Image Editing"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 23 August 2023 (2023-08-23), XP091586207;;CUI Y R ET AL: ""FashionGAN: Display your fashion design using Conditional Generative Adversarial Nets"", COMPUTER GRAPHICS FORUM : JOURNAL OF THE EUROPEAN ASSOCIATION FOR COMPUTER GRAPHICS, WILEY-BLACKWELL, OXFORD, vol. 37, no. 7, 24 October 2018 (2018-10-24), pages 109 - 119, XP071489436, ISSN: 0167-7055, DOI: 10.1111/CGF.13552;;ZHU PEIHAO PEIHAO ZHU@KAUST EDU SA ET AL: ""Barbershop"", ACM TRANSACTIONS ON GRAPHICS, ACM, NY, US, vol. 40, no. 6, 10 December 2021 (2021-12-10), pages 1 - 13, XP058659762, ISSN: 0730-0301, DOI: 10.1145/3478513.3480537;;YANG, LING ET AL., DIFFUSION MODELS: A COMPREHENSIVE SURVEY OF METHODS AND APPLICATIONS, March 2023 (2023-03-01), Retrieved from the Internet <URL:https://arxiv.org/pdf/2209.00796.pdf>;;PODELL, DUSTIN ET AL., SDXL: IMPROVING LATENT DIFFUSION MODELS FOR HIGH-RESOLUTION IMAGE SYNTHESIS, July 2023 (2023-07-01), Retrieved from the Internet <URL:https://arxiv.org/pdf/2307.01952.pdf>;;ROMBACH, ROBIN ET AL., HIGH-RESOLUTION IMAGE SYNTHESIS WITH LATENT DIFFUSION MODELS, July 2022 (2022-07-01), Retrieved from the Internet <URL:https://arxiv.org/pdf/2112.10752.pdf>;;HO, JONATHAN ET AL., DENOISING DIFFUSION PROBABILISTIC MODELS, December 2020 (2020-12-01), Retrieved from the Internet <URL:https://arxiv.org/pdf/2006.11239.pdf>;;META AL, SEGMENT ANYTHING MODEL, Retrieved from the Internet <URL:https://segment-anything.com/>",PENDING
71,WO,A1,WO 2024/215543 A1,170-004-117-908-702,10/17/2024,2024,US 2024/0022904 W,4/4/2024,US 202318299842 A,4/13/2023,DYNAMIC CONSTRUCTION OF LARGE LANGUAGE MODEL PROMPTS,"Example solutions for reducing the likelihood of hallucinations by language models, such as large language models (LLMs) are disclosed. By injecting a sufficient range and quantity of curated factual data into a prompt, the likelihood of a hallucination by an LLM may be reduced. This enables language models to be used in a wider range of settings, in which fabrication of facts is problematic, while reducing the need for a human to carefully check the generated text for accuracy. Examples include: generating a summary of a transcript using a summarization model; extracting topic-specific data from stored data using a scoring model; dynamically generating a language model prompt using the topic-specific data and the summary; and generating an output text using a language model and the language model prompt.",MICROSOFT TECHNOLOGY LICENSING LLC,ASI ABED EL KADER;;TSVETKOV ALEXANDER;;RONEN ROYI;;KUPER YARIN;;KEREN SHAHAR ZVI;;EISENSTADT ROY,,https://lens.org/170-004-117-908-702,Patent Application,yes,2,0,2,170-004-117-908-702;;108-344-570-416-282,US;;WO,2,170-004-117-908-702;;108-344-570-416-282,US;;WO,0,G06F40/30;;G06N20/00;;G10L15/26;;G06F40/56;;G06F40/166;;G06F40/40,G06F40/56;;G06F40/30;;G06N20/00,,1,0,,,"COBUS GREYLING: ""Preventing LLM Hallucination With Contextual Prompt Engineering - An Example From OpenAI"", 10 January 2023 (2023-01-10), XP093172839, Retrieved from the Internet <URL:https://cobusgreyling.medium.com/preventing-llm-hallucination-with-contextual-prompt-engineering-an-example-from-openai-7e7d58736162> [retrieved on 20240610]",PENDING
72,US,A1,US 2025/0131853 A1,043-037-123-715-68X,4/24/2025,2025,US 202418906573 A,10/4/2024,IN 202331071327 A,10/19/2023,"SYSTEM AND METHOD FOR AIRWAY MANAGEMENT TRAINING USING SMART MANIKINS, AUGMENTED REALITY AND ADAPTIVE LEARNING","The present invention provides a system for Airway Management training for healthcare professionals comprising a manikin having a head, a trachea, an esophagus, a pair of lungs and a stomach. The manikin also has endotracheal implements and is operatively connected to a family of sensors at one end and to an electronic controller device at the other end. The controller device is connected to a cloud server and a graphic user interface is connected to the system. The system has an Artificial Intelligence module, for processing the data collected by the controller device and sent to the cloud server instantaneously. The Artificial Intelligence module is for deriving relevant and useful insights as well as for personalizing the feedback and generating an Augmented reality effect in the user's Graphic Interface. This module is optimally distributed over the cloud server and the controller device.",MEDTRAINAI TECH PRIVATE LIMITED,BANERJEE NILABHRA,MEDTRAINAI TECHNOLOGIES PRIVATE LIMITED (2024-10-02),https://lens.org/043-037-123-715-68X,Patent Application,yes,0,0,4,150-418-708-291-26X;;155-233-363-612-187;;062-065-314-553-414;;043-037-123-715-68X,US;;GB;;JP,4,150-418-708-291-26X;;155-233-363-612-187;;062-065-314-553-414;;043-037-123-715-68X,US;;GB;;JP,0,G09B23/288;;G09B23/30;;G06F3/011;;G06N3/044;;G09B23/285;;G09B23/28;;G09B23/285;;G09B23/288;;G09B23/30;;G09B23/288;;G06N3/044;;G06F3/011;;G09B23/30,G09B23/28;;G06F3/01;;G06N3/044;;G09B23/30,,0,0,,,,PENDING
73,WO,A1,WO 2025/159896 A1,100-282-363-037-085,7/31/2025,2025,US US2025/010616,1/7/2025,"US 63/6/025,840",1/26/2024,SYSTEMS AND METHODS FOR GOAL-DRIVEN JOURNEY GENERATION USING ARTIFICIAL INTELLIGENCE,"Systems and methods for providing omnichannel cognition in a campaign are disclosed. An example platform can include a strategy hub configured to generate and provide a unified and real-time graphical interactive interface displaying an effectiveness of the campaign, wherein the strategy hub is further configured to allow users to dynamically connect strategies to tactics and track key performance indicators (KPIs) while making real-time adjustments and rebalancing of efforts across multiple channels to optimize campaign engagement; a tactic engine configured to utilize a generative artificial intelligence (GenAI) model for analysis and restacking of the tactics to generate an optimal tactic mix that improves engagement efficiency and outcomes based on predicted impact levels of the tactics; and an impact simulator configured to provide a virtual platform for simulating the campaign through virtual trials, to assess an effectiveness of the campaign prior to roll-out of the campaign.","AKTANA, INC.","SCHNEIDER, Diana;;PATI, Debabrata;;BEN-OR, Pinchas;;CHOY, Derek;;DHANUSHKODI, Satya;;FLAX, Jeremy",,https://lens.org/100-282-363-037-085,Patent Application,yes,0,0,1,100-282-363-037-085,WO,1,100-282-363-037-085,WO,0,,G06Q30/0242;;G16H50/20;;G06N20/00;;G06Q10/04;;G06Q10/0637;;G06N5/04,,0,0,,,,UNKNOWN
74,WO,A1,WO 2025/096500 A1,061-185-500-874-692,5/8/2025,2025,US 2024/0053505 W,10/30/2024,US 202363594675 P,10/31/2023,ARTIFICIAL INTELLIGENCE SYSTEMS AND METHODS FOR SECURING A PHARMACEUTICAL THERAPY,The present disclosure relates to using an artificial intelligence to assist a user in structuring a pharmaceutical distribution agreement. An artificial intelligence engine incorporating generative artificial intelligence can process user-driven queries in combination with proprietary and third party models and data to provide a response that can suggest an improvement to a computer-executable pharmaceutical distribution model. The artificial intelligence engine can be trained on both real world and simulation data for pharmaceutical distribution agreements.,PHARMACCX INC;;KLIPPEL ALEXANDER,KLIPPEL ALEXANDER;;BOSKEY COLE;;RICE PETER,,https://lens.org/061-185-500-874-692,Patent Application,yes,6,0,1,061-185-500-874-692,WO,1,061-185-500-874-692,WO,0,G06N3/00;;G06Q30/0206;;G06Q10/06375;;G06Q10/067;;G16H20/10;;G16H50/20;;G16H50/70;;G16H40/20,G06N3/00;;G06Q30/00;;G06Q50/00;;G16H20/00,,0,0,,,,PENDING
75,US,A1,US 2025/0196363 A1,133-564-302-681-013,6/19/2025,2025,US 202418976276 A,12/10/2024,EP 23216146 A,12/13/2023,LLM driven multimodal human-robot interaction planning,"A computer-implemented method for controlling a robot collaborating with a human in an environment of the robot comprises: obtaining, by at least one sensor, multimodal information on the environment of the robot including information on a human acting in the environment; converting, by a first converter, the obtained multimodal information into text information; estimating, by an intent estimator, an intent of the human based on the text information; determining, by a state estimator, a current state of the environment including the human based on the text information; planning, by a behavior planner, based on the current state of the environment and the estimated intent of the human, a behavior of the robot including at least one multimodal interaction output for execution by the robot, and generating control information including text information on the at least one multimodal interaction output; converting, by a second translator, the generated text information into multimodal actuator control information; and controlling at least one actuator of the robot based on the multimodal actuator control information.",HONDA MOTOR CO LTD,WANG CHAO;;GIENGER MICHAEL;;JOUBLIN FRANK;;CERAVOLA ANTONIO,HONDA MOTOR CO. LTD (2024-11-12),https://lens.org/133-564-302-681-013,Patent Application,yes,0,0,2,115-667-998-962-014;;133-564-302-681-013,US;;EP,2,115-667-998-962-014;;133-564-302-681-013,US;;EP,0,G05B2219/40202;;B25J9/1661;;G05B2219/40393;;G06F40/30;;G06F40/35;;B25J9/163;;B25J9/1653;;B25J9/1661;;B25J9/1697;;B25J11/0005,B25J11/00;;B25J9/16,,0,0,,,,PENDING
76,KR,B1,KR 102694794 B1,037-974-838-201-438,8/16/2024,2024,KR 20240088157 A,7/4/2024,KR 20240088157 A,7/4/2024,RAG - QUESTION-AND-ANSWER SYSTEM SERVER AND OPERATION METHOD FOR GENERATING ANSWER TO USER QUESTION BASED ON RAG TECHNIQUE,"질문-답변 서버가 RAG(Retrieval-Augmented Generation) 기술을 기반으로 사용자 질문에 대한 답변을 생성하는 방법은, 텍스트 변환된 사용자 질문을 로봇으로부터 수신하는 단계; 상기 사용자 질문에 기반하여 LLM(Large Language Model) 모듈에 대한 제1 프롬프트(prompt)를 생성하는 단계; 상기 제1 프롬프트를 상기 LLM 모듈에 입력하여, 상기 사용자 질문에 대한 제1 응답을 획득하는 단계; 상기 사용자 질문을 서치엔진(search engine)에 입력하여, 상기 사용자 질문의 맥락정보를 획득하는 단계; 상기 사용자 질문, 상기 제1 응답 및 상기 맥락정보에 기반하여, 상기 LLM 모듈에 대한 제2 프롬프트를 생성하는 단계; 상기 제2 프롬프트, 상기 사용자 질문, 상기 맥락정보 및 상기 제1 응답을 상기 LLM 모듈에 입력하여, 상기 사용자 질문에 대한 제2 응답을 획득하는 단계; 상기 제2 응답이 신뢰성이 있다고 판단되는 경우, 상기 제2 응답을 상기 사용자 질문에 대한 답변으로 결정하는 단계; 및 상기 답변을 상기 로봇에 전송하는 단계를 포함하되, 상기 제2 프롬프트는, 상기 제1 응답과 상기 맥락정보의 유사 여부를 판단하고, 상기 유사 여부에 기반하여 상기 제2 응답을 생성하라는 요청을 포함하고, 상기 제2 응답의 신뢰성 여부는, 상기 사용자 질문을 상기 서치엔진에 입력한 후 상기 맥락정보를 획득하는 데 소요된 시간에 기반하여 결정될 수 있다.",IBTECH CO LTD,KIM JINWOO,,https://lens.org/037-974-838-201-438,Granted Patent,no,2,9,1,037-974-838-201-438,KR,1,037-974-838-201-438,KR,0,,G06F16/33;;G06F16/31;;G06F16/332;;G06F16/338;;G06F40/205;;G06F40/237;;G06F40/279;;G06F40/30;;G06V30/413;;G10L15/26;;H04L51/02,,1,0,,,Prompt Engineering: Retrieval Augmented Generation(2023.07.24.),ACTIVE
77,WO,A1,WO 2025/160486 A1,095-037-361-114-448,7/31/2025,2025,US US2025/013063,1/25/2025,"US 63/6/025,060;;US 63/6/038,700",1/25/2024,COMPUTER-BASED TECHNIQUES TO SUPPORT OPERATING AND MAINTAINING COMPLEX ENTITIES,"Various embodiments described hereby include computer-based tools and techniques to support operating and maintaining complex entities composed of diverse and independently operated functional components (e.g., equipment/devices). For example, the computer-based tools and techniques may be utilized to support operating and maintaining a yacht as well as functional components included in a yacht. Many of the computer-based tools and techniques disclosed hereby leverage one or more of relational data structures, digital representations, artificial intelligence, and prompt engineering to improve aspects of operating and maintaining complex entities.","CARROLL, James Porter",,,https://lens.org/095-037-361-114-448,Patent Application,yes,0,0,1,095-037-361-114-448,WO,1,095-037-361-114-448,WO,0,,G06F16/28;;G06F3/0481;;G06F16/33;;G06F40/186;;G06F40/295;;G06F40/30;;G06N3/08;;G06N20/00,,0,0,,,,UNKNOWN
78,WO,A1,WO 2024/238928 A1,142-958-897-749-635,11/21/2024,2024,US 2024/0029958 W,5/17/2024,US 202363503031 P,5/18/2023,PRIVATE ARTIFICIAL INTELLIGENCE (AI) SEARCHING ON A DATABASE USING A LARGE LANGUAGE MODEL,"A system may receive, via an input field on a chat interface of a computing device, a user query. A system may retrieve, from a vector database, a private data portion that is responsive to the user query. A system may transmit a prompt to a large language model, where the prompt includes the user query and the private data portion. A system may receive, from the large language model, a model response with textual data that responds to the user query, where the textual data is generated by the large language model using the private data portion. A system may initiate display of the model response in the chat interface.",ELASTICSEARCH INC,ERICKSON DAVID,,https://lens.org/142-958-897-749-635,Patent Application,yes,0,0,2,138-357-371-688-710;;142-958-897-749-635,US;;WO,2,138-357-371-688-710;;142-958-897-749-635,US;;WO,0,G06F16/3329;;G06F21/6245;;G06F16/3329,G06F16/332;;G06F21/00,,2,0,,,"LILIAN WENG: ""Prompt Engineering | Lil'Log"", 15 March 2023 (2023-03-15), XP093187033, Retrieved from the Internet <URL:https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/> [retrieved on 20240717];;SIMRAN ARORA ET AL: ""Can Foundation Models Help Us Achieve Perfect Secrecy?"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 8 January 2023 (2023-01-08), XP091409531",PENDING
79,US,A1,US 2025/0238087 A1,198-119-557-299-417,7/24/2025,2025,US 202418419881 A,1/23/2024,US 202418419881 A,1/23/2024,SYSTEMS AND METHODS OF MULTIMODAL USER INTERFACE AUTOMATION,"Systems and methods provide user interface (UI) automation for multiple types of devices and applications. A computing device stores an objective for automated manipulation of a UI of a user device and conducts an iterative sequence to achieve the objective. The iterative sequence includes capturing current state information of the UI, wherein the current state information includes text and an image of the UI; sending multimodal input to a generative artificial intelligence (AI) system, wherein the multimodal input includes the image of the UI, a text prompt, and the objective; receiving, from the AI system, a predicted next action for the UI based on the multimodal input; initiating a programmatic action to implement the predicted next action on the UI; and recording the programmatic action. The computing device generates, based on the iterative sequence, a UI automation model associated with achieving the objective on the UI.",VERIZON PATENT AND LICENSING INC,PERKINS KEVIN,,https://lens.org/198-119-557-299-417,Patent Application,yes,0,0,1,198-119-557-299-417,US,1,198-119-557-299-417,US,0,G06F3/0237;;G06F40/174;;G06F3/0482,G06F3/023;;G06F3/0482;;G06F40/174,,0,0,,,,PENDING
80,WO,A1,WO 2025/011236 A1,034-944-423-621-119,1/16/2025,2025,CN 2024097982 W,6/7/2024,CN 202310834417 A,7/7/2023,"AUDIENCE SELECTION METHOD AND APPARATUS, DEVICE, AND STORAGE MEDIUM","Embodiments of the present application relate to the technical field of computers, and provide an audience selection method and apparatus, an electronic device, and a computer-readable storage medium. The method comprises: inputting first information into prompt engineering to construct first data, wherein the first information is related to an operational issue, and the first data comprises issue features, user features and data features; inputting the first data into a pre-trained large language model (LLM) to obtain a first index and a corresponding dimension; and on the basis of the first index, the dimension, and data corresponding to the dimension, performing a greedy algorithm to obtain an audience. The embodiments of the present application achieve the objective of improving the accuracy and efficiency of audience selection.",BEIJING DIPEAK TECH CO LTD,HE CHANGHUA;;ZHANG GUOXIAN;;ZHANG LEI,,https://lens.org/034-944-423-621-119,Patent Application,yes,6,0,3,007-467-918-860-826;;034-944-423-621-119;;103-682-523-572-127,WO;;CN,3,007-467-918-860-826;;034-944-423-621-119;;103-682-523-572-127,WO;;CN,0,G06F18/2193;;G06F40/216;;G06Q10/10;;G06Q30/0201;;G06N20/00,G06F18/21,,0,0,,,,PENDING
81,CN,A,CN 118013954 A,052-021-048-415-248,5/10/2024,2024,CN 202410211927 A,2/26/2024,CN 202410211927 A,2/26/2024,Emergency plan structured disassembly method and device based on large language model,"The invention relates to the technical field of emergency plans, and discloses an emergency plan structured disassembly method and device based on a large language model, and the method comprises the steps: receiving an emergency plan text of this round and a structured disassembly prompt template of this round; the emergency plan text of the round and the structured disassembly prompt template of the round are combined, and a combined result is used as input to be provided for the large language model; and obtaining an emergency plan structured disassembly result based on the large language model. Through a large language model and a prompt engineering technology, specific knowledge and information in the emergency plan are efficiently and accurately extracted, and a corresponding result is output.",STATE GRID SMART GRID RES INSTITUTE CO LTD;;STATE GRID GANSU ELECTRIC POWER CO ELECTRIC POWER RES INST,LIU ZEYU;;ZHAO JINXIONG;;ZHANG ZEHAO;;MA HONGZHONG;;MA ZHICHENG;;FENG JIE;;SEO HEE-WON;;YU ZHEN;;GUAN CHENG;;MI XINHE,,https://lens.org/052-021-048-415-248,Patent Application,no,0,0,1,052-021-048-415-248,CN,1,052-021-048-415-248,CN,0,G06F40/205;;G06F40/186;;G06N20/00,G06F40/205;;G06F40/186;;G06N20/00,,0,0,,,,PENDING
82,KR,B1,KR 102666247 B1,179-398-142-096-226,5/16/2024,2024,KR 20230143747 A,10/25/2023,KR 20230143747 A,10/25/2023,METHOD FOR GENERATING TRAINING DATA FOR GENERATIVE DEEP LEARNING MODEL THROUGH AUTOMATIC PROMPT GENERATION,"본 발명은 각각 다른 목적으로 추론을 수행하는 복수개의 생성형 딥러닝 모델에 대한 학습 데이터셋을 생성하기 위해, 프롬프트 생성 딥러닝 모델을 이용하여 학습용 데이터 생성에 사용될 프롬프트를 자동으로 생성하고, 생성된 프롬프트 및 추론을 수행할 입력 데이터를 각각의 생성형 딥러닝 모델에 적용하여 자동으로 학습데이터를 생성하는 방법에 관한 것으로, 생성형 딥러닝 모델의 학습 데이터셋의 생성 요청을 수신하는 단계; 생성 요청에 포함된 생성 지시어를 분석하여 학습 데이터셋을 생성할 생성형 딥러닝 모델을 판단하고, 상기 생성형 딥러닝 모델의 프롬프트를 생성하는 단계; 및 생성된 프롬프트에 추론입력 데이터를 삽입한 후 상기 생성형 딥러닝 모델에 적용하여 학습 데이터셋을 생성하는 단계;를 포함한다.",URP CO LTD,LEE HONG JAE;;KHO HYEONG SEOG;;LEE GEON MIN,,https://lens.org/179-398-142-096-226,Granted Patent,no,2,4,1,179-398-142-096-226,KR,1,179-398-142-096-226,KR,0,,G06N3/0475;;G06F16/33;;G06F16/34;;G06N5/04,,2,1,167-422-379-240-419,10.2139/ssrn.4504303,"A. K. Gao. “Prompt Engineering for Large Language Models”. SSRN*;;J. Wei 등. ""Chain-of-Thought Prompting Elicits Reasoning in Large Language Models"". arXiv:2201.11903v6",ACTIVE
83,WO,A1,WO 2025/158698 A1,122-735-258-794-76X,7/31/2025,2025,JP JP2024/029805,8/22/2024,JP 2024-010072,1/26/2024,LANGUAGE MODEL UTILIZATION SYSTEM AND LANGUAGE MODEL UTILIZATION METHOD,"The present invention makes it possible to appropriately perform prompt engineering even when accumulated confidential information or the like is included in knowledge external to an LLM. Provided is a language model utilization system 1 in which a sentence of a prompt 6 designated by a user 5 is input to a language model 4, and an answer 7 obtained from the language model 4 is output to the user 5. The system includes a knowledge holding unit 3 in which information pertaining to knowledge is accumulated. Knowledge related to or similar to the prompt 6 is acquired from the knowledge holding unit 3 on the basis of the prompt 6, and the knowledge and the prompt 6 are both input together to the language model 4 to obtain the answer 7.","NOMURA RESEARCH INSTITUTE, LTD.",KAWAGUCHI Masashi,,https://lens.org/122-735-258-794-76X,Patent Application,yes,0,0,1,122-735-258-794-76X,WO,1,122-735-258-794-76X,WO,0,,G06F16/90;;G06F16/903;;G06F16/9035,,1,0,,,蓬田綾香、外７名、“技術ナレッジ活用に向けたRetriever-Readerモデルの検証”、言語処理学会　第２９回年次大会　発表論文集、２０２３年３月、ｐ．２０３０－２０３３,UNKNOWN
84,EP,A1,EP 4582999 A1,197-898-925-225-489,7/9/2025,2025,EP 24222858 A,12/23/2024,US 202418406037 A,1/5/2024,MACHINE COGNITION WORKFLOW ENGINE,"A machine cognition workflow engine and a recommendation subsystem are provided in a computing system. The workflow engine receives a plurality of prompts, extracts a message and a context of each of the plurality of prompts, for each prompt, generates a workflow instance according to a recommended workflow definition that specifies a plurality of calls to one or more components, and for each prompt, executes the generated workflow instance to perform the calls to the one or more components to thereby generate responses for the plurality of prompts. The recommendation subsystem evaluates the responses to generate a score for each response generated by the workflow instances, receives a request from the machine cognition workflow engine for the recommended workflow definition for a current prompt, and outputs the recommended workflow definition to the machine cognition workflow engine based on the scores of responses generated by the workflow instances.",MICROSOFT TECHNOLOGY LICENSING LLC,KRABACH BRIAN SCOTT;;SCHILLACE SAMUEL EDWARD;;MADAN UMESH,,https://lens.org/197-898-925-225-489,Patent Application,yes,6,0,2,197-898-925-225-489;;141-522-913-324-079,US;;EP,2,197-898-925-225-489;;141-522-913-324-079,US;;EP,0,G06N3/006;;G06N7/01;;G06F16/24573;;G06F40/30;;G06F9/4843;;G06F9/5011;;G06F9/5038;;G06F2209/5019,G06N3/006;;G06N7/01,,1,0,,,"ANONYMOUS: ""Prompt engineering - Wikipedia"", 2 January 2024 (2024-01-02), XP093268512, Retrieved from the Internet <URL:https://en.wikipedia.org/w/index.php?title=Prompt_engineering&oldid=1193151090>",PENDING
85,CN,A,CN 117708195 A,040-381-577-023-032,3/15/2024,2024,CN 202311667394 A,12/6/2023,CN 202311667394 A,12/6/2023,Macroscopic analysis content generation method and system based on time sequence,"The invention provides a macroscopic analysis content generation method and system based on a time sequence. The generation method comprises the steps that S1, GDP acceleration data and CPI acceleration data are collected; s2, calculating historical quantiles where GDP speed increase and CPI speed increase in the latest report period are located, and obtaining a data table; s3, calculating a time sequence trend category and generating characters; s4, carrying out data visualization on the data table; and S5, generating a conclusion according to a Mellin clock theory template. By combining with a conclusion of human calculation and inputting specific data and prompt engineering, the problem that large model calculation knowledge is inaccurate is solved, and high-quality and credible answers are generated.",BOB FINANCIAL TECH CO LTD,SUN ZHIQIANG,,https://lens.org/040-381-577-023-032,Patent Application,no,0,0,1,040-381-577-023-032,CN,1,040-381-577-023-032,CN,0,G06F16/2474;;G06F16/287;;G06Q50/26,G06F16/2458;;G06F16/28;;G06Q50/26,,0,0,,,,PENDING
86,US,A1,US 2024/0361996 A1,191-721-442-580-679,10/31/2024,2024,US 202318141212 A,4/28/2023,US 202318141212 A,4/28/2023,REPOSITORY-LEVEL AUGMENTATION OF PROMPTS FOR CODE COMPLETION,"A code completion system utilizes a large language model to complete a partially-formed source code snippet of a source code program given a prompt that includes a repository-level context, an extended context and a local context. The repository-level extended context includes a few-shot examples and a focal context. The few-shot examples are code fragments from the repository having a close similarity to the partially-formed source code snippet. The focal context includes method signatures and namespace information of methods of custom classes defined in the repository. The augmentation of the prompt with the various context data enables the model to predict more relevant code completion candidates for custom data without training the model on the custom data.",MICROSOFT TECHNOLOGY LICENSING LLC,FU SHENGYU;;LIU XIAOYU;;SUNDARESAN NEELAKANTAN;;SVYATKOVSKIY ALEXEY,MICROSOFT TECHNOLOGY LICENSING LLC (2023-04-29),https://lens.org/191-721-442-580-679,Patent Application,yes,2,2,2,159-786-851-172-147;;191-721-442-580-679,US;;WO,2,159-786-851-172-147;;191-721-442-580-679,US;;WO,0,G06F8/31;;G06F8/36;;G06F8/73,G06F8/36;;G06F8/73,,3,0,,,"Patrick Bareiß et al., ""Code Generation Tools (Almost) for Free? A Study of Few-Shot, Pre-Trained Language Models on Code,"" 2022 [retrieved on 1/25/25], pp. 1-12, downloaded from <url>:https://arxiv.org/abs/2206.01335. (Year: 2022);;Jiachang Liu et al., ""What Makes Good In-Context Examples for GPT-3?"", 2021 [retrieved on 1/25/25], pp. 1-12, downloaded from <url>:https://arxiv.org/abs/2101.06804. (Year: 2021);;Rizel Scarlett, ""A Beginner's Guide to Prompt Engineering with GitHub Copilot,"" 2023 [retrieved on 1/23/25], pp. 1-18, downloaded from <url>:https://blackgirlbytes.dev/a-beginners-guide-to-prompt-engineering-with-github-copilot. (Year: 2023)",PENDING
87,KR,B1,KR 102666248 B1,044-506-839-650-194,5/16/2024,2024,KR 20230143746 A,10/25/2023,KR 20230143746 A,10/25/2023,PROMPT GENERATION DEVICE FOR GENERATING TRAINING DATA OF GENERATIVE DEEP LEARNING MODEL,"본 발명은 복수개의 생성형 딥러닝 모델의 학습을 위한 데이터셋을 자동으로 생성하기 위해 각 생성형 딥러닝 모델의 목적에 따라 프롬프트를 자동으로 생성하는 장치에 관한 것으로, 생성형 딥러닝 모델의 프롬프트 생성을 요청하는 생성 지시어를 입력받아 생성 지시어의 키워드를 추출하는 지시어 분석부; 및 상기 생성 지시어를 통해 획득한 지시어 키워드를 사용하여 생성할 프롬프트 주제 카테고리를 판단하고, 상기 주제 카테고리에 따라 생성형 딥러닝 모델의 프롬프트를 생성하는 프롬프트 생성부;를 포함한다.",URP CO LTD,LEE HONG JAE;;KHO HYEONG SEOG;;LEE GEON MIN,,https://lens.org/044-506-839-650-194,Granted Patent,no,2,2,1,044-506-839-650-194,KR,1,044-506-839-650-194,KR,0,,G06N3/0475;;G06F16/33;;G06F16/34,,3,1,167-422-379-240-419,10.2139/ssrn.4504303,Y. Zhou 등. “Large Language Models are Human-Level Prompt Engineers”. arXiv:2211.01910v2*;;A. K. Gao. “Prompt Engineering for Large Language Models”. SSRN*;;glevel. “Chatgpt 프롬프트 팁 - 출력값 지정하기”*,ACTIVE
88,US,A1,US 2024/0427742 A1,109-125-547-209-871,12/26/2024,2024,US 202418743297 A,6/14/2024,US 202418743297 A;;US 202363509218 P,6/20/2023,SYSTEMS AND METHODS FOR BUILDING AND EXECUTING A DATABASE DICTIONARY,"According to some aspects, systems and methods for optimizing the mapping and translating of natural language phrases into query code (e.g., SQL) via Generative AI are provided. Various embodiments employ optimizations to resolve at least some of the known issues with conventional LLM usage. Various embodiments are configured to leverage prompt engineering and/or fine tuning of a generative AI model to optimize the translation of natural language into code. For example, a database dictionary system manages creation of a database dictionary that describes an existing database target to a model. The database dictionary can be used as part of a query prompt input to an LLM. Employing the database dictionary, the output of the LLM is optimized for the specific database/context responsive to any request provided by a user. In various embodiments, the database dictionary is constructed and supplied to the LLM as part of a query prompt.",GUAN RUTH QINGYU;;GUAN TAO,GUAN RUTH QINGYU;;GUAN TAO,,https://lens.org/109-125-547-209-871,Patent Application,yes,0,2,2,109-125-547-209-871;;160-656-834-537-263,US;;CN,2,109-125-547-209-871;;160-656-834-537-263,US;;CN,0,G06F16/374;;G06F16/332;;G06F16/3331;;G06F16/212;;G06F16/213;;G06F16/243;;G06F16/212;;G06F16/213,G06F16/21,,0,0,,,,PENDING
89,CN,A,CN 118821845 A,146-270-233-163-228,10/22/2024,2024,CN 202410790378 A,6/19/2024,CN 202410790378 A,6/19/2024,Transaction question and answer recall method and device,"The invention relates to the technical field of artificial intelligence, and particularly provides a transaction question and answer recall method and device, and the method comprises the following steps: S1, generating a virtual user question based on a large language model of a prompt project; s2, constructing a positive sample, a negative sample and an anchor point anchor sample; s3, constructing a source problem-virtual problem metric learning module; and S4, test deployment. Compared with the prior art, the method has the advantages that the large language model can be developed through the prompt engineering, the question closer to the expression of the user is generated, the readability of the question and the understanding degree of the user are improved, meanwhile, the diversity of the question library is enriched, and the intelligent question-answering system can better meet the requirements of the user.",INSPUR SOFTWARE CO LTD,XIN JIANJIA;;CHEN ZHAOLIANG;;ZHANG ZHAOYONG;;SUN XIANWEN;;CUI SHENGLI,,https://lens.org/146-270-233-163-228,Patent Application,no,0,0,1,146-270-233-163-228,CN,1,146-270-233-163-228,CN,0,G06N3/045;;G06N3/048;;G06N3/0499;;G06N3/08,G06N3/045;;G06N3/048;;G06N3/0499;;G06N3/08,,0,0,,,,PENDING
90,TW,A,TW 202447482 A,052-305-471-821-811,12/1/2024,2024,TW 112117897 A,5/15/2023,TW 112117897 A,5/15/2023,Summary generation method based on prompt engineering and its computing device capable of generating a plurality of key paragraph prompts for being applied to bank credit reporting,"A computing device for generating summaries based on prompt engineering is suitable for generating a summary of text data, and includes a storage module and a processing module. The storage module is used to store a plurality of preset topic categories, a prompt generation model and a paragraph generation model. The processing module is configured to use the prompt generation model to obtain a plurality of key paragraph prompts based on the text data and the preset topic categories, use the paragraph generation model to generate one of a key paragraph response result and a generation failure result based on each of the key paragraph prompts, use the prompt generation model to obtain a paragraph summary prompt for each key paragraph response result, and finally, use the paragraph generation model to obtain a paragraph summary based on the paragraph summary prompt.",CTBC BANK CO LTD,WANG JUN-QUAN;;SONG ZHENG-LONG;;WU RUI-LIN;;QIU GUO-HAO;;ZHANG YU-HONG;;JIAN YU-TING;;PENG SHI-JUE,,https://lens.org/052-305-471-821-811,Patent of Addition,no,0,0,2,052-305-471-821-811;;049-713-384-407-246,TW,2,052-305-471-821-811;;049-713-384-407-246,TW,0,,G06N3/08;;G06Q40/00;;G09B7/00,,0,0,,,,ACTIVE
91,US,B1,US 12204855 B1,086-308-885-524-259,1/21/2025,2025,US 202418823584 A,9/3/2024,US 202418823584 A,9/3/2024,Partner management runtime enforcement,"A document is obtained that include natural language text and a set of conditions are extracted from the document. In at least one embodiment, the set of conditions is extracted using a machine learning model trained on other natural language text. A validation process is performed to result in a validated set of conditions and a machine-readable data structure is generated to indicate one or more conditions of the validated set of conditions expressed within the document.",CITIGROUP INC,SPANNHAKE II ERNST WILHEM;;VENKAT GAYATHRI;;SHAH HITEN JAYANTILAL;;GIANELLE THOMAS FRANCIS,CITIGROUP INC (2024-08-30),https://lens.org/086-308-885-524-259,Granted Patent,yes,1,0,1,086-308-885-524-259,US,1,086-308-885-524-259,US,0,G06F40/279;;G06F40/205;;G06F40/30;;G06Q10/10;;G06N20/00;;G06Q20/389;;G06F40/279,G06F40/279;;G06Q20/38,,0,0,,,,ACTIVE
92,US,A1,US 2025/0181612 A1,120-118-421-936-136,6/5/2025,2025,US 202318528655 A,12/4/2023,US 202318528655 A,12/4/2023,SYSTEM AND METHOD FOR LEARNING AND COMMUNICATING IMPLICIT STYLISTIC PREFERENCES FROM HISTORICAL USER INTERACTION DATA IN TEXT-TO-IMAGE PROMPT ENGINEERING,Systems and methods are provided for implementing stylistic preferences into an image generation model with an accompanying user interface. The system can generate a plurality of images for each of a plurality of user prompts received from a first user and relate each plurality of images to the other pluralities of images. The user interface can selecting a preferred plurality of images from the pluralities of images based on input from a second user and display the pluralities of images in a node tree diagram indicating the preferred plurality of images.,TOYOTA RES INST INC;;TOYOTA MOTOR CO LTD,HONG MATTHEW K;;TOYODA HEISHIRO;;CHEN YIN-YING;;HAKIMI SHABNAM;;KLENK MATTHEW,TOYOTA JIDOSHA KABUSHIKI KAISHA (2023-11-22);;TOYOTA RESEARCH INSTITUTE INC (2023-11-22),https://lens.org/120-118-421-936-136,Patent Application,yes,5,0,1,120-118-421-936-136,US,1,120-118-421-936-136,US,0,G06T11/00;;G06F16/3328;;G06F16/535;;G06F16/54;;G06T11/60;;G06F16/3328;;G06F16/535;;G06T11/00;;G06F16/54,G06F16/332;;G06F16/535;;G06F16/54;;G06T11/00,,0,0,,,,PENDING
93,EP,A1,EP 4513362 A1,158-457-151-472-495,2/26/2025,2025,EP 24193093 A,8/6/2024,US 202318454039 A,8/22/2023,DECENTRALIZED IDENTIFIER BASED AUTHENTICATION WITH VERIFIABLE CREDENTIALS,"Disclosed are various approaches for authenticating users using verifiable credentials. An enrollment request (233) is received from a browser (243). In response to the enrollment request (233), a set of authentication questions can be selected. The set of authentication questions can then be sent to the browser (243). Next, a set of answers to a subset of the set of authentication questions is received. Subsequently, a decentralized identifier communication (DIDComm) protocol connection is established with a wallet application (246). Then, a verifiable credential that represents the set of answers to the subset of the set of authentication questions is issued to the wallet application (246).",AMERICAN EXPRESS TRAVEL RELATED SERVICES CO INC,MADDUKURI AJAY BABU,,https://lens.org/158-457-151-472-495,Patent Application,yes,4,0,2,048-855-554-398-168;;158-457-151-472-495,US;;EP,2,048-855-554-398-168;;158-457-151-472-495,US;;EP,0,G06F2221/2103;;H04L2463/082;;H04L9/3271;;H04L63/0838;;H04L67/02;;H04L63/08;;G06F21/31;;G06N20/00;;H04L9/50;;H04L9/3242;;H04L9/3271;;H04L63/0838,G06F21/31;;H04L9/32;;H04L9/40,,1,0,,,"JULES WHITE ET AL: ""A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 21 February 2023 (2023-02-21), XP091444160",PENDING
94,CN,A,CN 117573877 A,178-671-903-896-323,2/20/2024,2024,CN 202410066570 A,1/17/2024,CN 202410066570 A,1/17/2024,Supply chain collaborative management platform material data processing method and system,"The invention discloses a supply chain collaborative management platform material data processing method and system. The method comprises the steps of receiving original material data information of an enterprise; extracting information of corresponding items from the original material data information according to preset standard items to form a preliminary material data table; longitudinal analysis and transverse analysis are carried out on the preliminary material data table to determine material data abnormal items, an abnormal item analysis report is formed based on an abnormal analysis result, and a named entity recognition model adopted for extracting corresponding items according to preset standard items is combined based on prompt engineering, manual annotation and a knowledge graph. The accuracy of material data entity identification is effectively improved, and the material data processing efficiency of the supply chain collaborative management platform is further improved.",ANHUI YOUZHICAI TECH DEVELOPMENT CO LTD,LU XIAOKAI;;FENG JUN;;GAO JUN;;ZHOU XI;;YAO LI,,https://lens.org/178-671-903-896-323,Patent Application,no,6,1,2,025-297-291-701-373;;178-671-903-896-323,CN,2,025-297-291-701-373;;178-671-903-896-323,CN,0,G06F16/35;;G06F16/3344;;G06F16/367;;G06F18/2433;;G06Q10/0631;;Y02P90/30,G06F16/35;;G06F16/33;;G06F16/36;;G06F18/2433;;G06Q10/0631,,0,0,,,,ACTIVE
95,CN,A,CN 117493586 A,073-833-795-739-25X,2/2/2024,2024,CN 202311489779 A,11/9/2023,CN 202311489779 A,11/9/2023,Planning design method and device and storage medium,"According to the planning and design method and device and the storage medium, a user is guided to input the planning and design condition information needed by planning and design through the preset problem chain, then the integrity of the information needed during planning and design can be ensured, and therefore the integrity and accuracy of the generated planning and design scheme can be ensured. And on the other hand, the situation that the user cannot obtain a professional planning and design scheme due to the fact that the user inputs the missing data but does not know which missing data is supplemented can be avoided by prompting the user to input the specified information through the preset problem chain, and therefore the user experience can be greatly improved. In conclusion, the scheme interacts with the user based on the prompt engineering technology and the large language model, a perfect and accurate planning and design scheme can be generated, and the user can have good use experience.",UNIV BEIJING FORESTRY;;YAO PENG;;SHAO MING;;TAO PEIYUAN,YAO PENG;;SHAO MING;;TAO PEIYUAN;;CAO ZEYU;;DU JIANING;;LIN YE;;MA CHAO;;WANG XING;;LIN JINGYUAN;;LI MENGYU;;WANG ZHENKUN;;LIANG HUAQIU;;SHEN MENGHAN,,https://lens.org/073-833-795-739-25X,Patent Application,no,0,1,1,073-833-795-739-25X,CN,1,073-833-795-739-25X,CN,0,G06F16/383;;G06N5/022;;G06N5/041,G06F16/383;;G06N5/022;;G06N5/04,,0,0,,,,PENDING
96,WO,A1,WO 2025/072550 A1,082-605-443-265-689,4/3/2025,2025,US 2024/0048701 W,9/26/2024,US 202318475588 A;;US 202418746326 A,9/27/2023,SYSTEMS AND METHODS FOR INTERACTING WITH A MULTIMODAL MACHINE LEARNING MODEL,"The disclosed embodiments may include a method of interacting with a multimodal machine learning model; the method may include providing a graphical user interface associated with a multimodal machine learning model. The method may further include displaying an image to a user in the graphical user interface. The method may also include receiving a textual prompt from the user and then generating input data using the image and the textual prompt. The method may further include generating an output at least in part by applying the input data to the multimodal machine learning model, the multimodal machine learning model configured using prompt engineering to identify a location in the image conditioned on the image and the textual prompt, wherein the output comprises a first location indication. The method may also include displaying, in the graphical user interface, an emphasis indicator at the indicated first location in the image.",OPENAI OPCO LLC,DEUTSCH NOAH;;TURLEY NICHOLAS;;ZWEIG BENJAMIN,,https://lens.org/082-605-443-265-689,Patent Application,yes,6,0,3,082-605-443-265-689;;095-791-113-342-446;;183-901-764-868-307,US;;WO,3,082-605-443-265-689;;095-791-113-342-446;;183-901-764-868-307,US;;WO,0,G06N3/08;;G06N3/0455;;G06N3/045;;G06N3/08;;G06N3/0455,G06N3/0455;;G06N3/08,,0,0,,,,PENDING
97,CN,A,CN 118471550 A,155-628-638-406-056,8/9/2024,2024,CN 202410569019 A,5/9/2024,CN 202410569019 A,5/9/2024,Intelligent medical assistant system based on large language model and interaction method and product thereof,"The invention discloses an intelligent medical assistant system based on a large language model and an interaction method and product thereof, relates to the technical field of intelligent medical treatment, and designs a data preprocessing module, a large language model module and an early warning system module. The data preprocessing module performs fine tuning and prompting engineering on the large language model by using collected historical real dialogue data of doctors-patients in different dialogue scenes, can be suitable for different dialogue scenes, and can also improve the accuracy of large language model output in different dialogue scenes; and the text reply output by the large language model module is evaluated by utilizing the early warning system module, so that the average reply quality of the large language model is improved, and the output accuracy of the large language model is improved.",INST BASIC MEDICAL SCIENCES CAMS,LONG ERPING;;WAN PEIXING;;HUANG ZIGENG,,https://lens.org/155-628-638-406-056,Patent Application,no,0,3,1,155-628-638-406-056,CN,1,155-628-638-406-056,CN,0,G16H80/00;;G06F16/3329;;G06F16/353;;G06N5/022;;G06F16/3346,G16H80/00;;G06F16/33;;G06F16/332;;G06F16/35;;G06N5/022,,0,0,,,,PENDING
98,WO,A1,WO 2025/128547 A1,024-732-128-299-801,6/19/2025,2025,US 2024/0059348 W,12/10/2024,US 202318535122 A,12/11/2023,THREAT INTELLIGENCE DIALOGUE SYSTEM FOR INTERFACING WITH A PROPRIETARY THREAT INTELLIGENCE DATABASE,"An LLM is adapted to generate database queries that are compatible with a proprietary database of a security provider. Adapting the LLM includes evaluating performance of the LLM after initial prompt engineering/fine-tuning to ensure that generated database queries are valid (i.e., comport to the database schema and can be executed to return results). When the LLM performance is satisfactory, a dialogue system uses the LLM to generate database queries from user queries. The dialogue system determines intent of each user query, which informs whether the query is supported. Supported user queries are converted to database queries using the LLM and submitted to the database. The dialogue system leverages another language model to generate a summarized, natural language representation of the database query results and constructs a response from the summary. The dialogue system also checks for XSS and prompt injection before database queries are ultimately submitted to the database.",PALO ALTO NETWORKS INC,FU YU;;HU MENGYING;;RASHEV KOSTA;;ZHANG ZHIBIN;;LI LIN;;GUO MINGXIAO;;XU SHENGMING;;WANG MEI,,https://lens.org/024-732-128-299-801,Patent Application,yes,0,0,2,024-732-128-299-801;;152-982-319-780-748,US;;WO,2,024-732-128-299-801;;152-982-319-780-748,US;;WO,0,G06F16/243;;G06F16/242;;G06F40/40;;G06F21/6218,G06F16/242,,2,0,,,"ANONYMOUS: ""How do i create a custom model for text to sql queries?"", 25 November 2023 (2023-11-25), XP093225304, Retrieved from the Internet <URL:https://web.archive.org/web/20231125003812/https://community.openai.com/t/how-do-i-create-a-custom-model-for-text-to-sql-queries/205539> [retrieved on 20241118];;ANONYMOUS: ""Ria GPT natural language interface to Postgres"", 23 November 2023 (2023-11-23), XP093225307, Retrieved from the Internet <URL:https://web.archive.org/web/20231123085502/https://github.com/drorm/ria> [retrieved on 20241118]",PENDING
99,WO,A1,WO 2024/258685 A1,053-124-379-775-596,12/19/2024,2024,US 2024/0032461 W,6/5/2024,US 202318209935 A,6/14/2023,CUSTOMIZED PROMPT GENERATION SERVICE FOR SOFTWARE ENGINEERING TASKS,"A customized prompt generation service automates prompts to a large language model to perform a specified software engineering task. The service stores the custom data of a client that includes code diff hunks, source code segments, code reviews, repaired code, and unit tests from a code base or repository of the client. Prompt templates are associated with each software engineering task that include the requisite information needed for the large language model to perform the target task. A prompt to a large language model includes examples of the software engineering task from the custom data of the client of the service.",MICROSOFT TECHNOLOGY LICENSING LLC,CLEMENT COLIN BRUCE;;FU SHENGYU;;GARG SPANDAN;;SUNDARESAN NEELAKANTAN;;YOU DONGJIANG;;ZILOUCHIAN MOGHADDAM,,https://lens.org/053-124-379-775-596,Patent Application,yes,0,0,2,053-124-379-775-596;;147-723-825-622-489,US;;WO,2,053-124-379-775-596;;147-723-825-622-489,US;;WO,0,G06N3/045;;G06F8/30;;G06F8/36;;G06N20/00;;G06F40/40;;G06F8/77,G06F8/36;;G06F8/30;;G06N3/045,,3,1,110-348-965-893-77X,10.1109/icse48619.2023.00205,"NASHID NOOR ET AL: ""Retrieval-Based Prompt Selection for Code-Related Few-Shot Learning"", PROCEEDINGS OF THE 2001 INTERNATIONAL ACM SIGGROUP CONFERENCE ON SUPPORTING GROUP WORK, ACM, NEW YORK, NY, US, 14 May 2023 (2023-05-14), pages 2450 - 2462, XP059147638, ISBN: 978-1-58113-294-6, DOI: 10.1109/ICSE48619.2023.00205;;JULES WHITE ET AL: ""A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 21 February 2023 (2023-02-21), XP091444160;;HENDRIK STROBELT ET AL: ""Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 16 August 2022 (2022-08-16), XP091295657",PENDING
100,CN,A,CN 118035392 A,185-695-104-890-339,5/14/2024,2024,CN 202311372823 A,10/20/2023,CN 202311372823 A,10/20/2023,"Intelligent question-answering system, question-answering interaction method, computer equipment and storage medium","The embodiment of the invention provides an intelligent questioning and answering system, a questioning and answering interaction method, computer equipment and a storage medium, and the intelligent questioning and answering system can generalize more generalization questions with higher quality on the basis of a small number of seed questions based on prompt engineering processing and a large language model; thirdly, removing generalization problems with similar or same semantic matching sentence patterns, and reserving generalization problems with different semantic matching sentence patterns in the knowledge base; and finally, performing vectorization processing on the questions needing to be reserved in the knowledge base based on the large voice model, and storing each question and the corresponding question vector and reply information in the knowledge base in an associated manner. Therefore, the defects of low efficiency, low accuracy, low recall rate and the like of the intelligent question-answering system in the aspect of retrieval performance can be effectively overcome.",CLOUDMINDS ROBOTICS CO LTD,WU YUNONG,,https://lens.org/185-695-104-890-339,Patent Application,no,0,1,1,185-695-104-890-339,CN,1,185-695-104-890-339,CN,0,G06F16/3329;;G06F16/3344;;G06F16/335;;G06F16/3347;;G06F16/338;;Y02D10/00,G06F16/332;;G06F16/33;;G06F16/335;;G06F16/338,,0,0,,,,PENDING
101,US,A1,US 2025/0117863 A1,053-615-708-403-926,4/10/2025,2025,US 202318482666 A,10/6/2023,US 202318482666 A,10/6/2023,GENERATION OF VERBOSE TAX CATEGORY DESCRIPTIONS USING A GENERATIVE LANGUAGE MODEL,"A computing system for generating verbose tax category descriptions includes a computing device with processing circuitry configured to identify defined tax categories. For each defined tax category, the processing circuitry is configured to extract source text data associated with the defined tax category, generate embeddings representing the source text data, and store the source text embeddings in a vector database. The processing circuitry is further configured to receive an instruction requesting a verbose tax category description of an indicated tax category, generate instruction text embeddings, and query the vector database with the instruction text embeddings to identify a subset of matching source text embeddings. The processing circuitry is further configured to retrieve matching source text data, generate a prompt for a generative language model, input the prompt into the model to generate verbose tax category description text, and output the verbose tax category description text.",VERTEX INC,ZANGRILLI CHRIS;;DEKEL OMER,VERTEX INC (2023-10-11),https://lens.org/053-615-708-403-926,Patent Application,yes,0,0,1,053-615-708-403-926,US,1,053-615-708-403-926,US,0,G06Q40/123;;G06F16/3347;;G06F16/338;;G06F40/40;;G06F40/30;;G06Q40/123;;G06F16/338;;G06F40/40;;G06F16/3347,G06Q40/12;;G06F16/33;;G06F16/338;;G06F40/40,,0,0,,,,PENDING
102,WO,A1,WO 2024/213988 A1,130-210-618-710-274,10/17/2024,2024,IB 2024053422 W,4/8/2024,IN 202341026661 A,4/11/2023,SYSTEM AND METHOD TO ALTER QUERIES PROVIDED TO AN ARTIFICIAL INTELLIGENCE PLATFORM FOR PRESERVING PRIVACY,"A system to alter queries provided to an artificial intelligence platform for preserving privacy is disclosed The system includes a query assessment module to identify sensitive attributes in prompts, a query annotation module to annotate them and a context and sensitivity based query paraphrasing module to generate synthetic attributes along with a privacy budget module to alter identified numerical values for creating synthetic prompt. The system includes a query output module to receive the synthetic privacy preserved query from upstream and forward it to downstream neural network with attention based language model and a query response origin module to receive an output generated by the artificial intelligence platform upon receiving the query. The system includes a query response assessment module to identify the sensitive synthetic attributes, a response privacy and context preservation module to modify the output to restore original entities and an output module to render the output.",PRIVASAPIEN TECH PRIVATE LIMITED,SOUNDARARAJAN ABILASH,,https://lens.org/130-210-618-710-274,Patent Application,yes,2,0,1,130-210-618-710-274,WO,1,130-210-618-710-274,WO,0,G06F40/30;;G06N3/0475;;H04L51/02;;G06F40/169;;G06F21/6245;;G06F16/90332;;G06F16/90335;;G06F16/9035;;G06N3/08;;G06N3/045;;G06N3/044,G06F16/335;;G06F16/9535;;G06F21/62;;G06F40/30;;G06N3/0475;;H04L51/02,,0,0,,,,PENDING
103,US,A1,US 2025/0228502 A1,120-833-406-948-035,7/17/2025,2025,US 202519017986 A,1/13/2025,US 202519017986 A;;US 202463620226 P,1/12/2024,AGENTIC GPT-BASED INTERACTIVE ELECTROCARDIOGRAPHIC ANALYSIS,"A system for interactive ECG monitoring is described. The system includes a data repository storing pre-processed ECG data. The pre-processed ECG data is associated with historical data, real-time data, or both derived from a plurality of ECG recorders. The pre-processed ECG data includes ECG measurements extracted or derived from raw ECG signals and annotations of cardiac events. Further, the system includes a multi-agent query processor to receive and process an input message related to health of a subject, retrieve relevant data elements from the pre-processed ECG data, raw ECG signals, or both based on the processed input message, compute metrics corresponding to the input message based on the retrieved data elements, and generate a response to the input message using an LLM or at least one agent to integrate retrieved data elements and computed metrics. The response is presented on a user interface to a healthcare provider.",CARDIACCLOUD AI INC,PYDAH SREERAM;;DEY SUJOYA;;MANGIONE NELSON JACK;;ILLANGO RAVI;;RANJAN SHASHI,,https://lens.org/120-833-406-948-035,Patent Application,yes,0,0,1,120-833-406-948-035,US,1,120-833-406-948-035,US,0,A61B5/7282;;A61B5/746;;A61B5/358;;A61B5/352;;A61B5/36;;G06F16/24522;;A61B5/363;;G16H10/60;;A61B5/742;;A61B5/7475;;A61B5/02405,A61B5/00;;A61B5/024;;A61B5/352;;A61B5/358;;A61B5/36;;A61B5/363;;G06F16/2452;;G16H10/60,,0,0,,,,PENDING
104,WO,A1,WO 2025/155709 A1,100-879-045-493-407,7/24/2025,2025,US 2025/0011858 W,1/16/2025,US 202463621388 P,1/16/2024,RULES MANAGEMENT FRAMEWORK FOR HETEROGENEOUS QUESTIONS AND ANSWERS MAPPING USING ARTIFICIAL INTELLIGENCE,"Systems, methods, and computer-readable media for mapping third-party specific question-and-answer pairs to standardized insurance-related question-and-answer pairs. A system may communicate with a third party and may receive third-party specific question-and-answer pairs. The system may include a rules management framework for mapping third-party specific question-and-answer pairs to standardized question-and- answer pairs. The rules management framework may interface with a library for housing the standardized question-and-answer pairs. The rules management framework may interface with a machine learning model to generate a similarity score between the third-party specific question-and-answer pairs and the standardized question-and-answer pairs. The system may include an ordering engine for ordering the questions of the standardized question-and-answer pairs. The system may include an error detection module for flagging when a third party indicates an error is present in the standardized question-and-answer pairs.",BOLT SOLUTIONS INC,WEINER PHILIP;;ZLODKOV OLEG;;BARRAUD ROMAIN,,https://lens.org/100-879-045-493-407,Patent Application,yes,0,0,2,100-879-045-493-407;;051-256-478-672-463,US;;WO,2,100-879-045-493-407;;051-256-478-672-463,US;;WO,0,G06N20/00;;G06F40/30;;G06Q40/08;;G06F40/35;;G06F16/33295;;G06F16/243;;G06F16/24578;;G06F16/248,G06Q40/08;;G06F16/3329;;G06F40/30;;G06N20/00,,0,0,,,,PENDING
105,WO,A1,WO 2025/026189 A1,077-839-335-924-182,2/6/2025,2025,CN 2024107673 W,7/25/2024,CN 202310945515 A,7/28/2023,"METHOD AND APPARATUS FOR PROMPT WORD MANAGEMENT, DEVICE, AND STORAGE MEDIUM","Embodiments of the present disclosure provide a method and apparatus for prompt word management, a device, and a storage medium. The method comprises: in response to receiving a prompt word editing request, presenting an editing interface, wherein the editing interface at least comprises an input area for receiving a target prompt word; and in response to receiving a prompt word publishing request, encapsulating the target prompt word into a callable target task at least on the basis of a user input in the editing interface, wherein the calling of the target task triggers the target prompt word to be inputted to a model. Thus, prompt words can be flexibly designed and managed, and the stability, reliability, convenience and high efficiency of prompt word management and model calling in practical application can be improved.",BEIJING ZITIAO NETWORK TECHNOLOGY CO LTD,ZHU WENHUAN;;MA SHICHAO;;FAN XINGGUANG;;BIAN CHAO;;LI XIANG,,https://lens.org/077-839-335-924-182,Patent Application,yes,3,0,2,077-839-335-924-182;;093-766-021-006-00X,WO;;CN,2,077-839-335-924-182;;093-766-021-006-00X,WO;;CN,0,G06F8/33;;G06F16/3329,G06F16/332;;G06F8/33,,1,1,165-689-824-574-442,10.1109/tvcg.2022.3209479;;36191099,"HENDRIK STROBELT ET AL.: ""Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models"", IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, vol. 29, no. 1, 31 January 2023 (2023-01-31), pages 1146 - 1156, XP011930319, DOI: 10.1109/TVCG.2022.3209479",PENDING
106,CN,A,CN 118626871 A,019-367-699-025-712,9/10/2024,2024,CN 202410431845 A,4/11/2024,CN 202410431845 A,4/11/2024,Class case matching method and system based on behavior pattern divide-and-conquer prompt,"The invention belongs to the technical field of similar case matching, and particularly discloses a class case matching method and system based on behavior pattern division prompt, and the method comprises the steps: for different types of judicial class case matching tasks, manually defining behavior patterns through legal experts, and decomposing the judicial class case matching tasks into a plurality of subtasks according to different behavior patterns; performing class case matching on each sub-task based on the behavior pattern by utilizing thinking chain prompt and a large language model; and obtaining class case matching results of all the subtasks, and performing aggregation to obtain a final judicial class case matching prediction result. By adopting the technical scheme, the performance of the LLM in the class case matching task is improved based on the behavior pattern divide-and-conquer prompt engineering method, so that the accuracy and interpretability of class case matching are improved.",UNIV CHONGQING,DAN JINGPEI;;YANG DONGBO;;XU LANLIN,,https://lens.org/019-367-699-025-712,Patent Application,no,0,1,1,019-367-699-025-712,CN,1,019-367-699-025-712,CN,0,G06F18/22;;G06N5/041;;G06F18/259;;G06F16/353;;G06N3/0455;;G06N3/08;;G06Q50/18,G06F18/22;;G06F16/35;;G06F18/25;;G06N3/0455;;G06N3/08;;G06N5/04;;G06Q50/18,,0,0,,,,PENDING
107,CN,A,CN 118569684 A,058-399-119-701-528,8/30/2024,2024,CN 202411040195 A,7/31/2024,CN 202411040195 A,7/31/2024,Emergency online decision-making method and system based on large language model,"The invention discloses an emergency online decision-making method and system based on a large language model, and relates to the field of emergency management of emergencies, the method comprises the following steps: establishing an offline decision-making model to design and construct a fine-tuning training data set for online decision making of the large language model, and utilizing the online decision fine-tuning training data set to make an online decision; and carrying out fine tuning training on the large language model by adopting prompt engineering and a model fine tuning technology, so that the large language model obtains the online decision-making capability. The effectiveness of the method provided by the invention is verified in simulation data and actual case data experiments, and experimental results show that the fine-tuned large language model has an online decision-making capability, and can better meet the requirements of emergency management and disposal of emergencies on timely decision making.",NAT UNIV DEFENSE TECHNOLOGY PLA,XIAO KAIMING;;QIU TAO;;ZHANG HANG;;WANG TENGYUN;;HUANG HONGBIN;;WU JIBING,,https://lens.org/058-399-119-701-528,Patent Application,no,5,0,1,058-399-119-701-528,CN,1,058-399-119-701-528,CN,0,G06Q10/0637;;G06Q10/06315;;G06N5/042;;G06N20/00;;Y02T10/40,G06Q10/0637;;G06N5/04;;G06N20/00;;G06Q10/0631,,0,0,,,,PENDING
108,CN,A,CN 118350350 A,030-346-205-379-293,7/16/2024,2024,CN 202410488849 A,4/23/2024,CN 202410488849 A,4/23/2024,Method and system for structured analysis of resume based on large model,"The invention discloses a method and a system for structurally analyzing a resume based on a large model, relates to the technical field of computer data processing, and greatly enhances the recognition accuracy of the system during processing of various layout resume texts through self-adaptive recognition capability. The problem that a traditional general OCR model cannot adapt to the structure loss of a complex layout resume is solved, the accuracy of key information is improved, the higher recall rate can be achieved, it is ensured that no details are omitted, and the accuracy of key information extraction is improved due to the fact that a large model is combined with the prompt engineering technology. Through the integration of the structured output module, the analysis method provided by the invention shows high efficiency and adaptability in coping with the diversification and individuation trend of the resumes in the modern job application market, the automation degree and efficiency of the recruitment process are improved in a large scale, and the recruitment efficiency is improved. Therefore, a tool is provided for human resource management personnel.",SHENZHEN YINGHE SOFTWARE TECH DEVELOPMENT CO LTD,YAO HONGFENG;;LIU CHUNMING;;SHAN XINQIANG,,https://lens.org/030-346-205-379-293,Patent Application,no,4,1,1,030-346-205-379-293,CN,1,030-346-205-379-293,CN,0,G06F40/16;;G06F40/30;;G06V30/414;;G06V30/19113;;G06Q10/1053,G06F40/16;;G06F40/30;;G06Q10/1053;;G06V30/19;;G06V30/414,,0,0,,,,PENDING
109,CN,A,CN 118468891 A,193-787-419-283-996,8/9/2024,2024,CN 202410626072 A,5/20/2024,CN 202410626072 A,5/20/2024,Prompt framework based on large language model and system and application thereof,"The invention relates to the technical field of prompt engineering, in particular to a prompt framework based on a large language model and a system and application of the prompt framework, and the proposed prompt framework dynamically loads dominant prompt words and soft prompt parameters according to downstream task requirements so as to migrate the general capability of the large model to a task in a specific field. The multi-round dialogue implementation system adopts a pipelined architecture and comprises a natural language understanding module, a dialogue management module and a natural language generation module. In the implementation of multiple rounds of dialogues, the system executes tasks such as natural language understanding, dialogue management and natural language generation by using the architecture. The modules cooperate with each other to realize an efficient and coherent dialogue process. Experimental results show that through reasonable construction of cue words and dominant prompt, the migration difficulty of the system or model field can be reduced, and meanwhile good performance is achieved.",UNIV ELECTRONIC SCI & TECH CHINA,LIAO WEIZHI;;TAN YIZHE;;LIU ZHAOYI,,https://lens.org/193-787-419-283-996,Patent Application,no,0,2,1,193-787-419-283-996,CN,1,193-787-419-283-996,CN,0,G06F40/35;;G06F40/16;;G06F16/35;;G06N3/0442,G06F40/35;;G06F16/35;;G06F40/16;;G06N3/0442,,0,0,,,,PENDING
110,US,A1,US 2025/0077511 A1,186-224-233-671-20X,3/6/2025,2025,US 202318459138 A,8/31/2023,US 202318459138 A,8/31/2023,IOT SECURITY KNOWLEDGE-BASED CHATBOT SYSTEM,"A stateful chatbot system leverages generative AI to provide an interface by which users can retrieve information from backend IoT databases of a security provider via natural language queries. Upon receiving a natural language query that corresponds to a request for information from the database, the chatbot generates a corresponding database query having a format compatible with the database. The chatbot comprises a generative model adapted to generate database queries based on natural language queries via prompt engineering using natural language and database query pairs. The chatbot queries the database with the generated database query, retrieves results comprising data/metadata that satisfy the query, and generates a summary of the results, both of which it presents as a response to the user's query. The chatbot also has access to a vulnerability database from which it can obtain information about known vulnerabilities documented therein to respond to user queries.",PALO ALTO NETWORKS INC,ZHAO YILIN;;TIAN KE;;SPAGNUOLO DYLAN STEWART;;WANG MEI;;KALAICHELVAN KANIMOZHI;;KHAN YELMAN UR REHMAN,PALO ALTO NETWORKS INC (2023-08-31),https://lens.org/186-224-233-671-20X,Patent Application,yes,3,1,1,186-224-233-671-20X,US,1,186-224-233-671-20X,US,0,G06F16/24522;;G06F16/252;;G06N3/0455;;G06F16/24522;;G06F16/252;;G06N3/0455,G06F16/2452;;G06F16/25;;G06N3/0455,,0,0,,,,PENDING
111,CN,A,CN 119311880 A,165-458-902-843-057,1/14/2025,2025,CN 202411798842 A,12/9/2024,CN 202411798842 A,12/9/2024,Multi-modal literature data extraction method and device and medium,"The invention discloses a multi-modal literature data extraction method and device and a medium. The method comprises the following steps: firstly, standardizing literatures to obtain a structured document comprising a literature directory, author information, a paragraph text, a paragraph layout, a table LaTeX code, a formula LaTeX code and/or image description; then, related retrieval of fragments is performed on texts, formulas, tables and images from the structured document according to keywords and/or vectorization retrieval strategies. The retrieved fragments are optimized through correlation sorting, and the number of the fragments needing to enter large model processing is reduced. And finally, performing question and answer configuration on the large language model based on a user extraction demand and a sorting fragment, generating a structured answer through a prompt engineering technology, ensuring that the results can be traced through an original fragment, ensuring the availability of question and answer results, and reminding the user to verify and process a part which cannot be traced when necessary.",ZHEJIANG LAB,YE JIEPING;;YANG JIANG;;SONG ZIQI,,https://lens.org/165-458-902-843-057,Patent Application,no,6,1,1,165-458-902-843-057,CN,1,165-458-902-843-057,CN,0,G06F16/35;;G06F16/3346;;G06F16/3347;;G06F16/332;;G06F16/3329;;G06F40/30;;G06N5/04;;G06N3/0455;;Y02D10/00,G06F16/35;;G06F16/332;;G06F16/334;;G06F40/30;;G06N3/0455;;G06N5/04,,0,0,,,,PENDING
112,KR,A,KR 20240176761 A,011-088-311-513-742,12/24/2024,2024,KR 20240026093 A,2/22/2024,KR 20230077478 A,6/16/2023,System and method for image creation prompt generator for image creation,"본 발명은 이미지 생성 시스템 및 방법, 이미지 생성을 위한 프롬프트 제너레이터에 관한 것으로, 생성 대상 이미지에 대해 입력된 텍스트 구조를 분석하여 분석된 각 요소에 대해 상세 정보를 추가하여 장면 증강 텍스트를 생성하고, 사용자가 선택하거나 상기 분석 결과에 기초한 이미지 스타일, 그리고 상기분석 결과에 기초한 감정 판단에 따르는 형용사 중 하나 이상을 포함하는 이미지 스타일 텍스트를 생성하며, 상기 장면 증강 텍스트 및 상기 이미지 스타일 텍스트로부터 상기 AI 모델에 입력되는 하나 이상의 최종 프롬프트를 생성할 수 있다. 본 발명에 따르면, 사용자의 간단한 입력을 통해 의도에 부합하는 이미지를 생성할 수 있다.",SMORETALK INC,HWANG HYEONJI;;LEE JEONGMIN,,https://lens.org/011-088-311-513-742,Patent Application,no,3,0,2,011-088-311-513-742;;065-686-867-413-260,KR,2,011-088-311-513-742;;065-686-867-413-260,KR,0,G06T11/00;;G06F40/279;;G06F40/30;;G06F40/58;;G06N3/0475;;G06T2211/441,G06F40/279;;G06F40/30;;G06F40/58;;G06N3/0475;;G06T11/00,,2,0,,,"Nikita Pavlichenko 외 1명, ""Best Prompts for Text-to-Image Models and How to Find Them"", <url:https://arxiv.org/abs/2209.11711v1>, (2022.02.23.), pp1-12. 1부.*;;VIVIAN LIU 외 1명, ""Design Guidelines for Prompt Engineering Text-to-Image Generative Models"", <url:https://arxiv.org/pdf/2109.06977v1>, (2021.02.14.), pp1-25. 1부.*",ACTIVE
113,US,B2,US 12298975 B2,147-301-894-763-533,5/13/2025,2025,US 202418429219 A,1/31/2024,US 202418429219 A;;US 202363587393 P,10/2/2023,Dynamic query planning and execution,"Embodiments of the disclosed technologies include receiving a first query including at least one first query term and configuring at least one prompt to cause a large language model to translate the at least one first query term into a set of functions that can be executed to obtain at least one second query term and generate and output a plan that is executable to create a modified version of the first query based on the at least one second query term. The plan is obtained by applying the large language model to the at least one prompt as configured. The plan is executed to determine the at least one second query term and create the modified version of the first query. The modified version of the first query is executed to provide, via the user interface, a response to the first query.",MICROSOFT TECHNOLOGY LICENSING LLC,BALDUA MANISH R;;HEWLETT DANIEL K;;POUNDS GREGORY E;;LU XIE;;POHL JONATHAN;;RIGANO PETER,MICROSOFT TECHNOLOGY LICENSING LLC (2024-02-11),https://lens.org/147-301-894-763-533,Granted Patent,yes,3,0,2,160-272-504-342-129;;147-301-894-763-533,US,3,160-272-504-342-129;;051-013-793-231-637;;147-301-894-763-533,US;;WO,0,G06F16/2425;;G06F16/24542;;G06F16/243;;G06F16/24542;;G06F16/243;;G06F16/2425,G06F16/2453;;G06F16/242,,6,1,040-052-730-126-840,10.1145/3539618.3591960,"International Search Report and Written Opinion received for PCT Application No. PCT/US2024/047345, Dec. 5, 2024, 17 Pages.;;Marwah et al., “Can Generative LLMs Create Query Variants for Test Collections? An Exploratory Study”, Proceedings of The 2023 Chi Conference On Human Factors in Computing Systems, Jul. 19, 2023, 5 pages.;;Zhu et al., “Furthest Reasoning with Plan Assessment: Stable Reasoning Path with Retrieval-Augmented Large Language Models”, Sep. 22, 2023, 16 pages.;;Greyling, Cobus, “Prompt Chaining & Large Language Models”, Retrieved from the URL: https://cobusgreyling.medium.com/prompt-chaining-large-language-models-a7c9b66eb5f9, Apr. 4, 2023, 20 Pages.;;Greyling, Cobus, “Prompt Engineering, OpenAI & Modes”, Retrieved from the URL: https://cobusgreyling.medium.com/prompt-engineering-openai-modes-597425540eae, Mar. 17, 2023, 20 Pages.;;Jagerman, et al., “Query Expansion by Prompting Large Language Models”, arXiv preprint arXiv:2305.03653, May 5, 2023, 7 Pages.",ACTIVE
114,WO,A1,WO 2025/087975 A1,066-124-034-342-252,5/1/2025,2025,EP 2024079964 W,10/23/2024,US 202318493205 A,10/24/2023,METHOD OF PERFORMING A CLINICAL ASSESSMENT,"A computer-implemented method (200) is disclosed for performing a clinical assessment, the method comprising: providing a first input (206) to a machine learning model (208), the first input comprising template data encoding a template for carrying out a part of the clinical assessment; providing a second input (210) to the machine learning model, the second input comprising assessment data recorded during the clinical assessment; wherein the first input is provided to the machine learning model to condition the machine learning model to provide an output (212) based on the second input for use in the clinical assessment; and using the output from the machine learning model to perform the clinical assessment.",NOVOIC LTD,WESTON JACK;;FRISTED EMIL,,https://lens.org/066-124-034-342-252,Patent Application,yes,0,0,2,002-169-359-184-616;;066-124-034-342-252,US;;WO,2,002-169-359-184-616;;066-124-034-342-252,US;;WO,0,G16H50/20;;G16H20/70;;G16H10/20;;A61B5/7267;;A61B5/4803;;G16H40/67;;G06N3/0455;;G06N3/045;;G16H50/20,G16H10/20;;A61B5/00;;G06F16/3329;;G06N3/0455;;G16H20/70;;G16H40/67;;G16H50/20,,4,2,035-504-059-394-390;;076-753-144-138-775,37128372;;pmc10148337;;10.1145/3613904.3642152,"SONISH SIVARAJKUMAR ET AL: ""HealthPrompt: A Zero-shot Learning Paradigm for Clinical Natural Language Processing"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 9 March 2022 (2022-03-09), XP091179637;;JIAQI WANG ET AL: ""Prompt Engineering for Healthcare: Methodologies and Applications"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 28 April 2023 (2023-04-28), XP091496615;;WOOSUK SEO ET AL: ""ChaCha: Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 21 September 2023 (2023-09-21), XP091619954;;JULES WHITE ET AL: ""A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 21 February 2023 (2023-02-21), XP091444160",PENDING
115,CN,A,CN 119578532 A,093-147-039-519-062,3/7/2025,2025,CN 202411893174 A,12/20/2024,CN 202411893174 A,12/20/2024,Knowledge graph completion method and system based on decoupling structure embedding,"The invention discloses a knowledge graph completion method based on decoupling structure embedding, and the method comprises the steps: inputting the structure information of a knowledge graph into a pre-training language model in a prompt manner through the capability of the pre-training language model and a prompt engineering method, and fusing a text score and a result score during the output, the strong text processing capability of the pre-training language model is prevented from covering the structure information provided in the prompt, and the quality of the knowledge graph in the search engine is improved; meanwhile, a relation perception attention mechanism is added in a decoupling graph learning device, decoupling is carried out according to different meanings represented by entities in different triads, the structure information of the knowledge graph can be transmitted to the text information more accurately, the text information can be utilized by the structure information more selectively, and the knowledge graph learning efficiency is improved. The balance during fusion of the structural information and the text information is achieved, and the accuracy of the knowledge graph in the search engine is improved.",UNIV HANGZHOU DIANZI,ZENG YUHANG;;XU XIAOLIANG;;GENG YUXIA;;ZHU RUNKAI,,https://lens.org/093-147-039-519-062,Patent Application,no,0,0,1,093-147-039-519-062,CN,1,093-147-039-519-062,CN,0,G06N5/022;;G06N3/042,G06N5/022;;G06N3/042,,0,0,,,,PENDING
116,CN,A,CN 118609149 A,144-812-133-998-720,9/6/2024,2024,CN 202410648143 A,5/23/2024,CN 202410648143 A,5/23/2024,Target detection method and system based on prompt project and regional text description,"The invention discloses a target detection method and system based on prompt engineering and regional text description, and the method comprises the steps: constructing an annotated data set which comprises a plurality of annotated images; constructing a target detection model with region attribute description, wherein the target detection model with the region attribute description is a new model formed by adding an adaptive region feature extraction module and a text generation decoding module on the basis of an RTDetr model structure; based on the labeled data set, performing model training on the target detection model with the region attribute description to obtain a trained target detection model with the region attribute description; and obtaining a to-be-detected image, and performing target detection on the to-be-detected image by adopting the trained target detection model with the region attribute description to obtain a target prediction frame, a prediction category and the region attribute description. The problems that target detection fine classification affects model performance reduction and category attribute judgment are solved.",CHENGDU HENENG CHUANGYUE SOFTWARE CO LTD,TANG JUN;;XUE XIAOXUAN;;XIANG HUAFENG;;ZHANG JIEBIN;;ZHENG YI;;CHEN JIE,,https://lens.org/144-812-133-998-720,Patent Application,no,5,0,2,144-812-133-998-720;;187-129-043-812-578,CN,2,144-812-133-998-720;;187-129-043-812-578,CN,0,Y02T10/40,G06V30/412;;G06V10/25;;G06V10/764;;G06V10/774;;G06V10/82;;G06V30/146;;G06V30/19,,0,0,,,,ACTIVE
117,CN,A,CN 118071153 A,140-562-562-987-881,5/24/2024,2024,CN 202410458357 A,4/17/2024,CN 202410458357 A,4/17/2024,Construction safety risk prompting method and system based on BIM and large language model,"The invention provides a construction safety risk prompting method and system based on BIM and a large language model. According to the method, a local knowledge base is constructed based on a construction safety management field data set, and construction safety management field knowledge is provided for a large language model; meanwhile, association with work package information in the BIM model is carried out, and a large language model and a LangChain framework are used for constructing a construction safety management knowledge base question and answer model; and designing a prompt engineering auxiliary model to generate a reply to obtain construction safety risk prompt information of the work package. According to the method, intelligent questions and answers of the construction safety management knowledge base are realized, rapid and accurate safety risk information is provided for the user, the decision-making efficiency is improved, intelligent and efficient technical support is brought to construction safety management, and the construction safety risk is effectively reduced by generating reply and utilizing field data through customization.",CENTRAL SOUTH ARCHITECTURAL DESIGN INST CO LTD,ZHANG SHEN;;LI XUECHUN;;WANG XINGYU;;YIN PENGFEI;;YAN YU,,https://lens.org/140-562-562-987-881,Patent Application,no,4,0,1,140-562-562-987-881,CN,1,140-562-562-987-881,CN,0,G06Q10/0635;;G06Q50/08;;G06F30/13,G06Q10/0635;;G06F30/13;;G06Q50/08,,2,0,,,"LIMAO ZHANG 等: ""Bim-Based Risk Identification System in tunnel construction"", 《JOURNAL OF CIVIL ENGINEERING AND MANAGEMENT》, 27 April 2016 (2016-04-27), pages 529 - 537;;丁志坤: ""基于大语言模型的BIM正向设计问答系统研究"", 《土木工程与管理学报》, 29 February 2024 (2024-02-29), pages 2 - 4",DISCONTINUED
118,CN,A,CN 119398155 A,065-888-145-578-528,2/7/2025,2025,CN 202510005726 A,1/3/2025,CN 202510005726 A,1/3/2025,Metacognition and multi-angle prompt-based large language model knowledge graph completion method,"The invention discloses a large language model knowledge graph completion method based on meta-cognition and multi-angle prompt, relates to the technical field of knowledge graph completion, and solves the problem of magical property caused when knowledge graph completion is solved by adopting prompt engineering in the prior art. The knowledge graph completion method comprises the following steps of performing data extraction on a knowledge graph data set in a medical database, constructing an original knowledge graph structure of medical data according to the extracted data, performing initial embedding on the original knowledge graph structure, and enhancing embedding generation; optimizing the large language model by adopting a meta-cognition prompting method and a multi-angle prompting method; and enriching the enhanced and embedded original mapping knowledge domain structure by adopting the optimized large language model, wherein the enriched mapping knowledge domain contains new relationships and entities. The method is suitable for completing the knowledge graph in the medical database in the medical field.",UNIV CHANGCHUN,FENG PING,,https://lens.org/065-888-145-578-528,Patent Application,no,4,1,1,065-888-145-578-528,CN,1,065-888-145-578-528,CN,0,G06N5/022;;G06N5/04;;G06F40/30,G06N5/022;;G06F40/30;;G06N5/04,,2,0,,,"YUJIA ZHOU ET AL: ""Metacognitive Retrieval-Augmented Large Language Models"", 《ARXIV》, 18 February 2024 (2024-02-18), pages 1 - 11;;DERONG XU ET AL: ""Multi-perspective Improvement of Knowledge Graph Completion with Large Language Models"", 《ARXIV》, 4 March 2024 (2024-03-04), pages 1 - 13",PENDING
119,CN,A,CN 119312932 A,121-741-854-134-738,1/14/2025,2025,CN 202411495243 A,10/24/2024,CN 202411495243 A,10/24/2024,"Reading assistant processing method and device, all-in-one machine and storage medium","The invention provides a reading assistant processing method and device, an all-in-one machine and a storage medium, and relates to the technical field of intelligent reading, and the method does not depend on a preset script, and allows a user to initiate a conversation at any time in any reading stage, so that more natural and smooth user interaction experience is realized. Moreover, the general large language model adopted in the method does not need to depend on sample data in a specific field for pre-training, so that the collection cost of the sample data and the model training cost through the sample data can be reduced, and meanwhile, the limitation that a traditional model depends on the data in the specific field is broken through; and a more flexible and wide application scene is realized. Besides, the corresponding reading prompt information is determined by determining the demand information of the user, the prompt engineering technology is effectively used for stimulating and guiding the general large language model to generate more accurate and targeted reply content to be returned to the user, and the method has higher universality and adaptability.",IFLYTEK CO LTD,CHEN YUJUE;;ZHOU MO;;CHENG SI,,https://lens.org/121-741-854-134-738,Patent Application,no,0,0,1,121-741-854-134-738,CN,1,121-741-854-134-738,CN,0,G06N5/041;;G06N20/00;;G06F40/20,G06N5/04;;G06F40/20;;G06N20/00,,0,0,,,,PENDING
120,US,A1,US 2025/0209156 A1,179-978-515-713-495,6/26/2025,2025,US 202318393652 A,12/21/2023,US 202318393652 A,12/21/2023,SECURITY THREAT MITIGATION,"The present disclosure provides methods, systems and computer readable media for training and implementing a generative machine learning model for identifying and mitigating security threats. Certain examples relate to generative model training, in which a training image is provided to a generative machine learning (ML) model in a training prompt, with an Indicator of Compromise (IoC) prediction instruction pertaining to the first security image. The model generates a predicted IoC and a parameter of the model is updated based on a loss function that quantifies error between a ground truth IoC and the predicted IoC. Other examples relate to the use of trained generative models for cybersecurity. A mitigation prompt comprising a second security image and an associated mitigation instruction is provided to a trained generative model. The model outputs an indication of a cybersecurity mitigation action based on the mitigation prompt, and the cybersecurity mitigation action is performed on the system. Certain example embodiments identify and automatically mitigate security issues using a multimodal generative model (MGM) though appropriate prompt engineering.",MICROSOFT TECHNOLOGY LICENSING LLC,SANKARAN ANUSH;;MOVVA SRISUMA;;WICKER ANDREW WHITE;;BULUT MUHAMMED FATIH;;AILEM MELISSA,MICROSOFT TECHNOLOGY LICENSING LLC (2024-01-04),https://lens.org/179-978-515-713-495,Patent Application,yes,13,0,1,179-978-515-713-495,US,1,179-978-515-713-495,US,0,H04L63/1425;;H04L63/20;;G06F21/554;;G06N3/08;;G06F2221/034;;G06N3/0475;;H04L63/1441;;G06N3/045;;G06F21/554;;G06F2221/034;;G06N3/08;;G06N3/0475;;H04L63/20;;H04L63/1425;;H04L63/1441,G06F21/55;;G06N3/0475;;G06N3/08,,0,0,,,,PENDING
121,CN,A,CN 119831022 A,187-109-271-639-289,4/15/2025,2025,CN 202411822133 A,12/11/2024,CN 202411822133 A,12/11/2024,Construction method and device for domain-oriented knowledge graph,"The invention relates to a domain-oriented knowledge graph construction method and device, and the method comprises the steps: obtaining the related text data of a bid invitation file, carrying out the filtering of stop words, and constructing a text data sample set for training; constructing an entity type and a type guide vector by utilizing priori knowledge and a text data sample set, and generating a prompt engineering structure; performing domain self-learning training on the first preset language model to grasp bid invitation file auditing domain knowledge; performing comparative learning training on the second preset language model to identify a related entity; through entity identification and a thinking chain strategy, entity relationship prediction training is performed on the first language model to identify the relationship between entities, through the above mode, the accuracy of entity identification and information extraction is improved, the compliance and the high efficiency of bid invitation auditing work are ensured, and thus a more perfect knowledge graph is constructed.",SHENZHEN POWER SUPPLY BUREAU,YANG YAMING;;CHEN YILIANG;;BU HUILAN;;LIANG CHUHENG;;ZENG ZHILING;;KUMO TATSUTA;;WEI BO;;LIU KANGJUN;;ZENG YI;;LIN DONGMING;;LIAO HENG;;GAO FENG,,https://lens.org/187-109-271-639-289,Patent Application,no,0,0,1,187-109-271-639-289,CN,1,187-109-271-639-289,CN,0,,G06N5/025;;G06F16/36;;G06F40/295;;G06N20/00,,0,0,,,,PENDING
122,CN,A,CN 117892710 A,009-647-430-215-285,4/16/2024,2024,CN 202410107510 A,1/25/2024,CN 202410107510 A,1/25/2024,"Prompt template processing method and device, equipment and storage medium","The invention provides a prompt template processing method and device, equipment and a storage medium, and relates to the field of artificial intelligence, in particular to the technical fields of AI models, natural language processing, prompt engineering and the like. The method comprises the following steps: displaying a template debugging page, wherein the template debugging page comprises a model editing area, a template editing area and a model result display area; in response to an input operation in the model editing area, obtaining model information of a target model selected from the plurality of large language models; in response to an input operation in the template editing area, obtaining a to-be-debugged target prompt template; according to the model information and the target prompt template, calling the target model to obtain an execution result of the target model; in the model result display area, the execution result is displayed, and the execution result is used for assisting content adjustment of the target prompt template. Therefore, through visual debugging of the prompt template, the update efficiency of the prompt template is improved.",BEIJING BAIDU NETCOM SCI & TECH CO LTD,YE WENWEI,,https://lens.org/009-647-430-215-285,Patent Application,no,0,0,1,009-647-430-215-285,CN,1,009-647-430-215-285,CN,0,G06F40/186;;G06F3/0481,G06F40/186;;G06F3/0481,,0,0,,,,PENDING
123,CN,A,CN 117235248 A,184-793-690-239-276,12/15/2023,2023,CN 202311214755 A,9/20/2023,CN 202311214755 A,9/20/2023,Data visualization analysis method based on natural language large model,"The invention discloses a data visualization analysis method based on a natural language large model, and the method comprises the following steps: converting data into a business model through metadata annotation; converting the labeled metadata into a vector form, and storing the metadata; performing data exploration and analysis by using a natural language, and realizing intention recognition in combination with a large model reasoning technology; metadata information related to analysis is extracted from a vector library; combining the analysis intention with the associated metadata, and generating an SQL/DSL language by using a prompt engineering technology; executing the generated SQL/DSL language by using an analysis engine, and obtaining and analyzing data; according to user requirements and data types, a proper data visualization mode is selected, and the processed data is visually displayed visually, flexibly and efficiently. The method is mainly applied to the field of data visualization, a user can be helped to better analyze and understand the data in a natural language large model mode, and visual query and analysis of the data are rapidly achieved.",MERITDATA TECH CO LTD,CHENG HONGBIN;;LIU HONG;;QIANG JIN;;WANG KUN;;LI HONGJUAN;;PAN XULONG,,https://lens.org/184-793-690-239-276,Patent Application,no,0,4,1,184-793-690-239-276,CN,1,184-793-690-239-276,CN,0,Y02D10/00,G06F16/338;;G06F16/33;;G06F40/117;;G06F40/205;;G06F40/279;;G06N5/04,,0,0,,,,PENDING
124,CN,A,CN 119130931 A,021-031-452-324-852,12/13/2024,2024,CN 202411142402 A,8/20/2024,CN 202411142402 A,8/20/2024,Zero sample image anomaly detection method and device,"The invention provides a zero sample image anomaly detection method and device, and belongs to the field of computer vision and image anomaly detection. The method comprises the steps that an image of a to-be-detected target is input into a preset zero sample image anomaly detection network, the network comprises an image encoder and a text encoder, and through multi-mode prompt learning, the image encoder outputs local visual features of the image, and the text encoder outputs text features capable of being learned and prompted to be embedded; and calculating the cosine similarity of the local visual features and the text features and interpolating to obtain a similar graph, and measuring the similarity to obtain an abnormal graph so as to obtain an abnormal detection result of the input image. According to the method, the flexibility of feature representation and the generalization ability of prompt are enhanced by constructing multi-modal prompt learning, the complexity of manual design of prompt engineering can be reduced, and a better anomaly detection prompt can be constructed, so that the effect of a zero sample anomaly detection model is improved.",UNIV TSINGHUA,LIU HUAPING;;WANG JINHONG;;XU XINYING;;YUAN XIAOHU;;XIE GANG,,https://lens.org/021-031-452-324-852,Patent Application,no,0,2,1,021-031-452-324-852,CN,1,021-031-452-324-852,CN,0,G06T7/0004;;G06T2207/20081;;G06T2207/20084,G06T7/00,,0,0,,,,PENDING
125,WO,A1,WO 2025/066351 A1,061-568-770-527-349,4/3/2025,2025,CN 2024102021 W,6/27/2024,CN 202311283213 A,9/28/2023,QUESTION PROCESSING METHOD AND APPARATUS AND COMPUTING DEVICE CLUSTER,"A question processing method comprises: acquiring a question input by a user; on the basis of the question, iteratively filtering for actions from among a plurality of actions related to prompt engineering, wherein in a first round of iteration, the question is used to filter for an action, and in any round of iteration other than the first round of iteration, the question and content obtained by performing the action determined through filtering are used to filter for an action; and when the number of iteration rounds reaches a threshold or the action determined through filtering in the current round of iteration is a termination action, inputting a prompt to a large language model to obtain an answer related to the question, wherein the prompt comprises the question and the content obtained by performing the actions determined through filtering in the rounds of iteration. In this way, the question and the content obtained by performing the actions can be continuously enhanced and optimized, so that the prompt finally input to the large language model is most easily understandable by the large language model, and the accuracy of reasoning results of the large language model is further improved.",HUAWEI TECH CO LTD,LI YINCHUAN;;SONG SHAOMING;;SHAO YUNFENG,,https://lens.org/061-568-770-527-349,Patent Application,yes,7,0,2,097-315-884-021-398;;061-568-770-527-349,WO;;CN,2,097-315-884-021-398;;061-568-770-527-349,WO;;CN,0,G06F16/3329;;G06F16/3344;;G06F16/35;;G06F40/35;;G06N3/08;;G06N3/0455,G06F16/332;;G06F16/33;;G06F16/35;;G06F40/35;;G06N3/0455;;G06N3/08,,0,0,,,,PENDING
126,CN,A,CN 119848185 A,153-557-356-170-34X,4/18/2025,2025,CN 202411630183 A,11/14/2024,CN 202411630183 A,11/14/2024,"Question and answer enhancement method, device and equipment for operation and maintenance question and answer robot and medium","The invention relates to the technical field of computers, in particular to a question and answer enhancement method, device and equipment for an operation and maintenance question and answer robot and a medium. The method comprises the following steps: constructing a corpus vector database by adopting corpus texts comprising operation and maintenance problems and corresponding solutions; enhancing operation and maintenance problems in the corpus vector database by adopting a large language model and a prompt engineering technology, and associating corresponding solutions to obtain an enhanced vector database; receiving a question text to be answered, and converting the question text into vector representation; and matching the vector representation with the enhanced vector database to obtain a solution corresponding to the question text. According to the method and the device, the operation and maintenance problem in the corpus vector database is enhanced, so that the coverage range of the corpus is improved, various problems input by the user are easier to match, and therefore, the problems that the search of the operation and maintenance question-answering robot based on the vector depends on the quality of the vector model and the inevitable mismatching of the search occurs are solved; and the search accuracy is improved.",TIANYI CLOUD TECH CO LTD,MO CHUXIAN,,https://lens.org/153-557-356-170-34X,Patent Application,no,0,0,1,153-557-356-170-34X,CN,1,153-557-356-170-34X,CN,0,G06F16/3329;;G06F16/3347;;G06F16/383;;G06N5/041;;G06Q10/20;;G06Q10/10,G06F16/3329;;G06F16/334;;G06F16/383;;G06N5/04;;G06Q10/10;;G06Q10/20,,0,0,,,,PENDING
127,CN,A,CN 118779364 A,089-729-912-144-644,10/15/2024,2024,CN 202411112889 A,8/14/2024,CN 202411112889 A,8/14/2024,Complex information retrieval system and method,"The invention provides a complex information retrieval system and method, and belongs to the technical field of artificial intelligence, the complex information retrieval system comprises a knowledge graph module, a subgraph expansion generation module, an agent construction module, a distributed retrieval module, an answer generation module and a strategy optimization module; precise retrieval and association of professional knowledge are realized through cooperative work of intelligent agents such as sub-graph updating, query understanding, strategy retrieval and cross-graph matching; meanwhile, an open-source large language model is introduced into the system to generate answers, the professionalism and interpretability of the system are enhanced by prompting engineering and field adaptive fine tuning, the accuracy and practicability of retrieval are greatly improved by constructing a knowledge graph and multiple agents and utilizing distributed retrieval, and finally, the answers are generated by utilizing the large model, so that the system has high practicability. The system can be widely applied to intelligent questions and answers, expert systems, auxiliary writing and other scenes, and has a good application prospect.",SHANDONG INSPUR SCIENCE RESEARCH INSTITUTE CO LTD,SONG CHEN;;DUAN QIANG;;LI ZHAOCHUAN;;JIANG KAI;;LI RUI;;LI JINPING,,https://lens.org/089-729-912-144-644,Patent Application,no,0,7,1,089-729-912-144-644,CN,1,089-729-912-144-644,CN,0,G06F16/2471;;G06F16/248;;G06F16/24534;;G06F16/25;;G06N3/092;;G06N3/006;;G06N5/045,G06F16/2458;;G06F16/2453;;G06F16/248;;G06F16/25;;G06N3/006;;G06N3/092;;G06N5/045,,0,0,,,,PENDING
128,CN,A,CN 116483982 A,069-630-052-503-663,7/25/2023,2023,CN 202310745142 A,6/25/2023,CN 202310745142 A,6/25/2023,"Knowledge question and answer method and device, electronic equipment and readable storage medium","The invention discloses a knowledge question answering method and device, electronic equipment and a readable storage medium, and belongs to the technical field of artificial intelligence. The knowledge question-answering method in the embodiment of the invention comprises the steps of obtaining a target domain question; processing the target domain problem by using a pre-trained domain large model to obtain a query statement, and extracting target knowledge from a corresponding domain knowledge base according to the query statement; the target domain problem and the target knowledge are fused into a prompt template, and prompt data are obtained; and inputting the prompt data into the domain large model, and generating a question answer of the target domain question. Therefore, the answers to the domain questions can be flexibly and accurately obtained.",BEIJING ZHONGGUANCUN KEJIN TECH CO LTD,YU HAO;;ZHANG JIE,,https://lens.org/069-630-052-503-663,Patent Application,no,8,12,2,069-630-052-503-663;;150-874-279-651-739,CN,2,069-630-052-503-663;;150-874-279-651-739,CN,0,G06F16/3329;;G06F16/2433;;G06F16/33;;G06F40/186;;Y02D10/00,G06F16/332;;G06F16/242;;G06F16/33;;G06F40/186,,2,0,,,"韩旭 等: ""知识指导的预训练语言模型"", 《中兴通讯技术》;;HENDRIK STROBELT 等: ""Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models"", 《IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS》, vol. 29, no. 1, XP011930319, DOI: 10.1109/TVCG.2022.3209479",ACTIVE
129,US,B1,US 12243646 B1,056-788-807-881-960,3/4/2025,2025,US 202418659846 A,5/9/2024,US 202418659846 A;;US 202463554881 P,2/16/2024,Systems and methods for improving retrieval- augmented generation in clinical decision support,"Described are systems and methods for artificial intelligence (AI)-based clinical decision support. Systems can include a platform configured with a user input processing module, a context matching module, a retrieval-augmented generation (RAG) module, and an output generation module. Outputs of the platform can include a differential diagnosis, an assessment and treatment plan, or a clinical reference. The platform can further include an AI-copilot module and an AI-notebook module.",GLASS HEALTH INC,PAUL JR DERECK WILLIAM;;RAMSEY GRAHAM,GLASS HEALTH INC (2024-09-13),https://lens.org/056-788-807-881-960,Granted Patent,yes,3,2,1,056-788-807-881-960,US,1,056-788-807-881-960,US,0,G16H50/20;;G16H20/00;;G16H15/00;;G16H50/70;;G16H70/20;;G06F40/30;;G16H50/20;;G16H15/00;;G10L15/26;;G16H20/00,G06N20/00;;G10L15/26;;G16H15/00;;G16H20/00;;G16H50/20,,21,14,108-373-434-352-31X;;018-393-224-068-367;;117-856-566-119-133;;137-739-550-509-324;;106-426-395-718-406;;044-649-600-683-769;;027-143-396-469-620;;124-602-153-857-713;;181-057-392-863-367;;022-234-302-547-213;;062-936-914-088-641;;066-615-909-601-410;;127-077-891-632-897;;024-898-069-074-425,10.1017/s1351324920000601;;pmc6268174;;10.1038/s41568-018-0016-5;;29777175;;10.1109/mcse.2007.55;;35448987;;pmc9022417;;10.1186/s12880-022-00798-2;;10.1016/j.jacr.2023.06.008;;37423349;;33134913;;pmc7585692;;10.1093/braincomms/fcaa096;;pmc9668209;;10.1038/s41390-022-02226-1;;35906317;;10.1016/j.jacr.2023.05.003;;pmc10733745;;37356806;;10.1038/s42256-022-00536-x;;10.1016/j.jacr.2023.06.005;;37400048;;pmc7056641;;pmc7056644;;10.1038/s41592-020-0772-5;;32094914;;10.14293/s2199-1006.1.sor-life.a7056644.v1.rysreg;;32015543;;10.1002/9781119790686.ch16;;10.1016/j.jacr.2024.01.007;;38224925;;36639799;;10.1186/s12911-023-02103-9;;pmc9840286,"ACR Appropriateness Criteria®. Retrieved from Internet URL: https://www.acr.org/Clinical-Resources/ACR-Appropriateness-Criteria. pp. 1-4. [retrieved on Oct. 16, 2023]. Retrieved from the Internet on May 19, 2024.;;AI-Powered Clinical Decision Support. [Website] Glass Health. Retrieved from Internet URL: https://glass.health/. pp. 1-6. [retrieved on Oct. 16, 2023]. Retrieved from the Internet on May 19, 2024.;;Chen, Lingjiao et al. How is ChatGPT's behavior changing over time?. arXiv: pp. 1-26 (2023) Retrieved from Internet on May 19, 2024 URL: https://doi.org/10.48550/arXiv.2307.09009.;;Dale, Robert. GPT-3: What's it Good For?. Natural Language Engineering vol. 27,1: pp. 113-118 (2021).;;GPT-4. Published online Mar. 14, 2023. Retrieved from Internet URL: https://openai.com/index/gpt-4-research/. pp. 1-19. [retrieved on Oct. 16, 2023]. Retrieved from the Internet on May 19, 2024.;;Hosny, Ahmed et al. Artificial Intelligence In Radiology. Nature Reviews Cancer vol. 18,8: pp. 500-510 (2018).;;Hunter, John D et al. Matplotlib: A 2D Graphics Environment. Computing in Science & Engineering vol. 9,3: pp. 90-95 (2007).;;Kjelle, Elin et al. Characterizing And Quantifying Low-value Diagnostic Imaging Internationally: A Scoping Review. BMC Medical Imaging vol. 22,1: 73, pp. 1-28 (2022).;;Nazario-Johnson, Lleayem et al. Use of Large Language Models to Predict Neuroimaging. Journal of the American College of Radiology vol. 20,10: pp. 1004-1009 (2023).;;Pedersen, Mangor et al. Artificial Intelligence For Clinical Decision Support In Neurology. Brain Communications vol. 2,2: pp. 1-11 (2020).;;Ramgopal, Sriram et al. Artificial Intelligence-Based Clinical Decision Support In Pediatrics. Pediatric Research vol. 93,2: pp. 334-341 (2023). Published online Jul. 29, 2022.;;Rao, Arya et al. Evaluating GPT as an Adjunct for Radiologic Decision Making: GPT-4 Versus GPT-3.5 in a Breast Imaging Pilot. Journal of the American College of Radiology vol. 20,10: pp. 990-997 (2023).;;Saporta, Adriel et al. Benchmarking Saliency Methods For Chest X-ray Interpretation. Nature Machine Intelligence vol. 4: pp. 867-878 (2022).;;Sun, Chi et al. How to Fine-Tune BERT for Text Classification? ArXiv, 2019, /abs/1905.05583. Published on Feb. 5, 2020. Retrieved from the Internet URL:https://arxiv.org/abs/1905.05583 Retrieved on May 20, 2024.;;Varney, Elliot T et al. The Potential for Using ChatGPT to Improve Imaging Appropriateness. Journal of the American College of Radiology vol. 20,10: pp. 988-989 (2023).;;Vaswani, Ashish et al. Attention is All you Need. Advances in Neural Information Processing Systems, Proceedings of the 31st International Conference on Neural Information Processing Systems vol. 30: pp. 1-11 (2017).;;Virtanen, Pauli et al. SciPy 1.0: Fundamental Algorithms For Scientific Computing In Python. Nature Methods vol. 17,3: pp. 261-272 (2020).;;White, Jules et al. A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT. arXiv: pp. 1-19 (2023) Retrieved from Internet URL: https://doi.org/10.48550/arXiv.2302.11382.;;Young, Albert T et al. AI in Dermatology. AI in Clinical Medicine: A Practical Guide for Healthcare Professionals, First Edition, John Wiley & Sons, Ltd: pp. 165-175 (2023).;;Zaki, Hossam A et al. The Application of (LLMs) Large Language Models for Radiologic Decision Making. Journal of the American College of Radiology vol. S1546-1440,24: pp. 1-21 (2024).;;Zhang, Jie et al. Ethics And Governance Of Trustworthy Medical Artificial Intelligence. BMC Medical Informatics and Decision Making vol. 23,1: 7, pp. 1-15 (2023).",ACTIVE
130,WO,A1,WO 2025/011047 A1,095-156-074-082-182,1/16/2025,2025,CN 2024079567 W,3/1/2024,CN 202310833408 A,7/7/2023,"EVALUATION RESULT DISPLAY METHOD AND APPARATUS FOR PROMPT TEMPLATE, DEVICE AND STORAGE MEDIUM","The present application relates to the technical field of AI, and discloses an evaluation result display method and apparatus for a prompt template, a device and a storage medium. The method comprises: when prompt templates of an AI model are evaluated, respectively displaying evaluation results of the prompt templates in different regions of an evaluation result display interface on the basis of different evaluation dimensions in the form of evaluation marks, so that related personnel can visually know the local use effect of using different prompt templates on a same use case and the global use effect of using different prompt templates on an entire use case set. In this way, the display effect of evaluation results is effectively improved, related personnel can quickly and visually know the evaluation results, the human-computer interaction efficiency is improved, and then the evaluation efficiency and accuracy of the prompt templates are improved.",HUAWEI TECH CO LTD,ZHAO YITING;;MENG LIANG;;ZHAO YUHANG;;GAO TONG;;LI QIUHONG,,https://lens.org/095-156-074-082-182,Patent Application,yes,3,1,2,095-156-074-082-182;;169-738-541-864-195,WO;;CN,2,095-156-074-082-182;;169-738-541-864-195,WO;;CN,0,G06F9/451;;G06F3/0482;;G06F3/04847;;G06F3/0486;;G06F40/186;;G06F16/3329;;G06F3/04847;;G06F3/0486;;G06F3/0482;;G06F16/3329;;G06F40/186;;G06F9/451,G06F9/451,,1,1,165-689-824-574-442,10.1109/tvcg.2022.3209479;;36191099,"HENDRIK STROBELT; ALBERT WEBSON; VICTOR SANH; BENJAMIN HOOVER; JOHANNA BEYER; HANSPETER PFISTER; ALEXANDER M. RUSH: ""Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 16 August 2022 (2022-08-16), 201 Olin Library Cornell University Ithaca, NY 14853, XP091295657",PENDING
131,CN,A,CN 119917403 A,099-902-937-169-433,5/2/2025,2025,CN 202411757541 A,12/3/2024,CN 202411713918 A,11/27/2024,Automatic penetration testing method and system with large language model as kernel,"The invention discloses an automatic penetration testing method and system with a large language model as a kernel. Comprising the steps of obtaining original text information of a test target and a penetration test task; cleaning information; performing vulnerability type prediction; generating a vulnerability test case by using the large model; generating a penetration test strategy, converting the penetration test strategy into a test script and automatically executing the test script to generate an execution result; and judging whether the test is completed or not, if not, integrating the test record and regenerating a test strategy, and if so, forming a test report. The steps are realized by adopting a large language model. According to the method, multiple capabilities of reasoning, understanding, code generation, basic safety knowledge reserve and the like required in fit and penetration test engineering in a large model are utilized, the capability of solving penetration test subtasks of the large model is improved through multiple strategies such as Prompt engineering, and a set of system which takes the large model as an execution kernel and can realize automatic penetration test is constructed. And a new technical means is provided for automatic penetration testing.",UNIV HANGZHOU DIANZI;;UNIV ZHEJIANG,FU LIRONG;;HUANG WEIGANG;;LIU PEIYU;;WANG WENHAI,,https://lens.org/099-902-937-169-433,Patent Application,no,0,0,1,099-902-937-169-433,CN,1,099-902-937-169-433,CN,0,,G06F11/3668;;G06F21/57,,0,0,,,,PENDING
132,CN,A,CN 118568650 A,134-608-114-671-73X,8/30/2024,2024,CN 202411059783 A,8/5/2024,CN 202411059783 A,8/5/2024,Industrial anomaly detection method and system based on fine-grained text prompt feature engineering,"The invention belongs to the technical field of computer vision and image recognition, and provides an industrial anomaly detection method and system based on fine-grained text prompt feature engineering, and the method comprises the steps: extracting text features, image block features and image features of an industrial image; optimizing and updating the text prompt by using the image features to obtain fine-grained text prompt features; performing similarity comparative analysis on the image block features and the fine-grained text prompt features, and adding and fusing abnormal result images generated by comparison to obtain a final abnormal detection result; and optimizing parameters of the model to minimize a loss function, and carrying out anomaly detection on the test set by utilizing the trained model. According to the invention, for few-sample industrial image anomaly detection, an anomaly detection model framework is established through the feature extraction module, the fine-grained text prompt engineering module and the cross-modal spatial domain multi-granularity interaction module, and the generalization ability of the model is improved.",SHANDONG COMPUTER SCIENCE CT NAT SUPERCOMPUTER CT JINAN,HAN DELONG;;ZHOU MINGLE;;LI GANG;;LI MIN;;WAN JIN;;LI JIACHEN;;XU LUO,,https://lens.org/134-608-114-671-73X,Patent Application,no,6,2,2,124-617-789-105-148;;134-608-114-671-73X,CN,2,124-617-789-105-148;;134-608-114-671-73X,CN,0,G06F18/2433;;G06F18/253;;G06V10/764;;G06V10/26;;G06V20/70;;G06V10/454;;G06V10/806;;G06V10/82;;G06F40/30;;G06N3/0464;;G06N3/0455;;G06N3/048,G06F18/2433;;G06F18/25;;G06F40/30;;G06N3/0455;;G06N3/0464;;G06N3/048;;G06V10/26;;G06V10/44;;G06V10/764;;G06V10/80;;G06V10/82;;G06V20/70,,2,1,138-370-028-753-286,10.3390/app13095649,"ZHANG, QIANJUN；YUAN, JIN: ""Semantic-Aligned Cross-Modal Visual Grounding Network with Transformers"", 《 APPLIED SCIENCES-BASEL》, 4 May 2023 (2023-05-04), pages 1 - 17;;邓旭冉;闵少波;徐静远;李攀登;谢洪涛;张勇东;: ""深度细粒度图像识别研究综述"", 南京信息工程大学学报(自然科学版), no. 06, 28 November 2019 (2019-11-28), pages 5 - 17",ACTIVE
133,CN,A,CN 119628918 A,119-094-451-960-47X,3/14/2025,2025,CN 202411772103 A,12/4/2024,CN 202411772103 A,12/4/2024,"Network attack threat trapping method, device and equipment","The invention relates to a network attack threat trapping method, device and equipment. Preprocessing and prompt engineering processing can be sequentially carried out on a Web intrusion request; judging whether the processed Web intrusion request is an attack request or not by utilizing a detection model, and if yes, generating an attack type result; constructing an attack knowledge base corresponding to different network attack types according to existing website resources and related data; according to an attack type result and attack content of the Web intrusion request, similar data are retrieved from the attack knowledge base; and splicing the attack content and the similar data, and inputting the spliced attack content and similar data into a first large language model to obtain a simulation response aiming at the attack content. According to the technical scheme, the type of the attack request can be accurately identified by using the detection model, and the detection capability is improved. And the obtained simulation response can perform more complex and flexible interaction with an attacker, so that attack behaviors can be better cheated and trapped.",UNIV NATIONAL DONG HWA;;SHANGHAI MOULE NETWORK TECH CO LTD,CHEN XIAOJUN;;ZHU MING;;SHANG XIA;;LUO QINGLAN;;CHEN NING;;SONG AIMI;;BAO XIAONAN;;LI XIAOBO;;ZHANG XUESONG;;XU HOUCHUN;;DENG GUANPING,,https://lens.org/119-094-451-960-47X,Patent Application,no,0,0,1,119-094-451-960-47X,CN,1,119-094-451-960-47X,CN,0,H04L63/1416;;H04L63/1425;;H04L63/1408;;H04L63/1491,H04L9/40,,0,0,,,,PENDING
134,CN,A,CN 119336743 A,180-826-704-941-30X,1/21/2025,2025,CN 202411559636 A,11/4/2024,CN 202411559636 A,11/4/2024,LMOps large model engineering platform and implementation method,"The invention discloses an LMOps large model engineering platform and an implementation method, the system comprises a data set management module, a sensitive word bank module, a data processing module, a model square module, a model fine tuning module, a model evaluation module, a module deployment module, a commercial large model module, a Prompt engineering module, an experience center module and a system management module, and the method comprises the steps of S1, managing data; s2, managing the model; s3, finely adjusting the model; s4, evaluating the model; s5, deploying the model; and S6, experiencing the model. According to the method, the capability is packaged into the platform through front and rear end programs, so that the technical threshold required by using a large model is reduced; the platform standardizes data standards and provides an efficient and visual data pipeline; a 1 + N low-cost deployment technology is supported, and the data and computing power cost is reduced; unified large model security, authority, interface and charging mechanisms are provided, and the engineering difficulty is reduced.",QIMING INFORMATION TECHNOLOGY CO LTD,QU YINGZHE;;SHAN XINGHANG;;PEI YILONG;;YU JIAXIN;;XU DIAN;;PING XIANGFAN;;DONG WENKANG;;ZHU SHUO;;ZHANG YONGHUI,,https://lens.org/180-826-704-941-30X,Patent Application,no,0,1,1,180-826-704-941-30X,CN,1,180-826-704-941-30X,CN,0,G06F16/215;;G06F16/23;;G06F16/219;;G06F8/60;;G06N20/00;;G06Q30/0283;;G06F40/284;;G06N3/0455;;G06N3/0985;;G06N5/022;;G06N5/041,G06F16/215;;G06F8/60;;G06F16/21;;G06F16/23;;G06F40/284;;G06N3/0455;;G06N3/0985;;G06N5/022;;G06N5/04;;G06N20/00;;G06Q30/0283,,0,0,,,,PENDING
135,CN,A,CN 119623604 A,102-379-893-676-822,3/14/2025,2025,CN 202510148562 A,2/11/2025,CN 202510148562 A,2/11/2025,"Archive knowledge editing and research method, system and equipment and storage medium","The invention provides an archive knowledge editing and research method, system and device and a storage medium, and the method comprises the steps: obtaining editing and research demand information and an archive knowledge graph, and rewriting the editing and research demand information through employing a prompt engineering technology, and obtaining an editing and research description; in the archive knowledge graph, determining and recalling a target tetrad matched with the editing and research description; determining an additional feature according to a demand type associated with the editing and research description, and associating the additional feature with the target tetrad; and taking the target tetrad, the source text associated with the target tetrad, the additional features associated with the target tetrad and the editing and research description as input information of a large language model, and outputting an archive knowledge editing and research result through the large language model. According to the technical scheme, the accuracy level of the input instruction of the large language model is improved, the illusion of the large language model can be overcome, and the credibility and the text quality of the target editing and research content output by the large language model are improved.",STATE GRID TIANJIN ELECTRIC POWER COMPANY CHENGDONG POWER SUPPLY BRANCH;;STATE GRID TIANJIN ELECTRIC POWER CO;;STATE GRID CORP CHINA,LIU HONGLIANG;;SONG HUI;;FAN WENFANG;;GAO JUNYAN;;NIU LI;;ZHAO FENGSONG;;LIU LICHAO;;LIU TINGTING;;YE QINGWU;;ZHENG SHUSHU;;LU YINGXUAN;;SHI MENG;;WU FAN;;WANG KAI,,https://lens.org/102-379-893-676-822,Patent Application,no,7,1,2,102-379-893-676-822;;100-303-021-783-168,CN,2,102-379-893-676-822;;100-303-021-783-168,CN,0,G06N5/022;;G06N5/041,G06N5/022;;G06N5/04,,0,0,,,,ACTIVE
136,CN,A,CN 117786091 A,003-837-861-694-23X,3/29/2024,2024,CN 202410186105 A,2/20/2024,CN 202410186105 A,2/20/2024,Self-inspiration intelligent question answering implementation method and system based on Scogla bottom type question asking,"The invention discloses a self-inspiration intelligent question answering implementation method and system based on Scogla bottom type questioning, and belongs to the field of large language model prompt engineering. According to the self-inspiration intelligent question answering implementation method based on the Scotch bottom type question, the original question is continuously questioned, evaluated and answered, the summary is finally generated, and the accuracy, comprehensiveness and leakproofness of question answering of a large language model are improved. The self-inspiration intelligent question-answering implementation system based on the Scotch bottom type question comprises a question-answering module, a Scotch bottom type question-tracing module, a question-tracing quality evaluation module and a question-answering summarization module. The method aims at improving the self-heuristic ability of the large language model, promoting the large language model to deeply understand and deeply answer input questions, getting rid of prejudice and unfairness, overcoming factual errors and model illusion, and finally improving the safety, accuracy, comprehensiveness and logic preciseness of the large language model.",NO 32806 TROOPS OF PLA,JI HAORAN;;WANG QIAN;;CHANG YUAN;;XU YINGJIE;;NIU CHENGJIE;;WANG YANZHEN,,https://lens.org/003-837-861-694-23X,Patent Application,no,8,3,2,003-837-861-694-23X;;172-298-736-402-996,CN,2,003-837-861-694-23X;;172-298-736-402-996,CN,0,,G06F16/332;;G06F16/33;;G06N3/0455;;G06N5/01;;G06N5/04,,0,0,,,,ACTIVE
137,CN,A,CN 119377411 A,052-566-069-498-345,1/28/2025,2025,CN 202411973890 A,12/30/2024,CN 202411973890 A,12/30/2024,Acute coronary syndrome classification prediction method and related equipment,"The invention relates to an acute coronary syndrome classification prediction method and related equipment. The method comprises the following steps: acquiring original information which is input by a user and comprises an acute coronary syndrome classification task about a target patient, and acquiring a hospital admission record text and target case information of the target patient; interacting with a user to determine the task content of the classification task, and constructing a cue word based on the task content; searching a plurality of historical admission record texts most similar to the admission record text of the target patient in a retrieval library as associated admission records; and inputting the classification task, the cue word and the associated admission record into a large language model, and processing the classification task by the model based on the cue word and the associated admission record to obtain the acute coronary syndrome category of the target patient. According to the method, the big language model is adopted to process the acute coronary syndrome classification task, resources consumed when the scheme is implemented are reduced, and the classification prediction performance and accuracy of the model are improved in combination with multiple prompt engineering technologies.",XUANWU HOSPITAL CAPITAL MEDICAL UNIV;;UNIV CAPITAL MEDICAL SCIENCES;;UNIV BEIJING POSTS & TELECOMM;;THE SECOND MEDICAL CENTER OF CHINESE PLA GENERAL HOSPITAL,LIU HONGLEI;;XIA JINGGANG;;YANG YUQING;;TAO TIANQI;;LEE YOUNG-HO;;MAO SHUAI;;GUO CHENGLONG;;WU DEWEI;;QIAN HAO;;WANG XIULING;;JING FUYU;;GUO WEIHONG,,https://lens.org/052-566-069-498-345,Patent Application,no,4,0,1,052-566-069-498-345,CN,1,052-566-069-498-345,CN,0,G06F16/35;;G16H50/70;;Y02A90/10,G06F16/35;;G16H50/70,,0,0,,,,PENDING
138,CN,A,CN 117828097 A,137-407-997-038-855,4/5/2024,2024,CN 202311827869 A,12/27/2023,CN 202311827869 A,12/27/2023,LLM-based book knowledge problem index knowledge base construction method and system,"The invention relates to the technical field of knowledge base construction, and provides an LLM-based book knowledge problem index knowledge base construction method and system, and the method comprises the steps: collecting book knowledge text information, and constructing a book knowledge fragment set through segmenting the collected book knowledge text information; according to the constructed book knowledge fragment set, generating a corpus set through prompt prompt engineering configuration and an LLM large language model; constructing a problem index vector library and an auxiliary index vector library according to the generated corpus set; and establishing a book knowledge question index knowledge base by establishing a mapping relationship between the book knowledge fragment set and the question index vector library as well as the auxiliary index vector library. According to the LLM-based book knowledge question index knowledge base construction method and system, a user can more accurately search, extract, answer and answer book knowledge, and the availability and the utilization rate of the book knowledge are improved.",CHINA ELECTRIC DATA IND CO LTD;;CLP SHUCHUANG BEIJING TECH CO LTD,LU ZHIPENG;;GUO LI;;HAN GUANG;;ZHENG XI;;WANG XIAOLIANG;;LIU GUODONG;;FAN GUOHAO;;TANG CHAO;;WANG HUAN;;ZHANG WENQIN;;LI YIFAN;;LYU XUAN,,https://lens.org/137-407-997-038-855,Patent Application,no,0,2,1,137-407-997-038-855,CN,1,137-407-997-038-855,CN,0,G06F16/367;;G06F16/316;;G06F16/3329;;G06F16/3344;;G06F40/30;;Y02P90/30,G06F16/36;;G06F16/31;;G06F16/33;;G06F16/332;;G06F40/30,,0,0,,,,PENDING
139,CN,A,CN 119938698 A,113-163-300-469-390,5/6/2025,2025,CN 202510021341 A,1/7/2025,CN 202510021341 A,1/7/2025,Query generation method in Text2SQL (Structured Query Language) task based on large language model,"The invention discloses a query generation method in a Text2SQL (Structured Query Language) task based on a large language model, which comprises the following steps of: collecting statement information in a plurality of user interaction rounds, carrying out user dialogue intention identification according to a learning model and context tracking, and fusing the obtained dialogue intention information into a prompt; constructing a problem analysis model to obtain an analysis target result, wherein the analysis target result comprises user SQL query intention recognition and entity extraction; and identifying entities, conditions and sorting requirements involved in the question by utilizing the question analysis model, analyzing a mode of a required SQL structure, realizing SQL mode identification, obtaining a mapping relationship between the question and the SQL query to generate an SQL query statement meeting user requirements, and performing SQL query structure supervised fine adjustment on the generated SQL query statement. According to the method, the query generation method in the Text2SQL task emphasizing situation learning, new prompt engineering and supervised fine tuning can be realized.",TIANJIN UNIV,HU YITAO;;GAO JIAHENG;;LI KEQIU;;CHEN SHENG,,https://lens.org/113-163-300-469-390,Patent Application,no,0,0,1,113-163-300-469-390,CN,1,113-163-300-469-390,CN,0,Y02D10/00,G06F16/2452;;G06F16/22;;G06F16/242;;G06F16/28;;G06F16/3329;;G06F16/334;;G06F40/211;;G06F40/279;;G06F40/284;;G06F40/30,,0,0,,,,PENDING
140,CN,A,CN 117573879 A,099-755-105-815-60X,2/20/2024,2024,CN 202311376599 A,10/23/2023,CN 202311376599 A,10/23/2023,Efficient knowledge graph construction method and system,"The invention discloses an efficient knowledge graph construction method and system. The method comprises the following steps: obtaining structured data and unstructured data; performing triple recognition on the unstructured data to generate triple data; using an AIGC large model similar to chatGPT to carry out prompt engineering to carry out data marking; the method comprises the following steps of: performing fine adjustment on an AIGC large model similar to chatGPT by using pre-marked data to generate a triple identification module based on a data set of the AIGC large model; performing knowledge fusion on the triple data and the structured data in a database to generate new structured data; and generating a corresponding knowledge graph by using the obtained new structured data. According to the method, data marking is carried out by using an AIGC large model of chatGPT, so that the labor investment of graph construction is greatly reduced; and then fine tuning is carried out by using a chatGPT-like AIGC large model, so that the accuracy of triple recognition can be improved.",YUNJI WISDOM ENG CO LTD,CHEN WUJIN;;MENG RUI,,https://lens.org/099-755-105-815-60X,Patent Application,no,0,0,1,099-755-105-815-60X,CN,1,099-755-105-815-60X,CN,0,G06F16/367;;G06F16/35;;G06F40/289;;G06N5/022;;G06N3/0455;;G06N3/08;;Y02D10/00,G06F16/36;;G06F16/35;;G06F40/289;;G06N3/0455;;G06N3/08;;G06N5/022,,0,0,,,,PENDING
141,CN,A,CN 118248267 A,196-714-302-169-219,6/25/2024,2024,CN 202410423757 A,4/9/2024,CN 202410423757 A,4/9/2024,High polymer material characterization conversion method based on retrieval enhancement generation,"The invention discloses a high polymer material representation conversion method based on retrieval enhancement generation. The method comprises the following steps: defining a test data set, a knowledge base, a mixed retrieval coefficient, a large language model, a prompt engineering template, a calibrator, Morgan fingerprint similarity, bge similarity, BM25 similarity and a sampling number topn; aiming at each input in the test data set, traversing each example sample in the knowledge base; sorting the mixed similarities, and selecting topn example samples with the highest similarity from the mixed similarities; the input sample and the example sample are embedded into a prompt project template together to obtain complete input; and sending the complete input into a large language model for reasoning, and calibrating the output by a calibrator to obtain a final output. According to the method, the application of the high-molecular material characterization conversion method generated by retrieval enhancement in the high-molecular material is realized, fine adjustment on a high-molecular material data set is avoided, and the generalization ability of the method is improved on the premise of ensuring the conversion precision.",UNIV SHANGHAI,WU XING,,https://lens.org/196-714-302-169-219,Patent Application,no,0,0,1,196-714-302-169-219,CN,1,196-714-302-169-219,CN,0,G16C60/00;;G06N5/04,G16C60/00;;G06N5/04,,0,0,,,,PENDING
142,CN,A,CN 119226512 A,025-599-606-463-79X,12/31/2024,2024,CN 202411305734 A,9/18/2024,CN 202411305734 A,9/18/2024,Customer service session content classification method and device,"Embodiments of the invention provide a customer service session content classification method and apparatus. The method comprises the steps of obtaining a classification tree and customer service session data; integrating the classification trees to obtain a plurality of classification prompt texts of different levels; calling a preset large model to classify the customer service session data for the classification prompt text of each level to obtain a classification result of each level; and integrating the classification results of all levels to obtain a target classification result. Customer service sessions are summarized and classified by using Prompt engineering of a large model, so that classification can be performed based on a self-defined rule instead of training a classification model based on a traditional machine learning supervision method, the cost of classifying customer service session contents is reduced, classification is performed by adopting a hierarchical classification mode in the classification process, and the classification efficiency is improved. The problem of inaccurate classification summarization caused by one-time classification can be avoided, so that the accuracy of customer service session content classification is improved, and the classification effect is better.",SHANGHAI BILIBILI TECH CO LTD,LYU FAN,,https://lens.org/025-599-606-463-79X,Patent Application,no,0,0,1,025-599-606-463-79X,CN,1,025-599-606-463-79X,CN,0,,G06F16/35;;G06F18/243,,0,0,,,,PENDING
143,CN,A,CN 119357970 A,097-204-576-460-303,1/24/2025,2025,CN 202411260482 A,9/10/2024,CN 202411260482 A,9/10/2024,LLM enhancement-based step-by-step utilization method for project dependent library vulnerabilities,"The invention belongs to the technical field of software engineering, and particularly relates to a project dependency library vulnerability step-by-step utilization method based on LLM enhancement. The method comprises the following steps: carrying out lightweight dependency tree and call graph reachability analysis on a project, and identifying all reachability call chains from the project to a vulnerability method; decomposing the fuzz test on the whole call chain into a directional fuzz test on each step of method call in the call chain; in combination with static analysis and prompt engineering technologies, seed generation is assisted by semantic understanding of LLM on a current test function and utilization information generated by a previous test. And performing directional fuzzy testing by utilizing the generated seeds, analyzing execution paths of the seeds through an execution feedback mechanism, guiding selection and variation of the seeds, and finally generating effective input capable of successfully utilizing the project dependent library vulnerabilities. According to the method, developers can be helped to quickly position and timely repair vulnerabilities, so that risks and potential loss of projects caused by dependency on the vulnerabilities are reduced.",UNIV FUDAN,CHEN BIHUAN;;ZHOU ZHUOTONG;;PENG XIN;;ZHAO WENYUN,,https://lens.org/097-204-576-460-303,Patent Application,no,0,0,1,097-204-576-460-303,CN,1,097-204-576-460-303,CN,0,G06F21/577,G06F21/57,,0,0,,,,PENDING
144,CN,A,CN 119558684 A,120-842-913-355-247,3/4/2025,2025,CN 202411646709 A,11/18/2024,CN 202411646709 A,11/18/2024,Task-driven multi-agent emergency decision support method and device,"The invention relates to a task-driven multi-agent emergency decision support method and device, and the method comprises the steps: constructing a sub-task for a risk guidance decision support model, and dividing a complex task into simple sub-tasks, so as to achieve a more precise emergency decision support process; constructing an interaction agent of each subtask, and constructing corresponding prompt engineering contents according to the definition to realize the construction of analysis agents and inspection agents of different tasks; collecting safety analysis report data, and establishing a sample database supported by emergency operation instruction decision; performing model training, handing over the sample database to an intelligent agent, and constructing a success case library and a failure case library; over-benchmark originating event information is input, and a decision support procedure for the described originating event is generated. Therefore, the problems that an existing emergency plan decision-making method is extremely dependent on expert knowledge and is limited by human cognition, so that field personnel are difficult to make quick decisions on events exceeding the emergency plan and the like are solved.",UNIV TSINGHUA,LIANG JINGANG;;XIAO XINGYU;;TONG JIEJUAN;;WANG HAITAO,,https://lens.org/120-842-913-355-247,Patent Application,no,0,0,1,120-842-913-355-247,CN,1,120-842-913-355-247,CN,0,G06Q10/0637;;G06Q10/067;;G06Q50/26;;G06N3/006,G06Q10/0637;;G06N3/006;;G06Q10/067;;G06Q50/26,,0,0,,,,PENDING
145,US,A1,US 2025/0045802 A1,131-290-929-407-861,2/6/2025,2025,US 202418766829 A,7/9/2024,US 202418766829 A;;US 202363529814 P,7/31/2023,"AUTOMATED ACTIONABLE INSIGHTS AND CONTENT GENERATION BASED UPON LARGE LANGUAGE MODELS, MULTI-VIEW MACHINE LEARNING, AND GENERATIVE","An apparatus and method are provided, which provide automated analysis and generation of marketing or advertising content, e.g., using large language models (LLMs). The apparatus extracts specific insights from input advertisements, such as needs served, brand personas, products advertised, target audiences, tone, and topical categories. These insights are summarized in the formats commonly used in digital marketing, including brand evaluations, comparative analyses of campaigns, possible future advertising content examples, and examples of user personas together with the imaginary persona stories supporting them. The apparatus may leverage multi-modal prompt engineering to have LLM identify key features of advertisements, generalize analyses, present examples, and generate customer personas, stories, marketing content examples. Sample outputs include brand values and goals identification, persona analysis with examples, campaign differentiators comparison, and Artificial Intelligence (AI)-enhanced customer persona generation. The automation and scalability of such formerly manual marketing tasks provide actionable insights to facilitate rapid and informed decision-making.",FARSEEV ALEKSANDR,FARSEEV ALEKSANDR;;ONGPIN MARLO ANTONIO LEONARDO;;YANG QI;;HUANG HAOWEN ALFRED;;NIKOLENKO SERGEY;;LIPIKHIN KIRILL;;CHU YU-YI,,https://lens.org/131-290-929-407-861,Patent Application,yes,3,0,1,131-290-929-407-861,US,1,131-290-929-407-861,US,0,G06Q30/0277;;G06Q30/0269;;G06Q30/0251;;G06Q30/0244;;G06Q30/0276;;G06Q30/0269;;G06Q30/0244;;G06Q30/0251;;G06Q30/0277,G06Q30/0251;;G06Q30/0241;;G06Q30/0242,,0,0,,,,PENDING
146,CN,A,CN 116974912 A,137-559-779-561-448,10/31/2023,2023,CN 202310766740 A,6/27/2023,CN 202310766740 A,6/27/2023,System for carrying out visual evaluation by using synthetic data table,"The invention discloses a system for performing visual evaluation by using a synthetic data table. A data feature declaration module is used for receiving data specifications and sequentially performing specification analysis, data generation, data improvement and data output; the visual result display module is used for receiving visual drawing codes, synthesizing a data table and performing visual display on the data table; the visual drawing code is defined in a visual function, and the visual function provides a synthetic data table, DOM elements and an external library; the self-defined evaluation module is used for receiving the evaluation codes, the synthetic data tables and the visual drawing result, calculating evaluation indexes of the synthetic data tables and outputting the evaluation indexes as evaluation function return values; if the evaluation index calculation mode is not defined, default operation time for returning the visualization function; the evaluation code is defined in an evaluation function that provides a synthetic data table, DOM elements, and drawing instances. According to the method, the satisfiability model theory solver and the prompt engineering are combined, so that the evaluation efficiency of visualization workers is improved.",UNIV ZHEJIANG,WU YINGCAI;;JIN JUNJIE;;FU SIWEI,,https://lens.org/137-559-779-561-448,Patent Application,no,0,0,1,137-559-779-561-448,CN,1,137-559-779-561-448,CN,0,G06F11/3688;;G06F8/34;;G06F16/26;;G06F16/2282,G06F11/36;;G06F8/34;;G06F16/22;;G06F16/26,,0,0,,,,PENDING
147,CN,A,CN 118885621 A,118-374-088-870-372,11/1/2024,2024,CN 202310975604 A,8/3/2023,CN 202310975604 A,8/3/2023,Medical decision extraction method based on pre-training language model and prompt project,"The invention discloses a medical decision extraction method based on a pre-training language model and a prompt project. The method comprises the following steps: firstly, determining a lightweight information extraction model, such as GPLinker, and carrying out triple extraction on a medical decision text; then performing prompt engineering on the medical decision text and the medical decision triple, and extracting decision pseudo codes by using a large-scale pre-training language model, such as ChatGPT; and finally, converting the decision pseudo code into a preorder decision binary tree through an algorithm for converting the decision pseudo code into the preorder decision binary tree. The method is suitable for automatically extracting the diagnosis and treatment decision tree (complete binary tree) task from the clinical diagnosis and treatment text, and a more economical and powerful solution is brought to the task. A new decision representation method is provided, and a decision pseudo code formed by if-else and a natural language is used, so that semantic information in a decision tree is more complete and accurate, and higher accuracy and more possibilities are brought to a downstream medical decision scene.",UNIV EAST CHINA SCIENCE & TECH,WANG XIAOJUN;;YE QI;;HOU RUIHUI;;RUAN TONG;;LIU JINGPING;;ZHAI JIE,,https://lens.org/118-374-088-870-372,Patent Application,no,0,0,1,118-374-088-870-372,CN,1,118-374-088-870-372,CN,0,G06F16/367;;G06F16/334;;G16H50/70;;G06N20/00,G06F16/36;;G06F16/33;;G06N20/00;;G16H50/70,,0,0,,,,PENDING
148,US,A1,US 2024/0037810 A1,184-931-124-348-841,2/1/2024,2024,US 202217877935 A,7/30/2022,US 202217877935 A,7/30/2022,Techniques for Abstract Image Generation from Multimodal Inputs with Content Appropriateness Considerations,"A data processing system implements a receiving a textual input comprising a query for a first image. The data processing system also implements analyzing the textual input to determine a predicted color palette associated with a subject matter of the query; and procedurally generating the first image using the predicted color palette. Another implementation of the data processing system implements providing the textual input to a first machine learning model to obtain the first image, the first machine learning model being trained using a dataset comprising abstract imagery and analyzing the textual input using the first machine learning model to obtain the first image in response to receiving the textual input.",MICROSOFT TECHNOLOGY LICENSING LLC,GONG JULIA;;HU HOUDONG;;GUYMAN WILLIAM DOUGLAS,MICROSOFT TECHNOLOGY LICENSING LLC (2022-07-30),https://lens.org/184-931-124-348-841,Patent Application,yes,6,9,3,184-931-124-348-841;;128-463-601-630-773;;042-583-374-756-082,US;;WO,3,184-931-124-348-841;;128-463-601-630-773;;042-583-374-756-082,US;;WO,0,G06F16/54;;G06F16/5838;;G06T7/90;;G06F16/5838;;G06F16/53;;G06F40/30;;G06F40/20;;G06T7/0002;;G06T11/001;;G06T2207/10024;;G06T2207/20081;;G06T2207/20084,G06T11/00;;G06F16/53;;G06F16/583;;G06F40/20;;G06F40/30;;G06T7/00;;G06T7/90,,2,2,005-255-471-675-335;;095-053-794-199-504,10.1109/tip.2018.2866698;;30136942;;10.1145/3491102.3501825,"Tan, W. and Aguirre, H., ""Improved ArtGAN for Conditional Synthesis of Natural Image and Artwork"", IEEE Transactions on Image Processing, 2018 Aug 22, 28(1), 394-409. (Year: 2018);;40. Liu, V & Chilton, L.B. (2022, April). “Design Guidelines for Prompt Engineering Text-to-Image Generative Models.” In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems (pp. 1-23) (Year: 2022)",ACTIVE
149,US,A1,US 2025/0054003 A1,095-602-986-101-718,2/13/2025,2025,US 202418673378 A,5/24/2024,US 202418673378 A;;US 202363518335 P,8/9/2023,COMPUTER IMPLEMENTED METHODS AND COMPUTER SYSTEMS FOR AUTOMATING MARKET RESEARCH USING ARTIFICIAL INTELLIGENCE AGENTS,"A computer-implemented method and a computer system for automating market research is disclosed. The computer-implemented method includes receiving a query from a user within a Market Research System (MRS). Collecting context relevant to the query based on availability of internal information retrieval by querying the user with one or more clarification questions using one or more Artificial Intelligence (AI) agents. Forming a strategy to retrieve data from available data sources based on the context. Retrieving data from the available data sources based on the strategy. Analysing the data to determine if the retrieved data is sufficient to complete the research objective. Requesting modification or additional information in the data, responsive to the data not being determined as sufficient to complete the research objective. Determining market research parameters based on the analysed data. Iteratively optimizing market research parameters by activating the one or more AI agents.",PROAL INC;;PROAI INC,HUGHES CHASE,PROAL INC (2024-06-13),https://lens.org/095-602-986-101-718,Patent Application,yes,0,0,1,095-602-986-101-718,US,1,095-602-986-101-718,US,0,G06Q30/0204;;G06Q30/0202;;G06Q30/0206;;G06Q30/0203;;G06Q10/0637;;G06Q30/0201;;G06Q30/0202;;G06Q30/0203;;G06Q10/0637;;G06Q30/0206;;G06Q30/0204,G06Q30/0202;;G06Q10/0637;;G06Q30/0201;;G06Q30/0203;;G06Q30/0204,,0,0,,,,PENDING
150,CN,A,CN 118862864 A,054-461-740-963-998,10/29/2024,2024,CN 202411336445 A,9/25/2024,CN 202411336445 A,9/25/2024,"Instruction data generation method and device, electronic equipment and storage medium","The embodiment of the invention provides an instruction data generation method and device, electronic equipment and a storage medium, and relates to the technical field of computers.The instruction data generation method comprises the steps that preset initial instruction data is obtained; performing type analysis on the initial instruction data by utilizing a mapping agent, and generating instruction data of which the type is the same as that of the initial instruction data to obtain similar instruction data; executing a preset evolution strategy on the similar instruction data by utilizing an evolution intelligent agent to obtain multiple pieces of candidate instruction data; executing a preset evaluation strategy on each piece of candidate instruction data by utilizing an evaluation agent to obtain an evaluation result corresponding to each piece of candidate instruction data; the candidate instruction data with the evaluation result meeting a preset condition is determined as target instruction data, and the target instruction data is used for training a large language model. By applying the embodiment of the invention, the efficiency of generating the instruction data is improved while the labor cost is reduced.",ANT CLOUD TECH GROUP CO LTD,LI ZEHUI;;FENG QIAOYU;;GAO JINCHAN;;YUE XIU,,https://lens.org/054-461-740-963-998,Patent Application,no,5,0,2,086-039-397-004-753;;054-461-740-963-998,CN,2,086-039-397-004-753;;054-461-740-963-998,CN,0,G06F40/205;;G06N3/006;;G06N20/00,G06F40/205;;G06N3/006;;G06N20/00,,2,0,,,"机器之心: ""还在人工炼丹？自动提示工程指南来了，还带从头实现"", pages 1 - 17, Retrieved from the Internet <URL:https://www.jiqizhixin.com/articles/2024-09-10-4>;;QINYUAN YE 等: ""Prompt Engineering a Prompt Engineer"", pages 1 - 39, Retrieved from the Internet <URL:https://arxiv.org/abs/2311.05661>",ACTIVE
151,CN,A,CN 118196567 A,076-867-321-415-637,6/14/2024,2024,CN 202410606167 A,5/16/2024,CN 202410606167 A,5/16/2024,"Data evaluation method and device based on large language model, equipment and storage medium","The invention belongs to the technical field of computers, and particularly discloses a data evaluation method and device based on a large language model, equipment and a storage medium, and the method comprises the steps that first input is received, and the first input is used for determining data description content of a to-be-evaluated data set; in response to the first input, a first evaluation task cue word is generated based on the data description content, an evaluation task description template and a preset mapping relation, and the preset mapping relation is used for representing the corresponding position of a data description item in the data description content in the evaluation template; inputting the first evaluation task cue word to the large language model, and obtaining an evaluation result output by the large language model; and based on the hyper-parameter, the big language model evaluation result and the non-training statistical evaluation result, determining a data evaluation result through weighted summation. A large language model evaluation result and a non-training statistical evaluation result are fused based on hyper-parameters, so that the effectiveness of data evaluation is improved under the condition of keeping relatively low computing resource consumption.",UNIV WUHAN,LIU XIAOHUI;;HUANG ZIHENG;;WU JIANG;;CHEN YI;;HE MENGTING;;JIANG ZIKE;;OU GUIYAN,,https://lens.org/076-867-321-415-637,Patent Application,no,7,2,2,129-844-767-036-42X;;076-867-321-415-637,CN,2,129-844-767-036-42X;;076-867-321-415-637,CN,0,G06V10/776;;G06V10/774;;G06V10/945;;G06F3/0482;;G06F3/04847;;G06F3/04842;;G06N3/045;;G06V10/82,G06V10/776;;G06F3/0482;;G06F3/04842;;G06F3/04847;;G06N3/045;;G06V10/774;;G06V10/82;;G06V10/94,,2,1,000-998-434-925-521,37952004;;10.1007/s10928-023-09892-6,"SHIN EUIBEOM ET AL: ""Evaluation of prompt engineering strategies for pharmacokinetic data analysis with the ChatGPT large language model"", JOURNAL OF PHARMACOKINETICS AND PHARMACODYNAMICS, 11 November 2023 (2023-11-11);;刘春丽等: ""科学文献中的知识实体抽取与评价研究综述"", 现代情报, 19 October 2023 (2023-10-19)",ACTIVE
152,CN,A,CN 118429628 A,007-330-481-990-662,8/2/2024,2024,CN 202311662487 A,12/6/2023,CN 202311662487 A,12/6/2023,Vision and laser fusion tower crane hanging object segmentation method and system based on prompt project,"The invention discloses a vision and laser fusion tower crane hanging object segmentation method and system based on prompt engineering, and the method comprises the following steps: collecting laser radar point cloud data of a hanging object through a laser radar, and collecting image data of the hanging object through an image collection device; the open source data set Meta 11B is used for training the Meta DINOv2 model, the Meta DINOv2 model is optimized, and a visual large model supporting points and frames is obtained; extracting point cloud data used for generating prompt information from the laser radar point cloud data, and clustering and projecting the point cloud data to obtain point form prompt information and frame form prompt information; and based on the point-form prompt information, the frame-form prompt information and the image data, obtaining an image segmentation result by using a visual large model supporting points and frames, and according to the image segmentation result, rejecting non-conforming clustering points to complete segmentation of the hanging object. The purpose of accurately segmenting the hanging object in real time is achieved.",TENGHUI TECH BUILDING INTELLIGENT SHENZHEN CO LTD;;GUANGDONG GUANGSU INTELLIGENT EQUIPMENT CO LTD;;GUANGDONG TENGHUI INFORMATION TECH DEVELOPMENT CO LTD,JIANG HE;;AN MIN SU;;GE XIAODONG,,https://lens.org/007-330-481-990-662,Patent Application,no,7,0,2,185-810-363-113-041;;007-330-481-990-662,CN,2,185-810-363-113-041;;007-330-481-990-662,CN,0,G06V10/26;;G06V10/762;;G06V10/774;;G06V10/806;;G06V10/82;;G06N3/08,G06V10/26;;G06N3/08;;G06V10/762;;G06V10/774;;G06V10/80;;G06V10/82,,1,0,,,"WENKAI LI: ""A New Method for Segmenting Individual Trees from the Lider Point Cloud"", 《ENVIRONMENTAL SCIENCE》, 31 December 2012 (2012-12-31)",ACTIVE
153,CN,A,CN 117035076 A,081-713-987-181-485,11/10/2023,2023,CN 202310965763 A,8/2/2023,CN 202310965763 A,8/2/2023,Domain knowledge graph automatic construction method based on large language model and prompt project,"The invention relates to a domain knowledge graph automatic construction method based on a large language model and prompt engineering, and belongs to the field of natural language processing. The method comprises the following steps: firstly, inputting a task demand and a Wikipedia document into a retriever of a retrieval enhancement generation model for encoding to obtain a document index most relevant to the task demand; after related documents are found according to the obtained document indexes, the related documents and task requirements are input into a generator of a retrieval enhancement generation model, context information combining the related documents and the task requirements is obtained, then key events are obtained, and finally event extraction is conducted on the context information through a large language model; inputting the event into a Role-Play framework in a thinking tree chain prompt mode, performing an automatic feedback process of a large language model, and generating text data for constructing a domain knowledge graph; and finally, carrying out data cleaning on the fed-back text data to obtain a final domain knowledge graph. According to the method, the knowledge graph can be efficiently, accurately and automatically constructed.",UNIV KUNMING SCIENCE & TECHNOLOGY,WANG QINGWANG;;LI CHAOHUI;;WANG PANXIN;;JIANG TAO;;WANG MINGYE;;SHEN TAO;;SONG JIAN,,https://lens.org/081-713-987-181-485,Patent Application,no,0,7,1,081-713-987-181-485,CN,1,081-713-987-181-485,CN,0,G06N5/022;;G06N5/027;;G06N3/045;;G06F16/313;;G06F16/316;;G06F16/367;;G06F16/9024;;Y02D10/00,G06N5/022;;G06F16/31;;G06F16/36;;G06F16/901;;G06N3/045;;G06N5/02,,0,0,,,,PENDING
154,CN,A,CN 118136185 A,036-680-665-134-838,6/4/2024,2024,CN 202410417083 A,4/8/2024,CN 202410417083 A,4/8/2024,High polymer material characterization conversion method based on retrieval parameter proxy,"The invention discloses a high polymer material representation conversion method based on retrieval parameter proxy. The method comprises the following steps: defining a test data set, a large language model, a prompt engineering template, a calibrator, Morgan fingerprint similarity and bge similarity; for each input in the test data set, traversing each example sample in the knowledge base, and calculating the similarity between the example sample and the input; feeding the input into a retrieval parameter agent to generate a retrieval number; sorting the similarities, and selecting several example samples with the highest similarity from the sample samples according to the retrieval quantity in the previous step; the input sample and the example sample are embedded into a prompt project template together to obtain complete input; and sending the complete input into a large language model for reasoning, and calibrating the output by a calibrator to obtain a final output. According to the method, the application of the retrieval parameter proxy high polymer material characterization conversion method in the high polymer material is realized, the context characterization space of the material is greatly enhanced, the characterization conversion performance is improved, and the total retrieval amount is reduced.",UNIV SHANGHAI,WU XING,,https://lens.org/036-680-665-134-838,Patent Application,no,0,0,1,036-680-665-134-838,CN,1,036-680-665-134-838,CN,0,G16C60/00;;G06N5/04;;Y02P90/30,G16C60/00;;G06N5/04,,0,0,,,,PENDING
155,CN,A,CN 119476465 A,116-206-456-640-859,2/18/2025,2025,CN 202411300586 A,9/18/2024,CN 202411300586 A,9/18/2024,Interactive tactical analysis method for team sports based on large language model,"The invention discloses a team motion interactive tactical analysis method based on a large language model, which comprises the following steps: carrying out multi-modal alignment on a visually edited tactical board and a tactical description text, and extracting tactical knowledge from the aligned tactical image-text; customizing a scene based on the provided visual elements, extracting scene knowledge from the scene, and fusing the scene knowledge and the tactical knowledge to form domain knowledge; constructing a prompt project template for tactical analysis of the large language model; natural language input is carried out on the basis of the provided structured labels, input prompts are formed on the basis of domain knowledge and the input natural language in combination with a prompt engineering template, and the large language model carries out tactical analysis reasoning on the basis of the input prompts and visualizes tactical analysis results. According to the method, a user is allowed to completely express tactical intentions including complex spatio-temporal context information to a large language model in a visual mode, iterative reasoning can be carried out on a thinking chain, and a tactical analysis result easy to understand is output.",UNIV ZHEJIANG,XIE XIAO;;WU YINGCAI;;LIU ZI'AO,,https://lens.org/116-206-456-640-859,Patent Application,no,0,0,1,116-206-456-640-859,CN,1,116-206-456-640-859,CN,0,G06N5/04;;G06N5/022,G06N5/04;;G06N5/022,,0,0,,,,PENDING
156,CN,A,CN 119509541 A,102-321-439-226-571,2/25/2025,2025,CN 202411500441 A,10/25/2024,CN 202411500441 A,10/25/2024,Passive intelligent navigation system based on NLP technology,"The invention relates to the technical field of intelligent navigation, and provides a passive intelligent navigation system based on an NLP technology, which comprises a positioning module, a boundary early warning module, a voice conversion module, a voice recognition module, a prompt engineering module, a navigation module, a navigation text generation module, a voice generation module and a remote app management background, the positioning module acquires real-time position information of a user by using a positioning technology, the boundary early warning module is used for prompting the user to return a mode for the user to perform interaction selection through voice, and the voice conversion module and the voice recognition module convert received voice of the user into text information. The boundary early warning is triggered by adopting the geo-fencing technology, and the position of the user is monitored in real time and compared with the preset geo-fencing, so that the early warning can be given out when the user is about to leave the set area, the user is reminded to pay attention to safety, the user can be prevented from getting lost in an unfamiliar environment or entering a dangerous area, and the travel of the old is greatly facilitated.",HBIS DIGITAL TECH CO LTD,XU JINGCHENG;;ZHAO YU;;MA XIAOJIN;;YANG XIULI;;ZHAO WEIJIAN;;AN PENG,,https://lens.org/102-321-439-226-571,Patent Application,no,0,0,1,102-321-439-226-571,CN,1,102-321-439-226-571,CN,0,G01C21/20;;G01S19/46,G01C21/20;;G01S19/46,,0,0,,,,PENDING
157,CN,A,CN 119003715 A,126-590-932-332-665,11/22/2024,2024,CN 202411002563 A,7/25/2024,CN 202411002563 A,7/25/2024,Large model medical insurance knowledge question and answer method and device,"The invention relates to the technical field of RAG, and particularly provides a large-model medical insurance knowledge question and answer method and device, and the method comprises the following steps: S1, collecting medical insurance related knowledge, and sorting and storing the knowledge into Fiss; s2, generating an initial Prompt by a user through a Speech-to-Text technology or by directly typing in a question; s3, recalling Top5 of related knowledge by using an initial Prompt in a PQx product quantization recall retrieval mode of Fiss; s4, transforming the second-generation Prompt by using Prompt Engineering, and upgrading the second-generation Prompt into a third-generation Prompt so as to enable the Prompt to improve the emergence ability of the large model for the medical insurance knowledge to the maximum extent; s5, the third-generation Prompt is sent to the large model, and the large model answers the questions of the user through the knowledge background recalled in the third-generation Prompt; and S6, processing the hyperlink and the WeChat official account. Compared with the prior art, accurate, intelligent and efficient question and answer service can be provided for the user, and better operation and utilization of the medical insurance system are promoted.",INSPUR CLOUD INF TECH CO LTD,SU QINGHUA,,https://lens.org/126-590-932-332-665,Patent Application,no,0,0,1,126-590-932-332-665,CN,1,126-590-932-332-665,CN,0,G06F16/3329;;G06N5/041;;G06Q40/08;;G06Q50/26,G06F16/332;;G06N5/04;;G06Q40/08;;G06Q50/26,,0,0,,,,PENDING
158,CN,A,CN 119849444 A,179-718-442-452-720,4/18/2025,2025,CN 202411750813 A,12/2/2024,CN 202411750813 A,12/2/2024,Long document simplification method based on multi-agent large model,"The invention discloses a long document simplification method based on a multi-agent large model. The method comprises the following steps: 1) dividing and simulating role distribution of a human expert team, and driving a large language model to realize different role division by means of a role play prompt template; 2) performing overall planning on the original document, and generating information with global guidance for each subsequent simplification work; 3) performing preliminary simplification and iterative optimization on the original document; 4) performing more detailed simplification on the basis of the preliminary simplification; 5) reconstructing the plurality of simplified fragments subjected to multiple simplification operations into a whole simplified article and revising the whole simplified article; and 6) finely adjusting the open source model based on the generated parallel corpora to improve the document simplification capability. Through multi-agent cooperation, prompt engineering and hierarchical simplification strategies, the problems of grammar errors, semantic deviation, long document processing logic disorder and the like in an existing document simplification technology are solved, and the accuracy, fluency and information integrity of document simplification are improved.",UNIV YANGZHOU,QIANG JIPENG;;FANG DENGCHAO;;ZHU YI;;YUAN YUNHAO,,https://lens.org/179-718-442-452-720,Patent Application,no,0,0,1,179-718-442-452-720,CN,1,179-718-442-452-720,CN,0,G06F40/166;;G06F40/216,G06F40/166;;G06F40/216,,0,0,,,,PENDING
159,CN,A,CN 119048260 A,105-327-183-554-243,11/29/2024,2024,CN 202411130600 A,8/16/2024,CN 202411130600 A,8/16/2024,"Account adjusting method and device based on multi-modal data, equipment and storage medium","The invention discloses an account adjusting method, device and equipment based on multi-modal data and a storage medium, and relates to the technical field of data processing, and the method comprises the steps: carrying out the content recognition of multi-modal data uploaded by a user, and obtaining first key information; the first key information is input into a preset large language model for text conversion, second key information is obtained, and the preset large language model is obtained after an initial large language model is improved through Prompt engineering; determining a cost reduction type matched with the user based on the second key information, and defining input parameter information corresponding to the workflow engine according to the cost reduction type and the first key information; and calling a workflow engine according to the input parameter information, so that the workflow engine performs account adjustment on the user based on the input parameter information. Compared with a traditional account adjusting method, the account adjusting method has the advantages that the dependence on artificial experience is reduced while the account adjusting process is simplified, so that the account adjusting efficiency and the account adjusting accuracy are improved.",PSBC CONSUMER FINANCE CO LTD,LIAO ZIKAI;;ZHANG BINGBING,,https://lens.org/105-327-183-554-243,Patent Application,no,0,0,1,105-327-183-554-243,CN,1,105-327-183-554-243,CN,0,G06Q40/125;;G06F40/30;;G06V30/19;;G06N3/08;;G06N3/0499;;G10L15/18,G06Q40/12;;G06F40/30;;G06N3/0499;;G06N3/08;;G06V30/19;;G10L15/18,,0,0,,,,PENDING
160,WO,A1,WO 2025/053922 A1,184-167-767-216-956,3/13/2025,2025,US 2024/0039968 W,7/29/2024,US 202363580644 P;;US 202318483394 A,9/5/2023,MONITORING COMPLIANCE OF A GENERATIVE LANGUAGE MODEL WITH AN OUTPUT CHARACTERISTIC RUBRIC,"A computing system (10) for monitoring language model compliance with a rubric (35) of one or more output characteristics (35A). The computing system (10) includes processing circuitry (14) configured to interface with a trained generative language model (46) that receives input of a prompt including natural language text input (42) and, in response, generates an output (48) that includes natural language text output. The processing circuitry (14) is further configured to monitor compliance of the generative language model (46) with the rubric (35), by feeding the output (48) of the generative language model (46) to a rubric classifier (34) configured to generate a predicted classification (36) for an output characteristic in the rubric (35), and output the predicted classification (36).",MICROSOFT TECHNOLOGY LICENSING LLC,KRABACH BRIAN SCOTT;;PAYNE PAUL ROBERT;;SCHILLACE SAMUEL EDWARD,,https://lens.org/184-167-767-216-956,Patent Application,yes,1,0,1,184-167-767-216-956,WO,2,184-167-767-216-956;;106-713-208-964-110,US;;WO,0,G06F40/30;;G06F40/56;;G06N20/00;;G06N3/047;;G06N3/045,G06F40/30;;G06F40/56;;G06N20/00,,2,0,,,"BAOLIN PENG ET AL: ""Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 24 February 2023 (2023-02-24), XP091445331;;THOMAS F HESTON: ""Prompt Engineering For Students of Medicine and Their Teachers"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 8 August 2023 (2023-08-08), XP091597909",PENDING
161,CN,A,CN 118445419 A,019-699-276-960-486,8/6/2024,2024,CN 202410896359 A,7/5/2024,CN 202410896359 A,7/5/2024,"Method, device and equipment for constructing prompt automatic labeling medical text based on large model and medium","The invention belongs to the technical field of medical text labeling, and particularly provides a method, device and equipment for automatically labeling a medical text based on large model construction prompt, and a medium. The method comprises the following steps: preprocessing medical text data to generate a sentence sample; constructing an entity undifferentiated category Prompt template based on the sentence samples, and capturing general entity information in the medical text; based on the captured general entity information and a preset entity type, constructing an entity distinguishing category Prompt template, and capturing entity type information in the medical text; based on the captured entity type information and a preset general entity relationship type, constructing an entity relationship undistinguished category Prompt template, and capturing entity relationship general information in the medical text; and on the basis of the captured entity relationship general information, presetting an entity relationship type, constructing an entity relationship distinguishing category Prompt template, and capturing entity relationship category information in the medical text. And the labeling efficiency is improved.",NORTH HEALTH MEDICAL BIG DATA TECHNOLOGY CO LTD,LI TAO;;WANG HUI;;GUO HAOYU;;CAI ZHUOREN;;MA JIE;;JIN JIAN,,https://lens.org/019-699-276-960-486,Patent Application,no,5,0,2,019-699-276-960-486;;177-369-567-552-906,CN,2,019-699-276-960-486;;177-369-567-552-906,CN,0,G06F16/35;;G06F16/367;;G06F40/295;;G06F40/30;;G16H50/70,G06F16/35;;G06F16/36;;G06F40/295;;G06F40/30;;G16H50/70,,2,0,,,"G MARVIN 等: ""Prompt Engineering in Large Language Models"", 《INTERNATIONAL CONFERENCE ON DATA INTELLIGENCE AND COGNITIVE INFORMATICS》, 7 January 2024 (2024-01-07), pages 387 - 402;;赵文辉 等: ""基于prompt tuning的中文文本多领域情感分析研究"", 《计算机工程与科学》, 15 January 2024 (2024-01-15), pages 179 - 190",ACTIVE
162,CN,A,CN 119416987 A,145-334-233-748-078,2/11/2025,2025,CN 202510019373 A,1/7/2025,CN 202510019373 A,1/7/2025,Criminal period prediction method based on sentencing rule knowledge graph driving,"The invention discloses a criminal period prediction method based on sentencing rule knowledge graph driving, and belongs to the technical field of criminal period prediction, and the method specifically comprises the steps: analyzing laws and regulations and guidance suggestions related to case sentencing, constructing a sentencing rule knowledge graph from the top to the bottom from a mode layer to a data layer, and summarizing and concluding a sentencing thinking chain; according to thinking chain guidance, structured data prompt engineering of the knowledge graph is used for structuring and labeling the legal documents of the criminal case, and an SSP instruction fine adjustment data set is generated; and finally, performing supervised instruction fine tuning on the large language model by adopting a low-rank adaptive LoRA parameter efficient fine tuning strategy, generating a criminal period prediction model, and constructing an interpretable criminal period prediction system driven by the sentencing rule knowledge graph. The system combines a case input by a user, completes entity recognition and retrieval through a sentencing rule knowledge graph, realizes generation retrieval enhancement of a criminal period prediction model by utilizing prompt assembly, and optimizes a criminal period prediction result.",CHINA UNIV OF POLITICAL SCIENCE AND LAW,SHI JIANZHONG;;HAN LINRUI;;DU ZUWEI;;SONG SHIJI;;JUNG IL;;XU LINRUI,,https://lens.org/145-334-233-748-078,Patent Application,no,8,1,1,145-334-233-748-078,CN,1,145-334-233-748-078,CN,0,G06Q10/04;;G06Q50/18;;G06N5/025;;G06N5/045;;G06N3/0442;;G06N3/0455;;G06N3/047;;G06N3/09;;G06N3/096;;G06N3/084;;G06N3/0985;;G06F18/243;;G06F40/30;;G06F16/367;;Y02D10/00,G06Q10/04;;G06F16/36;;G06F18/243;;G06F40/30;;G06N3/0442;;G06N3/0455;;G06N3/047;;G06N3/084;;G06N3/09;;G06N3/096;;G06N3/0985;;G06N5/025;;G06N5/045;;G06Q50/18,,0,0,,,,PENDING
163,WO,A1,WO 2025/096229 A1,177-825-281-068-058,5/8/2025,2025,US 2024/0052168 W,10/21/2024,US 202318500211 A,11/2/2023,MULTI-MODAL ARTIFICIAL INTELLIGENCE ROOT CAUSE ANALYSIS,"A data processing system implements obtaining build logs that include information associated with a software build problem; analyzing the logs to generate a knowledge graph identifying the relationship between various entities in the logs; extracting a signature of a candidate root cause of the build problem from the knowledge graph representing a subset of nodes and edges of the knowledge graph; providing the signature of the candidate root cause to a graphical language model to obtain a prediction of a category of root cause failure selected from among a plurality of root cause failures; constructing a prompt for a language model to generate a root cause failure analysis that describes the root cause of the build problem, the prompt including the category of root cause; receiving the root cause failure analysis from the language model; and performing one or more actions in response to receiving the root cause failure analysis.",MICROSOFT TECHNOLOGY LICENSING LLC,KHOLODKOV DMITRY VALENTINOVICH;;BIERLEIN RANDEE,,https://lens.org/177-825-281-068-058,Patent Application,yes,1,0,2,177-825-281-068-058;;019-912-676-136-330,US;;WO,2,177-825-281-068-058;;019-912-676-136-330,US;;WO,0,G06F11/079;;G06N5/022;;G06N3/042;;G06N3/0475;;G06N3/0455;;G06F40/20;;G06F8/70;;G06F11/079,G06F11/07;;G06N5/022,,2,0,,,"YILUN LIU ET AL: ""LogPrompt: Prompt Engineering Towards Zero-Shot and Interpretable Log Analysis"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 15 August 2023 (2023-08-15), XP091593068;;YINFANG CHEN ET AL: ""Empowering Practical Root Cause Analysis by Large Language Models for Cloud Incidents"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 25 May 2023 (2023-05-25), XP091518983",PENDING
164,CN,A,CN 119962896 A,138-024-496-906-923,5/9/2025,2025,CN 202510046620 A,1/13/2025,CN 202510046620 A,1/13/2025,Intelligent operation and maintenance method for mine hoist based on large model,"An intelligent operation and maintenance method for a mine hoist based on a large model comprises the following steps: acquiring operation and maintenance data of the mine hoist, and fusing the operation and maintenance data; constructing an intelligent operation and maintenance model of the mine hoist; an open source model Llama-3 is adopted as a base model, and Adapter and LoRA technologies are adopted for supervision and fine tuning, so that an intelligent operation and maintenance model of the mine hoist is obtained; a knowledge base containing various technical documents is constructed, and a mine hoist intelligent operation and maintenance model based on the knowledge base is formed; adding a text embedding function and a retrieval function in the intelligent operation and maintenance model of the mine hoist based on the knowledge base to form a retrieval-enhanced intelligent operation and maintenance model of the knowledge base; the inference and decision-making capabilities of the retrieval-enhanced knowledge base intelligent operation and maintenance model are improved by utilizing a prompt engineering technology; and performing intelligent operation and maintenance on the mine hoist by using the retrieval-enhanced knowledge base intelligent operation and maintenance model. The method is beneficial to early warning of finding potential faults, and the operation and maintenance efficiency of the mine hoist can be remarkably improved.",CHINA UNIV OF MINING AND TECHNOLOGY;;XUZHOU KERUI MINE TECH CO LTD,YANG XU;;YU XIAOJIE;;ZHANG KEJIA;;LI YUNTING;;WANG SHUDONG;;NIU QIANG;;YANG LEI;;SUN JIPING;;TIAN ZIJIAN;;LIU NIANSHENG;;LIU XIN,,https://lens.org/138-024-496-906-923,Patent Application,no,0,0,1,138-024-496-906-923,CN,1,138-024-496-906-923,CN,0,,G06Q10/0631;;G06F16/35;;G06N3/0499;;G06N5/022;;G06Q10/20,,0,0,,,,PENDING
165,CN,A,CN 118210914 A,174-602-611-782-303,6/18/2024,2024,CN 202410309555 A,3/19/2024,CN 202410309555 A,3/19/2024,Data mining and analysis method based on LLM large model,"The invention discloses a data mining and analysis method based on an LLM large model, the large language model can retrieve related literatures including books, journal papers, conference papers and the like from a library knowledge base according to keywords, topics or problems of researchers, and can also evaluate the literatures according to abstract or full text content, so that the literatures can be extracted from the library knowledge base. The most relevant resources including the latest research papers, the top-level conference recording papers and the like are screened out and submitted to researchers, interaction is simple and easy to master, and the prompt project has universality. The universal large language model can be applied to text analysis in various fields, including interview texts in the education field, and popularization of the universal large language model means that the universal large language model can be widely applied to different education research and practice scenes; meanwhile, the interaction mode of the natural language instruction enables the analysis process to be more visual and user-friendly, and each person can guide the large language model to individually execute a private text analysis task by referring to the set of prompt engineering framework.",SUOANSAI DATA CHENGDU CO LTD,ZHANG YANYAN,,https://lens.org/174-602-611-782-303,Patent Application,no,0,7,1,174-602-611-782-303,CN,1,174-602-611-782-303,CN,0,G06F16/335;;G06F16/367;;G06F16/332;;G06Q50/205,G06F16/335;;G06F16/332;;G06F16/36;;G06Q50/20,,0,0,,,,PENDING
166,CN,A,CN 117744796 A,094-365-604-511-816,3/22/2024,2024,CN 202311732694 A,12/15/2023,CN 202311732694 A,12/15/2023,"Generative large model-based cue word construction method and apparatus, and intelligent device","The invention relates to the technical field of prompt engineering, and discloses a method for constructing cue words based on a generative large model, and the method comprises the steps: obtaining an initial cue word which indicates a generative model to input from a target question sentence to output from a target answer sentence, a training question and answer set corresponding to the initial cue word, and a test question and answer set corresponding to the initial cue word; wherein the test question and answer set and the training question and answer set represent the same specific task; generating an intermediate cue word according to the initial cue word, the training question and answer set and the test question and answer set; and optimizing the intermediate cue word according to the intermediate cue word and the test question and answer set to obtain an optimized cue word corresponding to the intermediate cue word. The prompt word constructed in real time through combination of the generation prompt and the optimization prompt can improve the performance of the large model in a specific task, so that the application requirement of the large model of the current version is met. The invention further discloses a device for constructing the cue word based on the generative large model and intelligent equipment.",QINGDAO HAIER REFRIGERATOR CO LTD;;QINGDAO HAIER INTELLIGENT TECHNOLOGY RES & DEV CO LTD;;HAIER SMART HOME CO LTD,XIE CHONG;;ZHANG KUI;;WANG JIAN;;KONG LINGLEI;;ZENG SHUIFEI;;LIU WEIQIANG;;LI MIN;;ZHANG JINGRUI;;WU GUOZHANG;;DOU ZHENDONG;;CHEN WEI;;WU HAIBIN;;LI GUIXI;;WANG WEIQING;;CHEN JINXIN;;XIONG LINGJING,,https://lens.org/094-365-604-511-816,Patent Application,no,0,3,1,094-365-604-511-816,CN,1,094-365-604-511-816,CN,0,,G06N5/04;;G06N3/0455;;G06N3/08,,0,0,,,,PENDING
167,CN,A,CN 119088921 A,050-016-983-907-762,12/6/2024,2024,CN 202411140592 A,8/20/2024,CN 202411140592 A,8/20/2024,Question and answer method and system for table knowledge extraction in water taking permission field,"The invention provides a question and answer method and system for table knowledge extraction in the field of water taking permission, and belongs to the technical field of natural language processing and large language models.The method comprises the steps that table structure reconstruction is conducted by obtaining a table in the field of water taking permission, and a text format table is obtained; performing knowledge extraction based on a large language model by adopting a prompt engineering mode according to the text format table to obtain structured fact triple data; according to the method, the big language model and table knowledge extraction are combined by utilizing the prompt project, so that various types of table knowledge can be accurately extracted. Constructing a knowledge graph database according to the fact triple data; obtaining a user retrieval question, and obtaining a target answer set according to the user retrieval question and the knowledge graph database; and inputting the target answer set into the large language model to output a retrieval result, so that the table in the water taking permission field can be efficiently analyzed, and rapid question and answer is realized. The utilization rate of the table content in the water taking permission field and the analysis efficiency are greatly improved.",CHANGJIANG WATER RESOURCES COMMISSION NETWORK AND INFORMATION CENTER,ZENG DEJING;;ZHANG JUN;;GUAN DANGGEN;;XU JING;;KE SHENGLIN;;WU HUI;;SUN LICHENG;;ZHANG FAN;;LUO LEI;;PAN LINGHUI,,https://lens.org/050-016-983-907-762,Patent Application,no,0,2,1,050-016-983-907-762,CN,1,050-016-983-907-762,CN,0,G06F16/3329;;G06F16/3334;;G06F16/3344;;G06F16/3347;;G06F16/335;;G06F16/35;;G06F40/30,G06F16/332;;G06F16/33;;G06F16/335;;G06F16/35;;G06F40/30,,0,0,,,,PENDING
168,CN,A,CN 119761486 A,139-929-979-711-701,4/4/2025,2025,CN 202411966825 A,12/30/2024,CN 202411966825 A,12/30/2024,Language model question and answer process acceleration method for medical consultation scene,"The invention relates to a medical consultation scene-oriented language model question and answer process acceleration method, and belongs to the field of prompt engineering. The method comprises the following steps: S1, starting a time window timer, initializing a cache region, and receiving a user question through an event-driven framework; s2, judging whether the time window is overtime or not, if the time window is not overtime, receiving continuous questions of a user by the cache region, refreshing the time window, and asynchronously executing a step S4; otherwise, executing the step S3; s3, integrating all questions in the cache region and transmitting the questions to a language model, generating corresponding replies by the language model, and then skipping to the step S1; s4, performing entity identification and classification on the question set in the cache region in the step S2 by using a medical entity dictionary; and S5, generating a plurality of predicted questions for the medical entities identified and classified in the step S4 according to rules. If the question is predicted to be clicked and confirmed by the user, submitting the question to a language model to generate a corresponding reply; otherwise, skipping to the step S2; according to the invention, the problem of lengthy and low-efficiency question and answer process caused by a'question-answer 'chain mode of the current language model can be solved.",UNIV CHONGQING POSTS & TELECOM,XIONG ANPING;;WANG ZIYU;;JIANG YI;;SHEN JINGCHENG,,https://lens.org/139-929-979-711-701,Patent Application,no,0,0,1,139-929-979-711-701,CN,1,139-929-979-711-701,CN,0,,G06N5/022;;G06F9/48;;G06F16/353;;G06F40/279;;G06N3/0455,,0,0,,,,PENDING
169,CN,A,CN 118092918 A,096-801-521-400-193,5/28/2024,2024,CN 202410530089 A,4/29/2024,CN 202410530089 A,4/29/2024,Website front-end development method and device based on wireframe diagram conversion and storage medium,"The invention provides a website front-end development method and device based on wireframe diagram conversion and a storage medium, and relates to the technical field of software engineering.The website front-end development method comprises the steps that image data are received, and effective information in the image data is converted into content convenient to understand by a language model; calling the large language model and optimizing the input by adopting a prompt engineering technology to obtain a first draft file; generating a plurality of first draft files at the same time, and scoring and screening the first draft files; modifying the optimal first draft file according to the received natural language input; calling the large language model to obtain a function code corresponding to the demand; based on a code injection algorithm, injecting a function level code into a corresponding position of the first draft file to realize page updating; and after the conversion of the plurality of groups of single pages is completed, realizing the butt joint of the plurality of single pages through a page routing allocation algorithm and window jump code injection, and generating a complete website front-end page. The website front-end development workload is reduced, and the development efficiency is improved.",UNIV NANKAI;;ADVANCED COMPUTING AND KEY SOFTWARE XINCHUANG HAIHE LABORATORY;;TIANKAI HONGTU TIANJIN TECH CO LTD,GUO CHENKAI;;WANG QIANLU;;WANG TIANHONG;;ZHU JINGWEN;;XIE XUESHUO,,https://lens.org/096-801-521-400-193,Patent Application,no,4,1,2,119-913-823-383-527;;096-801-521-400-193,CN,2,119-913-823-383-527;;096-801-521-400-193,CN,0,G06F8/38;;G06F16/958;;Y02T10/40,G06F8/38;;G06F16/958,,2,0,,,"WEIXIN_33774615: ""(Keras)基于深度学习SketchCode将线框原型图转换成HTML代码"", Retrieved from the Internet <URL:https://segmentfault.com/a/1190000014229550>;;张志航: ""基于深度学习的前端代码智能生成算法"", 《中国优秀硕士学位论文全文数据库信息科技辑》, no. 03, 15 March 2024 (2024-03-15)",PENDING
170,CN,A,CN 118887049 A,145-438-195-326-961,11/1/2024,2024,CN 202411397368 A,10/9/2024,CN 202411397368 A,10/9/2024,Electricity utilization safety monitoring method and system based on multi-agent large model ensemble learning,"The invention relates to the technical field of power utilization safety management, in particular to a power utilization safety monitoring method and system based on multi-agent large model ensemble learning. The method comprises the following steps: preprocessing power consumption data of a report submitted by a sensor, an intelligent electric meter or/and a user; based on the power utilization safety knowledge data of the power industry, constructing a power utilization safety knowledge base; based on the specific problem of power utilization safety analysis, constructing a power utilization safety analysis agent model; based on the electricity utilization safety analysis agent model, the preprocessed electricity utilization data is combined with an electricity utilization safety knowledge base to analyze the electricity utilization safety hidden danger, and an analysis result of the electricity utilization safety hidden danger is obtained; and monitoring the power utilization safety based on the analysis result of the power utilization potential safety hazard. By combining multi-agent large model ensemble learning and prompting engineering and field expert knowledge, the accuracy and the real-time performance of power utilization safety monitoring are remarkably improved, and meanwhile, the self-adaptability and the intelligent level of the system are enhanced.",BINHAI POWER SUPPLY COMPANY STATE GRID TIANJIN ELECTRIC POWER COMPANY;;STATE GRID TIANJIN ELECTRIC POWER CO,QI JIAN;;LIU XUN;;WANG CONG;;WANG HONGWEI;;JI HAO;;DUAN ZHITIAN;;LI ZHIYUAN;;SI MAKAI;;LI BOYANG;;LIU LEI,,https://lens.org/145-438-195-326-961,Patent Application,no,4,0,2,182-347-912-912-129;;145-438-195-326-961,CN,2,182-347-912-912-129;;145-438-195-326-961,CN,0,G06Q50/06;;G06N3/006;;G06N20/20;;G06Q10/0635,G06Q50/06;;G06N3/006;;G06N20/20;;G06Q10/0635,,0,0,,,,ACTIVE
171,CN,A,CN 118038188 A,028-636-069-218-391,5/14/2024,2024,CN 202410374535 A,3/29/2024,CN 202410374535 A,3/29/2024,Small sample anomaly detection method based on single-class prompt learning,"The invention discloses a small sample anomaly detection method based on single-class prompt learning, which is characterized in that a semantic splicing method is utilized to splice a learnable prompt and an anomaly suffix, an obtained negative sample is used for knowing a prompt learning process, and meanwhile, by displaying an anomaly boundary constraint, a learning result is obtained. According to the method, the abnormal prompt features and the normal prompt features have enough distance constraints, a network model has better abnormal detection and positioning prediction performance, and small sample abnormal detection specifically comprises the steps of data set collection and processing, visual feature and text feature extraction, prompt learning training, abnormal detection and positioning prediction and the like. Compared with the prior art, the method has better anomaly detection and positioning prediction performance, the prompt engineering cost is reduced, only a small amount of unlabeled normal sample data is needed for prompt learning, prompts more effective than manual labeling can be learned, the application cost of a large modulus in the field of industrial quality inspection can be greatly reduced, and the method is suitable for popularization and application. And furthermore, industrial intelligent quality inspection can be realized.",UNIV EAST CHINA NORMAL,LI XIAOFAN;;ZHANG ZHIZHONG;;TAN XIN;;XIE YUAN;;ZOU GUCHU;;QI ZHENYI;;MA LIZHUANG,,https://lens.org/028-636-069-218-391,Patent Application,no,0,0,1,028-636-069-218-391,CN,1,028-636-069-218-391,CN,0,G06V10/764;;G06V10/82;;G06V10/774;;G06T7/73;;G06V10/761;;G06T2207/20081;;G06T2207/20084,G06V10/764;;G06T7/73;;G06V10/74;;G06V10/774;;G06V10/82,,0,0,,,,PENDING
172,CN,A,CN 118862856 A,139-288-926-503-442,10/29/2024,2024,CN 202411105713 A,8/13/2024,CN 202411105713 A,8/13/2024,Long text report intelligent creation method and system based on large language model,"The invention provides a long text report intelligent creation method and system based on a large language model, and the method comprises the steps: extracting key information of input data, dividing different sub-task scenes according to the key information, and storing the different sub-task scenes in a mysql database; task descriptions and corresponding templates of different subtask scenes are obtained, related information is obtained based on the corresponding templates and task requirements, whether the word number of the related information obtained each time exceeds a word number threshold value or not is judged, and if the word number does not exceed the word number threshold value, the related information is directly obtained; if the word number exceeds the word number threshold value, re-splitting the sub-task scene into a plurality of hierarchical sub-task scenes, and sequentially obtaining related information corresponding to the split hierarchical sub-task scenes; performing prompt engineering processing on the related information, and generating a sub-task queue; and executing the subtask queues in sequence, and generating a long text report. The technical problems that in the existing long text report generation process, the number of output words is limited, and the content matching accuracy is low are solved.",TUDOU DATA TIME AND SPACE INTELLIGENT TECH DEQING CO LTD,WANG ZHEN;;KANG LONGBIAO;;ZHANG BO;;LI HAOJIE;;QUAN QINGQING,,https://lens.org/139-288-926-503-442,Patent Application,no,0,1,1,139-288-926-503-442,CN,1,139-288-926-503-442,CN,0,G06F40/186;;G06F9/4881,G06F40/186;;G06F9/48,,0,0,,,,PENDING
173,GB,A,GB 2636072 A,069-392-331-578-253,6/11/2025,2025,GB 202317797 A,11/21/2023,GB 202317797 A,11/21/2023,Energy chatbot method and system,"A method or system for generating responses to prompts S201 from a user to a large language model (LLM); the prompt corresponds to a question relating to energy consumption and/or energy generation of one or more devices; a template, comprising one or more data fields requiring completion, is selected S202 from a plurality of templates based on a determination by a trained classification model that the selected template has the highest probability of generating an accurate response from the LLM; a completed version of the template is obtained S203; the completed template is provided to the LLM S204, which generates a response S205. The classifier can use Random Forests (RTM) of decision trees. The completed template preferably includes sensor data – such as on time, energy consumed in kWh, energy tariff, charge level of an electric vehicle (EV), temperature, motion sensor data, demand response information from an electricity grid, or aggregated data – associated with at least one of the devices – such as a smart meter, smart thermostat, solar panel (108, fig.8), smart plug. The LLM output may be used by a control unit (803, fig.8) to control operation of the devices (101). Problem: prompt engineering to generate an accurate answer from an LLM chatbot.",CENTRICA PLC,GIUSEPPE VETTIGLI;;NICHOLAS JAMES BAILEY;;MIROSLAV HAMOUZ;;SARAN SUBRAMANIAN,,https://lens.org/069-392-331-578-253,Patent Application,no,1,0,2,198-971-886-597-97X;;069-392-331-578-253,GB;;EP,2,198-971-886-597-97X;;069-392-331-578-253,GB;;EP,0,G06Q50/06;;G06N5/01;;G06F16/332;;G06F16/3329;;G06F40/186;;G16Y20/10;;G16Y20/30;;G16Y40/35,G06F16/332;;G06F40/186;;G16Y20/10;;G16Y20/30;;G16Y40/35,,2,0,,,"GAMAGE et al., June 2023, ""Augmenting Industrial Chatbots in Energy Systems using ChatGPT Generative AI"", [online], Available from https://ieeexplore.ieee.org/document/10228101 [Accessed 30 May 2024];;LIU et al., January 2023, ""Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"", [online], Available from: https://dl.acm.org/doi/pdf/10.1145/3560815 [Accessed 21 May 2024]",PENDING
174,CN,A,CN 119007992 A,117-561-943-296-525,11/22/2024,2024,CN 202411495489 A,10/25/2024,CN 202411495489 A,10/25/2024,Ophthalmology automatic inquiry system based on large language model dynamic prompt project,"The invention provides an ophthalmology automatic inquiry system based on large language model dynamic prompt engineering, and relates to the technical field of medical health informatization and artificial intelligence auxiliary diagnosis, and the system comprises a chief complaint classifier which is used for carrying out the preliminary classification of chief complaints inputted by a user; the dynamic cue word generation module is used for selecting and splicing dynamic cue words from the cue word database according to the classification result of the chief complaint classifier; the question prompt word generation module is used for generating question prompt words containing identity definitions, dynamic prompt words and user complaints; and the large language model interaction module is used for generating a question list according to the generated question prompt words, sending the question list to the user, receiving answers of the user, obtaining analysis prompt words, and generating illness state classification and treatment suggestions according to the obtained analysis prompt words. According to the invention, the accuracy and personalization of the doctor-seeing suggestion are improved, the artificial participation of the doctor is reduced, and the user can conveniently consult at any time and assist the triage doctor in quickly knowing the illness state.",UNIV SOOCHOW,CHEN XINJIAN;;CHENG QIAN;;SHI FEI,,https://lens.org/117-561-943-296-525,Patent Application,no,6,1,1,117-561-943-296-525,CN,1,117-561-943-296-525,CN,0,G16H50/20;;G06F16/3329;;G06F16/35;;G06N3/045;;Y02A90/10,G16H50/20;;G06F16/332;;G06F16/35;;G06N3/045,,0,0,,,,PENDING
175,WO,A1,WO 2025/034371 A1,002-458-290-712-927,2/13/2025,2025,US 2024/0038312 W,7/17/2024,US 202318231064 A,8/7/2023,CONTEXT-AWARE AND DYNAMIC VISUALIZATIONS IN APPLICATIONS,"The technology relates to systems and methods for generating context-aware, dynamic visualizations. In an example, a method includes extracting a dynamic context signal; based on the dynamic context signal, retrieving a first visualization: causing a display of the first visualization as part of an application user interface; at an expiration of a refresh period, extracting an updated dynamic context signal; based on the updated dynamic context signal, retrieving a second visualization; and replacing the first visualization with the second visualization as part of an application user interface.",MICROSOFT TECHNOLOGY LICENSING LLC,RASTOGI ASTHA;;KOGANTI RAVI TEJA;;ALBARGHOUTHI TANIA;;CLINTON NATHANIEL T,,https://lens.org/002-458-290-712-927,Patent Application,yes,0,0,2,002-458-290-712-927;;161-401-464-416-625,US;;WO,2,002-458-290-712-927;;161-401-464-416-625,US;;WO,0,G06F9/451;;G06N3/0475;;G06N3/08;;G06T11/00;;G06T2200/24,G06F9/451,,5,2,013-164-034-721-192;;126-077-160-382-04X,10.1002/met.1589;;10.1145/3560835,"ZABINI FEDERICA: ""Mobile weather apps or the illusion of certainty : Uncertainty in mobile weather apps"", METEOROLOGICAL APPLICATIONS, vol. 23, no. 4, 1 October 2016 (2016-10-01), pages 663 - 670, XP093209488, ISSN: 1350-4827, Retrieved from the Internet <URL:https://api.wiley.com/onlinelibrary/tdm/v1/articles/10.1002%2Fmet.1589> DOI: 10.1002/met.1589;;YINGCHAOJIE FENG ET AL: ""PromptMagician: Interactive Prompt Engineering for Text-to-Image Creation"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 18 July 2023 (2023-07-18), XP091566132;;JIACHENG LIU ET AL: ""Generated Knowledge Prompting for Commonsense Reasoning"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 28 September 2022 (2022-09-28), XP091327265;;LIU VIVIAN VIVIAN@CS COLUMBIA EDU ET AL: ""Opal: Multimodal Image Generation for News Illustration"", PROCEEDINGS OF THE 2022 ACM WORKSHOP ON SOFTWARE SUPPLY CHAIN OFFENSIVE RESEARCH AND ECOSYSTEM DEFENSES, ACMPUB27, NEW YORK, NY, USA, 29 October 2022 (2022-10-29), pages 1 - 17, XP058968077, ISBN: 978-1-4503-9889-3, DOI: 10.1145/3526113.3545621;;ANONYMOUS: ""Prompt engineering - Wikipedia"", 4 August 2023 (2023-08-04), pages 1 - 11, XP093210029, Retrieved from the Internet <URL:https://en.wikipedia.org/w/index.php?title=Prompt_engineering&oldid=1168754994>",PENDING
176,CN,A,CN 118314533 A,126-218-315-800-75X,7/9/2024,2024,CN 202410440356 A,4/12/2024,CN 202410440356 A,4/12/2024,Roadside sensing method based on visual language multi-modal model,"The invention relates to a roadside sensing method based on a visual language multi-modal model, which is characterized in that a brand new thought of semantically enhancing an aerial view is used, and basic data obtained by a computer vision subtask is combined with the strong understanding and reasoning capability of a visual language large model; various traffic task requirements are met, comprehensive perception and understanding are achieved, and interactive roadside perception is achieved. The method comprises the following four steps of: 1, detecting and tracking a traffic target; 2, converting the aerial view and resolving multi-dimensional information; 3, fusing the data and inputting the data into a large language model to generate a semantic enhanced aerial view; and 4, inputting the large language model for dialogue interaction through prompt engineering design. The method has excellent performance in the aspects of traffic overall scene understanding, instance analysis, decision judgment, spatial reasoning and the like, realizes comprehensive perception and understanding of the intersection, and supports real-time dialogue interaction. The method has wide application prospect and value in the fields of auxiliary driving, automatic driving, high-precision navigation, traffic flow data detection and the like.",UNIV BEIHANG;;SHANGHAI ARTIFICIAL INTELLIGENCE INNOVATION CENTER,ZOU ZHENGXIA;;YE JINXI;;YU JIAYU;;JIANG WENBO;;SHI ZHENWEI,,https://lens.org/126-218-315-800-75X,Patent Application,no,0,1,1,126-218-315-800-75X,CN,1,126-218-315-800-75X,CN,0,G06V20/54;;G06V20/70;;G06V10/25;;G06V20/41;;G06T7/246;;G06T7/73;;G06T3/04;;G06V2201/07;;G06T2207/10016,G06V20/54;;G06T3/04;;G06T7/246;;G06T7/73;;G06V10/25;;G06V20/40;;G06V20/70,,0,0,,,,PENDING
177,US,A1,US 2025/0165465 A1,084-823-875-243-860,5/22/2025,2025,US 202418805207 A,8/14/2024,KR 20230163013 A,11/22/2023,INFORMATION PROVISION DEVICE,"An information provision device comprising: a processor; and a memory operatively coupled to the processor, wherein the memory stores instructions that, when executed, cause the processor to: receive user query data; classify a type of the user query data by using a first language model; generate, based on the classified type, a target prompt being one of a first prompt requesting conversion of the user query data into structured data and a second prompt requesting identification of information related to the user query data based on context data; and provide response data corresponding to the user query data by using the target prompt and a second language model.",DUNAMU INC,LEE DONG JUN;;KIM JAE HYUK;;PARK HEE SOO;;HWANG SEOK HYUN;;PARK SU JIN;;JEON HYUN HO;;KIM GA EUN;;NAM SANG HO,DUNAMU INC (2024-08-09),https://lens.org/084-823-875-243-860,Patent Application,yes,1,0,2,084-823-875-243-860;;049-677-719-427-973,US;;KR,2,084-823-875-243-860;;049-677-719-427-973,US;;KR,0,G06F16/285;;G06F16/24522;;G06F16/3329;;G06F16/3326;;G06F16/3332;;G06F16/338;;G06F16/35;;G06N3/0475;;G06N3/045;;G06N3/096;;G06F16/285;;G06F16/24522,G06F16/2452;;G06F16/28,,5,2,032-661-285-145-093;;102-484-451-186-206,10.18653/v1/2023.findings-emnlp.39;;10.2139/ssrn.4453664,"Sun, SQLPrompt: In-Context Text-to-SQL with Minimal Labeled Data, pp. 1-9, November 6, (Year: 2023);;Krause, Proper Generative AI Prompting for Financial Analysis, pp. 1-28, October 27 (Year: 2023);;Liu, Datacentric FinGPT: Democratizing Internet-scale Data for Financial Large Language Models, pp. 1-43, November 14 (Year: 2023);;Raschka, Machine Learning with PyTorch and Scikit-Learn, pp. 1-48, Feb (Year: 2022);;Thompson, A Brief Understanding of Prompt Engineering, pp. 1-17 Sept 14 (Year: 2023)",PENDING
178,US,A1,US 2025/0193268 A1,153-800-415-889-555,6/12/2025,2025,US 202318536427 A,12/12/2023,US 202318536427 A,12/12/2023,SUFFIX PROXIED WEB APPLICATION COLLABORATION,"In some embodiments, a collaboration feature overlays a web application by receiving a network communication that was redirected from the web application by a suffix proxy. The collaboration feature supplements or replaces activity of the web application by maintaining per-user-account activity states, deriving a shared collaboration state from the activity states, and supplying the shared collaboration state to multiple user accounts. The collaboration feature is installed without modifying the web application. The collaboration feature provides user accounts with a collaboration capability, such as shared document editing, chat rooms, shared calendars, or shared private workspaces. Some collaboration features overlay multiple web applications, even from different vendors, and some collaboration features support posting collaboratively created content to a website even when some contributors to the content are not registered users of the website. Some collaboration features impose stricter or different cybersecurity than an underlying website.",MICROSOFT TECHNOLOGY LICENSING LLC,MALIK VIKAS;;RAPPAPORT NIR MARDIKS;;BLACHMAN MEIR BARUCH,MICROSOFT TECHNOLOGY LICENSING LLC (2023-12-11),https://lens.org/153-800-415-889-555,Patent Application,yes,6,0,1,153-800-415-889-555,US,1,153-800-415-889-555,US,0,H04L67/02;;G06F16/955;;H04L63/10;;H04L67/56;;H04L67/02;;G06F16/955;;H04L63/10;;H04L67/56,H04L67/02;;G06F16/955;;H04L9/40;;H04L67/56,,0,0,,,,PENDING
179,US,A1,US 2025/0112878 A1,112-170-761-299-514,4/3/2025,2025,US 202318478702 A,9/29/2023,US 202318478702 A,9/29/2023,KNOWLEDGE GRAPH ASSISTED LARGE LANGUAGE MODELS,"Techniques for a knowledge-graph system to use large language models (LLMs) to build knowledge graphs to answer queries submitted to a chatbot by users. The knowledge-graph system builds the knowledge graph using answers produced by an LLM for novel queries. The chatbot will continue to use the LLM to answer novel queries, but the chatbot may harness the knowledge graph to answer repeat questions to gain various efficiencies over LLM-backed chatbots. For example, the knowledge-graph system may easily debug or otherwise improve the answers in knowledge graphs, store provenance information in knowledge graphs, and augment the knowledge graphs using other data sources. Thus, the reliability and correctness of chatbots will be improved as the bugs and inaccuracies in answers provided by the LLM will be corrected in the knowledge graphs, but the chatbots can still harness the abilities of LLMs to provide answers across various subject-matter domains.",AMAZON TECH INC,BAYLESS SAMUEL;;LABAI NADIA;;LASSILA ORA YRJO,AMAZON TECHNOLOGIES INC (2023-09-26),https://lens.org/112-170-761-299-514,Patent Application,yes,4,0,1,112-170-761-299-514,US,1,112-170-761-299-514,US,0,H04L51/02;;G06F40/20;;G06F40/35;;G06F40/20;;H04L51/02,H04L51/02;;G06F40/20,,0,0,,,,PENDING
180,CN,A,CN 119206122 A,168-001-567-415-942,12/27/2024,2024,CN 202411240869 A,9/5/2024,CN 202411240869 A,9/5/2024,Three-dimensional memory carrier generation method and device,"The invention provides a three-dimensional memory carrier generation method and device, and the method comprises the steps: generating a first style feature vector and a first semantic feature vector based on a first scene description text inputted by a target user, and extracting first keyword information based on a first to-be-memorized text inputted by the target user, inputting the first style feature vector and the first keyword information into a first combined neural network model to obtain first stylized keyword information output by the first combined neural network model, generating a first memory carrier model based on the first stylized keyword information, generating a first three-dimensional geometric scene model based on the first semantic feature vector, and generating a second three-dimensional geometric scene model based on the second semantic feature vector. And on the basis of the first semantic feature vector, the first memory carrier modeling and the first three-dimensional geometric scene modeling, the first memory carrier set modeling is generated, so that the matching degree between the memory carrier set modeling and the to-be-memorized text is improved to a certain extent, and the usability of the memory carrier geometric model is improved.",THE OPEN UNIV OF CHINA,WANG XULIANG;;LI JING;;LI YAJING,,https://lens.org/168-001-567-415-942,Patent Application,no,6,0,2,156-732-603-735-921;;168-001-567-415-942,CN,2,156-732-603-735-921;;168-001-567-415-942,CN,0,G06T17/10;;G06F40/30;;G06F16/345;;G06N3/045,G06T17/10;;G06F16/34;;G06F40/30;;G06N3/045,,2,0,,,"VIVIAN LIU 等: ""“Design Guidelines for Prompt Engineering Text-to-Image Generative Models”"", 《CHI \'22: PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS》, 29 April 2022 (2022-04-29), pages 1;;方菲: ""“基于文本的场景图像生成技术研究”"", 《中国博士学位论文全文数据库 (信息科技辑)》, 15 March 2024 (2024-03-15), pages 1 - 113",ACTIVE
181,CN,A,CN 118158119 A,037-882-600-850-907,6/7/2024,2024,CN 202410359916 A,3/27/2024,CN 202410359916 A,3/27/2024,Pre-training large model assisted end-to-end network intention decomposition and decision-making method,"The invention discloses an end-to-end network intention decomposition and decision-making method assisted by a pre-training large model. S101, inputting an end-to-end network intention related to centralized management; s102, optimizing an end-to-end network intention input by a user based on Prompt engineering in a CoT form; the large model agent performs parameter fine adjustment on the end-to-end network intention through weight adjustment; s103, performing intention decomposition planning on the end-to-end network intention by the large model agent to generate different sub-targets/tasks; s104, inputting the action instruction set into the reinforcement learning intelligent decision-making small model to form action space of each domain; each domain selects an optimal action instruction through a maximized reward function; and S105, collecting data by using the data sensing function of each domain and feeding back the data to the large model, and adjusting the large model based on the real-time data of each domain. According to the method, corpora are accurately described, the environment interaction capability is improved, the generalization capability and the sample efficiency of the reinforcement learning intelligent decision model are improved, and the method is more suitable for various interaction decision scenes.",UNIV XIDIAN,YANG CHUNGANG;;WANG YAO;;LI TANGYI;;ZHAO XIAOXUE;;ZHANG JINGWEN;;OUYANG YING,,https://lens.org/037-882-600-850-907,Patent Application,no,0,5,1,037-882-600-850-907,CN,1,037-882-600-850-907,CN,0,H04L41/16;;H04L41/145;;H04L41/20;;H04W16/18;;H04W16/22;;H04W52/0206;;H04W52/18;;H04W52/34;;G06N20/00;;G06N3/006;;G06N5/04,H04L41/16;;G06N3/006;;G06N5/04;;G06N20/00;;H04L41/00;;H04L41/14;;H04W16/18;;H04W16/22;;H04W52/02;;H04W52/18;;H04W52/34,,0,0,,,,PENDING
182,CN,U,CN 213339557 U,109-402-205-894-517,6/1/2021,2021,CN 202022160997 U,9/25/2020,CN 202022160997 U,9/25/2020,Engineering process management display prompt device,"Provided is an engineering process management display prompting device. The product comprises a display board, the display board is connected with an outer frame, the display board is provided with a top transverse through groove, the top transverse through groove is connected with a top transverse partition board, the display board is provided with a group of transversely-arranged vertical inserting grooves, the vertical inserting grooves are connected with vertical partition boards, the display board is provided with a group of vertically-arranged transverse inserting grooves, and the vertical inserting grooves are connected with the vertical partition boards. The display board is provided with a group of vertical sliding grooves which are transversely arranged, the vertical sliding grooves are connected with vertical sliding blocks, the vertical sliding blocks are connected with indicator lights, the indicator lights are connected with a power supply, the transverse slots are inserted into transverse partition boards, the transverse partition boards are provided with bayonets, and the bayonets are connected with the display board. The bayonets correspond to the vertical sliding grooves, the lower portions of the vertical sliding blocks are connected with U-shaped sub-hanging pieces, and the U-shaped sub-hanging pieces are used for hanging the moon-day time hanging plate and the content hanging plate respectively. The system is used for displaying and prompting engineering process management.",HARBIN INST PETROLEUM,JING MINGYE;;ZHAO JINGYU,,https://lens.org/109-402-205-894-517,Limited Patent,no,0,0,1,109-402-205-894-517,CN,1,109-402-205-894-517,CN,0,,G09F15/00,,0,0,,,,INACTIVE
183,CN,A,CN 119514659 A,150-582-159-328-369,2/25/2025,2025,CN 202411492101 A,10/24/2024,CN 202411492101 A,10/24/2024,Coal mine safety intelligent question-answering system based on large language model and construction method,"The invention discloses a coal mine safety intelligent question-answering system based on a large language model and a construction method, and relates to the technical field of coal mine safety. The coal mine safety intelligent question-answering system comprises the steps of performing data processing and storage on coal mine safety data and coal mine safety knowledge, and constructing an adaptive base which can be applied to different external large models; a plurality of domestic large models are introduced, and analysis, research and adaptation are carried out. By constructing adaptive bases which can be applied to different external large models, introducing knowledge understanding ability, logical reasoning ability, decision planning ability and the like of a general large language model, and constructing a coal mine safety intelligent question-answering system through methods such as prompt engineering and efficient fine tuning, a center with intelligent processing ability in the field of coal safety can be obtained, and the intelligent question-answering system can be applied to the field of coal safety. The system has the capability of understanding proprietary knowledge, can accurately and intelligently provide safety knowledge sharing and safety system diffusion, effectively improves the level of coal mine safety management, and guarantees the life safety and property safety of coal miners.",SHAANXI ZHIYIN TECH CO LTD,LAN WEI;;SUN PENG;;ZHANG TAO;;XU RONGGE;;CHEN BEINI,,https://lens.org/150-582-159-328-369,Patent Application,no,0,1,1,150-582-159-328-369,CN,1,150-582-159-328-369,CN,0,G06N5/022;;G06N5/041;;G06Q50/02;;G06F16/90332;;G06F16/90335;;G06F16/9038,G06N5/022;;G06F16/903;;G06F16/9032;;G06F16/9038;;G06N5/04;;G06Q50/02,,0,0,,,,PENDING
184,US,A1,US 2024/0354513 A1,073-392-602-550-485,10/24/2024,2024,US 202318493732 A,10/24/2023,US 202318493732 A;;US 202363460977 P,4/21/2023,PROMPT CHAINING SYSTEM FOR GENERATIVE ARTIFICIAL INTELLIGENCE SYSTEMS,A method for processing text prompts includes identifying a set of elements in a text prompt that form a basis for a generative output. The method also includes identifying an element of the set of elements that satisfy a refinement condition. The method further includes updating the element based on the element satisfying the refinement condition. The method still further includes generating the generative output in accordance with updating the element.,TOYOTA RES INST INC;;TOYOTA MOTOR CO LTD,HONG MATTHEW KYUNG-SOO;;CHEN YIN-YING;;ZHANG YANXIA,TOYOTA JIDOSHA KABUSHIKI KAISHA (2023-10-18);;TOYOTA RESEARCH INSTITUTE INC (2023-10-18),https://lens.org/073-392-602-550-485,Patent Application,yes,0,2,1,073-392-602-550-485,US,1,073-392-602-550-485,US,0,G06F40/279;;G06F40/30;;G06N5/022;;G06F40/56;;G06F40/30;;G06F40/279;;G06N5/022,G06F40/30;;G06F40/279;;G06N5/022,,0,0,,,,PENDING
185,CN,A,CN 119227811 A,178-081-660-058-877,12/31/2024,2024,CN 202411718192 A,11/28/2024,CN 202411718192 A,11/28/2024,Chaotic engineering atomic fault library question-answering method and system based on retrieval enhancement generation,"The invention discloses a chaos engineering atomic fault library question-answering method and system based on retrieval enhancement generation, and the method comprises the steps: firstly obtaining an atomic fault library file, storing the atomic fault library file in a JSON format, carrying out the slicing through a JSON slicing algorithm, and converting a node into a vector through an embedded model; then, three retrievers are constructed based on the atomic fault library, the three retrievers are used for retrieval according to user questions, and matched information nodes are obtained; deduplication and rearrangement are carried out on the obtained information nodes to obtain a text block set, and the text block set is spliced into complete atomic fault information; and finally, inputting the text blocks and the user questions into the large model, constructing cue words, and guiding answering according to the types of the user questions. According to the method, the integrity of single atomic fault information is greatly reserved through the JSON format and the JSON slicing algorithm, meanwhile, similar atomic faults can be matched through the mixed retriever, and the integrity, reliability and usability of a question answering system are effectively improved.",NANJING ZHENGFENG INFORMATION TECH CO LTD,HONG QIANSEN;;GENG YILONG;;RUAN FENG,,https://lens.org/178-081-660-058-877,Patent Application,no,6,0,1,178-081-660-058-877,CN,1,178-081-660-058-877,CN,0,G06N5/041;;G06N5/045;;G06F16/3329;;G06F16/3347;;G06F16/345;;G06F16/383,G06N5/04;;G06F16/33;;G06F16/332;;G06F16/34;;G06F16/383;;G06N5/045,,2,0,,,"孙其航等: ""基于检索增强的故障诊断知识问答模型"", 《广东石油化工学院学报 》, vol. 34, no. 04, 15 August 2024 (2024-08-15), pages 100 - 103;;ASEN HIKOV等: ""Information retrieval from textual data:Harnessing large language models, retrieval augmented generation and prompt engineering"", 《JOURNAL OF AI, ROBOTICS & WORKPLACE AUTOMATION》, vol. 03, no. 02, 1 January 2024 (2024-01-01), pages 142 - 150",PENDING
186,US,B2,US 12346357 B2,112-183-619-800-091,7/1/2025,2025,US 202418736278 A,6/6/2024,US 202418736278 A;;US 202363588279 P;;US 202363588285 P,10/5/2023,Systems and methods of processing queries using multi-tool agents and modular workflows,"A system is provided for processing user queries by using an automated agent and a workflow. The system comprises reusable components that include states, tools, and/or data sources. Based on analysis of a query's content and goals, the system generates a workflow comprising a sequence of states, each state optimized for a subtask and dynamically bound to a selected tool(s) for that specific query. The workflow can provide a structured high-level control, while allowing for flexible selection of the tool(s) for each state of the workflow for that given query. The system produces a result using the structured workflow and selected tools, answering a user's original query.",NASDAQ INC,AGHAJANYAN VIKTOR;;STILLER MICHAEL,,https://lens.org/112-183-619-800-091,Granted Patent,yes,6,0,2,103-846-503-462-156;;112-183-619-800-091,US,6,029-365-994-406-677;;069-350-584-208-183;;112-183-619-800-091;;103-846-503-462-156;;180-717-041-120-38X;;116-253-303-398-004,US;;EP,0,G06F16/3344;;G06F16/3344,G06F7/00;;G06F16/334,,2,0,,,"Lewis Patrick “Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks”, Computer Science, Computation and Language, arXiv:2005.11401, 19 pages, Apr. 12, 2021.;;Extended European Search Report for Application No. EP 24204027.7, 12 pages, dated Feb. 4, 2025.",ACTIVE
187,EP,A1,EP 4535188 A1,069-350-584-208-183,4/9/2025,2025,EP 24204018 A,10/1/2024,US 202363588279 P;;US 202418736278 A,10/5/2023,SYSTEMS AND METHODS OF PROCESSING QUERIES USING MULTI-TOOL AGENTS AND MODULAR WORKFLOWS,"A system is provided for processing user queries by using an automated agent and a workflow. The system comprises reusable components that include states, tools, and/or data sources. Based on analysis of a query's content and goals, the system generates a workflow comprising a sequence of states, each state optimized for a subtask and dynamically bound to a selected tool(s) for that specific query. The workflow can provide a structured high-level control, while allowing for flexible selection of the tool(s) for each state of the workflow for that given query. The system produces a result using the structured workflow and selected tools, answering a user's original query.",NASDAQ INC,AGHAJANYAN VIKTOR;;STILLER MICHAEL,,https://lens.org/069-350-584-208-183,Patent Application,yes,2,0,1,069-350-584-208-183,EP,6,029-365-994-406-677;;069-350-584-208-183;;112-183-619-800-091;;103-846-503-462-156;;180-717-041-120-38X;;116-253-303-398-004,US;;EP,0,G06F16/3329;;G06F16/2425,G06F16/3329;;G06F16/24,,1,0,,,"LEWIS, PATRICK ET AL.: ""Retrieval-augmented generation for knowledge-intensive nlp tasks."", ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS, vol. 33, 2020, pages 9459 - 9474",PENDING
188,US,A1,US 2025/0111192 A1,140-026-377-818-817,4/3/2025,2025,US 202318375256 A,9/29/2023,US 202318375256 A,9/29/2023,GENERATING KNOWLEDGE GRAPHS USING LARGE LANGUAGE MODELS,"Techniques for a knowledge-graph system to use large language models (LLMs) to build knowledge graphs to answer queries submitted to a chatbot by users. The knowledge-graph system builds the knowledge graph using answers produced by an LLM for novel queries. The chatbot will continue to use the LLM to answer novel queries, but the chatbot may harness the knowledge graph to answer repeat questions to gain various efficiencies over LLM-backed chatbots. For example, the knowledge-graph system may easily debug or otherwise improve the answers in knowledge graphs, store provenance information in knowledge graphs, and augment the knowledge graphs using other data sources. Thus, the reliability and correctness of chatbots will be improved as the bugs and inaccuracies in answers provided by the LLM will be corrected in the knowledge graphs, but the chatbots can still harness the abilities of LLMs to provide answers across various subject-matter domains.",AMAZON TECH INC,BAYLESS SAMUEL;;LABAI NADIA;;LASSILA ORA YRJO,AMAZON TECHNOLOGIES INC (2023-09-26),https://lens.org/140-026-377-818-817,Patent Application,yes,0,2,2,015-425-897-590-293;;140-026-377-818-817,US;;WO,2,015-425-897-590-293;;140-026-377-818-817,US;;WO,0,G06F16/3329;;G06N3/042;;G06N3/0455;;G06N3/006,G06N3/042;;G06N3/006;;G06N3/0455,,0,0,,,,PENDING
189,US,A1,US 2025/0069744 A1,137-297-662-177-488,2/27/2025,2025,US 202318238453 A,8/25/2023,US 202318238453 A,8/25/2023,SYSTEM AND METHOD FOR MEDICAL DISEASE DIAGNOSIS BY ENABLING ARTIFICIAL INTELLIGENCE,"A medical image disease diagnostic system that is included in a clinical medical diagnosis workflow. In one embodiment, a user interface is configured to assess a medical imaging application that provides for viewing, analyzing, and annotating of medical images and medical non-image data and medical training data. A processor includes a pre-trained subsystem configured to generate AI pre-trained models based on the medical image and medical non-image data, a training data generation subsystem configured to generate the medical training data, and a medical image model training subsystem configured to transform the medical image and medical non-image data into the medical training data. The medical image model training subsystem is further configured to train or generate the pre-trained AI models based on the medical training data, and a model drift subsystem is configured to determine accuracy of the pre-trained AI models. A diagnostic reporting subsystem configured to generate clinical diagnostic reports.",MADAN NIKHIL,MADAN NIKHIL,,https://lens.org/137-297-662-177-488,Patent Application,yes,0,0,1,137-297-662-177-488,US,1,137-297-662-177-488,US,0,G16H50/70;;G16H30/40;;G16H30/20;;G16H50/20;;G16H10/60;;G16H15/00;;G16H50/20;;G16H10/60;;G16H50/70;;G16H30/20;;G16H30/40;;G16H15/00,G16H50/20;;G16H10/60;;G16H15/00;;G16H30/20;;G16H30/40;;G16H50/70,,0,0,,,,PENDING
190,WO,A1,WO 2025/024760 A1,128-134-794-240-773,1/30/2025,2025,US 2024/0039734 W,7/26/2024,US 202363529201 P;;US 202363529205 P,7/27/2023,TRAINING AND USE OF BAYESIAN NETWORKS AND LANGUAGE MODELS FOR AGRIBUSINESS DELINQUENCY RISK ASSESSMENT,"In some embodiments, a computer-implemented method includes reading a multiple dependencies. Each dependency can be between a pair of features of multiple features, the multiple features including a target feature. The method can comprise reading training data correlating each pair. The training data can comprise loan application data for multiple loans. The method can include determining, from the training data, a conditional probability for each pair of features. Each pair of features can comprise a first feature and a second feature. The conditional probability can represent a probability of the first feature based on an occurrence of the second feature. The method can include constructing a directed graph comprising multiple nodes and multiple edges. Each node can correspond to one of the features. Nodes corresponding to a dependency can be connected by an edge. The method can further include assigning the conditional probability to each edge corresponding to that pair.",TRAIVE INC,OLIVEIRA ALINE;;TEIXEIRA ANA;;YAZDANPANAH HAMED;;GHASSEMI MOHAMMAD;;MARAR VAISHALI,,https://lens.org/128-134-794-240-773,Patent Application,yes,4,0,1,128-134-794-240-773,WO,1,128-134-794-240-773,WO,0,G06N3/047;;G06F17/18;;G06N7/01;;G06Q40/03;;G06Q10/0635;;G06Q10/06375;;G06Q10/067;;G06Q30/0201;;G06Q30/0645;;G06Q40/08;;G06Q50/02;;G06Q50/165,G06F16/901;;G06F17/18;;G06N3/047;;G06N7/01,,0,0,,,,PENDING
191,US,A1,US 2025/0086439 A1,182-903-658-182-902,3/13/2025,2025,US 202318462519 A,9/7/2023,US 202318462519 A,9/7/2023,PLATFORM FOR ENTERPRISE ADOPTION AND IMPLEMENTATION OF GENERATIVE ARTIFICIAL INTELLIGENCE SYSTEMS,"Implementations for receiving, by a GAI integration platform, a request from an application executed by an enterprise system of an enterprise, the application being executed remotely from the GAI integration platform, processing, through a control tier of the GAI integration platform, at least a portion of the request through a set of modules to generate a prompt that is responsive to the request, the set of modules including one or more of a prompt template module, a prompt quality module, and a personally identifiable information (PII) detection module, transmitting, by the GAI integration platform, the prompt to a GAI system of a plurality of GAI systems, receiving, by the GAI integration platform, a response from the GAI system, the response comprising content generated by the GAI system in response to the prompt, and transmitting, by the GAI integration platform, the response to the application.",ACCENTURE GLOBAL SOLUTIONS LTD,PAUL NAYANJYOTI;;RAY ATISH SHANKAR;;SUBRAMANIAM KAMAKSHI;;TYAGI VINEET;;DILIP LOMATE SHEETAL,ACCENTURE GLOBAL SOLUTIONS LIMITED (2023-08-29),https://lens.org/182-903-658-182-902,Patent Application,yes,0,0,2,107-345-582-528-79X;;182-903-658-182-902,US;;EP,2,107-345-582-528-79X;;182-903-658-182-902,US;;EP,0,G06N3/10;;G06F40/186;;G06N3/0475,G06N3/0475,,0,0,,,,PENDING
192,EP,A1,EP 4530953 A1,032-179-222-492-658,4/2/2025,2025,EP 24202698 A,9/25/2024,US 202318375376 A,9/29/2023,CONTENT COLLABORATION PLATFORM WITH GENERATIVE ANSWER INTERFACE,Embodiments described herein relate to systems and methods for automatically generating content for a generative answer interface (520) of a collaboration platform. The system receives a natural language user input (532) identifies corresponding blocks of text using an content extraction service. A prompt is generated using the blocks of text and used to obtain a generative response (542). The generative response and links to corresponding content are displayed in the generative answer interface (520) and can be inserted into content of the collaboration platform. The systems and methods described use a network architecture that includes a prompt generation service and a set of one or more purpose-configured large language model instances (LLMs) and/or other trained classifiers or natural language processors used to provide generative responses (542) for content collaboration platforms.,ATLASSIAN PTY LTD,SHEA ALLISON;;BHOSALE ANIKET;;KOLAMBKAR NAVIN;;KOHOUT ISABELLE JANA;;ZHANG JACQUELINE;;WANG ZHAOHUI,,https://lens.org/032-179-222-492-658,Patent Application,yes,1,0,2,141-719-757-646-111;;032-179-222-492-658,US;;EP,2,141-719-757-646-111;;032-179-222-492-658,US;;EP,0,G06Q10/103;;G06Q30/015;;G06N3/0475;;G06F16/3329;;G06F16/3344;;G06F40/279;;G06F40/30;;G06Q10/101,G06Q10/10;;G06N3/0475;;G06Q30/015,,2,0,,,"JAWADEKAR ABHINAV ET AL: ""Quickly build high-accuracy Generative AI applications on enterprise data using Amazon Kendra, LangChain, and large language models"", AWS MACHINE LEARNING BLOG, 1 June 2023 (2023-06-01), XP093243823, Retrieved from the Internet <URL:https://aws.amazon.com/blogs/machine-learning/quickly-build-high-accuracy-generative-ai-applications-on-enterprise-data-using-amazon-kendra-langchain-and-large-language-models/> [retrieved on 20250128];;ANONYMOUS: ""Prompt Engineer Role: 25+ Interview Questions and Answers - Easy Prompt Guide"", 25 August 2023 (2023-08-25), XP093244286, Retrieved from the Internet <URL:https://easypromptguide.com/prompt-engineering-interview-questions-answers/> [retrieved on 20250128]",PENDING
193,US,A1,US 2025/0061290 A1,028-900-478-695-316,2/20/2025,2025,US 202418582262 A,2/20/2024,US 202418582262 A;;US 202318452496 A,8/18/2023,SYSTEMS FOR CONTROLLABLE SUMMARIZATION OF CONTENT,A method of generating summaries of content items using one or more large language models (LLMs) is disclosed. A first content item is identified. The first content item includes a set of sub-content items. A level of abstraction is determined for the content item. A prompt is automatically engineered for providing to the one or more LLMs. The prompt includes a reference to the first content item and the level of the abstraction for the first content item. A response to the prompt is received from the LLM. The response includes a second content item. The second content item includes a representation of the first content item that is generated by the LLM. The representation omits or simplifies one or more of the set of sub-content items based on the level of abstraction. The representation is used to control an output that is communicated to a target device.,ANZER INC,GARDNER RICHARD;;JOZWIAK JOHN,ANZER INC (2023-08-18);;MODULUS AI INC (2025-06-04),https://lens.org/028-900-478-695-316,Patent Application,yes,0,4,3,028-900-478-695-316;;084-026-983-166-223;;067-012-548-766-570,US;;WO,4,058-707-715-177-947;;028-900-478-695-316;;067-012-548-766-570;;084-026-983-166-223,US;;WO,0,G06F40/56;;G06F16/345;;G06F16/345;;G06F40/56,G06F40/56;;G06F16/34,,0,0,,,,PENDING
194,US,A1,US 2024/0428013 A1,082-196-654-811-227,12/26/2024,2024,US 202318340044 A,6/23/2023,US 202318340044 A,6/23/2023,ENHANCING CHATBOTS THROUGH PROMPT-ENGINEERED LARGE LANGUAGE MODELS,"A method, computer program product, and computer system are provided for enhancing chatbot responses. Data corresponding to a user input to a chatbot is received. A prompt is generated for a large language model based on the received data and a conversation flowchart associated with the chatbot. The generated prompt is input to the large language model. A natural language response to the received data is generated based on an output from the large language model. The generated natural language response substantially corresponds to a response associated with the conversation flowchart.",IBM,WEN BO;;WANG CHEN,INTERNATIONAL BUSINESS MACHINES CORPORATION (2023-06-22),https://lens.org/082-196-654-811-227,Patent Application,yes,3,1,1,082-196-654-811-227,US,1,082-196-654-811-227,US,0,G06F40/35;;G06F40/40;;G06N3/0455;;G06F40/56;;G06F40/40;;G06N3/0455;;G06F40/35,G06F40/40;;G06F40/35;;G06N3/0455,,0,0,,,,PENDING
195,US,B1,US 12135949 B1,045-296-307-788-786,11/5/2024,2024,US 202418759648 A,6/28/2024,US 202418759648 A;;US 202418759617 A;;US 202418737942 A,6/7/2024,"Layered measurement, grading and evaluation of pretrained artificial intelligence models","Systems and methods for evaluating a pre-trained artificial intelligence (AI) model using layered prompts. The system obtains a set of application domains in which the AI model will be used, and a set of guidelines that define one or more operational boundaries of the AI model. The system determines a set of layers, where each layer is associated with corresponding guidelines and mapped to a set of variables and benchmarks. Each variable represents an attribute within the guidelines and each benchmark indicates the degree of satisfaction of the AI model with the guidelines. The AI model is dynamically evaluated against these benchmarks using a series of assessments. Subsequent assessments are dynamically constructed based on the outcomes of previous assessments. Scores are assigned to the AI model for each layer by comparing the expected and actual responses. The results are then displayed in a graphical user interface (GUI).",CITIBANK NA,CAMERON WILLIAM FRANKLIN;;SILVER MIRIAM;;RAJARETNAM MANJIT,CITIBANK N.A (2024-07-19),https://lens.org/045-296-307-788-786,Granted Patent,yes,48,7,1,045-296-307-788-786,US,3,045-296-307-788-786;;124-570-349-033-640;;052-214-240-715-903,US,0,G06F40/106;;G06F40/40;;G06F40/106;;G06F40/40,G06F17/00;;G06F40/106;;G06F40/40,,24,2,031-869-986-592-669;;121-748-300-060-492,10.1109/models58315.2023.00037;;10.1016/j.infsof.2024.107468,"Chen, Kua, et at, Automated Domain Modeling with Large Language Models: A Comparative Study, 2023 ACM/IEEE 26th International Conference on Model Driven Engineering Languages and Systems (MODELS) (2023, pp. 162-172) (Year: 2023).;;Wang, Yudong, et al, “Exploring Activation Patterns of Parameters in Language Models”, ARXIV ID: 2405.17799 Publication Date: May 27, 2024, pp. 1-23. (Year: 2024).;;Brown, Nik Bear, “Enhancing Trust in LLMs: Algorithms for Comparing and Interpreting LLMs”, ARXIV ID: 2406.01943 Publication Date: Jun. 3, 2024, pp. 1-58. (Year: 2024).;;Mathews, A. W., “What AI Can Do in Healthcare—and What It Should Never Do,” The Wall Street Journal, published on Aug. 21, 2024, retrieved on Sep. 5, 2024, https://www.wsj.com.;;AI Risk Management Framework NIST, retrieved on Jun. 17, 2024, https://www.nist.gov/itl/ai-risk-management-framework.;;Independent analysis of AI language models and API providers. Artificial Analysis, retrieved on Jun. 13, 2024, https://artificialanalysis.ai/, 11 pages.;;Brown, D., et al., “The Great AI Challenge: We Test Five Top Bots on Useful, Everyday Skills,” The Wall Street Journal, published May 25, 2024.;;Dong, Y., et al., “Building Guardrails for Large Language Models,” https://ar5iv.labs.arxiv.org/html/2402.01822v1, published May 29, 2024, 20 pages.;;Mavrepis, P., et al., “XAI for All: Can Large Language Models Simplify Explainable AI?,” https://arxiv.org/abs/2401.13110, Jan. 23, 2024, 10 pages.;;Mollick, E., “Latent Expertise: Everyone is in R&D,” One Useful Thing, published on Jun. 20, 2024, https://www.oneusefulthing.org/p/latent-expertise-everyone-is-in-r.;;Zhao, H., et al., “Explainability for Large Language Models: A Survey,” https://arxiv.org/abs/2309.01029, Nov. 28, 2024, 38 pages.;;Aggarwal, Nitin , “Why measuring your new AI is essential to its succes”, KPIs for gen AI: Why measuring your new AI is essential to its succes, 7 pages.;;AI , “What is AI Verify?”, What is AI Verify—AI Verify Foundation.;;Altman, Sam , “Sam Altman Admits That OpenAI Doesn't Actually Understand How Its AI Works”, Sam Altman Admits That OpenAI Doesn't Actually Understand How Its AI Works—“We certainly have not solved interpretability.”, 4 pages.;;Anthrop/C , “Mapping the Mind of a Large Language Model”, Mapping the Mind of a Large Language Model, May 21, 2024.;;Claburn, Thomas , “OpenAI's GPT-4 can exploit real vulnerabilities by reading security advisories”, OpenAI's GPT-4 can exploit real vulnerabilities by reading security advisories, Apr. 17, 2024, 3 pages.;;Marshall, Andrew , “Threat Modeling AI/ML Systems and Dependencies”, Threat Modeling AI/ML Systems and Dependencies, Nov. 2, 2022, 27 pages.;;Roose, Kevin , “A.I. Has a Measurement Problem”, A.I. Has a Measurement Problem, Apr. 15, 2024, 5 pages.;;Roose, Kevin , “A.I.'s Black Boxes Just Got a Little Less Mysterious”, A.I.'s Black Boxes Just Got a Little Less Mysterious, May 21, 2024, 5 pages.;;Shah, Harshay , “Decomposing and Editing Predictions by Modeling Model Computation”, Decomposing and Editing Predictions by Modeling Model Computation, 5 pages.;;Shankar, Ram , “Failure Modes in Machine Learning”, , Nov. 2019, 14 pages.;;Teo, Josephine , “Singapore launches Project Moonshot”, Singapore launches Project Moonshot—a generative Artificial Intelligence testing toolkit to address LLM safety and security challenges, May 31, 2024, 8 pages.;;Dakhel et al., Apr. 2024, “Effective test generation using pre-trained Large Language Models and mutation testing” (Year: 2024).;;Do et al., Apr. 3, 2024, “Automatic Prompt Selection for Large Language Models” (Year: 2024).",ACTIVE
196,US,A1,US 2025/0053857 A1,027-012-524-516-955,2/13/2025,2025,US 202418444235 A,2/16/2024,US 202418444235 A;;US 202363486191 P,2/21/2023,ARTIFICIAL INTELLIGENCE MODEL THAT ACTS AS USER INTERMEDIARY TO EXTERNAL ARTIFICIAL INTELLIGENCE MODEL API,"A method and system for providing an intermediary AI model that interfaces with a general purpose generative AI engine (e.g., a chatbot) that improves interface with the general-purpose AI in a domain-specific environment. The intermediary AI makes use of user specific information, user preferences, domain-specific concerns, trends, and makes use of a feedback loop to improve the operation thereof.",AUDDIA INC,THRAMANN JEFFREY;;LAWLESS MICHAEL;;RODRIGUEZ PABLO CALDERON,,https://lens.org/027-012-524-516-955,Patent Application,yes,0,0,1,027-012-524-516-955,US,1,027-012-524-516-955,US,0,G06N20/00;;G06N20/00,G06N20/00,,0,0,,,,PENDING
197,US,A1,US 2025/0173806 A1,092-207-055-378-752,5/29/2025,2025,US 202318519605 A,11/27/2023,US 202318519605 A,11/27/2023,ADAPTIVE SKILL DEVELOPMENT AND ENHANCEMENT,"An adaptive skill development and enhancement system is presented for enhancing employee skills and competencies. Data encompassing an employee's skills, education, work history, performance, and aspirations are amassed. A machine learning algorithm analyzes the data, to establish an interpersonal affinity-behavioral matrix for use in identifying a skill gaps against a role-specific competency model. A customized learning experience, adapted to the employee's learning style as determined by the affinity-behavioral matrix, is generated and delivered through a user interface. The user interface collects feedback and performance metrics, which inform ongoing refinements to the learning content, ensuring continual alignment with the employee's development needs.",WELLS FARGO BANK NA,HORD MATTHEW TYLER;;KENDAPADI ANANTHARAMAN;;KETHARAJU RAMESHCHANDRA,WELLS FARGO BANK N.A (2023-11-27),https://lens.org/092-207-055-378-752,Patent Application,yes,8,0,1,092-207-055-378-752,US,1,092-207-055-378-752,US,0,G06Q10/063112;;G06Q50/2057;;G06Q10/06398;;G06Q10/105;;G06Q10/1097;;G06Q50/2057;;G06Q10/105;;G06Q10/1097;;G06Q10/063112;;G06Q10/06398,G06Q50/20;;G06Q10/0631;;G06Q10/0639;;G06Q10/105;;G06Q10/1093,,0,0,,,,PENDING
198,EP,A1,EP 4528476 A1,042-550-793-929-979,3/26/2025,2025,EP 23199098 A,9/22/2023,EP 23199098 A,9/22/2023,HUMAN-MACHINE INTERACTION METHOD AND COMPUTING SYSTEM,"A human-machine interaction method implemented by a computing system. The method includes: determining, by using a language model, whether a current state of a user meets a preset criteria based on current user data associated with one or more physical actions of the user during a current interaction session between the user and a machine; if a result of the determining step indicates that the current state of the user meets the preset criteria, performing following steps: obtaining, from data associated with a past interaction session between the user and a machine, data representing an environmental condition contributing to a target state of the user that is different from the current state; determining, by using the language model, an action to be performed by a device in a current environment where the user is located during the current interaction session to achieve or approximate the environmental condition based on current environmental data associated with the current environment; and sending a command to enable the device to perform the action.",TOYOTA MOTOR CO LTD,ABDELKAWY HAZEM;;DE WESER MARLEEN,,https://lens.org/042-550-793-929-979,Patent Application,yes,5,0,1,042-550-793-929-979,EP,1,042-550-793-929-979,EP,0,G06F3/167;;G10L25/63;;G10L15/22;;G10L2015/226,G06F3/16;;G10L15/22;;G10L25/63,,2,1,056-942-930-074-032,10.1145/3503161.3551570,"SHUNYU YAO ET AL., REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS, 10 March 2023 (2023-03-10), Retrieved from the Internet <URL:https://arxiv.org/abs/2210.03629>;;C. H. YAP ET AL.: ""Proceedings of the 30th ACM International Conference on Multimedia (MM '22"", ASSOCIATION FOR COMPUTING MACHINERY, article ""3D-CNN for Facial Micro- and Macro-expression Spotting on Long Video Sequences using Temporal Oriented Reference Frame"", pages: 7016 - 7020",PENDING
199,US,A1,US 2025/0061291 A1,058-707-715-177-947,2/20/2025,2025,US 202418807751 A,8/16/2024,US 202418807751 A;;US 202418582262 A;;US 202318452496 A,8/18/2023,SYSTEMS FOR CONTROLLABLE SUMMARIZATION OF CONTENT,A method of generating summaries of content items using one or more large language models (LLMs) is disclosed. A first content item is identified. The first content item includes a set of sub-content items. A level of abstraction is determined for the content item. A prompt is automatically engineered for providing to the one or more LLMs. The prompt includes a reference to the first content item and the level of the abstraction for the first content item. A response to the prompt is received from the LLM. The response includes a second content item. The second content item includes a representation of the first content item that is generated by the LLM. The representation omits or simplifies one or more of the set of sub-content items based on the level of abstraction. The representation is used to control an output that is communicated to a target device.,GARDNER RICHARD;;JOZWIAK JOHN,GARDNER RICHARD;;JOZWIAK JOHN,MODULUS AI INC (2025-06-04),https://lens.org/058-707-715-177-947,Patent Application,yes,0,2,1,058-707-715-177-947,US,4,058-707-715-177-947;;028-900-478-695-316;;067-012-548-766-570;;084-026-983-166-223,US;;WO,0,G06F16/345;;G06F40/56;;G06F16/345;;G06F40/56,G06F40/56;;G06F16/34,,0,0,,,,PENDING
200,EP,A1,EP 4575880 A1,046-939-863-397-826,6/25/2025,2025,EP 24216421 A,11/29/2024,IN 202321086605 A,12/18/2023,METHOD AND SYSTEM TO GENERATE PERSONA-BASED COMMENTARY DATA FOR MACHINE LEARNING MODEL CARD DOCUMENT,This disclosure relates generally to method and system to generate persona-based commentary data for machine learning model card document. Existing techniques on model card are designed mainly for personas and understanding section of the model card document requires a certain level of expertise in machine learning. The method of the present disclosure receives a model card document comprising a plurality of sections and the model card document corresponds to a persona. Each section of the model card document obtains a metadata for the persona. The data curator machine learning model automatically generates a persona-based report trajectory for a plurality of sections of the metadata and a plurality of schema rules to generate a prompt template. The commentary generator ML model generates one or more commentary data for each section associated with the prompt template corresponding to the persona.,TATA CONSULTANCY SERVICES LTD,JAIN ANUBHAV;;WALAVE PRAVIN DINKAR;;KALELE AMIT;;SUBBIAH RAVINDRAN,,https://lens.org/046-939-863-397-826,Patent Application,yes,0,0,2,094-924-893-980-747;;046-939-863-397-826,US;;EP,2,094-924-893-980-747;;046-939-863-397-826,US;;EP,0,G06F40/216;;G06F40/30;;G06F40/56;;G06F40/44;;G06F40/169;;G06F40/16;;G06F40/106;;G06N20/00,G06F40/106;;G06F40/16;;G06F40/169;;G06F40/216;;G06F40/30;;G06F40/44;;G06F40/56,,6,3,068-177-413-042-710;;051-109-220-654-41X;;050-611-541-056-741,10.1145/3531146.3533108;;35836130;;pmc9284683;;10.1186/s12859-022-04797-6;;10.1109/pst58708.2023.10320197,"ANONYMOUS: ""An MLOps story: how Wayflyer creates ML model cards"", WEB ARCHIVE COPY OF WEBPAGE, 5 December 2023 (2023-12-05), XP093269003, Retrieved from the Internet <URL:https://web.archive.org/web/20231205185808/https://www.evidentlyai.com/blog/how-wayflyer-creates-ml-model-cards> [retrieved on 20250410];;DROUHARD MARGARET ET AL: ""Interactive Model Cards: A Human-Centered Approach to Model Documentation"", 21 June 2022 (2022-06-21), XP093268530, Retrieved from the Internet <URL:https://dl.acm.org/doi/pdf/10.1145/3531146.3533108> [retrieved on 20250409];;MUHAMMADTUAN AMITH ET AL: ""Toward a standard formal semantic representation of the model card report"", BMC BIOINFORMATICS, BIOMED CENTRAL LTD, LONDON, UK, vol. 23, no. 6, 14 July 2022 (2022-07-14), pages 1 - 18, XP021305409, DOI: 10.1186/S12859-022-04797-6;;JULES WHITE ET AL: ""A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 21 February 2023 (2023-02-21), XP091444160;;MITCHELL MARGARET ET AL: ""Model Cards for Model Reporting"", 29 January 2019 (2019-01-29), XP093268312, Retrieved from the Internet <URL:https://dl.acm.org/doi/pdf/10.1145/3287560.3287596> [retrieved on 20250408], DOI: ISBN978-1-4503-6125-5/19/01.10.1145/3287560.3287596;;BRACAMONTE VANESSA ET AL: ""Effectiveness and Information Quality Perception of an AI Model Card: A Study Among Non-Experts"", 2023 20TH ANNUAL INTERNATIONAL CONFERENCE ON PRIVACY, SECURITY AND TRUST (PST), IEEE, 21 August 2023 (2023-08-21), pages 1 - 7, XP034473911, [retrieved on 20231122], DOI: 10.1109/PST58708.2023.10320197",PENDING
201,US,A1,US 2025/0094538 A1,101-836-003-938-769,3/20/2025,2025,US 202418589323 A,2/27/2024,US 202418589323 A;;US 202363538407 P,9/14/2023,DATASET CLUSTERING VIA LANGUAGE MODEL PROMPTS,"Various embodiments discussed herein relate to prompting a model, such as a Large Language Model (LLM), to ingest natural language clustering instructions and generate corresponding natural language clustering information, such as a cluster description and/or a cluster label without the need to generate any numeric text embeddings.",MICROSOFT TECHNOLOGY LICENSING LLC,WAN MENGTING;;NEVILLE JENNIFER LYNAY;;YANG LONGQI;;SAFAVI TARA LYNN;;JAUHAR SUJAY KUMAR;;SHAH CHIRAG;;BUSCHER GEORG LUDWIG WILHELM;;ANDERSEN REID MARLOW;;MANIVANNAN SATHISH KUMAR;;NI XIAOCHUAN;;COUNTS SCOTT JOSEPH;;SURI SIDDHARTH,MICROSOFT TECHNOLOGY LICENSING LLC (2024-01-02),https://lens.org/101-836-003-938-769,Patent Application,yes,0,0,1,101-836-003-938-769,US,1,101-836-003-938-769,US,0,G06F16/24578;;G06F18/23211;;G06F16/24578;;G06F18/23211,G06F18/23211;;G06F16/2457,,0,0,,,,PENDING
202,WO,A1,WO 2024/229578 A1,194-031-885-040-71X,11/14/2024,2024,CA 2024050640 W,5/10/2024,US 202363501641 P,5/11/2023,SYSTEMS FOR ADAPTING LANGUAGE MODELS USING USER-INFLUENCED DATA GENERATION,"There is a method for adapting a language model to represent the intentions of a user. The method includes receiving, from the user, a user input including user data of a request for a language model, analyzing the intentions of the user based on the user input and user data, generating user-influenced data reflective of the analyzed intentions of the user, adapting the language model based on the user-influenced data by at least one adaptation method, and generating an output from the adapted language model.",PRIMAL FUSION INC,SWEENEY PETER;;WILSON MATHEW;;LIN JIMMY;;SMITH HAROLD,,https://lens.org/194-031-885-040-71X,Patent Application,yes,2,0,1,194-031-885-040-71X,WO,1,194-031-885-040-71X,WO,0,G06N5/022;;G06N20/00;;G06F40/40;;G06F40/30;;G06F40/279;;G06F40/216;;G06N3/08,G06F40/00;;G06F40/30;;G06F40/40;;G06N5/022;;G06N20/00,,0,0,,,,PENDING
203,US,A1,US 2024/0378655 A1,077-231-033-529-296,11/14/2024,2024,US 202418661097 A,5/10/2024,US 202418661097 A;;US 202363501857 P,5/12/2023,SYSTEM AND METHOD FOR DEALS PIPELINE OPTIMIZATION,"A system and method for streamlining a deal pipeline based on large language models are provided. The method includes encoding an input query into a numerical representation in a business domain; retrieving data from a deal knowledge base based on the numerical representation; generating a prompt based on the encoded input query and data retrieved from the knowledge base; feeding the prompt to a generic-trained language model; and ranking responses provided by the generic-trained language model, wherein the responses are related to at least a deal pipeline.",GONG IO LTD,EYAL GUY NETSER;;SHALEV NADAV SHAI OVED;;MEDALION SHLOMI;;HOREV INBAL;;BEN-DAVID EYAL,GONG.IO LTD (2024-05-09),https://lens.org/077-231-033-529-296,Patent Application,yes,0,0,1,077-231-033-529-296,US,1,077-231-033-529-296,US,0,G06Q30/0631;;G06N5/02;;G06N5/02;;G06Q30/0631,G06Q30/0601;;G06N5/02,,0,0,,,,PENDING
204,US,A1,US 2025/0095227 A1,199-026-187-165-318,3/20/2025,2025,US 202418886452 A,9/16/2024,US 202418886452 A;;RO 202300507 A;;US 202363583380 P,9/15/2023,TEXT-GUIDED VECTOR IMAGE SYNTHESIS,"A method, apparatus, non-transitory computer readable medium, and system for training a text-guided vector image synthesis include obtaining training data including a vectorizable image and a caption describing the vectorizable image and generating, using an image generation model, a predicted image with a first level of high frequency detail. Then, the training data and the predicted image are used to tune the image generation model to generate a synthetic vectorizable image based on the caption, where the synthetic vectorizable image has a second level of high frequency detail that is lower than the first level of high frequency detail of the predicted image.",ADOBE INC,UNGUREANU-CONTES ADRIAN-STEFAN;;LUPASCU MARIAN;;LUNGU-STAN VLAD-CONSTANTIN;;MIRONICA IONUŢ;;BATRA VINEET,ADOBE INC (2024-09-06),https://lens.org/199-026-187-165-318,Patent Application,yes,0,0,2,009-806-067-036-56X;;199-026-187-165-318,US,2,009-806-067-036-56X;;199-026-187-165-318,US,0,G06T2210/32;;G06T2210/36;;G06T2200/24;;G06T3/4053;;G06T11/00;;G06T11/60;;G06F3/04847;;G06T11/00;;G06T2210/36;;G06T3/4053;;G06F3/04847;;G06T2200/24;;G06T2210/32,G06T11/00;;G06T3/4053,,0,0,,,,PENDING
205,US,A1,US 2025/0042032 A1,115-696-904-343-232,2/6/2025,2025,US 202318507020 A,11/10/2023,US 202318507020 A;;US 202363516839 P,7/31/2023,ENFORCING ROBOTIC SAFETY CONSTRAINTS BASED ON AI GENERATED SAFETY DESCRIPTIONS,"Methods, systems, and computer program products for robot safety. Multiple computer-implemented components are operatively interconnected to carry out operations for ensuring safe execution of robotic commands. Upon receiving a description (e.g., in text form or as an image) of an environment, and based on the description, forming a large language model (LLM) prompt that is provided to an artificial intelligence entity. After prompting the artificial intelligence entity, and upon receiving an LLM response that contains information about how to operate and/or constrain the robot, then guaranteeing safe operation of the robot by classifying aspects of the LLM response, labeling at least some parts of the LLM response, and then, based on the labeling, generating modified planning or control signals that ensure safe operation of the robot. Only the modified signals that ensure safe operation or other signals that are deemed to be safe are provided to the robot.",3LAWS ROBOTICS INC,SINGLETARY ANDREW W;;JIMENEZ IVAN;;AMES AARON D,,https://lens.org/115-696-904-343-232,Patent Application,yes,0,1,2,037-861-391-042-029;;115-696-904-343-232,US;;WO,3,037-861-391-042-029;;004-587-112-461-735;;115-696-904-343-232,US;;WO,0,B25J9/1676;;B25J9/1658;;B25J9/1658;;B25J9/1676,B25J9/16,,0,0,,,,PENDING
206,US,A1,US 2024/0311094 A1,060-238-275-040-498,9/19/2024,2024,US 202318214716 A,6/27/2023,US 202318214716 A;;US 202363453011 P,3/17/2023,OPTIMIZING BEHAVIOR AND DEPLOYMENT OF LARGE LANGUAGE MODELS,"The present disclosure relates to methods and systems that provide a framework for accelerating the development of large language models (LLM)s solutions. The present disclosure provides methods and systems that support a complete cycle for developing LLM solutions, testing the LLM solutions, deploying the LLM solutions, and providing feedback on the deployed LLM solutions.",MICROSOFT TECHNOLOGY LICENSING LLC,AULD DAVID HERRON;;DIMITROV KANIO GEORGIEV;;AL-KOFAHI JAFAR MAHMOUD;;MALSAN JONATHAN RICHARD;;IFTIMIE DIANA ANDREA;;KOHLI NATASHA;;LIU CHENMIN;;KINNEY CHRISTOPHER DIEGO;;ZHANG HAIZHEN;;FATADE DANIEL AKINTOLA;;AL-KOFAHI YOUSEF;;WILLIAMS CHARLES DAVID,MICROSOFT TECHNOLOGY LICENSING LLC (2024-02-28),https://lens.org/060-238-275-040-498,Patent Application,yes,23,0,1,060-238-275-040-498,US,1,060-238-275-040-498,US,0,G06F8/33;;G06F8/35;;G06F8/60;;G06F8/36;;G06F8/33;;G06F8/60;;G06F8/36;;G06F8/35,G06F8/33;;G06F8/35;;G06F8/36;;G06F8/60,,5,2,041-515-475-056-009;;161-436-280-851-681,10.18653/v1/2022.emnlp-main.115;;10.1049/cim2.12087,"Jukka Keisala ; ""Utilizing Large Language Models as nocode Interface in a Software Development Toolkit""; May 2023 Information and Communication Technology - Jamk University of Applied Sciences, May 2023.;;Li, Jingyao, et al. ""Motcoder: Elevating large language models with modular of thought for challenging programming tasks."" (2023).;;Mitchell, Eric, et al. ""Enhancing self-consistency and performance of pre-trained language models through natural language inference."" (2022).;;Holt, Samuel, Max Ruiz Luyten, and Mihaela van der Schaar. ""L2MAC: Large language model automatic computer for extensive code generation."" (2023).;;Yang, Kaiyuan, et al. ""A new design approach of hardware implementation through natural language entry."" IET Collaborative Intelligent Manufacturing 5.4 (2023).",PENDING
207,WO,A1,WO 2024/129694 A1,159-027-608-132-05X,6/20/2024,2024,US 2023/0083574 W,12/12/2023,US 202218067674 A;;US 202218067680 A,12/16/2022,ADAPTING PROMPTS SELECTED FROM PROMPT TASK COLLECTIONS,Prompt development techniques are implemented for tuning natural language processing machine learning models using selected prompts from a prompt task collection. A prompt development system may support requests to further adapt a pre-trained natural language processing machine learning model to tune the pre-trained natural language processing machine learning model for use with a selected prompt. Evaluation of the tuned natural language processing machine learning model may be performed and provided as a result.,AMAZON TECH INC,ZHA SHENG;;BALLESTEROS MARTINEZ MIGUEL;;BENAJIBA YASSINE;;HAWKINS COLE;;RAWAL ADITYA;;RAM DHANANJAY;;TAN MIN RONG SAMSON;;CASTELLI VITTORIO;;GOYAL ABHINAV;;SWIDLER BRANT,,https://lens.org/159-027-608-132-05X,Patent Application,yes,0,0,2,159-027-608-132-05X;;120-270-050-388-56X,WO;;CN,4,120-270-050-388-56X;;159-027-608-132-05X;;170-911-070-679-39X;;109-546-270-618-239,US;;WO;;CN,0,G06F40/30;;G06F40/216,G06F40/30;;G06F40/216,,3,0,,,"HENDRIK STROBELT ET AL: ""Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 16 August 2022 (2022-08-16), XP091295657;;TU VU ET AL: ""SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 16 March 2022 (2022-03-16), XP091171433;;BONAN MIN ET AL: ""Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, November 2021 (2021-11-01), XP091091156",PENDING
208,US,A1,US 2025/0148209 A1,167-618-208-615-313,5/8/2025,2025,US 202418604219 A,3/13/2024,IN 202341076295 A,11/8/2023,IMPROVING ACCURACY OF Gen. AI DRIVEN DOCUMENT ANALYSIS,An Artificial Intelligence (AI) & Generative AI-driven cross-domain document analysis system enables accurate and consistent narratives across a longitudinal timeline for an entity regarding communications in different operational aspects. The document analysis and insight system includes an Artificial Intelligence (AI) powered Search Interface (AIPS) and an Advanced Intelligent Knowledge Engine (AIKE). The AIPS is configured to pre-process documents from structured and unstructured data sources to generate data taxonomies and custom synonym files. The AIKE generates a preliminary evaluation of the various Large Language Models (LLMs) and uses the data taxonomies and custom synonym files to generate prompts that are configured to address limitations of the various LLMs to obtain accurate replies to user requirements.,ACCENTURE GLOBAL SOLUTIONS LTD,JADHAV SURAJ GOVIND;;RAMACHANDRAN ASHWIN;;KUMMAMURU KRISHNA;;DAWAR SIDDHARTH;;SHROFF MANOJ,ACCENTURE GLOBAL SOLUTIONS LIMITED (2024-03-08),https://lens.org/167-618-208-615-313,Patent Application,yes,0,1,1,167-618-208-615-313,US,1,167-618-208-615-313,US,0,G06F40/247;;G06F40/284;;G06F40/295;;G06F40/30;;G06F40/295;;G06F40/284;;G06F40/247,G06F40/295;;G06F40/247;;G06F40/284,,0,0,,,,PENDING
209,US,A1,US 2025/0225627 A1,143-663-408-372-338,7/10/2025,2025,US 202418409496 A,1/10/2024,US 202418409496 A,1/10/2024,IMAGE ASPECT RATIO ENHANCEMENT USING GENERATIVE AI,"A method includes adding an outpaint mask to an image to generate a masked image. The method also includes processing the image using an encoder neural network to generate an image representation of the image in a latent space. The method further includes processing the masked image using a convolution neural network and adding the image representation to generate an image embedding. The method also includes processing the image representation and the image embedding using at least one of a diffusion model and an interpolation process to generate a noisy latent image representation. The method further includes using a large language model to contextualize an outpainting prompt. The method also includes denoising the noisy latent image representation based on the contextualized outpainting prompt to generate a denoised latent image representation. In addition, the method includes processing the denoised latent image representation using a decoder neural network to generate an outpainted image.",SAMSUNG ELECTRONICS CO LTD,RAO ANIRUDH;;PALCZEWSKI TOMASZ J;;ZHU YINGNAN;;KIM HONG-HOE;;PRATURY CHAITANYA PRAVEEN,,https://lens.org/143-663-408-372-338,Patent Application,yes,0,0,1,143-663-408-372-338,US,1,143-663-408-372-338,US,0,G06T5/77;;G06T5/70;;G06T2207/20084;;G06T7/0002;;G06T2207/30168;;G06T5/60,G06T5/77;;G06T5/60;;G06T5/70;;G06T7/00,,0,0,,,,PENDING
210,US,A1,US 2025/0232114 A1,075-515-056-930-762,7/17/2025,2025,US 202418581668 A,2/20/2024,IN 202411001002 A,1/5/2024,DOCUMENT ENTITY EXTRACTION PLATFORM BASED ON LARGE LANGUAGE MODELS,"Systems and methods are provided for extracting entities from a body of text, using large language models. An example method comprises receiving, from a user, a first input comprising a body of text to be processed for information and a second input comprising a set of at least one element, wherein each of the at least one element comprises information associated with an entity, and wherein each of the at least one entity is data to be extracted from the first input. The example method further comprises creating a tailored input for a machine learning model based on the second input, sending the tailored input to the machine learning model, receiving an output from the machine learning model, processing the output, and providing a processed interactive output to the user.",FIDELITY INFORMATION SERVICES LLC,GANGAL SHRIKANT;;TILWANKAR TUSHAR;;SOUNDANKAR ABHINAY;;PATIL JAYDEEP;;SONI DEVENDRA,,https://lens.org/075-515-056-930-762,Patent Application,yes,0,0,1,075-515-056-930-762,US,2,119-554-731-991-371;;075-515-056-930-762,US;;WO,0,G06F16/338;;G06F40/258,G06F40/258;;G06F16/338,,0,0,,,,PENDING
211,US,A1,US 2025/0124474 A1,046-211-170-706-823,4/17/2025,2025,US 202318489148 A,10/18/2023,KR 20230138305 A,10/17/2023,METHOD AND SYSTEM FOR GENERATING REPORTS USING COMPANY DATA,"A method of generating a report using company data may include: collecting subscription company data related to a company subscribing to a platform; storing the collected subscription company data in association with a subscription company account; receiving consultation information through a consultation channel associated with the platform; specifying a consultee from the consultation information, and collecting consultee data related to the specified consultee; generating a report related to the specified agent, using a language model with at least some of the subscription company data and the consultee data as input; and providing the generated report to a subscriber account of the subscription company.",42 MARU INC,KIM DONG HWAN;;SEONG GIL JE;;KWON YOU KYUNG;;PARK JU SHICK;;CHANG HYUNG JIN;;ROE SOOK JIN,42 MARU INC (2023-10-18),https://lens.org/046-211-170-706-823,Patent Application,yes,0,0,3,046-211-170-706-823;;038-004-692-043-738;;110-377-472-871-954,US;;EP;;KR,3,046-211-170-706-823;;038-004-692-043-738;;110-377-472-871-954,US;;EP;;KR,0,G06Q30/01;;G06Q10/06;;G06Q30/0281;;G06Q10/10;;G06Q10/0637;;G06F16/3329;;G06F16/951;;G06Q30/0281,G06Q30/02,,0,0,,,,PENDING
212,US,A1,US 2025/0110618 A1,162-484-156-827-45X,4/3/2025,2025,US 202318374641 A,9/28/2023,US 202318374641 A,9/28/2023,CROSS-PLATFORM QUERY AND CONTENT CREATION SERVICE AND INTERFACE FOR COLLABORATION PLATFORMS,"Embodiments described herein relate to systems and methods for automatically generating content, generating API requests and/or request bodies, structuring user-generated content, and/or generating structured content in collaboration platforms, such as documentation systems, issue tracking systems, project management platforms, and other platforms. The systems and methods described use a network architecture that includes generative interface panel used to access a prompt generation service and a set of one or more purpose-configured large language model instances (LLMs) and/or other trained classifiers or natural language processors used to provide generative responses for content collaboration platforms.",ATLASSIAN PTY LTD,KUMAR NAVNEET,ATLASSIAN PTY LTD (2023-09-29),https://lens.org/162-484-156-827-45X,Patent Application,yes,0,0,2,162-484-156-827-45X;;072-453-322-393-964,US;;EP,2,162-484-156-827-45X;;072-453-322-393-964,US;;EP,0,G06F40/30;;G06F40/20;;G06Q10/103;;G06F16/90332;;G06F16/9038;;G06F16/93;;G06F3/0481;;G06Q30/015;;G06N3/0475;;G06F9/451;;G06F16/9538;;G06F40/35;;G06F3/0482;;G06F3/0483;;G06F3/0484,G06F3/0484;;G06F3/0482;;G06F3/0483;;G06F9/451;;G06F16/9538;;G06F40/35,,0,0,,,,PENDING
213,US,A1,US 2025/0217576 A1,076-659-098-938-323,7/3/2025,2025,US 202318399541 A,12/28/2023,US 202318399541 A,12/28/2023,GENERATIVE INTERFACE FOR MULTI-PLATFORM CONTENT,Embodiments described herein relate to systems and methods for automatically generating content for a generative answer interface of a collaboration platform. The system receives a natural language user input identifying corresponding blocks of text or snippets using a content extraction service. A prompt is generated using the blocks of text and is used to obtain a generative response. The generative response and links to corresponding content are displayed in the generative answer interface and can be inserted into content of the collaboration platform. The systems and methods described use a network architecture that includes a prompt generation service and a set of one or more purpose-configured large language model instances (LLMs) and/or other trained classifiers or natural language processors used to provide generative responses for content collaboration platforms.,ATLASSIAN PTY LTD,MANN CHRISTOPHER CHARLES;;OYE PHIL,,https://lens.org/076-659-098-938-323,Patent Application,yes,0,0,2,076-659-098-938-323;;055-719-551-678-970,US;;EP,3,076-659-098-938-323;;093-848-428-887-135;;055-719-551-678-970,US;;EP,0,G06F40/30;;G06F40/35;;G06F40/216;;G06F16/33295;;G06F16/243;;G06F16/248;;G06F40/166;;G06F40/30;;G06F3/0482;;G06F3/0484,G06F40/166;;G06F3/0482;;G06F3/0484;;G06F16/242;;G06F16/248;;G06F40/30,,0,0,,,,PENDING
214,US,A1,US 2025/0147937 A1,111-713-445-989-363,5/8/2025,2025,US 202318522849 A,11/29/2023,TW 112142619 A,11/6/2023,DATA CLEANING DEVICE AND DATA CLEANING METHOD,"The present invention is a data cleaning device executing a data cleaning method. The data cleaning method includes executing an application, and executing a prompt plugin management program. The operation of executing the prompt plugin management program includes generating a prompt instruction based on an unformatted content via a first prompt template, transmitting the prompt instruction to a first device, and receiving a formatted content from the first device. The formatted content is generated by the first device based on the prompt instruction through a large language model.",INST INFORMATION IND,TSAI YU-CHEN;;WENG MING-FANG,INSTITUTE FOR INFORMATION INDUSTRY (2023-11-29),https://lens.org/111-713-445-989-363,Patent Application,yes,6,0,2,036-588-242-214-826;;111-713-445-989-363,US;;CN,2,036-588-242-214-826;;111-713-445-989-363,US;;CN,0,G06F16/215;;G06F16/258;;G06F16/258;;G06F16/215,G06F16/215;;G06F16/25,,0,0,,,,PENDING
215,US,A1,US 2024/0419912 A1,016-419-753-134-77X,12/19/2024,2024,US 202318209232 A,6/13/2023,US 202318209232 A,6/13/2023,DETECTING HALLUCINATION IN A LANGUAGE MODEL,"Various embodiments discussed herein are directed to improving existing technologies by detecting a likelihood of hallucination arising from one-shot, few-shot, or outside knowledge contexts. For example, regarding the one-shot or few-shot contexts, some embodiments determine a set of tokens in a language model output that are not found in target content but are found in at least one example. When such phrases are not very common words, this is highly indicative that the model is hallucinating because these phrases should be located in the target content but are not, but are instead located in the examples.",MICROSOFT TECHNOLOGY LICENSING LLC,SOMECH HAIM;;MILLER ADI L;;AVIHOO ASSAF;;KANTOR AMIR,MICROSOFT TECHNOLOGY LICENSING LLC (2023-07-02),https://lens.org/016-419-753-134-77X,Patent Application,yes,33,5,2,016-419-753-134-77X;;024-695-182-388-91X,US;;WO,2,016-419-753-134-77X;;024-695-182-388-91X,US;;WO,0,G06N3/0455;;G06F40/56;;G06F40/279;;G06F40/226;;G06F40/40;;G06F40/30,G06F40/30;;G06F40/40,,1,1,175-171-134-453-359,10.1145/3624918.3625336,"Huo et al., title={Retrieving supporting evidence for generative question answering}, booktitle={Proceedings of the annual international acm sigir conference on research and development in information retrieval in the Asia Pacific region},pages={11--20}, year={2023} (Year: 2023)",PENDING
216,WO,A1,WO 2025/147342 A1,119-554-731-991-371,7/10/2025,2025,US 2024/0058202 W,12/3/2024,IN 202411001002 A;;US 202418581668 A,1/5/2024,DOCUMENT ENTITY EXTRACTION PLATFORM BASED ON LARGE LANGUAGE MODELS,"Systems and methods are provided for extracting entities from a body of text, using large language models. An example method comprises receiving, from a user, a first input comprising a body of text to be processed for information and a second input comprising a set of at least one element, wherein each of the at least one element comprises information associated with an entity, and wherein each of the at least one entity is data to be extracted from the first input. The example method further comprises creating a tailored input for a machine learning model based on the second input, sending the tailored input to the machine learning model, receiving an output from the machine learning model, processing the output, and providing a processed interactive output to the user.",FIDELITY INFORMATION SERVICES LLC,GANGAL SHRIKANT;;TILWANKAR TUSHAR;;SOUNDANKAR ABHINAY;;PATIL JAYDEEP;;SONI DEVENDRA,,https://lens.org/119-554-731-991-371,Patent Application,yes,0,0,1,119-554-731-991-371,WO,2,119-554-731-991-371;;075-515-056-930-762,US;;WO,0,,G06F40/295;;G06F16/583;;G06F18/21;;G06F40/20;;G06F40/30;;G06N3/02;;G06N3/08;;G06N20/00,,0,0,,,,PENDING
217,US,A1,US 2025/0245349 A1,001-842-553-834-345,7/31/2025,2025,US 19038669,1/27/2025,,,CUSTOM AI CO-PILOT FOR SOFTWARE SECURITY PEN-TESTING,"Systems and method for detecting vulnerabilities in code are provided herein. A pre-trained artificial intelligence (AI) model is engaged, and a plurality of prompts and the source code are provided to the AI model. A plurality of detected vulnerabilities and a plurality of code locations in the source code are identified using the AI model. Each of the plurality of code locations corresponds to at least one of the plurality of detected vulnerabilities. One or more false positive vulnerabilities in the plurality of detected vulnerabilities are identified. A plurality of augmented prompts is generated, based on the one or more false positive vulnerabilities. The plurality of augmented prompts is outputted to a database of prompts for use in future code analyses, without necessarily having to retrain the AI model.",UNIVERSITY OF SOUTH FLORIDA,Xinming Ou;;Dmitry B. Goldgof;;Jarred Ligatti;;Lawrence O'Higgins Hall,,https://lens.org/001-842-553-834-345,Patent Application,yes,0,0,1,001-842-553-834-345,US,1,001-842-553-834-345,US,0,G06F21/577;;G06F2221/033,G06F21/57,,0,0,,,,UNKNOWN
218,US,A1,US 2025/0156407 A1,196-378-496-566-852,5/15/2025,2025,US 202418749175 A,6/20/2024,CN 202311507880 A,11/13/2023,"QUERY PROCESSING METHOD BASED ON LARGE LANGUAGE MODEL, PROMPT CONSTRUCTION METHOD, ELECTRONIC DEVICE, AND STORAGE MEDIUM","Provided are a query processing method based on a large language model, a prompt construction method, an electronic device, and a storage medium. The query processing method includes acquiring a to-be-processed target query; acquiring a data field in a target data model and acquiring target format information of a specified data format; constructing a prompt based on the data field in the target data model, the target format information, and the target query; and inputting the prompt into the large language model to obtain a target format result outputted by the large language model.",BEIJING BAIDU NETCOM SCI & TECH CO LTD,GENG SHAOZHEN;;ZHANG JUN,,https://lens.org/196-378-496-566-852,Patent Application,yes,3,0,3,196-378-496-566-852;;129-782-726-973-141;;052-642-970-924-230,US;;CN,3,196-378-496-566-852;;129-782-726-973-141;;052-642-970-924-230,US;;CN,0,G06F16/3329;;G06F16/24575;;G06F16/2425;;G06F16/3329;;G06F16/2425;;G06F16/24575,G06F16/242;;G06F16/2457,,0,0,,,,PENDING
219,US,A1,US 2025/0124620 A1,043-222-460-804-872,4/17/2025,2025,US 202318380059 A,10/13/2023,US 202318380059 A,10/13/2023,COMPUTER NETWORK ACTIVITY SUMMARIZER AND CHAT INTERFACE,"Various disclosed embodiments are directed to deriving, via a language model, a summary of data by converting or encoding table data into one or more natural language sentences, which are then used as input to the language model for generating the summary. One or more embodiments are additionally or alternatively directed to deriving, via a language model, a response to a user question or command via a chat interface by providing the language model with the generated summary as input. In this way, for example, the language model can use the summary as a prompt or other target context for providing a response.",ADOBE INC,ARORA TARUN;;ANAND TANAY;;RAMESH SIDDARTH;;DESHMUKH SHRIPAD;;PRASOON PRANJAL;;DEWNANI PIYUSH;;ALAM MD ANIS;;SUBRAMANIAN JAYAKUMAR;;SATIJA GAURAV;;YERRAGUNTA DIWAKAR REDDY;;AMIRTHAGADESWARAN DEEPTHI;;KRISHNAMURTHY BALAJI;;KATIYAR AVINASH,ADOBE INC (2023-09-28),https://lens.org/043-222-460-804-872,Patent Application,yes,8,1,1,043-222-460-804-872,US,1,043-222-460-804-872,US,0,G06T11/206;;G06F40/40;;G06F40/30;;G06F40/40;;G06T11/206,G06T11/20;;G06F40/40,,0,0,,,,PENDING
220,US,A1,US 2025/0007955 A1,005-835-357-937-961,1/2/2025,2025,US 202318343863 A,6/29/2023,US 202318343863 A,6/29/2023,EFFICIENT ARBITRARY POLICIES FOR DATA AUTHORIZATION DECISION POINTS,One example method includes receiving a data file at a large language model (LLM). Arbitrary tags that include labels that are attachable to the data file and prompts are also received. The prompts are paired with the arbitrary tags to form arbitrary tag-prompt pairs and include information that is used by the LLM to find the paired arbitrary tag. The LLM determines a selected subset of the arbitrary tags that apply to the data file. A trust module receives the selected subset of the arbitrary tags that apply to the data file and data access policies that specify access rules for the data file. A conditional access decision is determined that specifies whether access should be given to the data file.,DELL PRODUCTS LP,FREUND WERNER SPOLIDORO;;PALATNIK DE SOUSA IAM;;PINTO JOÃO VICTOR;;DE ARAÚJO MICAEL VERÍSSIMO;;STELLING NETO ROBERTO NERY;;EVANS SARAH,DELL PRODUCTS L.P (2023-06-27),https://lens.org/005-835-357-937-961,Patent Application,yes,3,0,1,005-835-357-937-961,US,1,005-835-357-937-961,US,0,H04L63/20;;G06F40/30;;G06F40/30;;H04L63/20,H04L9/40;;G06F40/30,,0,0,,,,PENDING
221,WO,A1,WO 2024/196640 A1,169-840-848-125-654,9/26/2024,2024,US 2024/0019536 W,3/12/2024,US 202318186752 A,3/20/2023,ITERATIVE IMAGE GENERATION FROM TEXT,"Methods and systems are presented for automatically identifying additional descriptors of an image generated by a text-to-image generator from an initial prompt. The additional descriptors are either incorporated into the initial prompt or made into a new prompt in order to produce another image from the text-to-image generator. The initial prompt and additional descriptors can describe visual features represented in images including content, artistic styles, visual perspectives, and other visible attributes of images. The additional descriptors can be incorporated into the initial prompt by replacing or supplementing existing descriptors. Subsequent images generated by the text-to-image generator can be used to iteratively produce additional descriptors.",SONY INTERACTIVE ENTERTAINMENT INC,BEAN CELESTE M B,,https://lens.org/169-840-848-125-654,Patent Application,yes,2,0,4,012-177-871-836-022;;169-840-848-125-654;;047-294-090-490-308;;010-408-692-560-019,US;;WO;;TW;;KR,4,010-408-692-560-019;;169-840-848-125-654;;047-294-090-490-308;;012-177-871-836-022,US;;WO;;TW;;KR,0,G06F40/30;;G06T11/60;;G06V10/945;;G06F18/24;;G06N3/045;;G06T11/60;;G06F3/04895;;G06F40/279;;G06N3/0475;;G06N20/00;;G06F16/532;;G06T11/00;;G06T11/60;;G06N3/08;;G06F40/56;;G06T2207/20092,G06F40/30;;G06T11/60;;G06V10/40,,3,1,034-831-964-285-110,10.18653/v1/2022.emnlp-main.93,"AMIR HERTZ ET AL: ""Prompt-to-Prompt Image Editing with Cross Attention Control"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 2 August 2022 (2022-08-02), XP091285831;;JONAS OPPENLAENDER ET AL: ""Prompting AI Art: An Investigation into the Creative Skill of Prompt Engineering"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 13 March 2023 (2023-03-13), XP091467671;;ZHAO YU ET AL: ""Visual Spatial Description: Controlled Spatial-Oriented Image-to-Text Generation"", PROCEEDINGS OF THE 2022 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, 26 October 2022 (2022-10-26), pages 1437 - 1449, XP093173521, Retrieved from the Internet <URL:https://arxiv.org/pdf/2210.11109> DOI: 10.18653/v1/2022.emnlp-main.93",PENDING
222,US,A1,US 2025/0157106 A1,050-132-685-698-104,5/15/2025,2025,US 202418942011 A,11/8/2024,US 202418942011 A;;US 202363597483 P,11/9/2023,STYLE TAILORING LATENT DIFFUSION MODELS FOR HUMAN EXPRESSION,"Aspects of the present disclosure may include systems and methods generating visual content. The system may detect input of descriptive text associated with text content or audio content. The system may generate, based on the descriptive text, an initial latent representation by using a finetuned latent diffusion model. The system may apply a denoising process to the initial latent representation to produce a refined latent representation. The system may sample data points from a content distribution associated with prior timesteps and from a style distribution associated with subsequent timesteps, thereby generating a final image latent. The system may decode the final image latent to obtain a visually aligned image(s) corresponding to the descriptive text. The system may output the visually aligned image(s) on a user interface or a display.",META PLATFORMS INC,PAGA ARANTXA CASANOVA;;SUN BO;;KALIA ANMOL;;BEARMAN AMY LAWSON;;MAHAJAN DHRUV KUMAR;;SINHA ANIMESH,META PLATFORMS INC (2025-01-09),https://lens.org/050-132-685-698-104,Patent Application,yes,0,0,1,050-132-685-698-104,US,2,050-132-685-698-104;;164-898-092-892-000,US;;WO,0,G06T2200/24;;G06T11/60;;G06T11/60;;G06T2200/24;;G06F3/04845,G06T11/60;;G06F3/04845,,0,0,,,,PENDING
223,EP,A1,EP 4485297 A1,166-859-674-279-215,1/1/2025,2025,EP 24184674 A,6/26/2024,US 202363510287 P,6/26/2023,GENERATION AND USE OF CLASSIFICATION MODEL FROM SYNTHETICALLY GENERATED DATA,A method for training and using a field machine learning (ML) model to classify emission data is presented. The method includes generating synthetic data by a large language model (LLM) by prompting the LLM with emission classes and few shot examples. The synthetic data includes multiple synthetic data instances and corresponding instance labels. A training dataset is obtained from the synthetic data. The method further includes training the field ML model with training instances which are synthetic data instances from the training dataset and corresponding training labels. The field ML model generates a predicted probability distribution of a training output class corresponding to a training instance. The method further includes adjusting a model parameter weight of the field ML model to minimize a categorical cross-entropy loss function calculated based on the generated predicted probability distribution. The trained field ML model is used to classify emission data.,SERVICES PETROLIERS SCHLUMBERGER;;GEOQUEST SYSTEMS BV,MANIKANI SUNIL;;FREEMAN STEPHEN,,https://lens.org/166-859-674-279-215,Patent Application,yes,0,0,2,103-221-505-641-369;;166-859-674-279-215,US;;EP,2,103-221-505-641-369;;166-859-674-279-215,US;;EP,0,G06N20/00;;G06N3/0455;;G06N20/00,G06F40/10;;G06N20/00;;G06N3/0455,,5,0,,,"ARIAN ASKARI ET AL: ""Generating Synthetic Documents for Cross-Encoder Re-Rankers: A Comparative Study of ChatGPT and Human Experts"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 3 May 2023 (2023-05-03), XP091500626;;QIJIONG LIU ET AL: ""A First Look at LLM-Powered Generative News Recommendation"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 4 June 2023 (2023-06-04), XP091528405;;SHESHERA MYSORE ET AL: ""Large Language Model Augmented Narrative Driven Recommendations"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 4 June 2023 (2023-06-04), XP091529597;;RUIXIANG TANG ET AL: ""Does Synthetic Data Generation of LLMs Help Clinical Text Mining?"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 10 April 2023 (2023-04-10), XP091481002;;ALEXEY KURAKIN ET AL: ""Harnessing large-language models to generate private synthetic text"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 2 June 2023 (2023-06-02), XP091527666",PENDING
224,US,A1,US 2025/0103818 A1,019-863-681-482-002,3/27/2025,2025,US 202318471513 A,9/21/2023,US 202318471513 A,9/21/2023,HALLUCINATION DETECTION AS A METRIC FOR DETERMINING ACCURACY OF RESULTS FOR LARGE LANGUAGE MODELS IN MACHINE LEARNING,This disclosure describes detecting hallucination as a metric for determining the accuracy of responses from a large language model (LLM). Scores with and without an augmented system are compared. The similarity or dissimilarity may be mapped into a hallucination score. The hallucination score can accurately predict when an answer is likely to be a hallucination. This is accomplished using similarity analysis on the text between un-altered responses and altered responses.,BITVORE CORP,BOLCER GREGORY ALAN;;NADER RODRIGO SILVA;;ALMEIDA GABRIEL LUIZ FREITAS,,https://lens.org/019-863-681-482-002,Patent Application,yes,13,2,1,019-863-681-482-002,US,1,019-863-681-482-002,US,0,G06F16/3328;;G06F40/279;;G06F16/3344;;G06F40/30;;G06F40/30;;G06F16/3328;;G06F40/279;;G06F16/3344,G06F40/30;;G06F16/33;;G06F16/332;;G06F40/279,,1,0,,,"Fu et al., ""Gptscore: Evaluate as you desire."" arXiv preprint arXiv:2302.04166 (Year: 2023)",PENDING
225,US,A1,US 2025/0111167 A1,005-868-672-509-183,4/3/2025,2025,US 202318527117 A,12/1/2023,IN 202311066113 A,10/3/2023,DYNAMICALLY DETERMINED LANGUAGE MODEL SKILLS FOR RESPONDING TO A PROMPT,"Various embodiments of the technology described herein dynamically determine at least one target LM skill to use to generate an output for an initial prompt without the need for the target LM skill to be included in the original prompt. Embodiments of the technology described herein perform this determination via an intermediate LM skill layer that implements an orchestration loop in a computationally efficient manner that reduces effects of hallucination by identifying one or more target LM skills based on each task identified in the initial prompt. Embodiments of the intermediate LM skill layer are separate from the user device and the LLM. For example, the intermediate LM skill layer is positioned between an LLM abstraction layer and an application layer by which a user can interface with the intermediate LM skill layer.",MICROSOFT TECHNOLOGY LICENSING LLC,MCINTYRE CRAIG THOMAS;;STEVENSON BRADLEY SCOTT;;MCGOVERN ANDREW PAUL;;TROY ADAM DOUGLAS;;UNAWANE ANAND SHARAD;;AHER PANKAJ VITTHAL,MICROSOFT TECHNOLOGY LICENSING LLC (2023-10-16),https://lens.org/005-868-672-509-183,Patent Application,yes,0,1,1,005-868-672-509-183,US,1,005-868-672-509-183,US,0,G06F40/40;;G06F16/383;;G06F40/30;;G06F16/383;;G06F40/40,G06F40/40;;G06F16/383,,0,0,,,,PENDING
226,US,B1,US 11893981 B1,021-438-730-639-227,2/6/2024,2024,US 202318243588 A,9/7/2023,US 202318243588 A;;US 202318220437 A,7/11/2023,Search system and method having civility score,A scoring system and method identifies personal attacks in a piece of audio content and generates a civility score for the piece of audio content that can differentiate between personal attacks and vernacular/casual banter. The piece of audio content may be a podcast.,SEEKR TECH INC,CLARK ROBIN J;;KASGARI ALI TALEB ZADEH;;POULIS STEFANOS,SEEKR TECHNOLOGIES INC (2023-10-10),https://lens.org/021-438-730-639-227,Granted Patent,yes,67,4,5,097-242-993-959-591;;096-081-965-568-090;;034-912-405-602-620;;113-304-651-282-903;;021-438-730-639-227,US;;WO,11,099-308-893-149-585;;096-081-965-568-090;;034-912-405-602-620;;186-258-211-244-886;;021-438-730-639-227;;191-788-022-738-755;;113-304-651-282-903;;097-242-993-959-591;;187-529-063-709-837;;013-318-799-783-589;;113-669-545-482-225,US;;WO,0,G10L15/26;;G06Q30/0251;;G06N20/00;;G06Q30/0201;;G06F16/68;;G06F40/30;;G06N3/0895;;G10L15/183;;G10L15/26;;G10L25/48;;G10L25/30;;G10L15/22;;G10L15/16,G10L15/00;;G10L15/16;;G10L15/183;;G10L15/22;;G10L15/26;;G10L25/30;;G10L25/48,,0,0,,,,ACTIVE
227,US,A1,US 2025/0139188 A1,085-780-287-857-355,5/1/2025,2025,US 202418889622 A,9/19/2024,KR 20230144477 A,10/26/2023,SYSTEM AND METHOD FOR PROBLEM INFERENCE BASED ON MULTI-MODAL GENERATIVE ARTIFICIAL INTELLIGENCE,"A method for problem inference based on multi-modal generative artificial intelligence includes receiving question information including an image and text, generating formal languages by parsing the image and text of the question information, respectively, based on a pre-constructed problem solving template, generating text-based intermediate inference information for the question information by inputting the generated formal language to a formal language inference unit, generating image-based inference information by inputting the text-based intermediate inference information, the text included in the question information (hereinafter referred to as “text question information”), and the image included in the question information (hereinafter referred to as “image question information”) to a multi-modal image generation model, and generating text-based inference information by inputting the text-based intermediate inference information, the image-based inference information, and the text question information to a multi-modal text generation model.",ELECTRONICS & TELECOMMUNICATIONS RES INST,HEO JEONG;;KWON OH WOOG;;RYU JIHEE;;SEO YOUNG-AE;;SEONG JIN;;SHIN JONG HUN;;LEE KI YOUNG;;LEE YO HAN;;LIM SOOJONG,ELECTRONICS AND TELECOMMUNICATIONS RESEARCH INSTITUTE (2024-09-13),https://lens.org/085-780-287-857-355,Patent Application,yes,0,0,2,085-780-287-857-355;;101-405-160-715-353,US;;KR,2,085-780-287-857-355;;101-405-160-715-353,US;;KR,0,G06F40/205;;G06V10/86;;G06F40/40;;G06F17/11;;G06F40/30;;G06F16/9032;;G06F16/90335;;G06F16/9038;;G06F16/332;;G06F16/3332;;G06F16/3347;;G06F16/338;;G06F16/434;;G06F16/532;;G06F16/538;;G06F16/56;;G06F40/186;;G06N3/0475;;G06N3/0455;;G06F17/11;;G06V10/86;;G06F40/40;;G06F40/205,G06F17/11;;G06F40/205;;G06F40/40;;G06V10/86,,0,0,,,,PENDING
228,US,A1,US 2025/0148290 A1,023-653-038-296-787,5/8/2025,2025,US 202318386833 A,11/3/2023,US 202318386833 A,11/3/2023,OBJECTIVE SELECTION FOR LLM-BASED NETWORK TROUBLESHOOTING AND MONITORING AGENTS,"In one implementation, a device receives an input request for a large language model-based troubleshooting agent for a network. The device selects an optimization criterion for the large language model-based troubleshooting agent based on the input request. The device provides the optimization criterion to the large language model-based troubleshooting agent to cause the large language model-based troubleshooting agent to select a particular large language model to process the input request based on the optimization criterion. The device sends, to a user interface, an indication of a result of the particular large language model processing the input request.",CISCO TECH INC,VASSEUR JEAN-PHILIPPE;;SAVALLE PIERRE-ANDRÉ;;MERMOUD GRÉGORY;;SCHORNIG EDUARD,CISCO TECHNOLOGY INC (2023-11-02),https://lens.org/023-653-038-296-787,Patent Application,yes,0,0,1,023-653-038-296-787,US,1,023-653-038-296-787,US,0,G06N3/09;;G06N3/09,G06N3/09,,0,0,,,,PENDING
229,US,A1,US 2025/0238662 A1,100-462-926-531-377,7/24/2025,2025,US 202519034303 A,1/22/2025,US 202519034303 A;;US 202463700332 P;;US 202463645403 P;;US 202463624543 P,1/24/2024,SYSTEMS AND METHODS FOR IMPROVING PLATFORMS INTERACTING WITH ARTIFICIAL INTELLIGENCE MODELS,"Data characterizing a prompt and/or a parameter set can be received. Data characterizing an enhanced prompt can be generated. The enhanced prompt can be stored in a template. When a change in ta type of the artificial intelligence based model, a setting of the artificial intelligence based model, or a configuration for an enterprise in which the artificial intelligence based model is deployed, is determined to be above a threshold, the enhanced prompt can be modified. The modified enhanced prompt can be provided to one or more applications interfacing with the artificial intelligence model, or derivative of the template. Related apparatus, systems, techniques, and articles are also described.",AIBLE INC,SENGUPTA ARIJIT;;WRAY JONATHAN;;VELTKAMP JOSEPH;;SHAW ROBERT;;COOKE RICHARD;;DELANEY JOHN;;TAYLOR FRANK,,https://lens.org/100-462-926-531-377,Patent Application,yes,0,0,1,100-462-926-531-377,US,1,100-462-926-531-377,US,0,G06F40/40;;G06N3/0475,G06N3/0475;;G06F40/40,,0,0,,,,PENDING
230,US,A1,US 2025/0117432 A1,051-999-566-590-81X,4/10/2025,2025,US 202418907320 A,10/4/2024,US 202418907320 A;;US 202463623462 P;;US 202463623479 P;;US 202363588444 P;;US 202363588451 P;;US 202363588421 P,10/6/2023,SYSTEMS AND METHODS FOR DATABASE MANAGEMENT INTEGRATING AI WORKFLOWS,"Provided are systems and methods for AI management configured to guide interactions between end users systems and generative AI services. Various examples can manage data operations, among other options. In various embodiments, an AI management system is configured to host an interactive session via generating workflow steps for controlling interaction with AI models. The interactive session is configured to identify data management operations on user specified data sources. The AI management system can be used to analyze the data sources specified to generate a canonical data format spanning the multiple data sources, generate code for mapping the data sources into a canonical format, normalize the resulting data, cleanse the resulting data, validate the resulting data, and automatically generate code for each such function that can then be triggered by users interacting with the user interface.",TDAA TECH CORP,CURRAN ANDREW MCKENNIE;;FARR JON ERIC;;FRIEDMAN SANDY ROBERT,,https://lens.org/051-999-566-590-81X,Patent Application,yes,3,0,2,051-999-566-590-81X;;129-506-804-940-628,US;;WO,3,082-124-011-673-411;;051-999-566-590-81X;;129-506-804-940-628,US;;WO,0,G06F16/90335;;G06F9/453;;G06F16/9032;;G06F16/90335;;G06F9/453;;G06F16/9032,G06F16/903;;G06F9/451;;G06F16/9032,,0,0,,,,PENDING
231,WO,A1,WO 2025/102026 A1,164-898-092-892-000,5/15/2025,2025,US 2024/0055325 W,11/11/2024,US 202363597483 P;;US 202418942011 A,11/9/2023,STYLE TAILORING LATENT DIFFUSION MODELS FOR HUMAN EXPRESSION,"Aspects of the present disclosure may include systems and methods generating visual content. The system may detect input of descriptive text associated with text content or audio content. The system may generate, based on the descriptive text, an initial latent representation by using a finetuned latent diffusion model. The system may apply a denoising process to the initial latent representation to produce a refined latent representation. The system may sample data points from a content distribution associated with prior timesteps and from a style distribution associated with subsequent timesteps, thereby generating a final image latent. The system may decode the final image latent to obtain a visually aligned image(s) corresponding to the descriptive text. The system may output the visually aligned image(s) on a user interface or a display.",META PLATFORMS INC,PAGA ARANTXA CASANOVA;;SUN BO;;KALIA ANMOL;;BEARMAN AMY LAWSON;;MAHAJAN DHRUV KUMAR;;SINHA ANIMESH,,https://lens.org/164-898-092-892-000,Patent Application,yes,0,0,1,164-898-092-892-000,WO,2,050-132-685-698-104;;164-898-092-892-000,US;;WO,0,G06T11/60,G06T11/60,,2,1,141-753-770-896-691,10.1109/iccv51070.2023.00041,"TANVEER MAHAM ET AL: ""DS-Fusion: Artistic Typography via Discriminated and Stylized Diffusion"", 2023 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), IEEE, 1 October 2023 (2023-10-01), pages 374 - 384, XP034515383, DOI: 10.1109/ICCV51070.2023.00041;;WONWOONG CHO ET AL: ""Towards Enhanced Controllability of Diffusion Models"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 15 March 2023 (2023-03-15), XP091456519",PENDING
232,EP,A1,EP 4579492 A1,160-673-797-111-857,7/2/2025,2025,EP 24222981 A,12/23/2024,US 202363615244 P;;US 202418633465 A,12/27/2023,MULTI-PARTY CROSS-PLATFORM QUERY AND CONTENT CREATION SERVICE AND INTERFACE FOR COLLABORATION PLATFORMS,"Embodiments described herein relate to systems and methods for automatically generating content, generating API requests and/or request bodies, structuring user-generated content, and/or generating structured content in collaboration platforms, such as documentation systems, issue tracking systems, project management platforms, and other platforms. The systems and methods described use a network architecture that includes a generative interface panel having multiple automated assistant services. Each assistant service may access a prompt generation service and a set of one or more purpose-configured large language model instances (LLMs) and/or other trained classifiers or natural language processors used to provide generative responses for content collaboration platforms.",ATLASSIAN PTY LTD,KUMAR NAVNEET;;CANNON-BROOKES MICHAEL,,https://lens.org/160-673-797-111-857,Patent Application,yes,1,0,2,160-673-797-111-857;;072-624-657-144-170,US;;EP,2,160-673-797-111-857;;072-624-657-144-170,US;;EP,0,G06F40/30;;G06F40/35;;G06Q10/10;;G06F16/332;;G06Q10/101;;G06Q10/103,G06F16/958;;G06F40/30;;G06F40/35;;G06Q10/10,,1,0,,,"JAWADEKAR ABHINAV ET AL: ""Quickly build high-accuracy Generative AI applications on enterprise data using Amazon Kendra, LangChain, and large language models"", AWS MACHINE LEARNING BLOG, 1 June 2023 (2023-06-01), XP093243823, Retrieved from the Internet <URL:https://aws.amazon.com/blogs/machine-learning/quickly-build-high-accuracy-generative-ai-applications-on-enterprise-data-using-amazon-kendra-langchain-and-large-language-models/> [retrieved on 20250416]",PENDING
233,US,A1,US 2025/0005918 A1,160-663-532-598-824,1/2/2025,2025,US 202318217248 A,6/30/2023,US 202318217248 A,6/30/2023,SYSTEM AND METHOD FOR PROMPT SEARCHING,"A computer-implemented method that includes receiving a plurality of input images, generating a visual matrix utilizing the plurality of images and an image encoder, wherein the visual matrix includes a list of encoded images, receiving a plurality of text prompts, selecting a text prompt from the plurality of text prompts, send the first one of the text prompts to a language model to generate a candidate list of tokens, selecting tokens, converting the text prompts into updated text prompts via appending the tokens, generating a text matrix utilizing the text prompt and text encoder, and utilizing numerical values assigned at an image-text similarity matrix, determining a score associated with the image-text similarity matrix; and evaluating a criteria and outputting a final token to the updated text prompt in response to identifying a highest score associated with the final token after evaluating each of the plurality of text prompts.",BOSCH GMBH ROBERT;;UNIV CARNEGIE MELLON,WILLMOTT DEVIN T;;AKINWANDE VICTOR ABAYOMI;;JIANG YIDING;;SAM DYLAN JIANG;;KOLTER JEREMY,ROBERT BOSCH GMBH (2023-07-02);;CARNEGIE MELLON UNIVERSITY (2023-07-25),https://lens.org/160-663-532-598-824,Patent Application,yes,3,1,3,084-102-117-638-759;;132-425-855-079-819;;160-663-532-598-824,US;;DE;;CN,3,084-102-117-638-759;;132-425-855-079-819;;160-663-532-598-824,US;;DE;;CN,0,G06F40/20;;G06F40/151;;G06F18/22;;G06V10/70;;G06F18/213;;G06F18/2135;;G06N3/0895;;G06N3/0985;;G06V10/764;;G06V10/82;;G06N3/09;;G06V10/82;;G06V10/86;;G06F40/284;;G06V20/70;;G06V10/761;;G06V10/774;;G06V10/86;;G06V10/761;;G06F40/284;;G06V20/70;;G06V10/774;;G06V10/82,G06V10/86;;G06F40/284;;G06V10/74;;G06V10/774;;G06V10/82;;G06V20/70,,0,0,,,,PENDING
234,WO,A1,WO 2025/058959 A1,113-669-545-482-225,3/20/2025,2025,US 2024/0045731 W,9/6/2024,US 202318392402 A;;US 202318243588 A,9/7/2023,SEARCH SYSTEM AND METHOD HAVING CIVILITY SCORE,"A scoring system and method identifies personal attacks in a piece of audio content and generates a civility score for the piece of audio content that can differentiate between personal attacks and vernacular/casual banter. The piece of audio content may be a podcast. The system and method may display a civility score to a user or communicate, using an application programming interface, the generated civility score to a third party.",SEEKR TECH INC,CLARK ROBIN;;KASGARI ALI;;POULIS STEFANOS,,https://lens.org/113-669-545-482-225,Patent Application,yes,6,0,1,113-669-545-482-225,WO,11,099-308-893-149-585;;096-081-965-568-090;;034-912-405-602-620;;186-258-211-244-886;;021-438-730-639-227;;191-788-022-738-755;;113-304-651-282-903;;097-242-993-959-591;;187-529-063-709-837;;013-318-799-783-589;;113-669-545-482-225,US;;WO,0,G10L15/26;;G06F40/30;;G06F40/216;;G06F40/56;;G06F40/44;;G06F40/35,G10L15/183;;G10L15/16;;G10L15/22;;G10L15/26;;G10L25/30;;G10L25/48,,0,0,,,,PENDING
235,US,A1,US 2025/0045596 A1,016-697-898-759-05X,2/6/2025,2025,US 202318362508 A,7/31/2023,US 202318362508 A,7/31/2023,LARGE LANGUAGE MODEL REGULATION SYSTEMS AND METHODS,"At least one processor may receive a query response generated by a query machine learning (ML) model, wherein the query response is generated in response to a query from a client device. The at least one processor may generate an evaluated likelihood of the query response being found in a training data set comprising known valid data, wherein the generating is performed using an evaluation ML model. The at least one processor may determine that the evaluated likelihood indicates the query response is likely to include valid data. In response to the determining, the at least one processor may return the query response to the client device.",INTUIT INC,DREVAL LIRAN;;MARGOLIN ITAY,,https://lens.org/016-697-898-759-05X,Patent Application,yes,0,0,1,016-697-898-759-05X,US,1,016-697-898-759-05X,US,0,G06N3/096;;G06N3/045;;G06N20/00;;G06N3/045;;G06N3/096,G06N3/096;;G06N3/045,,0,0,,,,DISCONTINUED
236,US,A1,US 2025/0087208 A1,186-045-307-662-469,3/13/2025,2025,US 202418793044 A,8/2/2024,KR 20230120613 A;;KR 20240005376 A,9/11/2023,METHOD AND DEVICE FOR CLASSIFYING UTTERANCE INTENT CONSIDERING CONTEXT SURROUNDING VEHICLE AND DRIVER,"In a method and device for classifying the intent of an utterance in consideration of context surrounding a vehicle and a driver, the computer-implemented method for determining an intent of a user's utterance includes obtaining utterance data representing an utterance occurred within a vehicle and context information related to the utterance, generating a prompt based on the utterance data and the context information, obtaining a context-aware sentence from an output of a generative large language model by providing the prompt to the generative large language model, and providing the context-aware sentence to an intent classification model to determine the intent of the utterance.",HYUNDAI MOTOR CO LTD;;KIA CORP,LEE SONG EUN,KIA CORPORATION (2024-07-29);;HYUNDAI MOTOR COMPANY (2024-07-29),https://lens.org/186-045-307-662-469,Patent Application,yes,0,0,2,105-048-876-004-314;;186-045-307-662-469,US;;CN,3,186-045-307-662-469;;105-048-876-004-314;;147-334-326-263-566,US;;CN;;KR,0,G10L15/1822;;G06F18/241;;G06N3/0455;;B60R16/0373;;G10L15/1822;;G10L2015/228;;B60R16/0373;;G10L15/183,G10L15/183;;B60R16/037,,0,0,,,,PENDING
237,WO,A1,WO 2025/151891 A1,149-639-121-556-488,7/17/2025,2025,US 2025/0011446 W,1/13/2025,US 202463620503 P,1/12/2024,MICROSERVICE ARCHITECTURE ANALYSIS USING LARGE LANGUAGE MODELS,"Methods and systems for analyzing the architecture of microservice systems using large language models (LLMs) are described. An example method for analyzing an architecture of a microservice system includes generating an intermediate representation that includes a representation of dependencies between a plurality of microservices of the microservice system, and generating, based on the intermediate representation and a general LLM, at least one answer to at least one question associated with the architecture of the microservice system. The method further includes performing, based on the at least one answer, one or more operations that reconfigure at least one microservice of the plurality of microservices. An example system includes one or more processors configured to implement the above-described method.",UNIV ARIZONA;;UNIV BAYLOR;;QUEVEDO ERNESTO;;AISHA AMR ELSAYED MOHAMED ABDELFATTAH SAAD;;RODRIGUEZ ALEJANDRO;;YERO JORGE,QUEVEDO ERNESTO;;AISHA AMR ELSAYED MOHAMED ABDELFATTAH SAAD;;RODRIGUEZ ALEJANDRO;;YERO JORGE;;CERNY TOMAS,,https://lens.org/149-639-121-556-488,Patent Application,yes,0,0,1,149-639-121-556-488,WO,1,149-639-121-556-488,WO,0,,G06N3/04;;G06F9/44;;G06N3/08,,0,0,,,,PENDING
238,US,B1,US 12283291 B1,006-865-908-540-658,4/22/2025,2025,US 202318450695 A,8/16/2023,US 202318450695 A,8/16/2023,Factually consistent generative narrations,"Systems, devices, and methods are provided for determining factually consistent generative narrations. A narrative may be generated by performing steps to determine one or more metadata messages for a first portion of a video stream, determine transcribed commentary for a second portion of the video stream, wherein the second portion includes the first portion, and determine a prompt based at least in part on the one or more metadata messages and the transcribed commentary. The prompt may be provided to a generative model that produces an output text. Techniques for performing a factual consistency evaluation may be used to determine a consistency score for the output text that indicates whether the output text is factually consistent with the one or more metadata messages and the transcribed commentary. A narrated highlight video may be generated using the consistent narrative.",AMAZON TECH INC,SARFATI NOAH LIRONE;;YERUSHALMY IDO;;CHERTOK MICHAEL;;IDESES IANIR,AMAZON TECHNOLOGIES INC (2023-08-09),https://lens.org/006-865-908-540-658,Granted Patent,yes,5,1,1,006-865-908-540-658,US,1,006-865-908-540-658,US,0,H04N21/8549;;H04N21/8106;;G11B27/036;;G10L15/26;;H04N21/8106;;H04N21/8549;;G10L15/26;;G11B27/036,G11B27/036;;G10L15/26;;H04N21/81;;H04N21/8549,,0,0,,,,ACTIVE
239,CN,A,CN 119760573 A,164-682-184-047-629,4/4/2025,2025,CN 202411894914 A,12/20/2024,CN 202411894914 A,12/20/2024,一种交通事故成因分析方法、装置、设备及介质,本申请公开了一种交通事故成因分析方法、装置、设备及介质，涉及道路交通领域，包括：通过第一基座模型确定历史交通事故数据的前N级事故成因标签和相应的事故成因描述，利用第二基座模型对其进行归类以确定第N级事故成因标签的下一级事故成因标签，从而构建多层级事故成因标签，以便利用第一基座模型并基于多层级事故成因标签分析增加少样本提示词的交通事故数据，以得到该交通事故数据的前N+1级事故成因标签和相应的事故成因描述。本申请利用大语言模型的分析归类能力，以根据前N级事故成因标签和相应的事故成因描述确定第N级事故成因标签的下一级事故成因标签，从而构建更精细化的多层级事故成因标签，挖掘交通事故的多方面深层次原因。,杭州诚道科技股份有限公司,韦笑;;申琳;;陈教;;向坤;;周诚彪,,https://lens.org/164-682-184-047-629,Patent Application,no,4,0,2,164-682-184-047-629;;018-714-903-323-694,CN,2,164-682-184-047-629;;018-714-903-323-694,CN,0,,G06F18/2431;;G06F18/243;;G06F40/30;;G06N3/0455;;G06N5/04;;G06Q50/26;;G06Q50/40,,3,1,047-235-866-467-851,10.1162/dint_a_00251,"王文浩: ""城市轨道交通系统风险链群模型构建与应用方法研究"", 知网研学, 27 November 2024 (2024-11-27);;SONGLIN CHEN 等: ""LLaMA-LoRA Neural Prompt Engineering: A Deep Tuning Framework for Automatically Generating Chinese Text Logical Reasoning Thinking Chains"", DATA INTELLIGENCE, vol. 6, no. 2, 17 April 2023 (2023-04-17), pages 375 - 408;;邓创;刘友波;刘俊勇;黄丹青;: ""考虑降雨诱发次生地质灾害的电网风险评估方法"", 电网技术, no. 12, 5 December 2016 (2016-12-05), pages 221 - 230",ACTIVE
240,CN,A,CN 118395951 A,182-504-915-986-146,7/26/2024,2024,CN 202410833084 A,6/26/2024,CN 202410833084 A,6/26/2024,"Automatic data entry method and device, electronic equipment and storage medium","The invention discloses an automatic data entry method and device, electronic equipment and a storage medium, and belongs to the field of data processing.The automatic data entry method comprises the steps that a search word of to-be-entered data is obtained; recalling related text information from a database according to the search word, and determining a cue word according to the search word; using the cue word to guide the trained language model to extract an answer related to the search word from the text information; and inputting related answers into the system. According to the method, the information fragment most relevant to query can be accurately positioned and recalled, and the requirement for total data processing is remarkably reduced, so that a large amount of computing power and time are saved.",AISHA MEDICAL TECH WEIFANG CO LTD,TIAN YONGQIAN,,https://lens.org/182-504-915-986-146,Patent Application,no,4,1,1,182-504-915-986-146,CN,1,182-504-915-986-146,CN,0,G06F40/166;;G06F40/279;;G06F40/30;;G06Q10/103,G06F40/166;;G06F40/279;;G06F40/30;;G06Q10/10,,4,0,,,"TOUCH.AI: ""013篇 - 特定领域的提示词（Prompt Engineering - Prompts for Specific Domains）"", pages 1, Retrieved from the Internet <URL:https://blog.csdn.net/qq_51084193/article/details/139421389>;;SIMON LIU: ""提問(Prompt)的藝術：如何引導AI準確回答你的需求"", pages 1 - 7, Retrieved from the Internet <URL:https://blog.infuseai.io/prompt-introduction-concept-d45fc79576d7>;;INFOMO: ""GPT的Prompt基本范式"", pages 1 - 4, Retrieved from the Internet <URL:https://www.iofomo.com/blog/prompt/#关键要素>;;AI魔法学院: ""ChatGPT Prompt提示词学习手册（提示词万能公式），建议收藏！"", pages 1 - 12, Retrieved from the Internet <URL:https://www.wehelpwin.com/article/4840>",DISCONTINUED
241,US,A1,US 2025/0139372 A1,055-251-004-878-040,5/1/2025,2025,US 202318497001 A,10/30/2023,US 202318497001 A,10/30/2023,METHOD AND APPARATUS FOR ANALYZING EMOTIONS OF TEXT AND GENERATING FEEDBACK RESPONSES ON TEXT,"An apparatus for analyzing emotions of diaries and generating feedback response on diaries is provided. The apparatus includes a recorder, a negative-text analysis module, a positive-text adding module, and a visualization module. The recorder is configured to receive and store a text article. The negative-text analysis module is configured to analyze the text article and determine a negativity level and generate a basis for judgment according to an analyzing result with respect to the text article. The positive-text adding module is configured to receive the basis from the negative-text analysis module, generate feedback response that is positively oriented relative to the text article, and combine the text article with the feedback response to form a content. The visualization module is configured to visualize the content for creating a visual image.",THE EDUCATION UNIV OF HONG KONG,SONG YANJIE;;LEE CHI-KIN JOHN;;WU KAIYI;;LI QING,THE EDUCATION UNIVERSITY OF HONG KONG (2023-10-23),https://lens.org/055-251-004-878-040,Patent Application,yes,0,0,1,055-251-004-878-040,US,1,055-251-004-878-040,US,0,G06F40/30;;G06F40/30,G06F40/30,,0,0,,,,PENDING
242,WO,A1,WO 2025/046116 A1,066-444-683-108-426,3/6/2025,2025,EP 2024074363 W,8/30/2024,GB 202313397 A,9/1/2023,AUTOMATED AND SEMI-AUTOMATED PROGRAM CODE SYNTHESIS USING GENERATIVE MACHINE LEARNING COMPONENTS,"In one aspect, computer program code is synthesised based on program design artefacts. At least one code synthesis prompt is created based on a program design artefact, and synthesised program code is obtained by submitting the at least one code synthesis prompt to a machine learning (ML)-based generator. The program design artefact for synthesizing the first program code is obtained by submitting at least one program design prompt to the ML- based generator. When the synthesised program code is modified, at least one design update prompt is submitted to the ML-based generator based on the modified program code, causing the ML-based generator to generate an updated program design artefact. Alternatively, when the program design artefact is modified, at least one code update prompt is submitted to the ML-based generator based on the modified artefact, causing the ML-based generator to generate updated program code.",COGNA LTD,AYERS EDWARD;;MENNEN LARS ROBERT MONICA;;PETERS BENEDICT,,https://lens.org/066-444-683-108-426,Patent Application,yes,0,0,2,162-425-697-337-939;;066-444-683-108-426,GB;;WO,2,162-425-697-337-939;;066-444-683-108-426,GB;;WO,0,G06F8/30;;G06N20/00;;G06F8/65,G06F8/30;;G06F8/65;;G06N20/00,,4,0,,,"SIRUI HONG ET AL: ""MetaGPT: Meta Programming for Multi-Agent Collaborative Framework"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 1 August 2023 (2023-08-01), XP091583320;;MOHAMMED LATIF SIDDIQ ET AL: ""A Lightweight Framework for High-Quality Code Generation"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 17 July 2023 (2023-07-17), XP091565090;;NOAH SHINN ET AL: ""Reflexion: Language Agents with Verbal Reinforcement Learning"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 21 May 2023 (2023-05-21), XP091513777;;SHINN ET AL.: ""Reflexion: Language Agents with Verbal Reinforcement Learning"", ARXIV:2303.11366V3, 2023",PENDING
243,US,A1,US 2025/0111380 A1,137-134-548-324-353,4/3/2025,2025,US 202318375293 A,9/29/2023,US 202318375293 A,9/29/2023,GRAPHICAL USER INTERFACE INCLUDING ISSUE QUEUE MANAGEMENT FOR AN ISSUE TRACKING SYSTEM,"A computer-implemented method for defining and creating a request intake flow for an issue tracking system is described. Embodiments described herein include systems and techniques for creating custom portal intake flows for an issue tracking system. The systems may include a user interface that allows portal intake flows to be generated and the user to select the information and workflow for an intake flow during the generation process. Embodiments are also directed to system and methods for creating dynamic summaries for issues managed by an issue tracking system. The dynamic summaries may be generated using a generative output model, as described herein, and provide information to a user about a current status, history or other events associated with an issue. Embodiments are directed to systems and methods for using a generative output engine to provide suggestions for creating a project management interface for an issue tracking system.",ATLASSIAN PTY LTD,WILSON DAVID;;RAWSTHORNE KIMBERLY,ATLASSIAN PTY LTD (2023-09-27),https://lens.org/137-134-548-324-353,Patent Application,yes,0,0,1,137-134-548-324-353,US,1,137-134-548-324-353,US,0,G06Q30/016;;G06F3/0482;;G06F3/0482;;G06Q30/016,G06Q30/016;;G06F3/0482,,0,0,,,,PENDING
244,US,A1,US 2025/0111335 A1,175-947-885-716-40X,4/3/2025,2025,US 202318375365 A,9/29/2023,US 202318375365 A,9/29/2023,GENERATIVE CONTENT CREATION FOR A PORTAL INTAKE FLOW FOR AN ISSUE TRACKING SYSTEM,"A computer-implemented method for defining and creating a request intake flow for an issue tracking system is described. Embodiments described herein include systems and techniques for creating custom portal intake flows for an issue tracking system. The systems may include a user interface that allows portal intake flows to be generated and the user to select the information and workflow for an intake flow during the generation process. Embodiments are also directed to system and methods for creating dynamic summaries for issues managed by an issue tracking system. The dynamic summaries may be generated using a generative output model, as described herein, and provide information to a user about a current status, history or other events associated with an issue. Embodiments are directed to systems and methods for using a generative output engine to provide suggestions for creating a project management interface for an issue tracking system.",ATLASSIAN PTY LTD,WILSON DAVID;;RAWSTHORNE KIMBERLY,ATLASSIAN PTY LTD (2023-09-27),https://lens.org/175-947-885-716-40X,Patent Application,yes,0,0,1,175-947-885-716-40X,US,1,175-947-885-716-40X,US,0,G06Q10/103;;G06Q10/103;;G06F3/04845;;G06F3/0482,G06Q10/10;;G06F3/0482;;G06F3/04845,,0,0,,,,PENDING
245,WO,A1,WO 2025/046110 A1,030-586-817-475-035,3/6/2025,2025,EP 2024074356 W,8/30/2024,GB 202313394 A,9/1/2023,AUTOMATED AND SEMI-AUTOMATED PROGRAM CODE SYNTHESIS USING GENERATIVE MACHINE LEARNING COMPONENTS,"A software application is synthesised using one or more processors configured to cause a machine learning (ML)-based generator to perform the following operations, by submitting a series of prompts to the ML-based generator: generate a technical design for the software application based on a set of software requirements; generate a software skeleton for the application based on the technical design; and generate program code for the application based on the software skeleton.",COGNA LTD,MENNEN LARS ROBERT MONICA;;PETERS BENEDICT,,https://lens.org/030-586-817-475-035,Patent Application,yes,0,0,2,025-388-311-292-647;;030-586-817-475-035,GB;;WO,2,025-388-311-292-647;;030-586-817-475-035,GB;;WO,0,G06F8/30;;G06N20/00;;G06F11/3684,G06F8/30;;G06F11/36;;G06N20/00,,4,0,,,"SIRUI HONG ET AL: ""MetaGPT: Meta Programming for Multi-Agent Collaborative Framework"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 1 August 2023 (2023-08-01), XP091583320;;JIA ALLEN LI ET AL: ""AceCoder: Utilizing Existing Code to Enhance Code Generation"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 11 August 2023 (2023-08-11), XP091585925;;NOAH SHINN ET AL: ""Reflexion: Language Agents with Verbal Reinforcement Learning"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 21 May 2023 (2023-05-21), XP091513777;;SHINN ET AL.: ""Reflexion: Language Agents with Verbal Reinforcement Learning"", ARXIV:2303.11366V3, 2023, Retrieved from the Internet <URL:https://github.com/noahshinn024/reflexion>",PENDING
246,US,A1,US 2025/0111334 A1,189-672-050-023-62X,4/3/2025,2025,US 202318375271 A,9/29/2023,US 202318375271 A,9/29/2023,SYSTEM AND GRAPHICAL USER INTERFACE FOR GENERATING A PORTAL INTAKE FLOW FOR AN ISSUE TRACKING SYSTEM,"A computer-implemented method for defining and creating a request intake flow for an issue tracking system is described. Embodiments described herein include systems and techniques for creating custom portal intake flows for an issue tracking system. The systems may include a user interface that allows portal intake flows to be generated and the user to select the information and workflow for an intake flow during the generation process. Embodiments are also directed to system and methods for creating dynamic summaries for issues managed by an issue tracking system. The dynamic summaries may be generated using a generative output model, as described herein, and provide information to a user about a current status, history or other events associated with an issue. Embodiments are directed to systems and methods for using a generative output engine to provide suggestions for creating a project management interface for an issue tracking system.",ATLASSIAN PTY LTD,WILSON DAVID;;RAWSTHORNE KIMBERLY;;LARKIN BLAIR;;KITANOVIC JOANNA;;HAMID SHIHAB;;SCOUTAS DIMITRIOS,ATLASSIAN PTY LTD (2023-09-27),https://lens.org/189-672-050-023-62X,Patent Application,yes,0,0,1,189-672-050-023-62X,US,1,189-672-050-023-62X,US,0,G06Q10/103;;G06F3/0484;;G06F3/0482;;G06Q10/103;;G06F3/0484;;G06F3/0482,G06Q10/10;;G06F3/0482;;G06F3/0484,,0,0,,,,PENDING
247,WO,A1,WO 2025/046113 A1,145-221-886-781-077,3/6/2025,2025,EP 2024074359 W,8/30/2024,GB 202313395 A,9/1/2023,AUTOMATED AND SEMI-AUTOMATED PROGRAM CODE SYNTHESIS USING GENERATIVE MACHINE LEARNING COMPONENTS,"A machine learning (ML)-based generator is caused to generate an initial code artefact based by submitting at least one prompt to an ML-based generator. An error in the initial code artefact is identified by applying a static analysis to the initial indicating the identified error to the ML-based generator in at least one further prompt, causing the ML-based generator to generate an updated code artefact in response to the identified error.",COGNA LTD,MENNEN LARS ROBERT MONICA;;PETERS BENEDICT,,https://lens.org/145-221-886-781-077,Patent Application,yes,0,0,2,145-221-886-781-077;;160-603-715-695-577,GB;;WO,2,145-221-886-781-077;;160-603-715-695-577,GB;;WO,0,G06F8/30;;G06F8/75;;G06N20/00;;G06F11/3684,G06F8/30;;G06F8/75;;G06N20/00,,4,0,,,"VADIM LIVENTSEV ET AL: ""Fully Autonomous Programming with Large Language Models"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 20 April 2023 (2023-04-20), XP091489732, DOI: 10.1145/3583131.3590481;;XINYUN CHEN ET AL: ""Teaching Large Language Models to Self-Debug"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 11 April 2023 (2023-04-11), XP091481471;;SHUYANG JIANG ET AL: ""SelfEvolve: A Code Evolution Framework via Large Language Models"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 5 June 2023 (2023-06-05), XP091530366;;NOAH SHINN ET AL: ""Reflexion: Language Agents with Verbal Reinforcement Learning"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 10 June 2023 (2023-06-10), XP091535534",PENDING
248,WO,A1,WO 2025/046107 A1,028-925-063-818-805,3/6/2025,2025,EP 2024074353 W,8/30/2024,GB 202313396 A,9/1/2023,AUTOMATED AND SEMI-AUTOMATED PROGRAM CODE SYNTHESIS USING GENERATIVE MACHINE LEARNING COMPONENTS,"A computer system for synthesising computer program code comprises a requirements discovery component configured to receive a description of a software application to be synthesised. A machine learning (ML)-based generator is caused to generate, based on the description, an initial set of requirements for the software application, generate, based on the initial set of requirements, an initial program structure for the software application, and generate, based on the initial set of requirements and the initial program structure, an updated set of requirements for the software application. A code synthesis component is configured to receive the updated set of requirements, and cause the ML-based generator to generate program code for the software application based on the modified set of requirements.",COGNA LTD,MENNEN LARS ROBERT MONICA;;PETERS BENEDICT,,https://lens.org/028-925-063-818-805,Patent Application,yes,0,0,2,094-835-763-612-335;;028-925-063-818-805,GB;;WO,2,094-835-763-612-335;;028-925-063-818-805,GB;;WO,0,G06F8/30;;G06N20/00;;G06F8/10,G06F8/30;;G06F8/10;;G06N20/00,,4,0,,,"JIA ALLEN LI ET AL: ""AceCoder: Utilizing Existing Code to Enhance Code Generation"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 11 August 2023 (2023-08-11), XP091585925;;JIE JW WU: ""Does Asking Clarifying Questions Increases Confidence in Generated Code? On the Communication Skills of Large Language Models"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 25 August 2023 (2023-08-25), XP091599907;;NOAH SHINN ET AL: ""Reflexion: Language Agents with Verbal Reinforcement Learning"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 21 May 2023 (2023-05-21), XP091513777;;SHINN ET AL.: ""Reflexion: Language Agents with Verbal Reinforcement Learning"", ARXIV:2303.11366V3, 2023",PENDING
249,US,A1,US 2025/0217371 A1,093-848-428-887-135,7/3/2025,2025,US 202418622787 A,3/29/2024,US 202418622787 A;;US 202318399541 A,12/28/2023,GENERATIVE CONTENT SERVICE WITH MULTI-PATH CONTENT PIPELINE,"Embodiments described herein relate to systems and methods for automatically generating content for a generative content interface of a collaboration platform. The system may perform an intent analysis on a natural language user input to the generative content interface to determine an intent confidence score with respect to each of a set of request classifiers, the set of request classifiers comprising a first request classifier associated with a request for an action, a second request classifier associated with a request for information, and a third request classifier associated with a request for a contact. Based on the intent confidence scores of the request classifiers, the system may select a content store in which to search for content to satisfy a user's query.",ATLASSIAN PTY LTD,HAMID SHIHAB;;PRASAD AKSHAR;;RAO SHASHANK PRASAD;;OYE PHIL;;SINGH RAHUL,,https://lens.org/093-848-428-887-135,Patent Application,yes,0,0,1,093-848-428-887-135,US,3,076-659-098-938-323;;093-848-428-887-135;;055-719-551-678-970,US;;EP,0,G06F16/248;;G06F16/243;;G06F40/174;;G06F40/30;;G06F9/451;;G06F16/24578;;G06F16/24578;;G06F40/30;;G06F16/248;;G06F9/451;;G06F16/243;;G06F40/174,G06F16/2457;;G06F9/451;;G06F16/242;;G06F16/248;;G06F40/174;;G06F40/30,,0,0,,,,PENDING
250,US,A1,US 2025/0217425 A1,063-949-268-406-711,7/3/2025,2025,US 202418987120 A,12/19/2024,US 202418987120 A;;US 202363615431 P,12/28/2023,Method and System for an Intelligent Search Engine,"Systems, methods and interfaces are provided for processing natural language queries. A machine learning-powered search interface may process complex natural language queries across specialized domains. The method may utilize a transformer-based natural language processing model that analyzes user intent by examining both current and historical user inputs. A graph data structure may be used to represent interconnected domains like patient records, insurance claims, and business metrics enables dynamic information retrieval. The system may use an A* search algorithm to navigate domain nodes and identify relevant answers. An abbreviation expansion mechanism resolves technical shorthand by referencing domain-specific mapping databases, ensuring precise interpretation of user queries. The method may identify keywords, traces optimal answer pathways, and adapt by updating graph relationships and abbreviation mappings. By generating contextually rich natural language summaries, the system delivers precise, comprehensive responses through an intuitive search interface.",ELEVANCE HEALTH INC,GOLLAPUDI KRISHNA CHAITANYA;;SRIVASTAVA PRATEEK;;SINGIREDDY SANTOSH REDDY;;VASANTAVADA ATCHUTA SAI KUMAR;;RAO MOOVA NAGESHWARA,,https://lens.org/063-949-268-406-711,Patent Application,yes,0,0,2,031-439-123-294-498;;063-949-268-406-711,US;;WO,2,031-439-123-294-498;;063-949-268-406-711,US;;WO,0,G06F16/33295;;G06F16/9535;;G06F16/9538;;G06F16/9024;;G06F40/279;;G06F40/30,G06F16/9535;;G06F16/901;;G06F16/9538;;G06F40/279;;G06F40/30,,0,0,,,,PENDING
251,US,A1,US 2025/0036674 A1,085-967-764-503-518,1/30/2025,2025,US 202318458739 A,8/30/2023,US 202318458739 A;;US 202363515193 P,7/24/2023,CONTEXT INJECTION FOR IMPROVED AI RESPONSE,"A method comprises: receiving a query on a topic from a user associated with user attributes indicative of a user comprehension level on the topic; providing the query to an AI model; receiving from the AI model a response to the query that has a response comprehension level on the topic that is less than the user comprehension level; iteratively adding, to the query, topically-relevant user attributes of the user attributes to produce iterative queries that increase in technical detail on the topic; providing the iterative queries to the AI model; responsive to providing the iterative queries, receiving, from the AI model, iterative responses that increase in technical detail on the topic and have response comprehension levels that increase on the topic; and determining, among the iterative responses, a final response having a response comprehension level that most nearly matches the user comprehension level.",CISCO TECH INC,HANES M DAVID;;SINGH VIVEK KUMAR;;SALGUEIRO GONZALO A;;ENGI DEREK WILLIAM,CISCO TECHNOLOGY INC (2023-08-25),https://lens.org/085-967-764-503-518,Patent Application,yes,23,0,1,085-967-764-503-518,US,1,085-967-764-503-518,US,0,G06F16/3325;;G06F16/335;;G06F16/3325;;G06F16/335,G06F16/335;;G06F16/332,,0,0,,,,PENDING
252,US,A1,US 2024/0282131 A1,199-135-802-777-58X,8/22/2024,2024,US 202418421672 A,1/24/2024,US 202418421672 A;;US 202363481695 P,1/26/2023,Zero-Shot Prompt Ensembling for Zero-Shot Classification with Text-Image Models,Systems and methods for zero-shot prompt ensembling for zero-shot classification with text-image models can include utilizing a pre-trained text-image model to perform downstream tasks based on prompt-based weighting. The systems and methods may adjust for frequency-based bias and may automatically determine different prompt associations with a given downstream task. The systems and methods can aggregate weighted text embeddings and then determine a classification output based on similarity measures between an image embedding and the aggregated weighted text embeddings.,GOOGLE LLC,REN JIE;;LIU ZHE;;ALLINGHAM JAMES URQUHART;;DUSENBERRY MICHAEL WARD;;TRAN DUSTIN;;CUI YIN;;LAKSHMINARAYANAN BALAJI;;GU XIUYE,GOOGLE LLC (2023-03-22),https://lens.org/199-135-802-777-58X,Patent Application,yes,0,4,2,199-135-802-777-58X;;101-010-605-519-19X,US;;EP,2,199-135-802-777-58X;;101-010-605-519-19X,US;;EP,0,G06V10/7753;;G06V10/82;;G06N3/08;;G06N3/045;;G06F40/40;;G06V20/70;;G06V10/761;;G06V10/776;;G06V10/764,G06V20/70;;G06F40/40;;G06V10/74;;G06V10/764;;G06V10/776,,0,0,,,,PENDING
253,US,A1,US 2025/0094814 A1,016-762-655-942-341,3/20/2025,2025,US 202418824570 A,9/4/2024,US 202418824570 A;;US 202363538755 P,9/15/2023,FINE-TUNING A LARGE LANGUAGE MODEL (LLM) TO REDUCE THE INSTABILITY OF LLM OUTPUTS TO VARIATIONS IN PROMPTS,"Techniques are provided for fine-tuning large language models (LLMs) to reduce the instability of LLM outputs to prompt. In one technique, a plurality of prompts is stored. For each prompt of the plurality of prompts, a plurality of variants of that prompt is generated. A prompt generating LLM is fine-tuned based on that prompt and the plurality of variants. Each variant-prompt association (where the variant is generated based on the prompt and has an identical or similar meaning) is a training sample that is used to train or fine-tune the prompt generating LLM. The prompt generating LLM is configured to generate standardized prompts based on input prompts. In another technique, a response generating LLM is fine-tuned based on sets of training samples, each training sample in a set comprising a different variant of a prompt and a response that the response generating LLM generated based on the prompt.",ORACLE INT CORP,WANG ZHENG;;HU YAZHE;;GUO MENGQING;;SHENG TAO;;QIAN JUN;;MAMTANI VINOD M,ORACLE INTERNATIONAL CORPORATION (2023-09-15),https://lens.org/016-762-655-942-341,Patent Application,yes,0,2,1,016-762-655-942-341,US,1,016-762-655-942-341,US,0,G06N3/0895;;G06N20/00;;G06N3/0895,G06N3/0895,,0,0,,,,PENDING
254,US,A1,US 2025/0119604 A1,051-411-772-065-469,4/10/2025,2025,US 202418883440 A,9/12/2024,US 202418883440 A;;US 202363587906 P,10/4/2023,Delivery of Intermediate Media During Retrieval of Requested Media,"This document describes systems and techniques for presenting intermediate media to a user that has presented a media request. In aspects, a media request for requested media is received from an input device. The media request is provided to a media service to serve the requested media to a requested device. The media request is processed to identify attributes of the media request indicative of a subject matter of the requested media. Based on the identified attributes of the media request, intermediate media is accessed including one or more images related to the identified attributes. The intermediate media is delivered to the requested device. Accordingly, the intermediate media provides content to engage the user while the user waits for the requested media to be delivered.",GOOGLE LLC,SHIN DONGEEK,GOOGLE LLC (2023-10-01),https://lens.org/051-411-772-065-469,Patent Application,yes,0,0,1,051-411-772-065-469,US,1,051-411-772-065-469,US,0,G06T11/00;;G06F16/432;;H04N21/25;;H04N21/25;;G06F16/432;;G06T11/00,H04N21/25;;G06F16/432;;G06T11/00,,0,0,,,,PENDING
255,WO,A1,WO 2025/111323 A1,076-251-592-990-777,5/30/2025,2025,US 2024/0056634 W,11/20/2024,US 202363600925 P,11/20/2023,SYSTEMS AND METHODS FOR RETRIEVAL AUGMENTED GENERATION,"Systems and methods herein provide a processor; and a non-transitory, processor readable storage medium communicatively coupled to the processor. The non-transitory, processor readable storage medium may include one or more instructions stored thereon that, when executed, cause the processor to: input one or more queries into a large language model; generate, based on the one or more queries, a plurality of natural language queries, wherein each of the plurality of natural language queries are distinct queries and associated with the one or more queries; perform vector searches for the one or more queries and plurality of natural language queries; compile the plurality of natural language queries into a search result based on the vector searches; and generate a summary based on the search result.",ELSEVIER INC,RAUDASCHL ADRIAN;;SCHWARTZ ERIK;;CLELAND HENRY;;ZHANG KEHAN,,https://lens.org/076-251-592-990-777,Patent Application,yes,0,0,2,076-251-592-990-777;;071-009-444-251-457,US;;WO,2,076-251-592-990-777;;071-009-444-251-457,US;;WO,0,G06F16/24578;;G06F16/243;;G06F16/243;;G06F16/24578,G06F16/2452;;G06F16/22;;G06F16/2453;;G06F16/2455;;G06F16/2457;;G06F16/248;;G06F16/30;;G06F16/332;;G06N20/00,,0,0,,,,PENDING
256,US,A1,US 2025/0238427 A1,082-124-011-673-411,7/24/2025,2025,US 202519033072 A,1/21/2025,US 202519033072 A;;US 202418907320 A;;US 202463623462 P;;US 202463623479 P;;US 202363588444 P;;US 202363588451 P;;US 202363588421 P,10/6/2023,SYSTEMS AND METHODS FOR INTERACTION GOVERNANCE WITH ARTIFICIAL INTELLIGENCE,"Systems and methods are provided to facilitate user interaction with AI models. For example, guided sessions turn user requests into workflow steps, that enable optimization at each step. In other aspects, an interaction layer or component can be configured to manage interactions with AI models that are tailored to the requesting user (e.g., via curation agents or components) or tailored to a context identified during an interactive session. These interactive/guided sessions expand on the functionality to account for and/or encompass perspectives associated with source and/or generated content. Many AI models are known to be biased among other issues. The system can manage bias using context information. Leveraging context information, the system provides insight and associated context to eliminate the bias from outputs returned, and/or even enhance the bias of outputs returned as desired, among other options. AI models can be provided as curators having specific characteristics that constrain outputs.",TDAA TECH CORP,CURRAN ANDREW MCKENNIE;;FARR JON ERIC;;FRIEDMAN SANDY ROBERT,,https://lens.org/082-124-011-673-411,Patent Application,yes,0,0,1,082-124-011-673-411,US,3,082-124-011-673-411;;051-999-566-590-81X;;129-506-804-940-628,US;;WO,0,G06F16/24575;;G06F16/248,G06F16/248;;G06F16/2457,,0,0,,,,PENDING
257,WO,A1,WO 2025/160070 A1,024-050-238-580-508,7/31/2025,2025,US US2025/012421,1/21/2025,"US 63/6/023,462;;US 63/6/023,479",1/22/2024,SYSTEMS AND METHODS FOR INTERACTION GOVERNANCE WITH ARTIFICIAL INTELLIGENCE,"Systems and methods are provided to facilitate user interaction with Al models. For example, guided sessions turn user requests into workflow steps, that enable optimization at each step. In other aspects, an interaction layer or component can be configured to manage interactions with Al models that are tailored to the requesting user (e.g., via curation agents or components) or tailored to a context identified during an interactive session. These interactive/guided sessions expand on the functionality to account for and/or encompass perspectives associated with source and/or generated content. Many Al models are known to be biased among other issues. The system can manage bias using context information. Leveraging context information, the system provides insight and associated context to eliminate the bias from outputs returned, and/or even enhance the bias of outputs returned as desired, among other options. Al models can be provided as curators having specific characteristics that constrain outputs.","TDAA TECHNOLOGIES CORP;;CURRAN, Andrew McKennie;;FARR, Jon Eric;;FRIEDMAN, Sandy Robert",,,https://lens.org/024-050-238-580-508,Patent Application,yes,0,0,1,024-050-238-580-508,WO,1,024-050-238-580-508,WO,0,,G06F40/56;;G06N20/00;;G06N3/0475;;G06F40/30;;G06F16/3329;;G06F40/166;;G06F40/247;;G06F40/253,,0,0,,,,UNKNOWN
258,US,A1,US 2025/0045185 A1,042-540-170-761-998,2/6/2025,2025,US 202318228423 A,7/31/2023,US 202318228423 A,7/31/2023,"LARGE LANGUAGE MODELS FOR CREATING A MULTI-LINGUAL, LOW-RESOURCE CODE TRANSLATION DATASET","One or more unit-test cases are generated from a monolingual code corpus and the generated unit-test cases are filtered to generate a corpus of unit-test cases which have acceptability scores exceeding one or more predefined thresholds. One or more of the code samples of the monolingual code corpus are translated from a source language to a target language using a pretrained Large Language Model and the generated unit-test cases are translated from the source language to the target language. The LLM-translated code samples are validated using the translated unit-test cases and a parallel-data training corpus comprising the LLM-translated code samples that pass the validation is created. The pretrained large language model (LLM) is fine-tuned using the parallel-data training corpus, a given code segment is translated using the fine-tuned large language model (LLM), the translated given code segment is tested and the tested given code segment is deployed.",IBM;;MASSACHUSETTS INST TECHNOLOGY,TANG ZILU;;AGARWAL MAYANK;;CHEN JIE;;SHYPULA ALEXANDER GREGORY;;WANG BAILIN;;KIM YOON HYUNG,MASSACHUSETTS INSTITUTE OF TECHNOLOGY (2023-07-27);;INTERNATIONAL BUSINESS MACHINES CORPORATION (2023-07-11),https://lens.org/042-540-170-761-998,Patent Application,yes,5,3,1,042-540-170-761-998,US,1,042-540-170-761-998,US,0,G06F40/51;;G06F8/51;;G06F40/47;;G06F11/3684;;G06F11/3608;;G06F11/3608;;G06F8/51;;G06F40/47;;G06F40/51,G06F11/36;;G06F8/51;;G06F40/47;;G06F40/51,,3,1,107-633-604-402-394,10.1145/2931037.2931057,"Roziere, Baptiste, et al. ""Leveraging automated unit tests for unsupervised code translation."" arXiv preprint arXiv:2110.06773 (2021). pp.1-20. (Year: 2021);;Tufano, Michele, et al. ""Unit test case generation with transformers and focal context."" arXiv preprint arXiv:2009.05617 (2020). pp. 1-15. (Year: 2020);;Palomba, Fabio, et al. ""Automatic test case generation: What if test code quality matters?."" Proceedings of the 25th International Symposium on Software Testing and Analysis. 2016. pp.130-141. (Year: 2016)",PENDING
259,US,A1,US 2023/0154453 A1,119-303-652-025-996,5/18/2023,2023,US 202218046455 A,10/13/2022,KR 20210157067 A;;KR 20220081325 A,11/15/2021,Method of Generating Response Using Utterance and Apparatus Therefor,"Systems and techniques to generate imitative responses are illustrated. response generation method performed in an electronic apparatus of the present disclosure includes acquiring at least one piece of utterance data, acquiring a first context corresponding to the utterance data from a context candidate set, generating one or more dialogue sets including the first context and the utterance data, receiving a second context from a user, and acquiring a response corresponding to the second context using a language model based on the one or more dialogue sets.",HYPERCONNECT INC,ERDENEE ENKHBAYAR;;KIM BEOM SU;;KIM SANG BUM;;SEO SEOK JUN;;YOO JIN YONG;;CHANG BU RU;;HAN SEUNG JU,HYPERCONNECT INC (2022-10-04),https://lens.org/119-303-652-025-996,Patent Application,yes,0,5,4,114-054-912-071-571;;032-359-891-823-491;;119-303-652-025-996;;041-136-622-465-268,US;;EP;;JP,5,114-054-912-071-571;;032-359-891-823-491;;119-303-652-025-996;;012-004-801-982-272;;041-136-622-465-268,US;;EP;;KR;;JP,0,G06F40/35;;H04L51/02;;G06N5/041;;G06N3/0475;;G06N3/045;;G06N3/096;;G06N3/006;;G06F40/20;;G10L15/02,G10L15/02;;G06F40/20,,0,0,,,,PENDING
260,US,A1,US 2025/0103624 A1,122-242-275-279-190,3/27/2025,2025,US 202318473808 A,9/25/2023,US 202318473808 A,9/25/2023,COMBINATORIAL PROMPTING FOR LARGE LANGUAGE MODELS,"An embodiment for generating and employing incrementally optimized combinatorial prompts for tuning a target model. The embodiment may select a predetermined number of examples from a training dataset. The embodiment may concatenate each of the selected examples with a current prompt of a target model to obtain a set of candidate prompts. The embodiment may, for each individual candidate prompt in the set of candidate prompts, calculate a loss value over a validation dataset. The embodiment may replace the current prompt with the individual candidate prompt having a lowest calculated loss value that is less than or equal to an original loss value over the validation set for the current prompt to obtain an updated prompt.",IBM,CARTA THOMAS ANDRE MAXIME;;KIMURA DAIKI;;AGRAVANTE DON JOVEN RAVOY;;TATSUBORI MICHIAKI,INTERNATIONAL BUSINESS MACHINES CORPORATION (2023-09-20),https://lens.org/122-242-275-279-190,Patent Application,yes,12,0,2,077-862-570-050-329;;122-242-275-279-190,US;;JP,2,077-862-570-050-329;;122-242-275-279-190,US;;JP,0,G06F16/3329;;G06F40/20;;G06F40/20;;G06F16/3329,G06F16/332;;G06F40/20,,0,0,,,,PENDING
261,WO,A1,WO 2025/037145 A1,131-744-980-066-189,2/20/2025,2025,IB 2024000194 W,4/23/2024,US 202363518930 P;;US 202363597033 P,8/11/2023,METHOD AND SYSTEM FOR AUTOMATIC DETECTION OF FAIRY CIRCLES,"A method for finding sub-circular surface depression, SSD, which contributes to exploration of a subsurface resource, the method including receiving (900) target images (401) associated with an area of interest, generating (902) pseudo-labels (506) with a foundation model (400) by prompting the foundation model (400) with input images (502), which are different from the target images (401), training (904) a semantic segmentation model (500) based on the pseudo-labels (506), generating (906) SSD predictions (510) with the semantic segmentation model (500), from the target images (401), and producing (908) an image of the area of interest, based on the SSD predictions (510), to identify a location of the resource.",CGG SERVICES SAS,ISMAIL ALI;;HOU SONG;;FINDLAY JENNIFER;;BAINES ALFIE;;KELLY RANALD;;OLIVARES CAROLINA,,https://lens.org/131-744-980-066-189,Patent Application,yes,1,0,1,131-744-980-066-189,WO,1,131-744-980-066-189,WO,0,G06V10/82;;G06V20/13;;G06V20/194;;G06V20/188;;G06V20/70;;G06V10/774;;G06V10/26,G06V10/26;;G01V1/30;;G06V10/774;;G06V10/82;;G06V20/10;;G06V20/13;;G06V20/70,,18,10,044-267-091-628-10X;;031-542-741-769-433;;034-745-856-602-165;;101-992-462-989-21X;;099-298-187-717-18X;;145-105-524-958-973;;009-024-236-722-549;;036-686-035-767-363;;175-405-452-819-327;;167-131-435-704-717,10.1126/science.1222999;;23539605;;10.1016/j.scitotenv.2022.158969;;36162584;;23976962;;10.1371/journal.pone.0070876;;pmc3744476;;10.1111/jvs.13092;;10.1016/j.ijhydene.2021.07.023;;10.1002/essoar.10501881.1;;10.3390/rs13183770;;10.1109/avss.2018.8639450;;10.1016/j.jag.2023.103377;;10.1007/978-3-319-24574-4_28,"SUN WEIXUAN ET AL: ""An Alternative to WSSS? An Empirical Study of the Segment Anything Model (SAM) on Weakly-Supervised Semantic Segmentation Problems"", ARXIV, 18 June 2023 (2023-06-18), pages 1 - 7, XP093174900, Retrieved from the Internet <URL:https://arxiv.org/pdf/2305.01586> [retrieved on 20240614], DOI: 10.48550/ARXIV.2305.01586;;KIRILLOV ALEXANDER ET AL: ""Segment Anything"", ARXIV, 5 April 2023 (2023-04-05), pages 1 - 30, XP093175028, Retrieved from the Internet <URL:https://arxiv.org/pdf/2304.02643> [retrieved on 20240614], DOI: 10.48550/ARXIV.2304.02643;;N. JUERGENS: ""The Biological Underpinnings of Namib Desert Fairy Circles"", SCIENCE, vol. 339, 2013, pages 1618 - 1621;;B. MALVOISINF. BRUNET: ""Barren ground depressions, natural H2 and orogenic gold deposits: Spatial link and geochemical model"", SCIENCE OF THE TOTAL ENVIRONMENT, vol. 856, 2023, pages 158969;;M.D. CRAMERN.N. BARGER: ""Are Namibian ''fairy circles'' the Consequence of Self-Organizing Spatial Vegetation Patterning?"", PLOS ONE, vol. 8, 2013, pages e70876;;S. GETZINH. YIZHAQW.R. TSCHINKEL: ""Definition of ''fairy circles'' and how they differ from other common vegetation gaps and plant rings."", JOURNAL OF VEGETATION SCIENCE, vol. 32, 2021, pages e13092;;E. FRERYL. LANGHIM. MAISONI. MORETTI: ""Natural hydrogen seeps identified in the North Perth Basin, Western Australia."", INTERNATIONAL JOURNAL OF HYDROGEN ENERGY, vol. 46, 2021, pages 31158 - 31173;;M. LUNDINEA. C. TREMBANIS: ""Developing a CNN for automated detection of Carolina bays from publicly available LiDAR data"", AGU FALL MEETING ABSTRACTS, vol. 2019, 2019, pages EP54C - 03;;M. LUNDINEA. TREMBANIS: ""Using Convolutional Neural Networks for Detection and Morphometric Analysis of Carolina Bays from Publicly Available Digital Elevation Models"", REMOTE SENSING, vol. 13, no. 18, September 2021 (2021-09-01), pages 3770;;W. J. LEONGB. YADAVA. NEGRETEI. M. HOWATJ. MOORTGAT: ""H2OvalNet: Detecting Fairy Circles from Sentinel-2 Imagery in Australia"", AGU FALL MEETING ABSTRACTS, vol. 2022, 2022, pages H22,1039;;Y. ZHUZ. MOAYEDB. BOLLARD-BREENA. DOSHIJ. B. RAMONDR. KLETTE: ""Detection of Fairy Circles in UAV Images Using Deep Learning"", 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS, 2018, pages 1 - 6, XP033518264, DOI: 10.1109/AVSS.2018.8639450;;K. NOYM. SILVERO. PESEKH. YIZHAQE. MARAISA. KARNIELI: ""Spatial and spectral analysis of fairy circles in Namibia on a landscape scale using satellite image processing and machine learning analysis"", INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION, vol. 121, 2023, pages 103377;;ALEXANDER KIRILLOVERIC MINTUNNIKHILA RAVIHANZI MAOCHLOE ROLLANDLAURA GUSTAFSONTETE XIAOSPENCER WHITEHEADALEXANDER BERGWAN-YEN LO: ""Segment anything"", ARXIV PREPRINT ARXIV:2304.02643, 2023;;X. WANGX. ZHANGY. CAOW. WANGC. SHENT. HUANG: ""Seggpt: Segmenting everything in context"", ARXIV PREPRINT ARXIV:2304.03284, 2023;;F. LI ET AL.: ""Visual In-Context Prompting"", ARXIV, 2023;;O. RONNEBERGERP. FISCHERT. BROX: ""U-net: Convolutional networks for biomedical image segmentation"", MEDICAL IMAGE COMPUTING AND COMPUTER-ASSISTED INTERVENTION-MICCAI 2015: 18TH INTERNATIONAL CONFERENCE, 5 October 2015 (2015-10-05), pages 234 - 241;;A. DOSOVITSKIY ET AL.: ""An image is worth 16x16 words: Transformers for image recognition at scale"", ARXIV PREPRINT ARXIV:2010.11929, 2020;;K. CHEN ET AL.: ""RSPrompter: Learning to prompt for remote sensing instance segmentation based on visual foundation model"", ARXIV PREPRINT ARXIV:2306.16269, 2023",PENDING
262,EP,A1,EP 4485303 A1,102-782-499-790-635,1/1/2025,2025,EP 24185158 A,6/27/2024,US 202363523909 P;;US 202318216741 A,6/28/2023,AUTOMATED CONTENT CREATION AND CONTENT SERVICES FOR COLLABORATION PLATFORMS,"There is provided a computer-implemented method for accessing a content creation and modification service from within an editor of a collaboration platform. The method comprising to cause display of a graphical user interface (500) of a frontend of the collaboration platform on a client device, the graphical user interface including an editor region (502) configured to receive user-generated content; in response to a command character provided to the editor region of the graphical user interface, cause display of a command prompt interface (602) positioned at least partially over the editor region; cause display of a command selection interface window (520) positioned at least partially over the editor region (502), the command selection interface window (520) including a set of command controls (524); in response to a user selection of a content-assistant control of the set of command controls, provide a first user input to the command prompt interface (602); and in response to receiving a second user input in the command prompt interface, generate a prompt, the second user input comprising user-generated text or a link object including a path to a linked content item on the collaboration platform. The prompt comprising predefined query prompt text corresponding to the selected content-assistant control; and a portion of the user-generated text or content extracted from the linked content item. The computer-implemented method comprises providing the prompt to an external generative output engine using an application program interface call; obtaining a generative response from the external generative output engine, the generative response including content that is unique to the prompt; causing display of at least a portion of the generative response in the graphical user interface (500); and in response to a user insertion command, cause the at least the portion of the generative response to be inserted into the editor region (502) of the graphical user interface (500).",ATLASSIAN PTY LTD;;ATLASSIAN US INC,MANSOUR SHERIF;;AWADHWAL GAURAV;;NAGY BALAZS;;TEKHOV ROMAN;;NABI RIFAT;;GILBERT THOMAS JAMES;;KATTA SWATI,,https://lens.org/102-782-499-790-635,Patent Application,yes,2,1,4,170-510-503-956-405;;071-390-307-365-082;;102-782-499-790-635;;058-690-426-160-462,US;;EP,19,041-464-038-285-404;;083-149-380-620-435;;127-001-664-673-954;;102-782-499-790-635;;123-651-742-884-685;;172-836-124-214-770;;061-837-329-090-687;;034-140-942-535-796;;170-510-503-956-405;;067-396-781-777-79X;;127-906-364-435-010;;144-524-720-744-913;;162-486-709-753-905;;040-188-476-038-660;;187-630-016-341-95X;;071-390-307-365-082;;091-875-869-915-809;;058-690-426-160-462;;040-100-603-581-545,US;;EP,0,G06Q10/06316;;G06Q10/101;;G06F9/453;;G06F3/048;;G06F40/166;;G06F40/169;;G06F40/253;;G06F40/134;;G06F40/134;;G06F40/166;;G06F40/197;;G06F3/0482,G06Q10/0631;;G06F3/048;;G06F9/451;;G06Q10/101,,0,0,,,,PENDING
263,US,A1,US 2025/0005528 A1,162-486-709-753-905,1/2/2025,2025,US 202318216760 A,6/30/2023,US 202318216760 A;;US 202363523909 P,6/28/2023,AUTOMATED CONTENT CREATION AND CONTENT SERVICES FOR COLLABORATION PLATFORMS,"Embodiments described herein relate to systems and methods for automatically generating content, generating API requests and/or request bodies, structuring user-generated content, and/or generating structured content in collaboration platforms, such as documentation systems, issue tracking systems, project management platforms, and other platforms. The systems and methods described use a network architecture that includes a prompt generation service and a set of one or more purpose-configured large language model instances (LLMs) and/or other trained classifiers or natural language processors used to provide generative responses for content collaboration platforms.",ATLASSIAN PTY LTD;;ATLASSIAN US INC,MANSOUR SHERIF;;AWADHWAL GAURAV;;NAGY BALAZS;;TEKHOV ROMAN;;GILBERT THOMAS JAMES;;NABI RIFAT;;KATTA SWATI,ATLASSIAN PTY LTD (2023-06-20);;ATLASSIAN US INC (2023-06-20),https://lens.org/162-486-709-753-905,Patent Application,yes,0,0,15,041-464-038-285-404;;083-149-380-620-435;;127-001-664-673-954;;123-651-742-884-685;;172-836-124-214-770;;061-837-329-090-687;;034-140-942-535-796;;067-396-781-777-79X;;127-906-364-435-010;;144-524-720-744-913;;162-486-709-753-905;;040-188-476-038-660;;187-630-016-341-95X;;091-875-869-915-809;;040-100-603-581-545,US,19,041-464-038-285-404;;083-149-380-620-435;;127-001-664-673-954;;102-782-499-790-635;;123-651-742-884-685;;172-836-124-214-770;;061-837-329-090-687;;034-140-942-535-796;;170-510-503-956-405;;067-396-781-777-79X;;127-906-364-435-010;;144-524-720-744-913;;162-486-709-753-905;;040-188-476-038-660;;187-630-016-341-95X;;071-390-307-365-082;;091-875-869-915-809;;058-690-426-160-462;;040-100-603-581-545,US;;EP,0,G06F16/2455;;G06F40/197;;G06F16/93;;G06N3/0475;;H04L51/21;;G06F16/3334;;G06F16/243;;G06F40/40;;G06F16/345;;G06Q10/06316;;G06F9/451;;G06F40/20;;G06F16/954;;G06F16/9038;;G06Q10/063114;;G06F16/3329;;H04L51/02;;G06F40/134;;G06F40/174;;G06Q10/101;;G06F40/205;;G06F40/30;;G06Q10/103;;G06F16/90332;;G06F40/186;;G06F16/248;;G06F21/31;;G06F40/117;;G06F40/166;;G06F40/143;;H04L51/046;;G06F40/169;;G06N3/047;;G06F16/3334;;G06F16/345;;G06Q10/103;;G06F3/04812;;G06F16/3329;;G06F40/134;;G06F40/40;;G06F40/30;;G06F16/243;;G06F16/248;;G06F3/0484;;H04L51/02;;G06F40/117;;G06Q10/063114;;G06F16/954;;G06F9/547;;G06Q10/101;;G06F3/0486;;G06Q10/06316;;G06F40/20;;G06F21/31;;H04L51/21;;G06F9/451;;G06F40/174;;G06N3/0475;;G06F9/541;;G06F40/166;;G06F40/205;;G06F40/197;;G06F40/186;;G06F16/93;;G06F16/9038;;G06F16/90332;;G06F16/2455,G06Q10/10;;G06F40/186;;G06F40/40;;G06Q10/0631,,0,0,,,,PENDING
264,US,A1,US 2025/0217341 A1,088-377-867-644-021,7/3/2025,2025,US 202418924532 A,10/23/2024,US 202418924532 A;;US 202363616042 P,12/29/2023,METADATA DETERMINATION AND STORAGE METHOD,"Methods, systems, and techniques for metadata determination and storage. A large language model that is implemented using at least one artificial neural network receives an initial prompt that includes a query related to the metadata. The metadata is in respect of data that is part of a dataset, and the initial prompt includes context for the query. The large language model determines the metadata in response to the query using the context. Once determined, the metadata is stored in the dataset such that the metadata is associated with the data to which it relates.",ROYAL BANK OF CANADA,TITUS JINOJ;;AUGRUSO TONY;;KURUZAR NADA;;JOY AJAY;;LEUNG CHARLES;;RAY PRIYANKA;;WANG RUQI,,https://lens.org/088-377-867-644-021,Patent Application,yes,0,0,1,088-377-867-644-021,US,1,088-377-867-644-021,US,0,G06F16/24578;;G06F16/2237;;G06F16/24578;;G06F16/2237,G06F16/22;;G06F16/2457,,0,0,,,,PENDING
265,US,B1,US 12217340 B1,124-442-286-055-183,2/4/2025,2025,US 202418783413 A,7/25/2024,US 202418783413 A;;US 202463637254 P;;US 202363611006 P;;US 202463637258 P;;US 202463637266 P;;US 202463644385 P;;US 202463637275 P;;US 202463637277 P,12/15/2023,Multi-layer pre-generated content,"Methods, systems, and computer programs are presented for the generation of content in advance to enable quickly customized communications for multiple types of customers. One method includes an operation for identifying components of an image design that specifies how the components are combined to generate an image. For one or more of the identified components, variations of the components are generated using one of several generative artificial intelligence (GAI) models. The method further includes detecting a request, comprising user attributes, for the image. For one or more of the identified components, a respective variation is selected based on the user attributes, and a response image is created utilizing the image design and the one or more selected variations. Further, the response image is presented on a computer user interface.",TYPEFACE INC,PARASNIS ABHAY;;SOOD VISHAL;;MOREIRA JONATHAN;;SRIRAM SRIPAD;;KRISHNA HARI;;CHEN FRANK;;BENDAPUDI PERRAJU,TYPEFACE INC (2023-07-05),https://lens.org/124-442-286-055-183,Granted Patent,yes,18,1,5,038-024-101-354-760;;170-700-138-228-895;;147-907-512-157-164;;101-024-712-936-789;;124-442-286-055-183,US,13,101-024-712-936-789;;055-185-359-749-43X;;140-719-340-018-551;;041-858-994-965-698;;038-024-101-354-760;;144-304-260-041-154;;170-700-138-228-895;;143-143-756-117-625;;040-754-353-577-107;;187-642-363-420-941;;147-907-512-157-164;;037-305-382-999-104;;124-442-286-055-183,US;;WO,0,G06T2200/24;;G06T11/60;;G06T11/60;;G06T2200/24;;G06Q30/0242;;G06Q30/0276;;G06F16/9577;;G06Q30/0271,G06T11/60,,7,2,041-307-886-094-783;;074-548-612-543-478,10.62036/isd.2023.60;;10.1109/ojcs.2023.3300321,"Oppenlaender, Jonas, “Prompt engineering for text-based generative art”, arXiv preprint, (Apr. 20, 2022), 7 pgs.;;“U.S. Appl. No. 18/783,424, Non Final Office Action mailed Sep. 24, 2024”, 20 pgs.;;U.S. Appl. No. 18/783,416, Non Final Office Action mailed Oct. 1, 24, 13 pgs.;;U.S. Appl. No. 18/783,419, Non Final Office Action mailed Oct. 18, 24, 27 pgs.;;Kumar, Madhav, et al., “Generative Al and Personalized Video Advertisements”, Available at SSRN 4614118, (2023), 17 pgs.;;Smolinski, Pawel, et al., “Towards completely automated advertisement personalization: jan integration of generative Al and information systems”, 31st International Conference on Information Systems Development (ISD2023), Lisbon, Portugal (2023), 10 pgs.;;Wang, Yuntao, et al., “A Survey on ChatGPT: Al-Generated Contents, Challenges, and Solutions”, IEEE Open Journal of the Computer Society, vol. 4 (2023), pp. 280-302.",ACTIVE
266,WO,A1,WO 2025/117883 A1,040-057-767-171-189,6/5/2025,2025,US 2024/0057955 W,11/29/2024,US 202363603670 P,11/29/2023,"METHOD, SYSTEM AND COMPUTER PROGRAM PRODUCT FOR DATA MINING WITH ARTIFICIAL INTELLIGENCE (AI) BASED SMART AGENTS","The invention relates to an AI-driven system for data analytics, processing, mining, and user interaction, utilizing large language models (LLMs) and machine learning (ML) techniques. The system enables personalized, real-time access to company data, guided by AI Agents. These Agents handle tasks such as data extraction, transformation, and loading, with a multi-stage processing pipeline that includes raw data ingestion, curation, and modeling. Specialized Agents like Fixing and Modeling Agents ensure data quality, analysis, and visualization. The system also integrates with BI dashboards for generating insights and predictive analytics. Users interact via natural language queries (NLQs) to receive context-aware, AI-generated answers, including various types of plots, graphs and charts, thus improving decision-making and data management efficiency.",HALLEY SCORE CORP,UZAL LUCAS;;RUYU BRUNO,,https://lens.org/040-057-767-171-189,Patent Application,yes,0,0,1,040-057-767-171-189,WO,1,040-057-767-171-189,WO,0,G06F40/35;;G06N3/02;;G06F16/2465;;G06N20/00;;G06N5/022,G06F40/35;;G06F16/14;;G06F16/21;;G06F16/3329;;G06F16/9032;;G06N3/02,,0,0,,,,PENDING
267,US,A1,US 2025/0238347 A1,144-913-967-462-159,7/24/2025,2025,US 202519026975 A,1/17/2025,CA 3226517 A,1/18/2024,METHOD AND APPARATUS OF MONITORING AND MANAGING A GENERATIVE AI SYSTEM,"A computer system may have one or computers and one or more data storage devices storing instructions, which when executed by the one or more computers implements a characterization manager, comprising: a test data database storing a plurality of test data sets; the characterization manager configured for selecting one or more test data sets from the test data database and apply the selected test data sets to a Generative AI system to derive from the Generative AI system an output; an output analyzer for processing the output to generate characterization data describing one or more facets of the output.",PRICEWATERHOUSECOOPERS LLP,SATELI BAHAR;;PANT VIK,,https://lens.org/144-913-967-462-159,Patent Application,yes,0,0,1,144-913-967-462-159,US,1,144-913-967-462-159,US,0,G06F11/3668;;G06F9/451;;G06F11/3409,G06F11/3668;;G06F9/451;;G06F11/34,,0,0,,,,PENDING
268,US,A1,US 2025/0139411 A1,088-814-129-718-650,5/1/2025,2025,US 202318498229 A,10/31/2023,US 202318498229 A,10/31/2023,SYSTEMS AND METHODS FOR ARTIFICIAL INTELLIGENCE AGENTS,"Embodiments described herein provide a large language model (LLM) based AI agent that adopts Monte-Carlo Tree Search (MCTS) to execute a task. The LLM is prompted with a task description and it responds with its first attempted list of actions. Based on the success or failure of the first attempt, the LLM is prompted with an updated prompt which includes feedback from the first attempt based on a determined reward. The prompt may include a relative “score” for each action taken at each step. A numeric score may be mapped to a set of pre-defined text labels, such as “high” or “low” value putting the score in a form more suited for an LLM prompt. In this way, the LLM is iteratively given prompts which are updated with the scores from each action taken at each previous iterations so that it traverses different paths on the tree in each iteration.",SALESFORCE INC,MURTHY RITHESH;;HEINECKE SHELBY;;NIEBLES DUQUE JUAN CARLOS;;LIU ZHIWEI;;XUE LE;;YAO WEIRAN;;FENG YIHAO;;CHEN ZEYUAN;;GOKUL AKASH;;ARPIT DEVANSH;;XU RAN;;MUI LIK;;WANG HUAN;;XIONG CAIMING;;SAVARESE SILVIO,SALESFORCE INC (2023-11-03),https://lens.org/088-814-129-718-650,Patent Application,yes,0,0,1,088-814-129-718-650,US,1,088-814-129-718-650,US,0,G06N3/0455;;G06N3/084;;G06N3/006;;G06N3/08;;G06N5/01;;G06N3/084;;G06N3/0455,G06N3/0455;;G06N3/084,,0,0,,,,PENDING
269,US,A1,US 2025/0148753 A1,067-465-624-835-796,5/8/2025,2025,US 202318504038 A,11/7/2023,US 202318504038 A,11/7/2023,ADAPTIVE VIDEO COMPRESSION USING GENERATIVE MACHINE LEARNING,"Various embodiments of the technology described herein relate to compression of video data, including selecting a pivot image from a video including a plurality of images and causing a first machine learning model to generate a descriptor of the pivot image, where the descriptor includes a language description associated with the pivot image. In one example, the pivot image and the descriptor are provided to a decoder for reconstruction of the video. In an embodiment, the decoder includes a generative machine learning model that takes as an input the pivot image and the descriptor. The decoder uses the pivot image to generate an image based at least in part on the descriptor. The image is combined with other images generated by the generative machine learning model to reconstruct the video.",MICROSOFT TECHNOLOGY LICENSING LLC,MENASHOF ROEI SHLOMO;;ISTRIN OREN;;LATNIK ITAMAR,MICROSOFT TECHNOLOGY LICENSING LLC (2023-11-07),https://lens.org/067-465-624-835-796,Patent Application,yes,0,0,2,069-772-538-215-42X;;067-465-624-835-796,US;;WO,2,069-772-538-215-42X;;067-465-624-835-796,US;;WO,0,G06N3/045;;G06V20/46;;H04N21/26603;;H04N21/84;;H04N19/503;;H04N19/463;;G06V10/82;;G06N3/088;;G06F40/40;;G06V10/761;;G06V2201/07,G06V10/74;;G06F40/40,,0,0,,,,PENDING
270,US,A1,US 2025/0104017 A1,168-325-078-144-548,3/27/2025,2025,US 202418889015 A,9/18/2024,US 202418889015 A;;US 202363584315 P,9/21/2023,GENERATIVE CUSTOMER EXPERIENCE AUTOMATION,"This disclosure describes visual interfaces as well as underlying methods and systems for bringing generative customer experience automation to the enterprises and their end-users. A visual workflow builder is part of a micro-engagement system that allows for creation of workflows without writing any code. The micro-engagement platform is enhanced to support an environment where the content of the micro-engagement can be generated, presented and selected by an enterprise persona and launched to the end-users. The generated content is more dialog-friendly and is based on a set of parameters around specific workflows and prior practices as learned by Large Language Models or other relatively smaller but more domain-specific fine-tuned language models. End-users can also input their descriptions through which apt workflows can be dynamically generated at runtime, thereby personalizing the end-user's engagement experience further.",USHUR INC,PETER HENRY THOMAS;;SHAMANNA VIJAYENDRA MYSORE;;SADASIVA SIMHA;;MAHBUB KASHIF;;CHOUBEY MAYANK;;KASHYAP RAVIL,USHUR INC (2024-09-18),https://lens.org/168-325-078-144-548,Patent Application,yes,0,0,2,022-889-166-362-077;;168-325-078-144-548,US;;WO,2,022-889-166-362-077;;168-325-078-144-548,US;;WO,0,G06Q30/015;;G06Q10/103;;G06Q30/015;;G06Q10/103,G06Q10/10;;G06Q30/015,,0,0,,,,PENDING
271,US,A1,US 2025/0181336 A1,132-560-694-643-969,6/5/2025,2025,US 202318530055 A,12/5/2023,US 202318530055 A,12/5/2023,SYSTEMS AND METHODS FOR ENABLING SOFTWARE CODE FOR DIFFERENT LANGUAGES,"Embodiments of the present disclosure include techniques for enabling software code for different languages. In one embodiment, a user creates a prompt. The prompt may be to generate new code or modify existing code. The prompt may be automatically modified to include one or more instructions to extract code elements from source code and the code elements may be translated. In some embodiments, translation services are incorporated into and IDE or build environment as a plugin.",SAP SE,VASILTSCHENKO MICHAIL;;WIENOLD THOMAS;;LIESKE CHRISTIAN;;DUPONT MAITE FRIEDRICH,SAP SE (2023-12-03),https://lens.org/132-560-694-643-969,Patent Application,yes,0,0,1,132-560-694-643-969,US,1,132-560-694-643-969,US,0,G06F8/51;;G06F40/279;;G06F40/58;;G06F8/51;;G06F11/3604;;G06F40/279,G06F8/51;;G06F11/36;;G06F40/279,,0,0,,,,PENDING
272,US,A1,US 2024/0273371 A1,003-400-562-826-720,8/15/2024,2024,US 202418431804 A,2/2/2024,US 202418431804 A;;US 202363443005 P,2/2/2023,CODE-LEVEL NEURAL ARCHITECTURE SEARCH USING LANGUAGE MODELS,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for determining an architecture for a neural network configured to perform a machine learning task. In one aspect, a method comprises: receiving training data; searching for a final architecture of the neural network, wherein the searching comprises: maintaining current population data; and repeatedly performing evolutionary architecture search steps comprising: selecting one or more candidate architectures from the current population of candidate architectures defined by the source code included in the current population data; generating an input prompt; processing the input prompt using the language model neural network to generate output source code that defines a plurality of new candidate architectures; and using the plurality of new candidate architectures defined by the output source code to update the current population data.",GOOGLE LLC,CHEN ANGELICA;;SO DAVID RICHARD;;DOHAN DAVID MARTIN,GOOGLE LLC (2024-03-20),https://lens.org/003-400-562-826-720,Patent Application,yes,0,0,1,003-400-562-826-720,US,1,003-400-562-826-720,US,0,G06N3/086;;G06N3/045;;G06N3/044;;G06N3/082;;G06N3/08;;G06N3/084;;G06N3/086,G06N3/086,,0,0,,,,PENDING
273,US,A1,US 2025/0086427 A1,173-600-771-876-581,3/13/2025,2025,US 202418882621 A,9/11/2024,US 202418882621 A;;US 202363581873 P,9/11/2023,A Method and System for Generating Optimal Machine Learning Model Architectures,"A system and method capable of learning connections between machine learning (ML) datasets and optimal ML models to perform model selection for many different dataset types, ML task frameworks, and ML applications. A system and method for generating a desired machine learning model representation by providing as input a dataset representation and one or more target requirements representations for the desired machine learning model representation, training a transformer using a system dataset including a number of machine learning experiments, each machine learning experiment having an associated dataset representation, target requirements representation, model representation, and performance representation, and using the transformer to generate the desired machine learning model representation having a performance representation which equals or exceeds the target requirements representation.",MODLEE INC,MAGNETTA BRADLEY JAMES,MODLEE INC (2024-11-20),https://lens.org/173-600-771-876-581,Patent Application,yes,0,1,1,173-600-771-876-581,US,1,173-600-771-876-581,US,0,G06N3/092;;G06N3/045;;G06N3/084;;G06N3/045;;G06N3/092;;G06N3/084,G06N3/045;;G06N3/084;;G06N3/092,,0,0,,,,PENDING
274,US,A1,US 2025/0165589 A1,154-278-658-582-854,5/22/2025,2025,US 202318518257 A,11/22/2023,US 202318518257 A,11/22/2023,FILTERING FOR HARMFUL GENERATIVE ARTIFICIAL INTELLIGENCE RESULTS,Techniques for filtering for harmful generative artificial intelligence (AI) results are described. An example of filtering includes receiving a request for an input phrase to be responded to by a generative AI model; comparing to the received input phrase to at least one known harmful input phrase to determine that the received input phrase is to be provided to the generative AI model; providing the received input phrase to the generative AI model; and generating a response by at least in part on an output of the generative AI model.,AMAZON TECH INC,BANNIHATTI KUMAR VINAYSHEKHAR;;KHOSLA SOPAN;;LAWLER HAYDEN;;GOYAL SIDDHARTH SATISH;;GANGADHARAIAH RASHMI;;LUCKRIA BRIJESH;;HORSLEY JAMES W;;RANGASWAMY BHASKAR HOSAHALLI;;BARDE ABHIJIT S,AMAZON TECHNOLOGIES INC (2024-08-23),https://lens.org/154-278-658-582-854,Patent Application,yes,0,0,2,154-278-658-582-854;;128-206-458-080-344,US;;WO,2,154-278-658-582-854;;128-206-458-080-344,US;;WO,0,G06F40/216;;G06F40/30;;G06F40/35;;G06F40/56;;G06F40/44;;G06F21/55,G06F21/55,,0,0,,,,PENDING
275,US,A1,US 2024/0403194 A1,016-018-495-012-966,12/5/2024,2024,US 202418676141 A,5/28/2024,US 202418676141 A;;US 202363505216 P;;US 202363519789 P;;US 202363505224 P;;US 202363519800 P,5/31/2023,STRUCTURING AND RICH DEBUGGING OF INPUTS AND OUTPUTS TO LARGE LANGUAGE MODELS,"The disclosure is directed to methods and systems for improving interactions with a Large Language Model (LLM). An artificial intelligence system (AIS) can receive user inputs via a graphical user interface indicating a task to be performed by the LLM, one or more tools which may be accessed by the AIS in response to tool calls from the LLM, and an output schema for structuring a format of a response from the LLM. The AIS can generate a prompt for the LLM based on the user input. The prompt can include indications of the one or more tools, one or more example tool operations, the task to be performed, and an indication of the output schema. The AIS can include a debugging application or module enabling rich debugging of language model interactions in a single view.",PALANTIR TECHNOLOGIES INC,HAWES MATTHEW;;SHANKAR ANKIT;;TELLING MORTEN;;DOBSON JACK;;MAJID ADIL,PALANTIR TECHNOLOGIES INC (2024-09-10),https://lens.org/016-018-495-012-966,Patent Application,yes,0,0,2,016-018-495-012-966;;049-423-113-086-262,US;;EP,2,016-018-495-012-966;;049-423-113-086-262,US;;EP,0,G06F16/24522;;G06F16/243;;G06F11/3656,G06F11/36,,0,0,,,,PENDING
276,US,A1,US 2025/0095395 A1,100-289-518-726-662,3/20/2025,2025,US 202418889936 A,9/19/2024,US 202418889936 A;;US 202363539175 P,9/19/2023,METHOD FOR ASSOCIATING NATURAL LANGUAGE WITH DIGITAL IMAGES,"A method for associating natural language with digital images is provided. The method includes steps of receiving a digitized image; identifying elements in the digitized image as identified elements; associating a contextual label to each element that becomes content for each element; identifying predetermined relationships between the identified elements; describing the content for each element individually and relationships between the elements with a predetermined language; engineering a prompt to be sent to a Language Model (LM); and receiving a response from the LM. Characteristically, the prompt is configured to provide an LM input and instruct the LL regarding a manner and configuration for responding to the LM input.",ALCHEMIE SOLUTIONS INC,WINTER JULIA ENGLISH;;ENGALAN JOSEPH;;WEGWERTH SARAH;;URREA ALEXA;;ROCHON KATHERINE;;ZYSNARSKI JACOB,ALCHEMIE SOLUTIONS INC (2025-05-08),https://lens.org/100-289-518-726-662,Patent Application,yes,0,0,1,100-289-518-726-662,US,1,100-289-518-726-662,US,0,G06V30/274;;G06V10/82;;G06V10/82;;G06V30/274,G06V30/262;;G06V10/82,,0,0,,,,PENDING
277,US,B1,US 12177692 B1,152-830-934-920-092,12/24/2024,2024,US 202418436772 A,2/8/2024,US 202418436772 A,2/8/2024,Detection of electronic device presence using emitted Wi-Fi signals,"Machine learning-based methods are disclosed to identify and/or count a number of electronic devices present in an area using emitted passive Wi-Fi signals. The identification and/or counting of Wi-Fi-enabled devices improves private and public security in determining human presence. The disclosed methods use trained machine learning models that learns the relationship between real-time Wi-Fi probe request broadcast behavior distribution and the number of electronic devices present. The disclosed methods can include use of other wireless data transfer protocols, such as Bluetooth and Cellular.",UBIETY TECH INC,SAVARIS AUGUSTO;;LOFTUS JOSEPH;;COX MICHAEL B;;PUCKETT KEITH,UBIETY TECHNOLOGIES INC (2024-02-02),https://lens.org/152-830-934-920-092,Granted Patent,yes,13,1,1,152-830-934-920-092,US,1,152-830-934-920-092,US,0,H04L43/12;;H04W24/02;;H04W84/12;;H04W8/005;;H04W24/02;;H04W84/12;;H04L43/12;;H04W8/005,H04W24/02;;H04L43/12;;H04W8/00;;H04W84/12,,1,1,047-682-164-195-112,10.1109/icce-asia53811.2021.9641870,"A Study on Device Identification from BLE Advertising Packets with Randomized MAC Addresses Akiyama et al. (Year: 2021), 4 pgs.",ACTIVE
278,US,B1,US 12219423 B1,159-684-735-796-780,2/4/2025,2025,US 202418436820 A,2/8/2024,US 202418436820 A,2/8/2024,Detection of electronic device presence using emitted bluetooth low energy signals,"Methods are disclosed to identify and/or count a number of electronic devices present in an area using emitted passive Bluetooth Low Energy (BLE) signals. The identification and/or counting of Bluetooth-enabled devices improves private and public security in determining human presence. Bluetooth-enabled devices passively emit BLE signals for inter-device communication in the form of Bluetooth Advertising Packets. The packets are sent by BLE-enabled devices to search for other known or compatible BLE devices, and advertise information such as media access control (MAC) addresses, device manufacturers, connection capabilities, and manufacturer-specific data. By passively listening to and decoding the observed BLE signals, access to the packets and the metadata they contain is gained. The disclosed methods can include use of other wireless data transfer protocols, such as Bluetooth and Cellular.",UBIETY TECH INC,SAVARIS AUGUSTO;;LOFTUS JOSEPH;;COX MICHAEL B;;PUCKETT KEITH,UBIETY TECHNOLOGIES INC (2024-02-02),https://lens.org/159-684-735-796-780,Granted Patent,yes,13,0,1,159-684-735-796-780,US,1,159-684-735-796-780,US,0,H04W4/021;;H04W8/005;;H04W4/80;;H04W8/005;;H04W4/021,H04W4/021;;H04W8/00,,1,1,047-682-164-195-112,10.1109/icce-asia53811.2021.9641870,A Study on Device Identification from BLE Advertising Packets with Randomized MAC Addresses Akiyama et al. (Year: 2021).,ACTIVE
279,US,A1,US 2025/0117480 A1,062-270-131-424-532,4/10/2025,2025,US 202318484058 A,10/10/2023,US 202318484058 A,10/10/2023,CODE ANALYSIS FOR PRIVACY AND RISK ASSESSMENT USING A TRAINED MACHINE-LEARNING MODEL,"Systems and methods for code analysis are provided. A system receives, from a first data owner system, an input indicating one or more privacy constraints, wherein the one or more privacy constraints indicate one or more rules for operating on a sensitive data set in a data store associated with the first data owner system. The system receives data comprising code configured to operate on the sensitive data set. The system apples a first set of one or more machine-learning-trained models to process the first input and the data comprising the code to generate code analysis output data, wherein the code analysis output data comprises an indication of whether the code satisfies the one or more privacy constraints. The system generates and transmits, based on the code analysis output data, an instruction indicating whether to execute the code to operate on the sensitive data.",DEVRON CORP,WAGH SAMEER;;CHOPRA KARTIK;;ROY SIDHARTHA,CHOPRA KARTIK (2023-12-31),https://lens.org/062-270-131-424-532,Patent Application,yes,0,1,1,062-270-131-424-532,US,1,062-270-131-424-532,US,0,G06F21/563;;G06F21/6218;;G06F21/577;;G06N3/0455;;G06N3/092;;G06F2221/033;;G06F21/6245;;G06N20/00;;G06F21/563;;G06N3/0455;;G06F2221/033;;G06F21/6218;;G06F21/577;;G06N3/092,G06F21/56;;G06F21/57;;G06F21/62;;G06N3/0455;;G06N3/092,,0,0,,,,PENDING
280,WO,A1,WO 2025/128316 A1,126-509-022-146-416,6/19/2025,2025,US 2024/0057256 W,11/25/2024,US 202318540283 A,12/14/2023,NATURAL LANGUAGE GENERATION,"Techniques for using a model to generate a response to a user input, where the response is associated with a personality determined to be relevant to the user input, are described. The system receives a user input and context data associated with the user input. Using the user input data and/or the context data, the system determines a personality (e.g., including a personality type and/or personality characteristics) relevant to the user input. The system generates a prompt instructing a model to generate a response to the user input that corresponds to the personality. The model processes the prompt to generate a response to the user input that corresponds to the personality. In some embodiments, the model generates a request for another component of the system to generate information responsive to the user input. The model may transform the responsive information into the personality-associated response.",AMAZON TECH INC,LIU XIAOHU;;GUO CHENLEI;;KUMAR BHARATH BHIMANAIK;;SHEN WEI;;ZHANG YU;;SARIKAYA RUHI,,https://lens.org/126-509-022-146-416,Patent Application,yes,2,0,2,126-509-022-146-416;;006-267-903-475-316,US;;WO,2,126-509-022-146-416;;006-267-903-475-316,US;;WO,0,G06F40/35;;G10L13/00;;G10L15/22;;G06F40/35;;G06F40/40;;H04L67/306,G06F40/35;;G10L13/00,,4,2,021-244-154-816-823;;103-395-867-713-307,10.36227/techrxiv.22683919;;10.18653/v1/2022.naacl-main.377,"EKIN SABIT: ""Prompt Engineering For ChatGPT: A Quick Guide To Techniques, Tips, And Best Practices"", TECHRXIV, 31 October 2023 (2023-10-31), XP093251321, Retrieved from the Internet <URL:https://d197for5662m48.cloudfront.net/documents/publicationstatus/174684/preprint_pdf/f94a60a2566eade6c63a19601bcf39b4.pdf> DOI: 10.36227/techrxiv.22683919.v2;;SHEN YONGLIANG ET AL: ""HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face"", 25 May 2023 (2023-05-25), XP093220072, Retrieved from the Internet <URL:https://arxiv.org/pdf/2303.17580v3>;;SEUNGJU HAN ET AL: ""Meet Your Favorite Character: Open-domain Chatbot Mimicking Fictional Characters with only a Few Utterances"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 22 April 2022 (2022-04-22), XP091208382;;CHUNG HOON HONG ET AL: ""Audrey: A Personalized Open-Domain Conversational Bot"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 11 November 2020 (2020-11-11), XP081811715",PENDING
281,US,A1,US 2024/0303423 A1,088-656-568-800-09X,9/12/2024,2024,US 202318314994 A,5/10/2023,US 202318314994 A;;US 202363489683 P,3/10/2023,PROMPT CHAINING FOR LLM INTEGRATIONS IN SPREADSHEET ENVIRONMENTS,"Technology is disclosed herein for an application service which interfaces with an LLM service. In an implementation, the application service receives a natural language input from a user associated with a spreadsheet. The application service generates multiple prompts based on the natural language input and a portion of the spreadsheet and determines an order in which to input the prompts to an LLM service. The application service determines an order in which to input the prompts to an LLM service, then inputs the prompts to the LLM service according to the determined order.",MICROSOFT TECHNOLOGY LICENSING LLC,FABIAN DANIEL;;BABANOV ALEXANDER A;;MUDUMBAI CHAKRAVARTHY RASIKA;;KOTYNIA JAKUB PIOTR;;TAN JASON CHRISTOPHER;;GOODELL SKYLER MARK,MICROSOFT TECHNOLOGY LICENSING LLC (2023-05-04),https://lens.org/088-656-568-800-09X,Patent Application,yes,2,1,1,088-656-568-800-09X,US,2,142-238-546-614-004;;088-656-568-800-09X,US;;WO,0,G06F40/18;;G06F40/40;;G06F40/40;;G06F40/18,G06F40/18;;G06F40/40,,6,2,087-324-918-367-349;;089-001-809-021-425,10.1016/j.procs.2016.04.065;;10.1145/3491101.3519729,"Kojima et al. ""Large Language Models are Zero-Shot Reasoners”. 36th Conference on Neural Information Processing Systems (NeurIPS 2022 (Year: 2022);;Wachtel et al. “Initial implementation of natural language turn-based dialog system”. 7th International Conference in Intelligent Human Computer Interaction, IHCI 2015, Procedia Computer Science 84 (2016), 49-56 (Year: 2016);;Arora et al. “ASK ME ANYTHING: A SIMPLE STRATEGY FOR PROMPTING LANGUAGE MODELS”. arXiv:2210.02441v3 [cs.CL] 20 Nov 2022 (Year: 2022);;Wu et al. ""PromptChainer: Chaining Large Language Model Prompts through Visual Programming"". CHI ’22 Extended Abstracts, April 29-May 5, 2022, New Orleans, LA, USA (Year: 2022);;Zhang et al. “Automatic Chain of Through Prompting in Large Language Models”. arXiv:2210.03493v1 [cs.CL] 7 Oct 2022 (Year: 2022);;White et al. “A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT”. arXiv:2302.11382v1 [cs.SE] 21 Feb 2023 (Year: 2023)",PENDING
282,US,A1,US 2025/0036918 A1,185-515-111-151-621,1/30/2025,2025,US 202418784400 A,7/25/2024,US 202418784400 A;;US 202363515975 P,7/27/2023,ARTIFICAL INTELLIGENCE BASED SUPPORT AND INFORMATION PRESENTATION TOOLS FOR HVAC SYSTEMS,"A system may include a non-transitory storage medium storing computer program instructions and a processor configured to execute the computer program instructions to cause operations. The operations may include receiving, by a generic language model, a question from a user and querying, by the generic language model, a domain-specific knowledge model for an answer to the question. The operations may further include providing the answer to the user and/or providing documentation associated with the answer to the user.",WATSCO VENTURES LLC,CRUZ MARIO;;RUPP STEVE;;MCKEOWN JAMES,WATSCO VENTURES LLC (2024-07-25),https://lens.org/185-515-111-151-621,Patent Application,yes,0,0,3,016-351-760-954-188;;072-901-152-736-595;;185-515-111-151-621,US;;WO,3,016-351-760-954-188;;185-515-111-151-621;;072-901-152-736-595,US;;WO,0,G06N3/045;;G06N3/096;;G06N3/042;;G06N3/042;;G06N3/096;;G06N3/045,G06N3/042;;G06N3/045;;G06N3/096,,0,0,,,,PENDING
283,EP,A1,EP 4582968 A1,157-449-932-347-121,7/9/2025,2025,EP 24222066 A,12/20/2024,US 202418404677 A,1/4/2024,"EFFICIENT GENERATION OF APPLICATION PROGRAMMING INTERFACE CALLS USING LANGUAGE MODELS, DATA TYPES, AND ENRICHED SCHEMA","Various embodiments of the technology described herein cause an LLM to intelligently process data based on a user query and a schema determined for a data set. Certain embodiments programmatically leverage an LLM and utilize its output based on a user query. In this manner, data is processed without the LLM having to access an entire data set, and instead only utilizes information associated with the user query and the schema. The schema comprises a textual description, such as a string of alphanumeric characters, that describes the data, data types, and/or data structure of the data set. Embodiments of the technology described herein are performed by an LLM interface layer separate from a user device layer and an LLM layer. The LLM interface layer is positioned between an LLM abstraction layer and an application layer by which a user can interface with the LLM interface layer.",MICROSOFT TECHNOLOGY LICENSING LLC,DOTAN-COHEN DIKLA;;NOWAK KATHLEEN O'BRIEN;;AVIHOO ASSAF;;ABRAMOV TOM;;VIT ADAR,,https://lens.org/157-449-932-347-121,Patent Application,yes,1,0,2,140-454-330-275-422;;157-449-932-347-121,US;;EP,2,140-454-330-275-422;;157-449-932-347-121,US;;EP,0,G06F16/90332;;G06F16/9038;;G06F16/243;;G06F16/90324;;G06F9/547,G06F16/242;;G06F16/9032;;G06F16/9038,,1,0,,,"PATIL SHISHIR G ET AL: ""Gorilla: Large Language Model Connected with Massive APIs"", ARXIV, 24 May 2023 (2023-05-24), pages 1 - 18, XP093202974, Retrieved from the Internet <URL:https://arxiv.org/pdf/2305.15334>",PENDING
284,WO,A1,WO 2025/151365 A1,035-837-157-806-251,7/17/2025,2025,US 2025/0010452 W,1/6/2025,US 202418407232 A,1/8/2024,NEURAL NETWORK TUNING USING TEXT ENCODER,"Methods, systems, and non-transitory computer-readable mediums for tuning a generative text-to-image neural network. Text prompts are processed using a pre-trained text encoder to obtain embedded text prompts, which are used by a pre-trained diffusion model to generate images. Reward scores are iteratively determined for the images while the pre-trained diffusion model is fixed and weights of the pre-trained text encoder are updated to fine tune the neural network in order to improve the quality of generated images. Additionally, reward scores for the images can then be determined with the updated weights of the text encoder fixed to update weights of the pre-trained diffusion model to further fine tune the neural network.",SNAP INC,DING ERLI;;HU JU;;IDELBAYEV YERLAN;;KAG ANIL;;LI YANYU;;REN JIAN;;SAGAR DHRITIMAN;;TULYAKOV SERGEY,,https://lens.org/035-837-157-806-251,Patent Application,yes,0,0,2,035-837-157-806-251;;163-819-410-484-770,US;;WO,2,035-837-157-806-251;;163-819-410-484-770,US;;WO,0,G06N3/0475;;G06N3/0455;;G06N3/084;;G06V10/82;;G06N3/045,G06N3/0455;;G06N3/0475;;G06N3/084,,5,0,,,"HAO YARU ET AL: ""Optimizing Prompts for Text-to-Image Generation"", 29 December 2023 (2023-12-29), XP093246620, Retrieved from the Internet <URL:https://arxiv.org/abs/2212.09611v1> [retrieved on 20250402];;CLARK KEVIN ET AL: ""Directly Fine-tuning Diffusion Models on Differentiable Rewards"", 29 September 2023 (2023-09-29), pages 1 - 28, XP093266130, Retrieved from the Internet <URL:https://arxiv.org/abs/2309.17400> [retrieved on 20250402];;ZHIXUAN LIU ET AL: ""Towards Equitable Representation in Text-to-Image Synthesis Models with the Cross-Cultural Understanding Benchmark (CCUB) Dataset"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 28 January 2023 (2023-01-28), XP091424781;;GAL RINON ET AL: ""Encoder-based Domain Tuning for Fast Personalization of Text-to-Image Models"", 30 August 2023 (2023-08-30), pages 1 - 13, XP093266162, Retrieved from the Internet <URL:https://arxiv.org/abs/2302.12228> [retrieved on 20250402];;YANYU LI ET AL: ""TextCraftor: Your Text Encoder Can be Image Quality Controller"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 27 March 2024 (2024-03-27), XP091713400",PENDING
285,US,A1,US 2025/0147737 A1,082-701-510-792-578,5/8/2025,2025,US 202418991211 A,12/20/2024,US 202418991211 A;;US 202418437941 A;;US 202363595798 P,11/3/2023,PLC PROGRAM GENERATOR/COPILOT USING GENERATIVE AI,"An integrated development environment (IDE) for uses a generative artificial intelligence (AI) model to generate industrial control code in accordance with functional requirements provided to the industrial IDE system as natural language prompts. The system's generative AI model leverages both a code repository storing sample control code and a document repository that stores device or software manuals, program instruction manuals, functional specification documents, or other technical documents. These repositories are synchronized by digitizing selected portions of document text from the document repository into control code for storage in the code repository, as well as contextualizing control code from the code repository into text-based documentation for storage in the document repository.",ROCKWELL AUTOMATION TECH INC,MATURANA FRANCISCO P;;HE MEILING;;CHOWDHURY ANKAN;;DA SILVA ADERIANO,ROCKWELL AUTOMATION TECHNOLOGIES INC (2023-11-09),https://lens.org/082-701-510-792-578,Patent Application,yes,0,0,3,180-743-872-811-666;;006-110-156-606-574;;082-701-510-792-578,US;;EP,3,180-743-872-811-666;;006-110-156-606-574;;082-701-510-792-578,US;;EP,0,G06F8/33;;G06F8/73;;G06F8/33,G06F8/33,,0,0,,,,PENDING
286,WO,A1,WO 2024/215533 A1,182-745-758-392-260,10/17/2024,2024,US 2024/0022761 W,4/3/2024,US 202318134310 A,4/13/2023,TOPIC EVALUATION ENGINE FOR A MESSAGING SERVICE,"Described herein is a topic evaluation engine that operates in connection with a messaging service by analyzing individual text-based messages, received during a text-based communication session, to identify various message characteristics of each text-based message, and/or to infer one or more topics to which each message relates. Each message that is determined to have a particular message characteristic is then forwarded to any application that previously subscribed with the messaging service to receive messages having the specific message characteristic. Similarly, each message that is associated with a specific topic is distributed to any application integrated with the messaging service that has previously subscribed with the messaging service to receive messages relating to the specific topic. The integrated applications can then process the message and provide enhanced functionality.",MICROSOFT TECHNOLOGY LICENSING LLC,LE VU;;NGUYEN QUAN;;UPPAL SIDDHARTH;;GOVIL ANKIT,,https://lens.org/182-745-758-392-260,Patent Application,yes,2,0,2,182-745-758-392-260;;103-354-030-198-533,US;;WO,2,182-745-758-392-260;;103-354-030-198-533,US;;WO,0,H04L51/046;;H04L51/02;;H04L51/214;;G06N20/00;;G06F40/289;;G06F40/30;;H04L51/214;;G06F9/44526,H04L51/02;;H04L51/046;;H04L51/214,,1,0,,,"AAKASH AHMAD ET AL: ""Towards Human-Bot Collaborative Software Architecting with ChatGPT"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 26 February 2023 (2023-02-26), XP091448375",PENDING
287,US,A1,US 2024/0403984 A1,145-414-535-607-975,12/5/2024,2024,US 202418637545 A,4/17/2024,US 202418637545 A;;US 202363505524 P,6/1/2023,SYSTEMS AND METHODS FOR PROTECTING PROPRIETARY DATA WHILE USING THIRD-PARTY AI/ML SERVICES,"Systems and methods are provided for utilizing AI/ML services to solve business problems while protecting proprietary information. Third-party AI/ML services are utilized in a multi-stage approach to answer a question and/or or solve a problem, create code to validate the answer, execute that code inside a proprietary system, and then use that answer to create a better answer without exposing proprietary data to a third-party.",LNRS DATA SERVICES INC,HIGHTOWER KEVIN,LNRS DATA SERVICES INC (2024-03-20),https://lens.org/145-414-535-607-975,Patent Application,yes,0,1,2,145-414-535-607-975;;079-564-888-988-787,US;;CN,2,145-414-535-607-975;;079-564-888-988-787,US;;CN,0,G06F21/604;;G06F21/645;;G06F21/6218;;G06Q50/184;;G06F21/6218;;G06Q50/184,G06Q50/18;;G06F21/62,,0,0,,,,PENDING
288,US,B1,US 12316585 B1,159-715-369-698-206,5/27/2025,2025,US 202418932510 A,10/30/2024,US 202418932510 A,10/30/2024,Workflow insights and data assistant,"A system for improving approval processes to at least one software service, including a workflow platform with multiple business processes and user roles, an AI-enabled chatbot integrated with the workflow platform, the chatbot utilizing GAI techniques to provide information on policies, procedures, and workflow transactions, a data integration module retrieving and aggregating data from multiple sources, and a user interface displaying summarized information and recommendations generated by the AI-enabled chatbot. The AI-enabled chatbot automatically approving workflows based on thresholds.",MORGAN STANLEY SERVICES GROUP INC,EAPEN SUJIT;;KIM JULIUS H;;JAYAPATHI PARTHASARATHI,MORGAN STANLEY SERVICES GROUP INC (2024-10-07),https://lens.org/159-715-369-698-206,Granted Patent,yes,15,0,1,159-715-369-698-206,US,1,159-715-369-698-206,US,0,G06F16/345;;G06Q10/0635;;H04L51/02;;G06Q10/0633;;H04L51/02;;G06Q10/0635;;G06Q10/0633;;G06F16/345,H04L51/02;;G06F16/34;;G06Q10/0633;;G06Q10/0635,,0,0,,,,ACTIVE
289,WO,A1,WO 2025/090261 A1,111-785-245-417-742,5/1/2025,2025,US 2024/0049568 W,10/2/2024,US 202363545729 P;;US 202363607982 P,10/25/2023,TECHNIQUES AND ARCHITECTURE FOR SECURING LARGE LANGUAGE MODEL ASSISTED INTERACTIONS WITH A DATA CATALOG,"A computer-implemented system, computer -implemented method, and computer¬ program product includes receiving a natural language query from a user for executing an analytical task; generating an analytical large language model (LLM) prompt based on the natural language query and, in response to generating the analytical LLM prompt, orchestrating an LLM-directed workflow for handling the natural language query by: automatically prompting, using the analytical LLM prompt, an analytical task-oriented LLM to generate a structured query for querying a data catalog application; querying the data catalog application using the structured query generated by the analytical task- oriented LLM; obtaining query results from the data catalog application, where the query results include metadata associated with at least one element accessible to the data catalog application; prompting the analytical task-oriented LLM to identify a given analytical task associated with a given analytical agent; and automatically executing, by the given analytical agent, the analytical task.",SAS INST INC,WEIK DAVID,,https://lens.org/111-785-245-417-742,Patent Application,yes,3,0,3,111-785-245-417-742;;190-520-978-960-98X;;070-490-668-746-691,US;;WO;;EP,3,111-785-245-417-742;;190-520-978-960-98X;;070-490-668-746-691,US;;WO;;EP,0,G06F16/243;;H04L63/102;;H04L63/102;;G06F16/243,G06F16/33;;G06F16/242;;G06F16/2452;;G06F40/40,,0,0,,,,PENDING
290,US,A1,US 2025/0139064 A1,113-327-550-085-646,5/1/2025,2025,US 202418927933 A,10/26/2024,US 202418927933 A;;US 202363593745 P,10/27/2023,Method for automatically expanding factor graph databases,"The expansion of a computer graph database upon receipt of novel information involves identifying whether the novel information should be stored as part of the existing categories contained in the computer graph database, thereby requiring the addition of a new variable to an extant category of the computer graph database, or whether the new information should be stored as a new category that intersect with extant categories of the computer graph database, thereby requiring an extension of a relation between two or more extant categories, or whether the new information should be stored as a new category that only connects to a single extant category, thereby requiring the creation of a new portion of the computer graph database.",VERSES AI INC,LEE JOSEPH;;SMÉKAL JAKUB;;VERBELEN TIM;;CATAL OZAN;;TSCHANTZ ALEXANDER D D;;ALBARRACIN MAHAULT,,https://lens.org/113-327-550-085-646,Patent Application,yes,4,0,1,113-327-550-085-646,US,1,113-327-550-085-646,US,0,G06F16/211;;G06F16/9024;;G06F16/9024;;G06F16/211,G06F16/21;;G06F16/901,,0,0,,,,PENDING
291,US,B1,US 12321343 B1,089-344-429-582-196,6/3/2025,2025,US 202519046934 A,2/6/2025,US 202519046934 A,2/6/2025,Natural language to SQL on custom enterprise data warehouse powered by generative artificial intelligence,"Systems and methods for translating natural language to SQL on a custom enterprise data warehouse powered by Generative AI. With an embodiment of the present invention, a natural language question may be converted to a meaningful and accurate database query, e.g., SQL query, relevant to tables existing in an enterprise data warehouse. An embodiment of the present invention is directed to a comprehensive approach of transforming a natural language query to a focused SQL query using domain specific data models across firmwide metadata systems and data systems. In response to a user query, an embodiment of the present invention performs metadata analysis, targeted data retrieval and then SQL generation. An embodiment of the present invention may apply data warehousing standards and guidelines followed in the enterprise and provide a plug-and-play type architecture and solution that is scalable to large warehousing and other systems.",MORGAN STANLEY SERVICES GROUP INC,MEHTA SANJIT VIJAY;;SINGH ASHISH;;JAIN MAYANK;;SINGH MEET;;VERMA SATYA;;NAIK ABHIJIT ANANT;;MEHTA MEHAK;;BUTTE VIJAY KUMAR;;JANGHEL SOURABH KUMAR;;RAMESH ADITYA,MORGAN STANLEY SERVICES GROUP INC (2025-01-13),https://lens.org/089-344-429-582-196,Granted Patent,yes,7,0,1,089-344-429-582-196,US,1,089-344-429-582-196,US,0,G06F16/243;;G06F16/24539;;G06F16/24522;;G06F16/24539;;G06F16/243,G06F16/242;;G06F16/2453,,0,0,,,,ACTIVE
292,US,A1,US 2025/0138910 A1,025-842-745-682-949,5/1/2025,2025,US 202418433999 A,2/6/2024,US 202418433999 A;;US 202363594246 P,10/30/2023,GENERATING AND USING CONTEXT BRIEFS TO IDENTIFY RELEVANT CHAT RESPONSES,"Methods, computer systems, and computer-storage media are provided for generating and using context briefs to identify relevant chat responses. In embodiments, a context template associated with an intent is obtained. The context template includes a data reference referencing dynamic data and content providing context for the dynamic data. Thereafter, a context brief associated with the intent is generated by obtaining the dynamic data and incorporating the dynamic data with the content. Upon obtaining an input data request indicating a user intent, the context brief is identified as corresponding with the user intent of the input data request based on the intent associated with the context brief. A prompt to be input into a large language model is generated. The prompt includes the input data request and the context brief. A response relevant to the input data request is obtained as output from the large language model.",MICROSOFT TECH LICENSEING LLC,GULATI SWATI;;HE CHUJIE;;GOOI CHUNGHEONG;;CANGUSSU JOAO WAGNER LIMA;;BANMAN KELLY JOHN;;VON HADEN KYLE MATTHEW;;BEAUJON NOELLE RENEE;;CANAPATHY SUBASH CHANDRAN;;FAGNAN JUSTIN JOSEPH,MICROSOFT TECHNOLOGY LICENSING LLC (2023-11-16),https://lens.org/025-842-745-682-949,Patent Application,yes,0,0,1,025-842-745-682-949,US,1,025-842-745-682-949,US,0,G06F40/35;;G06F40/186;;G06F40/30;;G06F40/35;;G06F9/541,G06F9/54;;G06F40/35,,0,0,,,,PENDING
293,US,A1,US 2025/0199842 A1,028-118-742-722-994,6/19/2025,2025,US 202418977100 A,12/11/2024,US 202418977100 A;;US 202363609423 P,12/13/2023,CONFORMING DIGITAL DOCUMENTS TO STYLE GUIDES,"In an embodiment, non-transitory computer-readable storage media store one or more sequences of instructions which, when executed using one or more processors, cause the one or more processors to execute: executing a document processing application; receiving a digitally stored electronic document, alone or in combination with one or more other relevant documents, and an engineered prompt; transmitting an application programming interface (API) call to an API of a pre-trained large language model (LLM), wherein the call comprises the engineered prompt, wherein the engineered prompt comprises a plurality of objective instructions to the pre-trained LLM specifying transforming the electronic document according to a style guide to cause the pre-trained LLM to execute an inference stage over the electronic document and automatically generate output text based on the electronic document and the plurality of objective instructions that transforms the electronic document to conform to the style guide; storing the output text using a storage device of a user computer, a hosted storage environment, or in memory associated with the document processing application.",GRAMMARLY INC,KULKARNI VIVEK;;LEACOCK CLAUDIA;;ALIKANIOTIS DIMITRIOS;;GUBIN MAXIM,GRAMMARLY INC (2024-01-16),https://lens.org/028-118-742-722-994,Patent Application,yes,0,0,2,028-118-742-722-994;;152-062-305-641-147,US;;WO,2,028-118-742-722-994;;152-062-305-641-147,US;;WO,0,G06F9/45558;;G06F9/54;;G06F9/45558,G06F9/455;;G06F9/54,,0,0,,,,PENDING
294,US,A1,US 2025/0022023 A1,004-563-321-240-473,1/16/2025,2025,US 202418791764 A,8/1/2024,US 202418791764 A;;US 202318197063 A;;US 202117149572 A;;US 201715557229 A;;US 2016/0022232 W;;US 202363530472 P;;US 201562132489 P,3/12/2015,TRANSACTIONAL PLATFORM UTILIZING ARTIFICIAL INTELLIGENCE,"A system implements an online marketplace through digital communications sessions with users and providers to match providers with available provider time to a consumer user requiring services of the provider with payment exchanged between the consumer user and the provider user. Market pricing for services are calculated based on a metric of demand. Digital communications sessions are delivered for a duration corresponding to the payment made. Fictional personas may be utilized, including those associated with an artificial intelligence.",MINE ZERO GMBH,HERKEN ROLF,MINE ZERO GMBH (2024-08-06),https://lens.org/004-563-321-240-473,Patent Application,yes,0,1,1,004-563-321-240-473,US,13,015-080-264-570-072;;135-942-474-500-520;;024-669-185-368-923;;004-563-321-240-473;;028-182-074-262-377;;044-816-109-990-027;;084-160-913-731-175;;173-712-615-812-216;;150-774-851-332-598;;184-991-776-183-135;;047-848-837-842-159;;113-789-892-008-567;;103-558-371-892-501,US;;WO;;EP,0,H04L63/0428;;G06Q30/0601;;G06Q30/0206;;G06Q30/0213;;H04L51/04;;H04L65/1069;;G06Q50/01;;G06Q20/12;;G06Q30/0615;;G06Q30/0207;;G06Q20/127;;G06Q20/145;;G06N20/00;;G06Q10/107;;G06Q10/109;;G06Q50/01;;G06Q20/12;;G06Q10/10;;G06Q30/0601;;G06Q30/0206;;G06Q30/0213;;H04L51/04;;H04L63/0428;;H04L65/1069,G06Q30/0601;;G06Q10/10;;G06Q10/107;;G06Q10/109;;G06Q20/12;;G06Q30/0201;;G06Q30/0207;;G06Q50/00;;H04L9/40;;H04L51/04;;H04L65/1069,,0,0,,,,PENDING
295,EP,A1,EP 4390868 A1,123-875-405-182-546,6/26/2024,2024,EP 23202359 A,10/9/2023,JP 2022207690 A,12/23/2022,"ALERT GENERATION PROGRAM, ALERT GENERATION METHOD, AND INFORMATION PROCESSING APPARATUS","An alert generation program that causes a computer to execute a process, the process includes acquiring a video of a person who holds a merchandise to be registered in a checkout machine; specifying merchandise candidates corresponding to merchandises included in the video and a number of the merchandise candidates by inputting the acquired video to a machine learning model; acquiring items of merchandises registered by the person and a number of the items of the merchandises; and generating an alert indicating an abnormality of merchandises registered in the checkout machine based on the acquired items of the merchandises and the number of the items of the merchandises, and the specified merchandise candidates and the number of the merchandise candidates.",FUJITSU LTD,OBINATA YUYA;;YAMAMOTO TAKUMA;;UCHIDA DAISUKE,,https://lens.org/123-875-405-182-546,Patent Application,yes,2,0,4,123-875-405-182-546;;031-380-284-173-423;;054-979-582-725-682;;087-922-420-712-723,US;;EP;;KR;;JP,4,123-875-405-182-546;;031-380-284-173-423;;054-979-582-725-682;;087-922-420-712-723,US;;EP;;KR;;JP,0,G06V20/52;;G08B13/19613;;G06V10/82;;G07G3/003;;G07G1/0045;;G06V20/64;;G06V10/469;;G06V30/1823;;G06V10/761;;G06N20/00;;G06N3/0455;;G06Q20/20;;G08B25/14;;G06T2207/30242;;G06V20/52;;G06V2201/07;;G06Q20/208,G06V10/82;;G06V20/52;;G08B13/196,,0,0,,,,PENDING
296,EP,A1,EP 4390870 A1,138-880-559-768-241,6/26/2024,2024,EP 23205170 A,10/23/2023,JP 2022207687 A,12/23/2022,"ALERT GENERATION PROGRAM, ALERT GENERATION METHOD, AND INFORMATION PROCESSING DEVICE","An alert generation program that causes a computer to execute a process, the process includes acquiring a video of a person who holds a product to be registered in an accounting machine; specifying, by inputting the acquired video to a machine learning model, a product candidate that corresponds to the product included in the video from a plurality of product candidates; acquiring an item of the product input by the person from a plurality of product candidates output by the accounting machine; and generating an alert that indicates an abnormality of the product registered in the accounting machine based on the acquired item of the product and the specified product candidate.",FUJITSU LTD,OBINATA YUYA;;AOKI YASUHIRO;;YAMAMOTO TAKUMA;;UCHIDA DAISUKE,,https://lens.org/138-880-559-768-241,Patent Application,yes,2,0,4,138-880-559-768-241;;017-440-688-304-359;;147-170-284-546-50X;;146-636-392-378-537,US;;EP;;KR;;JP,4,138-880-559-768-241;;017-440-688-304-359;;147-170-284-546-50X;;146-636-392-378-537,US;;EP;;KR;;JP,0,G06V10/82;;G06V20/52;;G08B13/19613;;G07G3/003;;G07G1/0036;;G06V20/64;;G06V10/469;;G06V30/1823;;G06V10/761;;G06N20/00;;G08B25/14;;G06F40/279;;G06V20/52;;G06V10/761;;G06V20/41;;G06V10/764;;G06Q20/208,G06V10/82;;G06V20/52;;G08B13/196,,0,0,,,,PENDING
297,EP,A1,EP 4390869 A1,177-545-583-559-200,6/26/2024,2024,EP 23202361 A,10/9/2023,JP 2022207688 A,12/23/2022,"DATA GENERATION PROGRAM, DATA GENERATION METHOD, AND INFORMATION PROCESSING DEVICE","A data generation program that causes a computer to execute a process, the process includes acquiring product data; generating reference source data in which attributes of products are associated with each of a plurality of hierarchies based on a variance relationship of attributes of products included in the acquired product data; and setting the generated reference source data as data to be referred to by a zero-shot image classifier.",FUJITSU LTD,OBINATA YUYA;;AOKI YASUHIRO;;YAMAMOTO TAKUMA;;UCHIDA DAISUKE,,https://lens.org/177-545-583-559-200,Patent Application,yes,1,0,4,089-169-371-007-301;;177-545-583-559-200;;028-017-240-062-612;;185-052-388-397-335,US;;EP;;KR;;JP,4,089-169-371-007-301;;177-545-583-559-200;;028-017-240-062-612;;185-052-388-397-335,US;;EP;;KR;;JP,0,G06V10/82;;G06V10/774;;G06V10/764;;G06V20/64;;G06V20/63;;G07G3/003;;G07G1/0036;;G06V10/764,G06V10/82,,2,2,079-673-691-597-064;;076-548-528-819-585,10.1109/wacv.2019.00058;;10.1109/wacv.2015.116,"MARCUS KLASSON ET AL: ""A Hierarchical Grocery Store Image Dataset with Visual and Semantic Labels"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 3 January 2019 (2019-01-03), XP081011017;;ZIAD AL-HALAH ET AL: ""How to Transfer? Zero-Shot Object Recognition via Hierarchical Transfer of Semantic Attributes"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 1 April 2016 (2016-04-01), XP080692837, DOI: 10.1109/WACV.2015.116",PENDING
298,WO,A1,WO 2025/037294 A1,105-043-778-001-731,2/20/2025,2025,IL 2024050354 W,4/9/2024,US 202363519856 P,8/16/2023,GENERATIVE ARTIFICIAL INTELLIGENCE AUTHORSHIP DETECTION,"A method of detecting whether a submitted text was generated by an artificial intelligence computer program includes: feeding a textual prompt, in response to which the submitted text had been written, into a plurality of artificial intelligence composition programs; generating comparison texts with the artificial intelligence composition programs that are responsive to the textual prompts; comparing the comparison texts to the submitted text; and based on the results of the comparing step, determining a probability whether the submitted text is derived from one or more of the comparison texts.",COPYLEAKS TECH LTD,BITTON YEHONATAN;;BITTON ELAD;;YAMIN ALON,,https://lens.org/105-043-778-001-731,Patent Application,yes,0,0,1,105-043-778-001-731,WO,1,105-043-778-001-731,WO,0,G06F40/194;;G06N3/0475;;G06N20/00,G06N3/0475;;G06F40/194,,4,1,159-344-480-277-637,10.35542/osf.io/fnh48,"SAFI ROOZMEHR, JALALI AZADEH: ""The Work of Students and ChatGPT Compared: Using Machine Learning to Detect and Characterize AI-Generated Text"", 1 May 2023 (2023-05-01), pages 1 - 6, XP093281566;;BIORCK JOHANN, SOFIA EIKSSON: ""Detecting Plagiarism with ChatGPT Using Prompt Engineering"", KTH ROYAL INSTITUE OF TECHNOLOGY, 1 January 2023 (2023-01-01), pages 1 - 39, XP093281569;;""Learning and Collaboration Technologies"", vol. 32, 9 June 2023, SPRINGER NATURE SWITZERLAND, Cham, ISBN: 978-3-031-34410-7, ISSN: 0302-9743, article KHALIL MOHAMMAD; ER ERKAN: ""Will ChatGPT Get You Caught? Rethinking of Plagiarism Detection"", pages: 475 - 487, XP047662324, DOI: 10.1007/978-3-031-34411-4_32;;JAN PHILIP WAHLE; TERRY RUAS; FREDERIC KIRSTEIN; BELA GIPP: ""How Large Language Models are Transforming Machine-Paraphrased Plagiarism"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 3 November 2022 (2022-11-03), 201 Olin Library Cornell University Ithaca, NY 14853, XP091359231",PENDING
299,EP,A1,EP 4390867 A1,103-397-649-198-713,6/26/2024,2024,EP 23202097 A,10/6/2023,JP 2022207685 A,12/23/2022,"SPECIFYING PROGRAM, SPECIFYING METHOD, AND INFORMATION PROCESSING DEVICE","A specifying program that causes a computer to execute a process, the process includes acquiring a video that includes an object; narrowing down, by inputting the acquired video to a machine learning model that refers to reference source data in which attributes of objects are associated with each of a plurality of hierarchies, attributes of the object included in the video among attributes of objects of a first hierarchy; identifying attributes of objects of a second hierarchy under the first hierarchy by using the attributes of the object obtained by the narrowing down; and specifying, by inputting the acquired video to the machine learning model, an attribute of the object included in the video among the attributes of the objects of the second hierarchy.",FUJITSU LTD,OBINATA YUYA;;AOKI YASUHIRO;;YAMAMOTO TAKUMA;;UCHIDA DAISUKE,,https://lens.org/103-397-649-198-713,Patent Application,yes,1,0,4,194-934-452-528-872;;103-397-649-198-713;;078-068-260-320-15X;;006-157-848-637-580,US;;EP;;KR;;JP,4,194-934-452-528-872;;103-397-649-198-713;;078-068-260-320-15X;;006-157-848-637-580,US;;EP;;KR;;JP,0,G06V10/82;;G06V20/46;;G06V10/761;;G06V10/469;;G06N20/00;;G06N3/0455;;G06Q20/20;;G07G1/0045;;G06V10/764,G06V10/82,,2,1,168-196-193-654-959,10.1109/cvpr52729.2023.02251,"HANGJIE YUAN ET AL: ""RLIP: Relational Language-Image Pre-training for Human-Object Interaction Detection"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 5 September 2022 (2022-09-05), XP091311143;;SHAN NING ET AL: ""HOICLIP: Efficient Knowledge Transfer for HOI Detection with Vision-Language Models"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 26 July 2023 (2023-07-26), XP091572813",PENDING
300,US,A1,US 2025/0220140 A1,016-358-579-935-785,7/3/2025,2025,US 202318399491 A,12/28/2023,US 202318399491 A,12/28/2023,CONTENT GENERATION SERVICE FROM VIDEO CONFERENCE CONTENT FOR A CONTENT COLLABORATION PLATFORM,"Embodiments described herein relate to systems and methods for collaboration content creation from video conferencing content. In one or more examples, a content collaboration system may receive a notification from a video conferencing platform that a video conference session has ended. The system then receives a transcript of the video conference session. From the transcript, the system generates a transcript-processing prompt to provide to a generative output engine, which returns a generative response including a natural language string that is based on the transcript, prompt, and an output format indicated by the prompt. The system then creates a new collaboration content object, or modifies an existing object, using at least a portion of the generative response.",ATLASSIAN PTY LTD,KASHYAP ANAND;;SOECHTING DYLAN;;GARZA ALEXANDER,,https://lens.org/016-358-579-935-785,Patent Application,yes,0,0,1,016-358-579-935-785,US,1,016-358-579-935-785,US,0,G06F3/0482;;G10L15/26;;H04N7/155;;H04N7/155;;G10L15/26;;G06F3/0482,H04N7/15;;G06F3/0482;;G10L15/26,,0,0,,,,PENDING
301,US,B1,US 12242468 B1,160-551-441-214-868,3/4/2025,2025,US 202418797294 A,8/7/2024,US 202418797294 A;;IN 202311078197 A;;US 202418659799 A,11/17/2023,Generative machine learning with retriever having reconfigurable sequence of rankers,"A method includes obtaining an input query at a retriever model, where the retriever model includes a reconfigurable sequence of one or more rankers selected from among a plurality of rankers. Each ranker is configured to identify a specified number of information chunks relevant to the input query. The method also includes providing one or more of the information chunks from the retriever model to a generative model. The method further includes using the generative model to create a response to the input query, where the response is based on the one or more information chunks. The plurality of rankers includes a bi-encoder, a cross-encoder, and a large language model (LLM)-ranker.",GOLDMAN SACHS & CO LLC,BRENNER ELIOT P;;DASGUPTA KOUSTUV;;GUPTA DINESH;;HEGDE MANJUNATH G;;PAJAK AMY FRANCESCA;;VENTURA DE MELO GONCALO NUNO;;BASHIR ABDALLAH MOHAMED ABDO MOHAMED,GOLDMAN SACHS & CO. LLC (2024-05-03),https://lens.org/160-551-441-214-868,Granted Patent,yes,4,1,3,002-737-770-141-619;;160-551-441-214-868;;032-411-519-051-160,US;;WO,3,002-737-770-141-619;;160-551-441-214-868;;032-411-519-051-160,US;;WO,0,G06F16/242;;G06F16/24522;;G06F16/24578;;G06F16/24578;;G06F16/242;;G06F16/24522,G06F16/242;;G06F16/2452;;G06F16/2457,,24,3,014-840-934-556-089;;092-167-546-813-014;;165-996-560-235-470,10.1145/3397271.3401075;;10.1145/1571941.1572114;;10.18653/v1/2024.findings-acl.21,"Lewis et al., “Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks”, arXiv:2005.11401v4 [cs.CL], Apr. 2021, 19 pages.;;Wikipedia, “Large Language Model”, Oct. 2023, 20 pages.;;Wikipedia, “Self-Supervised Learning”, Oct. 2023, 6 pages.;;Allenai, “A Repository of Language Instructions for NLP Tasks”, GitHub, Feb. 2023, 11 pages.;;Bigscience-Workshop, “PromptSource”, GitHub, Jul. 2022, 7 pages.;;LangChain, “Prompting Strategies”, Mar. 2024, 44 pages.;;Weng, “Prompt Engineering”, Lil'Log, Mar. 2023, 80 pages.;;Hwchase17, “LangChainHub”, GitHub, Apr. 2023, 10 pages.;;Yuan et al., “Self-Rewarding Language Models”, arXiv:2401.10020v2 [cs.CL], Feb. 2024, 23 pages.;;Khattab et al., “ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT”, arXiv:2004.12832v2 [cs.IR], Jun. 2020, 10 pages.;;Rafailov et al., “Direct Preference Optimization: Your Language Model is Secretly a Reward Model”, arXiv:2305.18290v2 [cs.LG], Dec. 2023, 27 pages.;;Raudaschl, “RAG-Fusion: The Next Frontier of Search Technology”, GitHub, Sep. 2023, 7 pages.;;Pradeep et al., “RankVicuna: Zero-Shot Listwise Document Reranking with Open-Source Large Language Models”, arXiv:2309.15088v1 [cs.IR], Sep. 2023, 10 pages.;;Cormack et al., “Reciprocal Rank Fusion outperforms Condorcet and individual Rank Learning Methods”, SIGIR '09: Proceedings of the 32nd international ACM SIGIR Conference, Jul. 2009, 2 pages.;;Wikipedia, “Bradley—Terry model”, Jun. 2023, 3 pages.;;U.S. Securities and Exchange Commission, “Credit Agreement among Dunkin Finance Corp.”, Nov. 2010, 34 pages.;;Bclavie, “Welcome to RAGatouille”, GitHub, Mar. 2024, 17 pages.;;Lucidrains, “Self-Rewarding Language Model”, GitHub, Apr. 2024, 25 pages.;;Ouyang et al., “Training language models to follow instructions with human feedback”, arXiv:2203.02155v1 [cs.CL], Mar. 2022, 68 pages.;;Myscale, “RQABench: Retrieval QA Benchmark”, GitHub, Sep. 2024, 11 pages.;;Ma et al., “Query Rewriting for Retrieval-Augmented Large Language Models”, arXiv:2305.14283v3 [cs.CL], Oct. 2023, 13 pages.;;Yu et al., “Generate rather than Retrieve: Large Language Models are Strong Context Generators”, arXiv:2209.10063v3 [cs.CL], Jan. 2023, 27 pages.;;Ye et al., “Prompt Engineering a Prompt Engineer”, arXiv:2311.05661v2 [cs.CL], Feb. 2024, 31 pages.;;Brenner et al., “Retrieval-Augmented Generation (RAG) System Optimization”, U.S. Appl. No. 18/659,799, filed May 9, 2024, 54 pages.",ACTIVE
302,US,A1,US 2025/0200174 A1,132-445-685-867-051,6/19/2025,2025,US 202418988365 A,12/19/2024,US 202418988365 A;;US 202117540637 A;;US 201816145891 A,9/28/2018,METHOD AND SYSTEM FOR INSERTION OF CYBERSECURITY AND HARDWARE ASSURANCE INSTRUMENTS WITHIN INTEGRATED CIRCUITS AND ELECTRONIC SYSTEMS USING MULTI-STAGE HARDWARE MARKING,"A hardware trojan security system may perform a computer implemented method to secure an electronic facility in relation to a hardware trojan, by performing a trojan vulnerability analysis, locating an instrument site location, identifying a selected instrument in relation to an effect of the trojan, marking instrument control-side markers and instrument operative-side markers, marking facility model control-side markers and facility model operative-side markers, marking access architecture control-side markers, and connecting the instrument with the facility model and access architecture by matching corresponding markers.",AMIDA TECH SOLUTIONS INC,NASWA SEEMA;;CROUCH ALFRED LARRY;;LEVIN PETER LAWRENCE;;KARTHIKEYAN KARPAGAM,AMIDA TECHNOLOGY SOLUTIONS INC (2024-12-19),https://lens.org/132-445-685-867-051,Patent Application,yes,0,0,1,132-445-685-867-051,US,8,132-445-685-867-051;;057-943-343-966-82X;;066-595-854-744-442;;102-903-658-077-801;;055-788-384-145-630;;110-727-948-782-226;;091-912-398-180-18X;;149-875-059-121-241,US,0,G06F2221/034;;G06F21/554;;G06F21/552;;G06F21/76;;G06F21/552;;G06F2221/034;;G06F21/554,G06F21/55,,0,0,,,,PENDING
303,US,A1,US 2025/0209103 A1,142-432-083-189-695,6/26/2025,2025,US 202318390346 A,12/20/2023,US 202318390346 A,12/20/2023,MISSING CONTROL IDENTIFICATION,"Systems and methods for determining control objective for electronic documents using models may include obtaining electronic documents and a control objectives library, determining a first set of summaries based on the electronic documents, extracting a set of embeddings from the control objectives library, and determining a set of control objectives based on the summaries and the embeddings. The method may also include determining control objective candidates based on the summaries and embeddings, ranking the control objective candidates based on a confidence score, filtering the control objective candidates based on the ranking, categorizing the control objectives candidates into a second and third set of control objectives, updating the control objectives library to include one or more control objectives from the third set of control objectives, and validating control objectives in the third set of control objectives based on a test plan and updating the control objectives library that pass validation.",PAYPAL INC,ZAFAR ZUHEB;;CAO LI;;MANGISETTY SUNITHA,PAYPAL INC (2023-12-18),https://lens.org/142-432-083-189-695,Patent Application,yes,3,0,1,142-432-083-189-695,US,1,142-432-083-189-695,US,0,G06F16/338;;G06F16/35;;G06F16/383;;G06F16/338;;G06F16/383;;G06F16/35,G06F16/338;;G06F16/35;;G06F16/383,,0,0,,,,PENDING
304,WO,A1,WO 2025/049051 A1,156-655-533-159-220,3/6/2025,2025,US 2024/0041012 W,8/6/2024,US 202363579730 P;;US 202318534299 A,8/30/2023,SCALING UTILIZATION OF LARGE LANGUAGE MODELS,"The present disclosure relates to efficiently receiving and processing input tasks in a way that is scalable and which reduces both the quantity of tokens processed by a foundation model (e.g., an LLM) as well as the number of API calls that are made in processing the input tasks. A system batches a set of inputs to provide as a single batch of input(s) into an LLM. The system generates one or more permutations of the batched input(s) to determine outputs based on variable orders in which the input data is provided within the respective permutations of the batched inputs. The system further may eliminate one or more of the data inputs within the respective batches to facilitate smaller batched inputs without sacrificing accuracy in a set of outputs generated by the LLM responsive to the batch permutations.",MICROSOFT TECHNOLOGY LICENSING LLC,LIN JIANZHE;;DIESENDRUCK MAURICE;;MAO MANQING;;XIANG YIJIAN;;CHEN JULIA T;;TING PAISHUN;;XU MINGYANG;;DU LIANG;;ABRAHAM ROBIN,,https://lens.org/156-655-533-159-220,Patent Application,yes,0,0,1,156-655-533-159-220,WO,2,033-410-315-863-871;;156-655-533-159-220,US;;WO,0,G06N3/045;;G06N3/0475,G06N3/045;;G06N3/0475,,4,1,031-988-798-736-321,10.18653/v1/2023.emnlp-industry.74,"CHENG ZHOUJUN ET AL: ""Batch Prompting: Efficient Inference with Large Language Model APIs"", ARXIV, 19 January 2023 (2023-01-19), pages 1 - 18, XP093203678, Retrieved from the Internet <URL:https://arxiv.org/pdf/2301.08721v1> [retrieved on 20241111], DOI: 10.18653/v1/2023.emnlp-industry.74;;ZHAO TONY Z ET AL: ""Calibrate Before Use: Improving Few-Shot Performance of Language Models"", PROCEEDINGS OF THE 38TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING, PMLR 139:-, 2021., 18 July 2021 (2021-07-18), pages 12697 - 12706, XP093222859, Retrieved from the Internet <URL:https://proceedings.mlr.press/v139/zhao21c/zhao21c.pdf> [retrieved on 20241111];;COLEMAN KEVIN: ""Batch Prompting (cost reduction for LLMs/ChatGPT) | Kevin Coleman"", 11 March 2023 (2023-03-11), pages 1 - 4, XP093222892, Retrieved from the Internet <URL:https://www.kcoleman.me/llm/prompt-engineering/chatgpt/2023/03/11/llm-prompt-engineering.html> [retrieved on 20241111];;MA HUAN ET AL: ""Fairness-guided Few-shot Prompting for Large Language Models"", 31 March 2023 (2023-03-31), pages 1 - 15, XP093222880, Retrieved from the Internet <URL:https://arxiv.org/pdf/2303.13217> [retrieved on 20241111]",PENDING
305,US,A1,US 2025/0021548 A1,135-575-509-890-978,1/16/2025,2025,US 202418770654 A,7/12/2024,US 202418770654 A;;US 202363513322 P,7/12/2023,METHOD AND SYSTEM FOR SPECIFYING AN ACTIVE INFERENCE BASED AGENT USING NATURAL LANGUAGE,A method and system for specifying an active inference-based agent using natural language.,VERSES AI INC,PETERSEN CAPM;;HEINS CONOR;;ALBARRACIN MAHAULT;;PITLYA RIDDHI;;VERBELEN TIM;;TSCHANTZ ALEXANDER;;CONSTANT AXEL;;BUCKLEY CHRISTOPHER L;;KIEFER ALEXANDER BERNARD;;FRISTON KARL;;SWANSON STEVEN;;RENE GABRIEL;;SALVATORI TOMMASO,VERSES AI INC (2024-06-17),https://lens.org/135-575-509-890-978,Patent Application,yes,0,0,1,135-575-509-890-978,US,1,135-575-509-890-978,US,0,G06F16/24522;;G06F16/2237;;G06F16/258;;G06F16/24522;;G06F16/2237;;G06F16/258,G06F16/2452;;G06F16/22;;G06F16/25,,0,0,,,,PENDING
306,US,A1,US 2025/0173171 A1,086-924-915-406-923,5/29/2025,2025,US 202418963247 A,11/27/2024,US 202418963247 A;;US 202363604123 P,11/29/2023,Method for generating user specific interfaces using Generative UI,"In a method of generating a user interface, a user query is submitted to an encoder LLM which provides variable elements used to infer novel variable elements using a factor graph document database, which are in turn passed to a decoder LLM to generate user interface elements.",VERSES AI INC,TSCHANTZ ALEXANDER D D;;VERBELEN TIM;;ALBARRACIN MAHAULT;;RENE GABRIEL JOSEPH BRADLEY;;SCOTT ARISA;;FOX JASON G;;MUZZI ALESSANDRO;;BUNKER DARIN;;WEI RAN;;EDWARDS TROY;;ZAKI RYAN ANDREW TAREK,,https://lens.org/086-924-915-406-923,Patent Application,yes,0,0,1,086-924-915-406-923,US,1,086-924-915-406-923,US,0,G06F9/451;;G06N20/00;;G06N3/0475;;G06N5/022;;G06F9/451,G06F9/451,,0,0,,,,PENDING
307,US,A1,US 2025/0069114 A1,018-515-687-717-135,2/27/2025,2025,US 202418813973 A,8/23/2024,ES 202330707 A,8/23/2023,GENERATIVE JOURNEYS,"A computer-implemented method for generating optimized user journeys leveraging artificial intelligence is disclosed. The method includes receiving a user text prompt describing a desired journey objective and extracting context data for multiple users from a customer data platform. This context data encompasses attributes, events, predicted traits and audience memberships. A journey generation prompt is constructed by combining the received user prompt and extracted context data. This prompt is input into a machine learning model which processes the prompt to produce a user journey definition comprising interconnected nodes representing journey phases like audiences, waits and messages. The journey system validates the definition, modifying nodes to conform to predefined schema rules. The validated journey is output to campaign orchestration systems for execution across customer touchpoints. As journeys run, engagement data is collected for retraining models to improve journey performance over time.",LINTZ CHRISTOPHER;;RODRIGO ALFREDO LAINEZ,LINTZ CHRISTOPHER;;RODRIGO ALFREDO LAINEZ,TWILIO INC (2025-03-28),https://lens.org/018-515-687-717-135,Patent Application,yes,0,0,1,018-515-687-717-135,US,1,018-515-687-717-135,US,0,G06Q30/0251;;G06Q30/0251,G06Q30/0251,,0,0,,,,PENDING
308,WO,A1,WO 2024/203786 A1,191-918-645-943-037,10/3/2024,2024,JP 2024011174 W,3/21/2024,JP 2023050693 A;;JP 2023087330 A;;JP 2023095935 A;;JP 2023146576 A;;JP 2023191199 A;;JP 2024001343 A;;JP 2024003651 A,3/28/2023,"DEVICE FOR ANALYZING TECHNICAL DOCUMENT, METHOD, AND PROGRAM FOR SAME","According to the present invention, in a method for analyzing technical documents, effort for imparting of classification that can be used as an analysis axis is minimized. First, specification of a p count (p > 1) of technical documents D = {D1, D2, ..., Dp} to be analyzed is received from a user terminal (S201). Next, a device 100 requests a generative AI model to generate a q count of classifications C = {C1, C2, ..., Cq} capable of classifying the p count of technical documents D, on the basis of a p count of features F = {F1, F2, ..., Fp} associated respectively with the p count of technical documents D (S202). Before the generation of the classifications C is requested, the generation AI model may be requested to generate a feature Fi by inputting at least a part of technical documents. The device 100 then receives the generated classifications C (S203), and requests the AI model to associate, from among the classifications C, for i that is no less than 1 and no more than p, one or a plurality of classifications representing technical documents Di, as C'i (S204). The device 100 then receives and stores the classifications C'i associated with the technical documents Di for i that is no less than 1 and no more than p (S205).",OTANI KAN,OTANI KAN,,https://lens.org/191-918-645-943-037,Patent Application,yes,1,0,4,175-907-157-101-857;;173-449-917-025-423;;122-068-429-134-621;;191-918-645-943-037,WO;;JP,4,175-907-157-101-857;;173-449-917-025-423;;122-068-429-134-621;;191-918-645-943-037,WO;;JP,0,G06F16/35;;G06F40/56;;G06Q50/18;;G06F40/216;;G06F40/279;;G06F16/9032;;G06F16/383;;G06F16/906,G06F16/383;;G06F16/35;;G06F16/906;;G06F40/216;;G06F40/279,,5,0,,,"ALFORD ANTHONY: ""Google Announces AI-Powered Summary Generation Feature for Google Docs"", WWW.INFOQ.COM, 27 April 2022 (2022-04-27), pages 1 - 5, XP093215141, Retrieved from the Internet <URL:https://www.infoq.com/jp/news/2022/04/google-docs-ai-summaries/>;;HONDA SHION, ARAI HIDEHISA: ""What is the ""foundation model"" -a new paradigm for AI development?"", BLOG.RECRUIT.CO.JP, 4 July 2022 (2022-07-04), pages 1 - 16, XP093215325, Retrieved from the Internet <URL:https://blog.recruit.co.jp/data/articles/foundation_models/>;;ANONYMOUS: ""[chatGPT] Introduction to Prompt Engineering for People with Weak English"", FUMI_BLOG, 27 February 2023 (2023-02-27), pages 1 - 12, XP093215328, Retrieved from the Internet <URL:https://qiita.com/fumi_blog/items/c6a8a53f25af31b5e1ba>;;SONESUKE: ""[ChatGPT] Prompt pattern summary"", QIITA INC, 12 March 2023 (2023-03-12), pages 1 - 33, XP093215341, Retrieved from the Internet <URL:https://qiita.com/sonesuke/items/981925cfcc610a602e94>;;DORY | HUMAN RESOURCES × AI AGENT: ""I tried the KJ method using ChatGPT!"", TWITTER, 22 March 2023 (2023-03-22), XP009557863, Retrieved from the Internet <URL:https://twitter.com/dory111111/status/1638516779617251333>",PENDING
309,EP,A1,EP 4390884 A1,170-095-487-350-271,6/26/2024,2024,EP 23196796 A,9/12/2023,JP 2022207686 A,12/23/2022,"ALERT GENERATION PROGRAM, ALERT GENERATION METHOD, AND INFORMATION PROCESSING APPARATUS","An information processing apparatus acquires video image on a person who is scanning a code of a commodity product to an accounting machine, specifies, by analyzing the acquired video image, from among a plurality of commodity product candidates that are set in advance, a commodity product candidate that corresponds to the commodity product that is included in the video image, acquires an item of the commodity product that has been registered to the accounting machine by scanning the code of the commodity product to the accounting machine, and generates, based on an item of the specified commodity product candidate and the item of the commodity product acquired from the accounting machine, an alert that indicates an abnormality of the commodity product that has been registered to the accounting machine.",FUJITSU LTD,OBINATA YUYA;;AOKI YASUHIRO;;YAMAMOTO TAKUMA;;UCHIDA DAISUKE,,https://lens.org/170-095-487-350-271,Patent Application,yes,3,0,4,170-095-487-350-271;;035-558-070-257-219;;166-184-203-898-914;;128-801-616-346-619,US;;EP;;KR;;JP,4,170-095-487-350-271;;035-558-070-257-219;;166-184-203-898-914;;128-801-616-346-619,US;;EP;;KR;;JP,0,G07G3/003;;G06Q20/206;;G06Q20/208;;G07G1/0063;;G07G3/003;;G07G1/0045;;G06V20/64;;G06V10/469;;G06V30/1823;;G06V10/761;;G06N20/00;;G06N3/0455;;G06Q20/20;;G06V20/68;;G06V20/52;;G06V20/40;;G06K7/1413,G07G1/00;;G06Q20/20;;G07G3/00,,0,0,,,,PENDING
310,US,A1,US 2025/0156955 A1,149-825-018-392-306,5/15/2025,2025,US 202318506933 A,11/10/2023,US 202318506933 A,11/10/2023,DOMAIN-SPECIFIC PROCESSING AND INFORMATION MANAGEMENT USING EXTRACTIVE QUESTION ANSWERING MACHINE LEARNING AND ARTIFICIAL INTELLIGENCE MODELS,"Systems and techniques are provided for automatically analyzing and processing domain-specific image artifacts and document images. A process can include training a domain-adapted ML network using a domain-specific training dataset including a plurality of training data inputs corresponding to a lexicon of domain-specific terminology. A first fine-tuning training of the domain-adapted ML network yields a domain-adapted general QA ML network, based on using a first question answering (QA) dataset comprising a first plurality of question-answer training pairs that do not correspond to the lexicon of domain-specific terminology. A second fine-tuning training of the domain-adapted general QA ML network yields a fine-tuned domain-adapted general QA ML network, and uses a second QA dataset comprising a second plurality of question-answer pairs generated based on a corpus of text narratives utilizing the lexicon of the domain-specific terminology.",32HEALTH INC,RAMASWAMY DEEPAK;;KOMPELLA RAVINDRA;;PUTHUSSERY SHAJU,32HEALTH INC (2024-03-16),https://lens.org/149-825-018-392-306,Patent Application,yes,3,0,1,149-825-018-392-306,US,1,149-825-018-392-306,US,0,G06Q40/08;;G06N20/00;;G06Q40/08;;G06N20/00,G06Q40/08,,0,0,,,,PENDING
311,US,A1,US 2025/0217214 A1,005-849-059-198-74X,7/3/2025,2025,US 202318399319 A,12/28/2023,US 202318399319 A,12/28/2023,AUTOMATION RULE CREATION FOR COLLABORATION PLATFORMS,"Embodiments described herein relate to systems and methods for automation rule creation for collaboration platforms. A natural language user input may be input to a centralized automation rule service that creates prompts for a generative output service to automatically create an automation rule understandable to one or more collaboration platforms of a system. A trigger-selection prompt, component-selection prompt, and rule-selection prompt are generated by the system and provided to the generative output engine. An automation rule can then be identified from the generative response, verified, and used in the system for the one or more collaboration platforms. In some cases, the automation rule creation from natural language input may reduce the burden on a user to craft and manage automation rules in a collaboration platform.",ATLASSIAN PTY LTD,KASHYAP ANAND;;BROWN TYLER;;ANGLE TREVOR;;WILLIAMS ALEXANDER;;ZHANG STEVEN;;SUKMAJAYA ERIC,,https://lens.org/005-849-059-198-74X,Patent Application,yes,0,0,1,005-849-059-198-74X,US,1,005-849-059-198-74X,US,0,G06F40/40;;G06F40/289;;G06F3/0484;;G06F9/547;;G06F40/40;;G06F3/0484;;G06F40/289,G06F9/54;;G06F3/0484;;G06F40/289;;G06F40/40,,0,0,,,,PENDING
312,CN,A,CN 119311376 A,159-521-637-098-86X,1/14/2025,2025,CN 202411855412 A,12/17/2024,CN 202411855412 A,12/17/2024,Method and system for measuring thickness of glomerular basement membrane under electron microscope based on artificial intelligence,"The invention belongs to the technical field of glomerular basement membrane thickness measurement, and particularly relates to an electron microscope glomerular basement membrane thickness measurement method and system based on artificial intelligence. On the basis of continuously acquired electron microscope image data of the glomerular basement membrane, the thickness of the glomerular basement membrane can be accurately measured, the influence of accidental factors is avoided, an important reference basis is provided for early diagnosis and treatment of kidney diseases, and through automatic image processing and analysis, the accuracy of diagnosis and treatment is improved. The accuracy and efficiency of glomerular basilar membrane thickness detection are improved, errors of manual operation are reduced, in addition, the kidney state can be automatically evaluated according to the measurement result, timely intervention measures are provided under abnormal conditions, diagnosis and treatment of kidney diseases are more accurate and timely, and the kidney disease diagnosis and treatment efficiency is improved. And meanwhile, a doctor can formulate a more accurate treatment scheme, and better treatment effect and life quality are brought to a patient.",UNIV SOUTHEAST,ZHAO YU;;ZHU XIAODONG;;NI HAIFENG;;ZHANG XIAOLIANG;;CHEN KUI;;SUN LI,,https://lens.org/159-521-637-098-86X,Patent Application,no,4,0,2,035-812-311-647-850;;159-521-637-098-86X,CN,2,035-812-311-647-850;;159-521-637-098-86X,CN,0,G06T7/0012;;G06T7/11;;G06T7/13;;G06T5/70;;G01B15/02;;G06T2207/30084;;Y02A90/10,G06F9/455,,4,2,110-684-678-320-12X;;022-738-599-461-654,19646774;;10.1016/j.cmpb.2009.07.002;;10.1007/978-3-031-72114-4_27,"李溪玥;徐峰: ""合并系膜溶解肾脏疾病患者的临床病理特征及预后"", 《肾脏病与透析肾移植杂志》, 28 October 2022 (2022-10-28);;WU, HS (WU, HAI-SHAN): ""A semi-automatic algorithm for measurement of basement membrane thickness in kidneys in electron microscopy images"", 《COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE》, 1 March 2010 (2010-03-01);;LIU, XY (LIU, XUEYU): ""Feature-Prompting GBMSeg: One-Shot Reference Guided Training-Free Prompt Engineering for Glomerular Basement Membrane Segmentation"", 《MEDICAL IMAGE COMPUTING AND COMPUTER ASSISTED INTERVENTION - MICCAI 2024, PT IX》, 26 November 2024 (2024-11-26);;范萍;杨霓芝;: ""通脉口服液对实验性糖尿病肾病模型大鼠肾脏病理及转化生长因子β_1的影响"", 广州中医药大学学报, no. 06, 15 November 2008 (2008-11-15)",ACTIVE
313,US,A1,US 2024/0054909 A1,087-569-501-206-609,2/15/2024,2024,US 202318234134 A,8/15/2023,US 202318234134 A;;US 202263397971 P,8/15/2022,Automated Evaluation of Free-Form Answers and Generation of Actionable Feedback to Multidimensional Reasoning Questions,"In an illustrative embodiment, methods and systems for automatically evaluating content of freeform text answers involve obtaining sections of text answering a multi-dimensional reasoning question, analyzing section content of each section using AI model(s), analyzing logical connections between the sections of text, and calculating score(s) corresponding to the freeform answer based on the analyses.",BRAINPOP IP LLC,RUSHKIN ILIA P;;ROSEN YIGAL;;BAKKEN SARA;;NEWSTADT MICHELLE,BRAINPOP IP LLC (2023-09-07),https://lens.org/087-569-501-206-609,Patent Application,yes,19,9,7,087-569-501-206-609;;151-868-757-085-563;;065-864-807-446-107;;107-043-496-548-619;;109-293-665-391-128;;162-652-214-118-986;;049-891-033-792-957,US;;WO;;EP;;AU;;KR,7,087-569-501-206-609;;109-293-665-391-128;;065-864-807-446-107;;107-043-496-548-619;;151-868-757-085-563;;162-652-214-118-986;;049-891-033-792-957,US;;WO;;EP;;AU;;KR,0,G09B7/04;;G06Q50/20;;G09B7/02;;G06F40/216;;G06F40/30;;G06Q50/20;;G09B7/04;;G06F40/216;;G06F40/232;;G06F40/253;;G06F40/30;;G09B7/04;;G06F40/253;;G06F40/232;;G06Q50/20,G09B7/04;;G06F40/232;;G06F40/253;;G06Q50/20,,0,0,,,,ACTIVE
314,US,B1,US 12314300 B1,077-052-678-588-177,5/27/2025,2025,US 202318399684 A,12/28/2023,US 202318399684 A,12/28/2023,Methods and systems of content integration for generative artificial intelligence,"Systems and methods are provided for a device to obtain a query, such as from a user. The query is vectorized to obtain a numerical representation of the query and provided to a vector database to find the nearest vectors corresponding to most relevant context, such as for a particular domain or subject matter. The query, query vector, and context vectors, and optionally past query history and past query responses, are provided to an artificial intelligence, such as a large language model (LLM), to receive a response to the query without providing the context to the LLM.",OPEN TEXT INC,SHARMA VIKASH;;SINGH CHAUHAN LAXMAN;;LALWANI RAJA PARSHOTAM,OPEN TEXT INC (2023-12-16),https://lens.org/077-052-678-588-177,Granted Patent,yes,9,0,2,135-879-722-775-357;;077-052-678-588-177,US,2,135-879-722-775-357;;077-052-678-588-177,US,0,G06F40/40;;G06F16/3347;;G06F40/40;;G06F16/3347,G06F16/334;;G06F40/40,,0,0,,,,ACTIVE
315,WO,A1,WO 2024/168275 A1,111-282-423-874-82X,8/15/2024,2024,US 2024/0015215 W,2/9/2024,US 202363484375 P,2/10/2023,SYSTEMS AND METHODS FOR ENHANCING PROVISION OF INFORMATION TECHNOLOGY SUPPORT SERVICES,"In some embodiments, systems and methods described here provide the ability to automatically generate scripts and optimize them for execution on a remotely managed endpoint. In some embodiments, a method includes receiving a request, optionally augmented, at a user interface of a managed service provider. The request is a request for assistive service implementing the managed service provider. The method further includes selecting generative model to respond to the request. The generative model is selected based on information of a profile of the managed service provider. The method further includes receiving, from the selected generative model, a response to the request. The response provides the assistive service implementing the managed service provider.",CONNECTWISE LLC,SHORT JASON MARC;;TURPIN JACOB EDWARD;;KARIM AMEER;;BONGULA RAGHU RAM,,https://lens.org/111-282-423-874-82X,Patent Application,yes,5,0,1,111-282-423-874-82X,WO,1,111-282-423-874-82X,WO,0,G06N20/00;;H04L41/16;;G06F8/31,G06F16/182;;G06F9/4401;;G06F15/177,,0,0,,,,PENDING
316,US,A1,US 2024/0281457 A1,025-247-445-325-927,8/22/2024,2024,US 202418649681 A,4/29/2024,US 202418649681 A;;US 202117506787 A;;US 202017117208 A;;US 201962946360 P;;US 202463551994 P;;US 202463552124 P,12/10/2019,COMPUTERIZED METHOD AND SYSTEM FOR DYNAMIC ENGINE PROMPT GENERATION,"A computerized method providing for generating a predicted intent usable for generating a prompt for an artificial intelligence engine, as well as other computing resources. The method includes capturing user interactions on a computing device and storing user interaction data. The method includes accessing at least one data storage device having user interaction data therein. The user interaction data can be stored via vector modeling. The method includes analyzing the user interaction data and generating a user context therefrom. Therefrom, the method includes generating a predicted intent within a user display interface, the predicted intent generated from the user context.",HIGHLIGHT US INC,DE WITTE WILHELMUS;;JEYAPAL KARTHICK;;YILDIRIM UMUT,HIGHLIGHT USA INC (2024-04-29),https://lens.org/025-247-445-325-927,Patent Application,yes,6,0,1,025-247-445-325-927,US,5,025-247-445-325-927;;103-041-122-437-338;;105-194-960-347-892;;038-898-736-296-274;;046-877-714-334-302,US,0,H04N21/2187;;H04N21/25891;;H04N21/2743;;H04N21/84;;H04N21/8549;;G06F16/3347;;G06F16/335;;G06F16/335;;G06F16/3347,G06F16/33;;G06F16/335,,0,0,,,,PENDING
317,US,A1,US 2025/0022027 A1,067-967-208-217-85X,1/16/2025,2025,US 202318397938 A,12/27/2023,US 202318397938 A;;US 202363513346 P,7/12/2023,GENERATIVE ARTIFICIAL INTELLIGENCE PERSONALIZATION ENGINE IN AN ITEM LISTING SYSTEM,"Methods, systems, and computer storage media for providing generative artificial intelligence (AI) personalization management using a generative AI personalization engine in an item listing system. A generative AI personalization engine supports generative AI personalization management based on an automotive personalization platform including personalization training operations, personalization operations, and personalization interfaces associated with a generative AI model and an automotive domain. The generative AI personalization engine provides generative AI personalization engine operations to improve personalization and presentation of automotive-related data in an item listing system. In operation, a request associated with a user is accessed. Based on the request, automotive personalization data associated with a generative AI model is accessed. The generative AI model is associated with personalization training operations and an automotive personalization data structure that support personalized automotive upgrade guidance in the item listing system. The automotive personalization data is communicated for display via an item listing system client.",EBAY INC,SIPE III RICHARD VANCE;;SPRAGUE COREY ALAN;;ZADORSKII MAKSIM;;BRADSHAW NICKALAS N;;BOEDIGHEIMER LAUREN ELIZABETH;;JONES RYAN DANIEL;;NI YAN,EBAY INC (2024-04-17),https://lens.org/067-967-208-217-85X,Patent Application,yes,0,0,2,067-967-208-217-85X;;039-381-921-146-31X,US,2,067-967-208-217-85X;;039-381-921-146-31X,US,0,G06Q30/0627;;G06F40/40;;G06Q30/0625;;G07C5/0808;;G06Q30/0629;;G06Q30/0621;;G06Q30/0631;;G06Q30/0643;;G06Q30/0625;;G07C5/0808;;G06Q30/0631;;G06F40/40;;G06Q30/0621;;G06Q30/0627;;G06Q30/0629,G06Q30/0601;;G06F40/40,,0,0,,,,PENDING
318,US,A1,US 2025/0068625 A1,070-145-071-670-041,2/27/2025,2025,US 202418809814 A,8/20/2024,US 202418809814 A;;US 202363534290 P,8/23/2023,LEARNING AND PERSONAL DATA MANAGEMENT PLATFORM,"Methods, systems, and techniques for processing natural language queries. A natural language query related to personal information of the user is obtained. Query vectors that include embeddings of the query are generated and matched with document vectors generated from chunks of reference documents related to the personal data. The document chunks are retrieved from a database and used as context for a prompt to a large language model that is used to respond to the natural language query. The query itself is also included in the prompt. The query may be in respect of a particular goal, and the large language model's response may include recommendations to help the user achieve that goal.",ROYAL BANK OF CANADA,CURRELL NATHAN;;LUU HILTON;;ZHANG LINNA;;GHASSEL ABDELLAH,,https://lens.org/070-145-071-670-041,Patent Application,yes,0,1,1,070-145-071-670-041,US,1,070-145-071-670-041,US,0,G06F16/243;;G06F16/243,G06F16/242,,0,0,,,,PENDING
319,WO,A1,WO 2025/144435 A1,077-850-294-973-152,7/3/2025,2025,US 2024/0021907 W,3/28/2024,US 202363615299 P,12/28/2023,PLC PROGRAMMING USING LARGE LANGUAGE MODELS,Methods for generating programmable logic controller (PLC) code and corresponding systems and computer-readable mediums. A method (400) includes receiving (402) at least one specification (160) by a computer system (100). The method includes generating (404) a model-based design plan (158) based on the at least one specification (160) and a large-language model (LLM) (154) and processing (406) the model-based design plan (158) using low-rank adaption techniques (162) and the LLM (154) to produce PLC code (156). The method includes performing (408) a syntax check on the PLC code (156) and outputting (414) the PLC code (156).,SIEMENS AG;;UNIV CALIFORNIA,QUIROS ARAYA GUSTAVO ARTURO;;OGUNDARE OLUWATOSIN;;FAKIH MOHAMAD;;DHARMAJI RAHUL;;MOGHADDAS YASAMIN;;AL FARUQUE MOHAMMAD ABDULLAH,,https://lens.org/077-850-294-973-152,Patent Application,yes,0,0,1,077-850-294-973-152,WO,1,077-850-294-973-152,WO,0,G06F8/35;;G06N3/02;;G06F11/3608;;G05B19/056;;G05B19/0426,G06F8/35;;G05B19/00;;G06F11/36;;G06N3/02,,5,0,,,"SADIK AHMED ET AL: ""Coding by Design: GPT-4 Empowers Agile Model Driven Development :"", PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON MODEL-BASED SOFTWARE AND SYSTEMS ENGINEERING, 6 October 2023 (2023-10-06), pages 149 - 156, XP093201150, Retrieved from the Internet <URL:https://arxiv.org/pdf/2310.04304> DOI: 10.5220/0012356100003645;;CHEN KUA ET AL: ""Automated Domain Modeling with Large Language Models: A Comparative Study"", 2023 ACM/IEEE 26TH INTERNATIONAL CONFERENCE ON MODEL DRIVEN ENGINEERING LANGUAGES AND SYSTEMS (MODELS), IEEE, 1 October 2023 (2023-10-01), pages 162 - 172, XP034490665, DOI: 10.1109/MODELS58315.2023.00037;;KOZIOLEK HEIKO ET AL: ""ChatGPT for PLC/DCS Control Logic Generation"", 2023 IEEE 28TH INTERNATIONAL CONFERENCE ON EMERGING TECHNOLOGIES AND FACTORY AUTOMATION (ETFA), IEEE, 12 September 2023 (2023-09-12), pages 1 - 8, XP034442780, DOI: 10.1109/ETFA54631.2023.10275411;;ANONYMOUS: ""Fine-tuning (deep learning) - Wikipedia"", 26 December 2023 (2023-12-26), pages 1 - 4, XP093201424, Retrieved from the Internet <URL:https://en.wikipedia.org/w/index.php?title=Fine-tuning_(deep_learning)&oldid=1191972088>;;OVATMAN TOLGA ET AL: ""An overview of model checking practices on verification of PLC software"", SOFTWARE & SYSTEMS MODELING, SPRINGER BERLIN HEIDELBERG, BERLIN/HEIDELBERG, vol. 15, no. 4, 25 December 2014 (2014-12-25), pages 937 - 960, XP036060346, ISSN: 1619-1366, [retrieved on 20141225], DOI: 10.1007/S10270-014-0448-7",PENDING
320,US,A1,US 2025/0217399 A1,163-353-971-994-648,7/3/2025,2025,US 202318399638 A,12/28/2023,US 202318399638 A,12/28/2023,CONTENT GENERATION SERVICE FOR USER INTERFACE OF A CONTENT COLLABORATION PLATFORM,"Embodiments described herein relate to systems and methods for content summary generation within a content collaboration system. A graphical user interface for a platform of the system may include selectable graphical objects, which may contain a portion of content obtained from target content, and other selectable elements and graphics. A user may be provided with an input to request a summary of the target content. The system may generate a prompt and provide to a generative output engine instructions to prepare such summary, and generate within the graphical user interface a summary including natural language. The summary may be a summary of a page, a set of messages, a list of actions, key decisions, or items and summaries related to the target content. Processing may include populating the summary with system-specific mentions, links, tables, video, audio, and so on, which may be specific to permissions for the user.",ATLASSIAN PTY LTD,MAURITZ ANDRE;;GENG BRIGHT;;HERNANDEZ ANDRES;;COPPINGER JAKE;;LI TONG;;MERRISON MATTHEW,,https://lens.org/163-353-971-994-648,Patent Application,yes,0,0,2,163-353-971-994-648;;025-239-906-658-653,US;;EP,2,163-353-971-994-648;;025-239-906-658-653,US;;EP,0,G06F40/30;;G06F16/958;;G06F16/345;;G06F3/0482,G06F16/34;;G06F3/0482,,0,0,,,,PENDING
321,WO,A1,WO 2024/258414 A1,022-055-068-442-961,12/19/2024,2024,US 2023/0025560 W,6/16/2023,US 2023/0025560 W,6/16/2023,PROMPT ELEMENT GENERATION FOR USE AS INPUT IN GENERATIVE MODELS,"Example embodiments of the present disclosure provide for an example method for prompt element generation for use as input into generative models. The example method includes obtaining user input data including initial prompt data. The example method includes selecting one or more suggested prompt elements based at least in part on the initial prompt data. The example method includes transmitting the one or more suggested prompt elements to be presented for display as selectable user interface elements via a user interface. The example method includes obtaining second user input data including data indicative of a selection of the one or more suggested prompt elements. The example method includes responsive to obtaining the second user input data, providing the second user input to an image generation model to generate an output image including a visual representation associated with the one or more suggested prompt elements.",GOOGLE LLC,SHRIVASTAVA ABHISHEK;;DABBIRU LAKSHMI KUMAR;;MARFATIA HINALI NAIMISH,,https://lens.org/022-055-068-442-961,Patent Application,yes,0,0,3,098-386-645-452-195;;139-774-643-163-808;;022-055-068-442-961,WO;;EP;;CN,3,139-774-643-163-808;;098-386-645-452-195;;022-055-068-442-961,WO;;EP;;CN,0,G06F40/216;;G06F40/30;;G06F40/44;;G06F40/56;;G06N3/0985;;G06N20/00;;G06N3/08;;G06N3/045,G06F40/216;;G06F40/56;;G06F40/30;;G06F40/44;;G06N3/0985;;G06T11/60,,4,3,037-496-814-767-783;;038-846-521-309-205;;045-440-245-149-586,10.1145/3586183.3606725;;10.1145/3563657.3596098;;10.1145/3544548.3581402,"STEPHEN BRADE ET AL: ""Promptify: Text-to-Image Generation through Interactive Prompt Exploration with Large Language Models"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 18 April 2023 (2023-04-18), XP091488309;;LIU VIVIAN ET AL: ""3DALL-E: Integrating Text-to-Image AI in 3D Design Workflows"", PROCEEDINGS OF THE 2023 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE, 20 October 2022 (2022-10-20), New York, NY, USA, pages 1955 - 1977, XP093111873, ISBN: 978-1-4503-9893-0;;WANG YUNLONG ET AL: ""RePrompt: Automatic Prompt Editing to Refine AI-Generative Art Towards Precise Expressions"", PROCEEDINGS OF THE 23RD INTERNATIONAL MIDDLEWARE CONFERENCE DOCTORAL SYMPOSIUM, IEEE PRESSPUB767, PISCATAWAY, NJ, USA, 19 April 2023 (2023-04-19), pages 1 - 29, XP058999209, DOI: 10.1145/3544548.3581402;;LIU VIVIAN ET AL: ""Design Guidelines for Prompt Engineering Text-to-Image Generative Models"", PROCEEDINGS OF THE 34TH ACM SYMPOSIUM ON PARALLELISM IN ALGORITHMS AND ARCHITECTURES, ACMPUB27, NEW YORK, NY, USA, 29 April 2022 (2022-04-29), pages 1 - 23, XP059160855, ISBN: 978-1-4503-9408-6, DOI: 10.1145/3491102.3501825",PENDING
322,JP,A,JP 2025064242 A,001-697-177-075-104,4/17/2025,2025,JP 2023173841 A,10/5/2023,JP 2023173841 A,10/5/2023,プログラム、情報処理方法及び情報処理装置,【課題】言語生成モデルにより動画に関するクエリに対する応答を出力することが可能なプログラム等を提供すること。【解決手段】一つの側面に係るプログラムは、複数の動画の各構造化データに関する情報を特定し、前記動画に関するクエリを取得し、取得したクエリ及び特定した各構造化データに関する情報を用いる言語モデルにより、前記クエリに対する応答を出力する処理をコンピュータに実行させる。これによって、言語生成モデルにより動画に関するクエリに対する応答を出力することが可能となる。【選択図】図１,もみじテック株式会社,平岡 弦己,,https://lens.org/001-697-177-075-104,Patent Application,no,6,0,1,001-697-177-075-104,JP,1,001-697-177-075-104,JP,0,,G06F16/732;;G06F16/783,,3,0,,,"KOTARO TANAHASHI: ""GPT-3.5-turboの新機能を使ってCVPRの論文を良い感じに検索・推薦・要約するシステム"", ZENN（エンジニアのための情報共有コミュニティ）, JPN6024025460, 14 June 2023 (2023-06-14), ISSN: 0005458210;;@SAKUBUN IN NOVEL株式会社: ""ChatGPTのパワーを最大限に引き出す！「Prompt Engineering Guide」をわかりやすく解説"", QIITA, JPN6024025459, 29 May 2023 (2023-05-29), ISSN: 0005458211;;白井 宏一 ほか: ""説明文を付した動画ファイルに対する文章比較モデルを用いた検索"", 言語処理学会第１４回年次大会発表論文集, JPN6025019223, 17 March 2008 (2008-03-17), pages 119 - 122, ISSN: 0005614383",PENDING
323,US,A1,US 2025/0200123 A1,135-928-431-586-220,6/19/2025,2025,US 202318542012 A,12/15/2023,US 202318542012 A,12/15/2023,"ENHANCED SEARCH REPORT BASED ON LEVERAGING SEARCH ENGINE APIs, LARGE LANGUAGE MODELS, AND WEB CRAWLERS","Systems and methods that generate an enhanced search report, which provides a significant improvement over conventional searches are provided. The systems and methods leverage a combination of keyword-based searches using search engine APIs to return URLs that are hit by the searches, large language models to generate additional keywords based on contextual information, and web crawlers to search the returned URLs with the additional keywords. The enhanced search report is not confined to the conventional keyword-URL match, but instead provides a sophisticated capture and compilation of additional useful information.",INTUIT INC,SONI VISHAL;;ZHAO YIFAN;;CONOPHY KELSEY RAE;;NICHOLSON JAMIE;;LAFRANCE CHRISTIAN,INTUIT INC (2023-11-30),https://lens.org/135-928-431-586-220,Patent Application,yes,1,0,1,135-928-431-586-220,US,1,135-928-431-586-220,US,0,G06F16/9538;;G06F16/951;;G06F16/9538;;G06F16/951;;G06F9/547,G06F16/9538;;G06F9/54;;G06F16/951,,0,0,,,,PENDING
324,US,A1,US 2025/0061917 A1,122-479-029-179-472,2/20/2025,2025,US 202318235372 A,8/18/2023,US 202318235372 A,8/18/2023,LANGUAGE-MODEL SUPPORTED SPEECH EMOTION RECOGNITION,"The technology relates to enhancing speech emotion recognition models with methods that enable the use of unlabeled data by inferring weak emotion labels. This is done by pre-trained large language models through weakly-supervised learning. For inferring weak labels constrained to a taxonomy, a textual entailment approach selects an emotion label with the highest entailment score for a speech transcript extracted via automatic speech recognition. The system may employ a method that generates, by one or more processors, a text transcript for a snippet of input speech, and then applies the text transcript to a pre-trained language model. The system can generate, using the pre-trained language model according to an engineered prompt and a predetermined taxonomy, a textual entailment from the text transcript. Based on this, the system may generate, by the one or more processors using the textual entailment, a predicted emotion corresponding to the input speech.",GOOGLE LLC,BELANICH JOSH;;GONG TAESIK;;SOMANDEPALLI KRISHNA;;EOFF BRIAN;;JOU BRENDAN WESLEY;;NAGRANI ARSHA,GOOGLE LLC (2023-08-18),https://lens.org/122-479-029-179-472,Patent Application,yes,0,0,1,122-479-029-179-472,US,1,122-479-029-179-472,US,0,G10L25/63;;G06F40/30;;G06F40/279;;G10L15/063;;G10L25/63;;G06F40/279;;G06F40/30,G10L25/63;;G10L15/06,,0,0,,,,PENDING
325,US,A1,US 2024/0295953 A1,056-244-246-466-71X,9/5/2024,2024,US 202318116003 A,3/1/2023,US 202318116003 A,3/1/2023,PROMPT MODIFICATION FOR AUTOMATED IMAGE GENERATION,"Examples disclosed herein describe prompt modification techniques for automated image generation. An image generation request comprising a base prompt is received from a user device. A plurality of prompt modifiers is identified. A processor-implemented scoring engine determines, for each prompt modifier, a modifier score. The modifier score for each prompt modifier is associated with the base prompt. One or more of the prompt modifiers are automatically selected based on the modifier scores. A modified prompt is generated. The modified prompt is based on the base prompt and the one or more selected prompt modifiers. The modified prompt is provided as input to an automated image generator to generate an image, and the image is caused to be presented on the user device.",SNAP INC,ZAKHAROV ALEKSANDR;;SMETANIN SERGEY;;GHOSH ARNAB;;SAVCHENKOV PAVEL,SNAP INC (2023-03-07),https://lens.org/056-244-246-466-71X,Patent Application,yes,0,4,3,143-175-587-982-04X;;056-244-246-466-71X;;011-018-465-854-116,US;;WO,3,143-175-587-982-04X;;056-244-246-466-71X;;011-018-465-854-116,US;;WO,0,G06T11/00;;G06N3/02;;G06V10/993;;G06V10/82;;G06V20/30;;G06F40/216;;G06F40/30;;G06F40/279;;G06N3/045;;G06N3/08;;G06N3/044;;G06N3/084;;G06F40/12;;G06F3/04845;;G06T11/00;;G06T2200/24,G06F3/04845;;G06T11/00,,0,0,,,,ACTIVE
326,US,A1,US 2025/0111209 A1,040-696-672-889-535,4/3/2025,2025,US 202318477596 A,9/29/2023,US 202318477596 A,9/29/2023,COLLABORATIVE PROMPT BUILDING FOR GENERATIVE AI MODELS,"Aspects of the invention include techniques for collaborative prompt building for generative artificial intelligence models. A non-limiting example method includes receiving, from a client, a prompt for a large language model. A decision tree is built to determine one or more decision points for refining the prompt and a knowledge graph is built having one or more nodes associated with a feature of the prompt. The method includes delivering, to the client, a challenge comprising a query associated with at least one of the one or more decision points and the one or more nodes, receiving, from the client, an answer to the challenge, and delivering, to the client, a refined prompt by modifying the prompt using the answer to the challenge.",IBM,CUOMO GENNARO ANTHONY;;MUNOZ LUIS FERNANDO;;DOLPH BLAINE H;;HAY CHRISTOPHER,INTERNATIONAL BUSINESS MACHINES CORPORATION (2023-09-26),https://lens.org/040-696-672-889-535,Patent Application,yes,0,0,1,040-696-672-889-535,US,1,040-696-672-889-535,US,0,G06N3/0475;;G06N5/01;;G06N5/022;;G06N3/0475,G06N3/0475,,0,0,,,,PENDING
327,WO,A2,WO 2024/238699 A2,057-638-452-201-972,11/21/2024,2024,US 2024/0029528 W,5/15/2024,US 202363502392 P,5/15/2023,CHEMICAL FUNCTIONAL HOMOLOGUE SEARCH USING INCONSISTENT CANONICALIZED QUERY,"A system and method for providing a chemical similarity search of functional homologs using inconsistently standardized molecular SMILES model inputs or other molecular model inputs to a chemical language model. Consistent, standardized modular searches have yielded molecules with high structural similarity but cannot provide functionally similar yet structurally dissimilar molecules. Using inconsistently standardized molecular SMILES model inputs, the exemplary system was observed to identify molecules that are functionally similar to the query and was also indicated by the associated patent literature to be structurally distinct from the query and thus would have been unlikely to be found with traditional chemical similarity search methods. The current similarity searches use structural elements only to conduct chemical searches. The exemplary method can aid in the discovery of novel structural classes of molecules that achieve target functionality.",UNIV TEXAS,ELLINGTON ANDREW D;;KOSONOCKY CLAYTON;;FELLER AARON,,https://lens.org/057-638-452-201-972,Patent Application,yes,0,1,2,057-638-452-201-972;;143-453-663-713-27X,WO,2,057-638-452-201-972;;143-453-663-713-27X,WO,0,G06N3/00;;G16C20/70;;G16C20/40,,,0,0,,,,PENDING
328,US,A1,US 2025/0028969 A1,179-493-837-479-122,1/23/2025,2025,US 202418909783 A,10/8/2024,US 202418909783 A;;US 202318143512 A;;US 202263338445 P;;US 202263341011 P,5/4/2022,Mitigation for Prompt Injection in A.I. Models Capable of Accepting Text Input,"A system for use with an artificial intelligence (AI) model configured to accept text input, such as generative pre-trained transformer (GPT), that detects and tags trusted instructions and nontrusted instructions of an input provided by a user responsive to an AI model prompt. The system uses reinforcement learning (RL) and a set of rules to remove the untrusted instructions from the input and provide only trusted instructions to the AI model. The input is represented as tokens, wherein the trusted instructions and the untrusted instructions are represented using incompatible token sets.",PREAMBLE INC,CEFALU JONATHAN;;MCHUGH JEREMY CHARLES;;HEICHMAN RON,,https://lens.org/179-493-837-479-122,Patent Application,yes,0,0,5,179-493-837-479-122;;038-964-321-296-689;;093-824-952-507-817;;012-900-355-126-286;;197-355-927-433-352,US;;WO,5,179-493-837-479-122;;093-824-952-507-817;;038-964-321-296-689;;197-355-927-433-352;;012-900-355-126-286,US;;WO,0,G06N3/0475;;G06N3/0455;;G06N3/092;;G06N3/091;;G06F40/279;;G06F40/30;;G06N3/092;;G06F40/40;;G06N3/0455;;G06N3/0475,G06N3/092;;G06F40/40;;G06N3/0455;;G06N3/0475,,5,3,070-599-923-105-461;;197-466-799-563-516;;137-942-587-940-218,10.1007/s11227-021-04251-z;;10.1088/1757-899x/1085/1/012008;;10.1007/s10994-013-5411-2,"Shaokang Cai, ""An reinforcement learning‑based speech censorship chatbot system"", 2022 (Year: 2022);;Jing Xu, ""Recipes for Safety in Open-domain Chatbots"" (Year: 2021);;Subbaraju Pericherla, ""Performance analysis of Word Embeddings for Cyberbullying Detection"" (Year: 2020);;Semiu Salawu, ""Detection and Prevention of Cyberbullying on Social Media"", 2021 (Year: 2021);;Filipe Rodrigues, ""Sequence labeling with multiple annotators"", 2012 (Year: 2012)",PENDING
329,US,B2,US 12372943 B2,081-029-212-866-808,7/29/2025,2025,US 18906819,10/4/2024,,,Generation of computer-executable instructions based on monitoring network communications of remote computing systems,The disclosure generally relates to a system for identifying a formula to build a customized object. The system may identify one or more attributes of an object based on monitoring remote computing systems. The system may provide a prompt to a computing system based on the identified one or more attributes and the computing system may provide an output indicative of a customized object. The system may identify a formula to build the customized object based on the output. The system may provide an output indicative of the formula and/or the customized object.,Starbucks Corporation,Ningyu Chen,,https://lens.org/081-029-212-866-808,Granted Patent,yes,15,0,1,081-029-212-866-808,US,1,081-029-212-866-808,US,0,G05B19/40937;;G05B13/0265;;G05B2219/32005,G05B19/4093;;G05B13/02,,1,0,,,"International Search Report and Written Opinion in application No. PCT/US2024/050111, mailed on Nov. 25, 2024, in 18 pages.",UNKNOWN
330,WO,A1,WO 2025/081073 A1,140-654-286-477-284,4/17/2025,2025,US 2024/0051093 W,10/11/2024,US 202363544022 P,10/13/2023,ARCHITECTURES OF LARGE LANGUAGE MODELS FOR MEDICAL TREATMENT DECISION SUPPORT,"Large language models in conjunction with natural language processing models for medical treatment decision support are provided. In some embodiments, a method of training a large language model is provided. The method can comprise obtaining a plurality of terms associated with a medical topic. The method can comprise generating, using a natural language processing (NLP) model, a plurality of prompts based on the plurality of terms. The plurality of prompts are configured to train a large language model (LLM). The method can comprise providing each of the plurality of prompts to the LLM, thereby training the LLM on the plurality of terms.",TRIALMATCH ME INC D/B/A/TRIALJECTORY,BADER TZVIA;;GILDOR GUY,,https://lens.org/140-654-286-477-284,Patent Application,yes,3,0,2,140-654-286-477-284;;088-017-298-504-803,US;;WO,2,140-654-286-477-284;;088-017-298-504-803,US;;WO,0,G16H50/20;;G06F40/20;;G16H10/60;;G16H50/70;;G06F40/20;;G16H50/20;;G16H10/60,G06F16/38;;G06F40/205;;G06F40/237;;G06F40/279;;G06F40/56;;G06N20/00;;G16H10/00;;G16H50/70,,0,0,,,,PENDING
331,WO,A1,WO 2025/140771 A1,086-175-252-435-276,7/3/2025,2025,EP 2023087883 W,12/28/2023,EP 2023087883 W,12/28/2023,"METHOD, DEVICE AND SYSTEM FOR MONITORING COOKING ACTIVITY","One aspect concerns a method for monitoring cooking activity carried out by a device comprising a processor, comprising: - obtaining (201) time series data from one or more sensors (102_i, 103, 104) configured to monitor the use of one or more appliances (101_J) for meal preparation; - obtaining (202_2) a plurality of cooking activity signatures, wherein a cooking activity signature identifies a meal type as a function of the time series sensor data; - determining (202_3) a probability of preparation of a meal type associated with a given cooking activity signature responsive to a match of the given cooking activity signature with the time series sensor data; - generating (202_4) a signal function of at least one determined meal type.",EATON INTELLIGENT POWER LTD,RYAN PADHRAIG;;BOUHINI CHAHRAZED;;MUCKLEY LEO;;TÓTH PANNA,,https://lens.org/086-175-252-435-276,Patent Application,yes,7,0,1,086-175-252-435-276,WO,1,086-175-252-435-276,WO,0,A47J36/321;;G16H20/60;;G16H40/63;;G16H50/20;;G16H50/30,G16H20/60;;G16H40/63;;G16H40/67;;G16H50/20;;G16H50/30,,0,0,,,,PENDING
332,US,A1,US 2025/0111107 A1,129-258-053-983-001,4/3/2025,2025,US 202418591578 A,2/29/2024,US 202418591578 A;;US 202363586632 P;;US 202463556088 P,9/29/2023,SYSTEMS AND METHODS FOR GENERATING DESIGNS USING ANALOGICS WITH LEARNING MODELS,"Systems, methods, and other embodiments described herein relate to generating designs using learning models for analogics that process text and sketch-based inputs. In one embodiment, a method includes estimating analogical suggestions using a transformer model for a text prompt having design parameters. The method also includes generating an image using a learning model for an expression selected from the analogical suggestions and a sketched stroke inputted. The method also includes manipulating a modified sketch by the learning model and the modified sketch is derived from a sketched conversion of the image by an edge model.",TOYOTA RES INST INC;;TOYOTA MOTOR CO LTD;;UNIV CARNEGIE MELLON,LIN CHUAN-EN;;KANG HYEONSU B;;MARTELARO NIKOLAS A;;KITTUR ANIKET D;;CHEN YIN-YING;;HONG MATTHEW K,TOYOTA JIDOSHA KABUSHIKI KAISHA (2024-02-19);;CARNEGIE MELLON UNIVERSITY (2024-02-27);;TOYOTA RESEARCH INSTITUTE INC (2024-02-19),https://lens.org/129-258-053-983-001,Patent Application,yes,0,0,1,129-258-053-983-001,US,2,144-802-471-359-930;;129-258-053-983-001,US,0,G06F30/27;;G06F30/27,G06F30/27,,0,0,,,,PENDING
333,WO,A1,WO 2025/076462 A1,080-378-047-033-915,4/10/2025,2025,US 2024/0050111 W,10/4/2024,US 202363588508 P,10/6/2023,GENERATION OF COMPUTER-EXECUTABLE INSTRUCTIONS BASED ON MONITORING NETWORK COMMUNICATIONS OF REMOTE COMPUTING SYSTEMS,The disclosure generally relates to a system for identifying a formula to build a customized object. The system may identify one or more attributes of an object based on monitoring remote computing systems. The system may provide a prompt to a computing system based on the identified one or more attributes and the computing system may provide an output indicative of a customized object. The system may identify a formula to build the customized object based on the output. The system may provide an output indicative of the formula and/or the customized object.,STARBUCKS CORP,CHEN NINGYU,,https://lens.org/080-378-047-033-915,Patent Application,yes,5,0,2,046-083-273-174-643;;080-378-047-033-915,US;;WO,2,046-083-273-174-643;;080-378-047-033-915,US;;WO,0,G06N3/0475;;G06Q30/0621;;G06N20/00;;G05B13/0265;;G05B19/40937;;G05B2219/32005,G06Q30/0601;;G06N3/0475,,0,0,,,,PENDING
334,US,A1,US 2025/0124234 A1,129-836-367-262-356,4/17/2025,2025,US 202318484964 A,10/11/2023,US 202318484964 A,10/11/2023,AUTOMATICALLY UPDATING PROMPTS IN RESPONSE TO DATA DRIFT,"Techniques for correcting data drift of a language model are disclosed. A model is built, and this model is designed to solve a same task for which the language model has been trained. The model is applied to new input data. This application results in generation of a prediction comprising predicted label data. Context is stored in a context management structure (CMS). The context includes a prompt template, a prediction, and labeled input data used to train the language model. The data drift is determined to have occurred. This determination is performed by determining that the context is within a threshold level of similarity to a previously stored context. In response to determining that the data drift has occurred, an operation is performed to correct the data drift.",DELL PRODUCTS LP,ENES KAREN BRAGA;;DA SILVA PABLO NASCIMENTO;;MARTINS KAREN STÉFANY;;PALATNIK DE SOUSA IAM,DELL PRODUCTS L.P (2023-10-02),https://lens.org/129-836-367-262-356,Patent Application,yes,0,1,1,129-836-367-262-356,US,1,129-836-367-262-356,US,0,G06F40/40;;G06F40/40,G06F40/40,,0,0,,,,PENDING
335,US,A1,US 2025/0136130 A1,155-667-179-569-447,5/1/2025,2025,US 202318499913 A,11/1/2023,US 202318499913 A,11/1/2023,MACHINE OPERATION ASSISTANCE USING LANGUAGE MODEL-AUGMENTED PERCEPTION,"Various embodiments of the present disclosure relate to operator assistance based on extracting natural language characters from one or more sensed objects. For instance, particular embodiments may generate a natural language utterance based on extracting natural language text in a nearby traffic sign. In an illustrative example, particular embodiments may detect, via object detection and within image data, one or more regions of the image data depicting the traffic sign. Particular embodiments can then extract one or more first natural language characters represented in the traffic sign based at least on performing optical character recognition within the one or more regions of the image data in response to detecting the one or more regions of the image data depicting the traffic sign.",NVIDIA CORP,SHETTY RAJATH;;KUMAR RATIN;;PATHAK NIRAL LALIT;;AVADHANAM NIRANJAN,NVIDIA CORPORATION (2023-10-31),https://lens.org/155-667-179-569-447,Patent Application,yes,0,0,2,113-466-392-744-270;;155-667-179-569-447,US;;CN,6,098-406-454-278-281;;155-667-179-569-447;;113-466-392-744-270;;002-241-258-892-086;;009-898-408-071-621;;152-198-975-467-195,US;;DE;;CN,0,B60W2540/21;;B60W2420/403;;G06V20/582;;G06V30/1444;;G06V30/19;;G06V30/262;;G06V20/63;;G06V20/597;;G10L13/00;;G10L15/26;;B60W50/10;;G06V20/582;;G06V20/63;;G06V30/1444;;G10L15/183;;B60W2420/403;;G06V20/597;;G06V30/19;;B60W60/001;;B60W2540/21;;G06V30/262,B60W50/10;;B60W60/00;;G06V20/58;;G06V20/59;;G06V20/62;;G06V30/14;;G06V30/19;;G06V30/262;;G10L15/183,,0,0,,,,PENDING
336,US,A1,US 2025/0136134 A1,098-406-454-278-281,5/1/2025,2025,US 202318499942 A,11/1/2023,US 202318499942 A,11/1/2023,MACHINE OPERATION ASSISTANCE USING LANGUAGE MODEL-AUGMENTED OPERATOR MONITORING,"Various embodiments of the present disclosure relate to operator assistance based on operator monitoring. For instance, during long drives, a driver may become drowsy or may not otherwise be alert. As such, particular embodiments have the capability of starting a conversation with the driver based on driver interests and/or detecting that the driver is getting drowsy. In an illustrative example, a Driver Monitoring System (DMS) camera of a vehicle may employ a component that derives pixel-level information showing head nodding, hands dropping, or the like. Based on image pattern characteristics in the image data, particular embodiments generate a score representing an alertness level. A representation of the alertness level can be provided as input to a machine learning model so that the model may generate a suitable natural language or other response, such as starting a conversation with personalized trivia, sending a control signal to honk a horn, or the like.",NVIDIA CORP,SHETTY RAJATH;;KUMAR RATIN;;PATHAK NIRAL LALIT;;AVADHANAM NIRANJAN,NVIDIA CORPORATION (2023-10-31),https://lens.org/098-406-454-278-281,Patent Application,yes,0,0,2,098-406-454-278-281;;009-898-408-071-621,US;;CN,6,098-406-454-278-281;;155-667-179-569-447;;113-466-392-744-270;;002-241-258-892-086;;009-898-408-071-621;;152-198-975-467-195,US;;DE;;CN,0,G06V20/597;;B60W2050/143;;B60W2050/146;;B60W50/14;;G10L15/22;;G10L13/027;;B60W50/14;;G06V20/597;;B60W2050/146;;G10L15/22;;B60W2050/143;;G10L13/027,B60W50/14;;G06V20/59;;G10L13/027;;G10L15/22,,0,0,,,,PENDING
337,US,A1,US 2025/0071726 A1,143-480-930-583-785,2/27/2025,2025,US 202318237299 A,8/23/2023,US 202318237299 A,8/23/2023,ALTITUDE DETECTION BY SMARTPHONE WITHOUT USING GPS INFORMATION,"Systems and methods are provided for determining that the device is not reporting precise location information, based on output from one or more sensors determining that the device is located indoors and determining the altitude of the device. Based on the determination that the device is located indoors, suspending precise location services until it is determined that the device is back outdoors.",T MOBILE INNOVATIONS LLC,TRAN ANTOINE;;WU PO-HAN;;KIELY DOUG FRANCIS;;HUI JIE,T-MOBILE INNOVATIONS LLC (2023-08-07),https://lens.org/143-480-930-583-785,Patent Application,yes,0,0,1,143-480-930-583-785,US,1,143-480-930-583-785,US,0,H04W64/006;;H04W76/50;;H04W4/90;;H04W24/04;;H04W24/10;;H04W4/029;;H04W4/025;;H04W4/38;;H04W4/33;;H04W64/006,H04W64/00,,0,0,,,,PENDING
338,US,A1,US 2025/0071515 A1,193-688-959-527-214,2/27/2025,2025,US 202318237302 A,8/23/2023,US 202318237302 A,8/23/2023,INDOOR DETECTION BY SMARTPHONE WITHOUT USING GPS INFORMATION TO CONSERVE POWER,"Systems and methods are provided for determining that the device is not reporting precise location information, based on output from one or more sensors determining that the device is located indoors and determining the altitude of the device. Based on the determination that the device is located indoors, suspending precise location services until it is determined that the device is back outdoors.",T MOBILE INNOVATIONS LLC,TRAN ANTOINE;;WU PO-HAN;;KIELY DOUG FRANCIS;;HUI JIE,T-MOBILE INNOVATIONS LLC (2023-08-07),https://lens.org/193-688-959-527-214,Patent Application,yes,0,0,2,112-329-815-084-650;;193-688-959-527-214,US;;EP,2,112-329-815-084-650;;193-688-959-527-214,US;;EP,0,G01S5/012;;G01S5/015;;H04W4/02;;G01S19/48;;G01S19/34;;H04W4/38;;H04W4/33;;H04W4/029,H04W4/029;;H04W4/33;;H04W4/38,,0,0,,,,PENDING
339,US,A1,US 2025/0060447 A1,125-044-045-529-256,2/20/2025,2025,US 202318235282 A,8/17/2023,US 202318235282 A,8/17/2023,INDOOR-OUTDOOR DETECTION BY SMARTPHONE WITHOUT USING GPS INFORMATION,"Systems and methods are provided for determining that the device is not reporting precise location information, based on output from one or more sensors determining that the device is located indoors and determining the altitude of the device. Based on the determination that the device is located indoors, suspending precise location services until it is determined that the device is back outdoors.",T MOBILE INNOVATIONS LLC,TRAN ANTOINE;;WU PO-HAN;;KIELY DOUG FRANCIS;;HUI JIE,T-MOBILE INNOVATIONS LLC (2023-08-04),https://lens.org/125-044-045-529-256,Patent Application,yes,0,0,1,125-044-045-529-256,US,1,125-044-045-529-256,US,0,H04W64/006;;G01S5/012;;G01S5/16;;H04W64/006;;G01S5/012,G01S5/00;;H04W64/00,,0,0,,,,PENDING
340,WO,A1,WO 2025/093106 A1,194-087-584-034-140,5/8/2025,2025,EP 2023080340 W,10/31/2023,EP 2023080340 W,10/31/2023,"DEVICE FOR SERVICE-BASED INTERFACE (SBI) COMMUNICATION WITH AT LEAST ONE CONTROL FUNCTION OF A TELECOMMUNICATION NETWORK, AND METHOD OF OPERATING SAID DEVICE","Device for Service-Based Interface (SBI) communication with a control function of a telecommunication network. The device comprises a GPT model interface; a NRF interface; a NWDAF interface; and a processor. The processor is configured to retrieve, via the GPT model interface, a GPT model of the SBI communication; retrieve, via the NRF interface, an indication of available services provided by the control function; retrieve, via the NWDAF interface, a real-time state information of the telecommunication network; receive a first service intent or request; validate, using the GPT model, the received first service intent or request; determine, using the GPT model, one or more implementing services of the available services based on the validated first service intent or request and the real-time state information; and send a second service intent or request for at least one of the implementing services.",HUAWEI TECH CO LTD;;ABBOUD OSAMA,ABBOUD OSAMA;;KHALILI RAMIN,,https://lens.org/194-087-584-034-140,Patent Application,yes,3,0,1,194-087-584-034-140,WO,1,194-087-584-034-140,WO,0,H04L41/145;;H04L41/40,H04L41/14;;H04L41/40,,1,0,,,"GSM ASSOCIATION, GSM ASSOCIATION, GSMA FLOOR2 THE WALBROOK BUILDING 25 WALLBROOK LONDON, UK, 1 December 2020 (2020-12-01), XP040719484",PENDING
341,US,B1,US 12197859 B1,082-042-370-293-809,1/14/2025,2025,US 202418782019 A,7/23/2024,US 202418782019 A;;US 202418771876 A;;US 202418661532 A;;US 202418661519 A;;US 202418633293 A,4/11/2024,Identifying and analyzing actions from vector representations of alphanumeric characters using a large language model,"The systems and methods disclosed herein receive an output generation request from that includes input for generating an output using a language model. The input includes a set of alphanumeric characters associated with operative standards for a first set of actions. The system divides the set of alphanumeric characters into text subsets. For each text subset, a vector representation is determined. Prompts are created for each vector representation including the set of alphanumeric characters, query contexts, keywords, and/or the text subset. Each vector representation's prompt is input into the language model, which generates a second set of actions of related actions, where subsequently generated actions are based on prior generated actions. The system aggregates the second set of actions into a third set of actions and displays a graphical layout. The graphical layout displays a representation of the set of alphanumeric characters and the corresponding actions.",CITIBANK NA,MALVIYA SHARDUL;;LIAO WAYNE;;JAIN DEEPAK;;CORY SAMANTHA;;SATERNUS MARIUSZ;;LEWANDOWSKI DANIEL;;RATH BIRAJ KRUSHNA;;MURRAY STUART;;DAVIES PHILIP;;JAIN PAYAL;;MAONAH TARIQ HUSAYN,CITIBANK N.A (2024-05-14),https://lens.org/082-042-370-293-809,Granted Patent,yes,26,5,1,082-042-370-293-809,US,36,166-860-055-274-237;;192-529-172-020-159;;117-165-481-521-817;;062-084-390-952-648;;009-332-012-767-769;;130-711-467-813-772;;150-084-174-776-205;;134-859-487-724-028;;136-076-696-451-742;;174-498-778-674-614;;135-411-020-650-37X;;082-042-370-293-809;;081-164-654-051-886;;126-999-415-386-749;;101-393-155-626-043;;028-517-317-595-400;;183-393-311-078-435;;120-491-497-842-713;;071-444-314-653-665;;151-710-271-944-022;;169-310-367-816-659;;114-332-483-825-36X;;176-222-606-932-299;;109-693-731-347-460;;187-959-165-043-749;;165-235-788-605-427;;184-797-936-150-334;;129-627-428-962-735;;132-864-126-338-301;;147-316-129-152-657;;087-574-341-939-358;;052-233-397-211-176;;154-552-332-382-958;;158-104-528-887-831;;122-629-432-281-208;;053-045-267-490-224,US;;WO;;EP,0,G06F40/216;;G06F40/216,G06F40/216,,7,0,,,"Generative machine learning models; IPCCOM000272835D, Aug. 17, 2023. (Year: 2023).;;Peers, M., “What California AI Bill Could Mean,” The Briefing, published and retrieved Aug. 30, 2024, 8 pages, https://www.theinformation.com/articles/what-california-ai-bill-could-mean.;;Empower Your Team with a Compliance Co-Pilot, Sedric, retrieved on Sep. 25, 2024. https://www.sedric.ai/.;;Cranium, Adopt & Accelerate Al Safely, retrieved on Nov. 7, 2024, from https://cranium.ai/.;;Guldimann, P., et al. “COMPL-AI Framework: A Technical Interpretation and LLM Benchmarking Suite for the EU Artificial Intelligence Act,” arXiv:2410.07959v1 [cs.CL] Oct. 10, 2024, 38 pages.;;Hu, Q., J., et al., “Routerbench: A Benchmark for Multi-LLM Routing System,” arXiv:2403.12031v2 [cs.LG] Mar. 28, 2024, 16 pages.;;Mathews, A. W., “What Al Can Do in Healthcare-and What It Should Never Do,” The Wall Street Journal, published on Aug. 21, 2024, retrieved on Sep. 5, 2024, https:/www.wsi.com.",ACTIVE
342,US,B2,US 12175204 B2,197-608-042-166-819,12/24/2024,2024,US 202217584068 A,1/25/2022,US 202217584068 A,1/25/2022,Aspect prompting framework for language modeling,"Techniques for dynamically developing a contextual set of prompts based on relevant aspects extracted from s set of training data. One technique includes obtaining training data comprising text examples and associated labels, extracting aspects from the training data, generating prompting templates based on the training data and the extracted aspects, concatenating each of the text examples with the respective generated prompting template to create prompting functions, training a machine learning language model on the prompting functions to predict a solution for a task, where the training is formulated as a masked language modeling problem with blanks of the prompting templates being set as text labels and expected output for the task being set as specified solution labels, and the training learns or updates model parameters of the machine learning language model for performing the task. The machine learning language model is provided with the learned or updated model parameters.",ORACLE INT CORP,REZA SHAHID;;BHAT NAGARAJ N,ORACLE INTERNATIONAL CORPORATION (2022-01-23),https://lens.org/197-608-042-166-819,Granted Patent,yes,3,0,2,197-608-042-166-819;;195-301-793-764-394,US,2,197-608-042-166-819;;195-301-793-764-394,US,0,G06F40/186;;G06F40/284;;G06F40/40;;G06F40/169;;G06N3/0455;;G06N3/096;;G06N3/0475;;G06F40/40;;G06F40/284;;G06F40/186;;G06V30/19147,G06F40/169;;G06F40/186;;G06F40/284;;G06F40/40;;G06N3/0455;;G06N3/0475;;G06N3/096;;G06V30/19,,3,0,,,"Brown, et al. Language Models for Few-Shot Learners, OpenAI, arXiv:2002.14165v4 Juy 22, 2020, 75 pages.;;Ziegler, et al., FINE-Tuning Language Models for Human Preferences, OpenAI, arCiv:1919.08593v2 Jan. 8, 2020, 26 pages.;;Liu et al., “Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing”, Jul. 28, 2021, 46 pages.",ACTIVE
343,US,A1,US 2025/0139251 A1,097-986-894-391-007,5/1/2025,2025,US 202318495626 A,10/26/2023,US 202318495626 A,10/26/2023,SECURE CODE ANALYSIS COPILOT,"An approach is provided that identifies a vulnerability corresponding to an initial source code. Then, the approach generates a prompt comprising the initial source code and the vulnerability. The approach inputs the prompt into an artificial intelligence model (AIM) that is trained to determine whether the initial source code comprises the vulnerability. In turn, the approach removes, using the AIM, the vulnerability from the initial source code to produce a refactored source code in response to determining that the initial source code comprises the vulnerability.",CROWDSTRIKE INC,SUMEDREA PAUL;;POPA CRISTIAN VIOREL;;SAVA VASILE-DANIEL,CROWDSTRIKE INC (2023-10-26),https://lens.org/097-986-894-391-007,Patent Application,yes,0,1,1,097-986-894-391-007,US,1,097-986-894-391-007,US,0,G06F21/563;;G06F8/72;;G06F21/577;;G06F21/577;;G06F8/72;;G06F21/563,G06F21/57;;G06F8/72;;G06F21/56,,0,0,,,,PENDING
344,US,A1,US 2025/0117589 A1,020-017-526-948-733,4/10/2025,2025,US 202418830758 A,9/11/2024,US 202418830758 A;;US 202363587735 P,10/4/2023,Large Language Models for Predictive Modeling and Inverse Design,"An inverse design system combines a large language model (LLM) with a task-specific optimizer, which includes a search function, a forward model, and a comparator. The LLM adjusts parameters of the optimizer's components in response to a design scenario. Then the optimizer processes the design scenario to produce design candidates. Optionally, the LLM learns from the design candidates in an iterative process. A stochastic predictive modeling system combines an LLM with input distributions and a forward model. The LLM adjusts one or more of the input distributions and/or the forward model in response to a forecast scenario. Then the forward model processes a sampling of the input distributions to produce a forward distribution. Optionally, the LLM informs the sampling process. Optionally, the LLM learns from the forward distribution.",X DEV LLC,LING JULIA BLACK;;MARTINEZ ALBERTO CAMACHO;;ANDRE DAVID;;HAHN CHRISTOPHER,X DEVELOPMENT LLC (2024-08-27),https://lens.org/020-017-526-948-733,Patent Application,yes,0,0,1,020-017-526-948-733,US,2,020-017-526-948-733;;149-282-254-924-855,US;;WO,0,G06F40/30;;G06F40/30,G06F40/30,,0,0,,,,PENDING
345,US,A1,US 2025/0165718 A1,046-670-374-641-390,5/22/2025,2025,US 202418904441 A,10/2/2024,KR 20230159132 A,11/16/2023,DEVICE AND METHOD FOR ARTIFICIAL INTELLIGENCE REASONING BASED ON LANGUAGE MODEL,"Provided are a device and method for artificial intelligence (AI) reasoning based on a language model. The method for AI reasoning based on a language model includes generating a question core summary by inputting a natural language question to a language model, decomposing the natural language question into sub-questions using a reasoning model on the basis of the question core summary and the natural language question, obtaining an answer to the natural language question by solving the sub-questions and synthesizing solutions of the sub-questions.",ELECTRONICS & TELECOMMUNICATIONS RES INST,SEO YOUNG-AE,ELECTRONICS AND TELECOMMUNICATIONS RESEARCH INSTITUTE (2024-09-25),https://lens.org/046-670-374-641-390,Patent Application,yes,0,0,2,153-557-502-393-219;;046-670-374-641-390,US;;KR,2,153-557-502-393-219;;046-670-374-641-390,US;;KR,0,G06F40/35;;G06F40/30;;G06F16/345;;G06F16/3329;;G06F16/3338;;G06N3/096;;G06N5/04;;G06F40/35,G06F40/35,,0,0,,,,PENDING
346,US,A1,US 2025/0047622 A1,013-855-260-374-080,2/6/2025,2025,US 202318487408 A,10/16/2023,US 202318487408 A;;US 202363517867 P,8/4/2023,GENERATING DIVERSE MESSAGE CONTENT SUGGESTIONS,"Embodiments of the disclosed technologies are capable of generating diverse suggested message content. The embodiments describe generating a message plan comprising attribute data and section data. The embodiments further describe inputting the message plan as a prompt to a first generative model. The first generative model is fine-tuned using a training message plan. The training message plan comprises an ordered sequence of training attribute data and training section data. The training attribute data and training section data are extracted from historic messages or generated messages. The embodiments further describe generating, by the first generative model, message content suggestions based on the attribute data and section data.",MICROSOFT TECHNOLOGY LICENSING LLC,BODIGUTLA PRAVEEN KUMAR;;BOLLAM SAI KRISHNA;;GUPTA SAURABH,MICROSOFT TECHNOLOGY LICENSING LLC (2023-10-17),https://lens.org/013-855-260-374-080,Patent Application,yes,7,2,1,013-855-260-374-080,US,2,115-678-978-221-300;;013-855-260-374-080,US;;WO,0,G06F16/35;;H04L51/04;;G06F16/334;;H04L51/02;;G06F40/56;;G06F40/30;;H04L51/02;;G06F40/56;;H04L51/04;;G06F16/35;;G06F16/334,H04L51/02;;G06F40/56;;H04L51/04,,0,0,,,,PENDING
347,US,A1,US 2024/0345551 A1,055-978-743-718-718,10/17/2024,2024,US 202418419464 A,1/22/2024,US 202418419464 A;;US 202363458871 P;;US 202363466203 P;;US 202363528183 P;;US 202363541261 P,4/12/2023,BUILDING MANAGEMENT SYSTEM WITH NATURAL LANGUAGE MODEL-BASED DATA STRUCTURE GENERATION,"Systems and methods are disclosed relating to building management systems with language model-based data structure generation. For example, a method can include receiving a query to select, from a plurality of data sources of a building management system, a selected one or more data sources according to a characteristic indicated by the query in at least one of a natural language representation or a semantic representation. The method can further include applying the query as input to a machine learning model to cause the machine learning model to generate an output indicating the selected one or more data sources, the machine learning model configured using training data comprising sample data and metadata from the plurality of data sources. The method can further include presenting, using at least one of a display device or an audio output device, the output.",JOHNSON CONTROLS TYCO IP HOLDINGS LLP,RAMANASANKARAN RAJIV;;SELVARAJ KRISHNAMURTHY,JOHNSON CONTROLS TYCO IP HOLDINGS LLP (2024-01-24);;TYCO FIRE & SECURITY GMBH (2024-02-01),https://lens.org/055-978-743-718-718,Patent Application,yes,22,8,3,074-319-129-582-574;;180-103-041-774-432;;055-978-743-718-718,US,18,122-107-496-444-741;;074-319-129-582-574;;173-181-749-887-897;;054-010-372-186-271;;190-317-871-112-741;;179-054-288-764-021;;061-723-496-275-034;;019-574-095-821-55X;;091-999-733-244-633;;055-978-743-718-718;;035-915-377-872-630;;140-199-033-725-831;;070-886-440-498-207;;180-103-041-774-432;;139-917-656-167-854;;058-800-914-390-886;;127-040-264-295-888;;182-947-486-447-322,US;;WO,0,G06N3/0895;;G06F16/248;;G05B13/027;;G05B13/027;;G06N3/0895;;G06F16/248,G05B13/02;;G06F16/248;;G06N3/0895,,0,0,,,,ACTIVE
348,US,A1,US 2023/0222393 A1,047-733-388-357-771,7/13/2023,2023,US 202318187757 A,3/22/2023,US 202318187757 A,3/22/2023,SYSTEMS AND METHODOLOGIES FOR THE PROPAGATION OF MODULARDYNAMIC AI ENVIRONMENTS IN LOWER DIMENSIONAL SPACE THROUGHGUIDED AND AUTONOMOUS LEARNING,"In this paper, I introduce Recombinant AI. By, leveraging pre-trained language models, such as GPT-4, a recombinant contextual learning loop, and efficient indexing techniques like Hierarchical Navigable Small World (HNSW) Graphs, we are able to generate. AI modules that when sufficiently robust, will inherently (with human input and direction) begin to function as distinct entities with their own knowledge, conversational history, and personality guidelines. These isolated environments technically only exist in lower-dimensional space, at the time of interface with an external influence.The proposed framework allows for the creation of powerful and interactive AI applications, with the potential to enhance user experiences across various domains, including, but not limited to:Interactive storytellingCustomer supportPersonalized AI assistants,Instantly customizable solutions",ZAHM MARK,ZAHM MARK,,https://lens.org/047-733-388-357-771,Patent Application,yes,0,3,1,047-733-388-357-771,US,1,047-733-388-357-771,US,0,G06N3/008;;G06F40/216;;G06F40/30;;G06F40/35;;G06N3/042;;G06N3/045;;G06N3/0475;;G06N20/00,G06N20/00,,0,0,,,,DISCONTINUED
349,US,A1,US 2025/0131455 A1,067-662-270-319-198,4/24/2025,2025,US 202418920874 A,10/19/2024,US 202418920874 A;;US 202363591549 P;;US 202363591560 P;;US 202363591566 P;;US 202363591646 P;;US 202363591690 P;;US 202463655183 P,10/19/2023,SYSTEM AND METHOD FOR SAAS DATA CONTROL PLATFORM,There is provided an automated system for generating mappings and enumerated tree objects. Documents containing compliance rules may be converted to tree-structured documents. Mappings may be generated which link nodes within the tree-structured documents to one another. Compliance controls may be created which continuously monitor a computing environment for compliance by applications with the controls. Compliance evidence objects may be received which indicate an application's compliance or non-compliance with one or more controls.,ROYAL BANK OF CANADA,SHARIEH SALAH;;HUSSAIN FATIMA JAVAID;;OSTANIN EVGENII;;NOYE BRETT;;DUZI PAULA;;BAI HAOYUE;;DJOSIC NEBOJSA,ROYAL BANK OF CANADA (2024-11-26),https://lens.org/067-662-270-319-198,Patent Application,yes,0,0,6,065-404-123-480-569;;147-118-825-235-272;;057-285-146-119-929;;176-325-360-927-976;;056-861-113-172-64X;;067-662-270-319-198,US,6,057-285-146-119-929;;147-118-825-235-272;;067-662-270-319-198;;065-404-123-480-569;;056-861-113-172-64X;;176-325-360-927-976,US,0,G06F2221/033;;G06Q30/018;;G06V30/414;;G06N20/00;;G06F21/57;;G06F40/40;;G06F16/322;;G06F21/577;;G06Q10/0635;;G06N20/20;;G06V30/414;;G06Q10/0635;;G06F21/577;;G06F2221/033;;G06N20/00;;G06Q30/018;;G06F40/40;;G06F16/322;;G06F21/57,G06Q30/018,,0,0,,,,PENDING
350,US,A1,US 2025/0086211 A1,181-667-160-173-146,3/13/2025,2025,US 202318465677 A,9/12/2023,US 202318465677 A,9/12/2023,GROUNDING LARGE LANGUAGE MODELS USING REAL-TIME CONTENT FEEDS AND REFERENCE DATA,"This disclosure describes a system and method, using one or more processors, for grounding large language models using real-time content feeds and reference data. The system is able to receive/generate queries, prompt an AI model and evaluate the answer given by the AI model. A hallucination score is generated according to the evaluation of the answer. According to the hallucination score, the AI model may be iteratively accessed to improve the truthfulness of the answer.",BITVORE CORP,BOLCER GREGORY ALAN;;NADER RODRIGO SILVA;;ALMEIDA GABRIEL LUIZ FREITAS,BITVORE CORP (2023-09-12),https://lens.org/181-667-160-173-146,Patent Application,yes,17,2,1,181-667-160-173-146,US,1,181-667-160-173-146,US,0,G06F16/3344;;G06F16/3325;;G06F16/3325;;G06F16/3344,G06F16/33;;G06F16/332,,0,0,,,,PENDING
351,WO,A1,WO 2024/226830 A1,045-197-935-678-170,10/31/2024,2024,US 2024/0026311 W,4/25/2024,US 202363498213 P,4/25/2023,"TEXT AND MEDIA ENCODERS FOR CLASSIFYING MEDIA, DETERMINING PROMPTS, AND UNCOVERING BIAS IN MACHINE LEARNING MODELS",Embodiments are directed to methods and systems for media classification that may be used to better improve classification models and understand results of such classification. Various embodiments can determine a classification for a media item and can determine a prompt that includes the classification for a media item. Further embodiments can train a machine learning model using media items with known classifications. The results of each training iteration may be used to understand the result and improve the machine learning model.,VISA INT SERVICE ASS,WANG JUNPENG;;YEH MICHAEL;;FAN YUJIE;;DAI XIN;;ZHENG YAN;;WANG LIANG;;ZHANG WEI,,https://lens.org/045-197-935-678-170,Patent Application,yes,5,0,1,045-197-935-678-170,WO,1,045-197-935-678-170,WO,0,G06N3/0455;;G06N3/09;;G06N3/045;;G06N3/08;;G06N3/044;;G06N3/084;;G06N3/088,G06N3/09;;G06N3/0455,,0,0,,,,PENDING
352,WO,A1,WO 2025/053946 A1,084-138-254-167-601,3/13/2025,2025,US 2024/0041380 W,8/8/2024,US 202318244229 A,9/9/2023,EXECUTING A CLIENT MODEL USING A TASK PROMPT PRODUCED BY A MAIN SYSTEM,"A technique executes a client machine-trained model (""client model"") on a client device. In operation, the client device submits a description of a task to be performed by the client device to a network-accessible main system. The main system uses a main-system machine-trained model (""main-system model"") to produce a task prompt based on the task description. The client device subsequently uses the task prompt to process queries pertaining to the task. The main-system is trained to increase the accuracy of responses produced by the client model, while reducing the sizes of task prompts produced by the main system. The training process is performed by holding weights of the client model constant.",MICROSOFT TECHNOLOGY LICENSING LLC,FAYYAZ MOHSEN;;IMANIGOOGHARI AYYOOB;;SOMMERLADE ERIC CHRIS WOLFGANG,,https://lens.org/084-138-254-167-601,Patent Application,yes,2,0,2,084-138-254-167-601;;123-843-618-802-028,US;;WO,2,084-138-254-167-601;;123-843-618-802-028,US;;WO,0,G06N20/00;;G06N3/045;;G06F16/24564,G06N20/00,,10,0,,,"VASWANI ET AL.: ""Attention Is All You Need"", 31ST CONFERENCE ON NEURAL INFORMATION PROCESSING SYSTEMS (NIPS 2017, 2017;;DEVLIN ET AL.: ""arXiv:1810.04805v2 [cs.CL"", 24 May 2019, CORNELL UNIVERSITY, article ""BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"";;RADFORD ET AL.: ""Improving Language Understanding by Generative Pre-training"", OPENAI, 11 June 2018 (2018-06-11);;TOUVRON ET AL.: ""LLaMA: Open and Efficient Foundation Language Models"", ARXIV:2302.13971V1 [CS.CL, 27 February 2023 (2023-02-27);;SCAO ET AL.: ""arXiv:2211.051 00v2 [cs.CL"", 11 December 2022, CORNELL UNIVERSIT, article ""BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"";;RAO ET AL.: ""DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification"", 35TH CONFERENCE ON NEURAL INFORMATION PROCESSING SYSTEMS (NEURIPS 2021, 2021;;BANINO ET AL.: ""PonderNet: Learning to Ponder"", 8TH ICML WORKSHOP ON AUTOMATED MACHINE LEARNING, 2021;;HU: ""arXiv:2106.09685v2 [cs.CL"", 16 October 2021, CORNELL UNIVERSITY, article ""LoRA: Low-Rank Adaptation of Large Language Models"";;HOULSBY ET AL.: ""arXiv:1902.00751v2 [cs.LG"", June 2019, CORNELL UNIVERSITY, article ""Parameter-Efficient Transfer Learning for NLP"";;PFEIFFER ET AL.: ""2005.00247v3 [cs.CL"", 26 January 2021, CORNELL UNIVERSITY, article ""AdapterFusion: Non-Destructive Task Composition for Transfer Learning""",PENDING
353,US,A1,US 2025/0045531 A1,120-520-785-808-368,2/6/2025,2025,US 202318229504 A,8/2/2023,US 202318229504 A,8/2/2023,AI HALLUCINATION AND JAILBREAKING PREVENTION FRAMEWORK,"The disclosed embodiments include systems and methods configured to provide a Generative AI framework that uses the power of multiple LLMs by separating the generative aspect into multiple distinct large language models. In some disclosed embodiments, a first large language model evaluates an input prompt and transforms it if needed (e.g., in a first processing stage of the framework); a second large language model performs a generative function based on an input prompt it receives from the first large language model (e.g., in a second processing stage); and a third large language model analyzes and as necessary transforms the output of the second large language model to ensure accuracy, no hallucinations, and no harmful content in the final generated response to the input prompt (e.g., in a third processing stage).",UNUM GROUP,HAYES REED,UNUM GROUP (2023-08-01),https://lens.org/120-520-785-808-368,Patent Application,yes,8,3,1,120-520-785-808-368,US,1,120-520-785-808-368,US,0,G06F21/64;;G06N3/045;;G06F40/40;;G06F40/56;;G06N3/047;;G06F40/40;;G06F21/64;;G06N3/045;;G06F16/338;;G06F16/33;;G06F16/334;;G06F16/3344;;G06F16/3331;;G06F40/10;;G06F40/279;;G06F40/20,G06F40/40;;G06F21/64;;G06N3/045,,4,0,,,"Helping Large Language Models Protect Themselves: An enhanced filtering and summarization system, Muhaimen et al, May 5, 2025, https://arxiv.org/pdf/2505.01315 (Year: 2025);;JailbreaksOverTime: Detecting Jailbreak Attacks under Distribution Shift, Piet et al, April 28, 2025, https://arxiv.org/pdf/2504.19440 (Year: 2025);;Safeguarding Large Language Models: A Survey, Dong et al, June 3, 2024, https://arxiv.org/pdf/2406.02622 (Year: 2024);;Diversity Helps Jailbreak Large Language Models, Zhao et al, May 11, 2025, https://arxiv.org/pdf/2411.04223 (Year: 2025)",PENDING
354,WO,A1,WO 2025/034468 A1,115-678-978-221-300,2/13/2025,2025,US 2024/0040251 W,7/31/2024,US 202363517867 P;;US 202318487408 A,8/4/2023,GENERATING DIVERSE MESSAGE CONTENT SUGGESTIONS,"Embodiments of the disclosed technologies are capable of generating diverse suggested message content. The embodiments describe generating a message plan comprising attribute data and section data. The embodiments further describe inputting the message plan as a prompt to a first generative model. The first generative model is fine-tuned using a training message plan. The training message plan comprises an ordered sequence of training attribute data and training section data. The training attribute data and training section data are extracted from historic messages or generated messages. The embodiments further describe generating, by the first generative model, message content suggestions based on the attribute data and section data.",MICROSOFT TECHNOLOGY LICENSING LLC,BODIGUTLA PRAVEEN KUMAR;;BOLLAM SAI KRISHNA;;GUPTA SAURABH,,https://lens.org/115-678-978-221-300,Patent Application,yes,2,1,1,115-678-978-221-300,WO,2,115-678-978-221-300;;013-855-260-374-080,US;;WO,0,G06N3/0475;;H04L51/02;;G06Q10/1053,G06Q10/1053;;G06N3/0475;;H04L51/02,,0,0,,,,PENDING
355,US,A1,US 2025/0005901 A1,070-590-917-838-545,1/2/2025,2025,US 202318478265 A,9/29/2023,US 202318478265 A;;US 202363511339 P,6/30/2023,System And Method For Extracting Object Information From Digital Images To Evaluate For Realism,"Described herein are systems, methods, devices, and other techniques for comprehensive and automated evaluation of digital images generated from artificial intelligence (AI) models in order to promote accurate representations of real-world content. Prompts are received at the system that are then passed to both a search engine and a generative AI model. Synthesized digital images are obtained from the generative AI model. The top-matching image from the search engine is used as a verification of the ground truth of the synthesized digital images. A realism score is generated for each synthesized digital image that characterizes the accuracy of the synthesized digital image with reference to the verification image. The realism score can be used to assist and expedite the image selection process, as well as serve as input to fine-tune the performance of generative models.",ACCENTURE GLOBAL SOLUTIONS LTD,CHA SUJEONG;;VADLAMANI SURYA RAGHAVENDRA;;KANG SUKRYOOL;;TRIPATHI ANUPAM ANURAG;;SUHAIL MOHAMED;;SMITH JR PETER ROYER;;ZHANG BO;;GARRISON DANIEL;;SINGH JATINDER;;DANG NEHA WADHWA,ACCENTURE GLOBAL SOLUTIONS LIMITED (2024-04-01),https://lens.org/070-590-917-838-545,Patent Application,yes,0,0,2,070-590-917-838-545;;003-101-673-632-718,US;;EP,2,070-590-917-838-545;;003-101-673-632-718,US;;EP,0,G06V20/70;;G06V10/26;;G06V10/82;;G06V10/435;;G06V10/74;;G06T7/50;;G06V20/70;;G06V10/761;;G06V10/764;;G06V2201/07;;G06T5/20,G06V10/764;;G06T5/20;;G06T7/50;;G06V10/74;;G06V20/70,,0,0,,,,PENDING
356,US,A1,US 2024/0394481 A1,112-934-151-404-775,11/28/2024,2024,US 202418670369 A,5/21/2024,US 202418670369 A;;US 202363468129 P;;US 202363537272 P,5/22/2023,Prompt Generation,"A system and computer implemented method for generating validated prompt-templates for generating prompts for instructing large language models (LLMs) to perform specific tasks. An initial prompt is generated instructing an LLM to produce a plurality of candidate prompt-templates. The initial prompt includes an input data type to be included with a prompt generated using a candidate prompt-template, and output data to be produced by an LLM that has processed a prompt generated using a candidate prompt-template. The initial prompt is passed through an LLM to generate candidate prompt-templates. Test prompts are generated, each constructed from a candidate prompt-templates using input data from a set of pre-labelled input data having items of input data and corresponding labels. Each test prompt is passed through a further LLM to generate an output. The output is assessed, and candidate-prompt-templates are selected for subsequent generation of prompts.",SAGE GLOBAL SERVICES LTD,EDWARDS JEREMIAH;;KUMAR ROHIT;;RAJAMOHAN SRIJITH;;TSAI YU-CHENG,,https://lens.org/112-934-151-404-775,Patent Application,yes,0,0,5,039-583-683-185-529;;067-158-428-786-237;;099-748-588-076-85X;;112-934-151-404-775;;043-285-414-007-109,US,5,039-583-683-185-529;;067-158-428-786-237;;112-934-151-404-775;;099-748-588-076-85X;;043-285-414-007-109,US,0,G06F40/30;;G06F40/186;;G06Q10/107;;G06F40/35;;G06N3/0455;;G06F16/3344;;H04L51/02;;G06F16/3329;;G06N20/00;;G06F40/186;;G06F40/35;;G06N3/0455;;G06Q10/107;;G06N20/00;;G06F16/3329;;G06F16/3344;;H04L51/02;;G06F40/30,G06F40/35;;G06F40/186,,0,0,,,,PENDING
357,CN,A,CN 117807961 A,126-629-503-814-311,4/2/2024,2024,CN 202410236982 A,3/1/2024,CN 202410236982 A,3/1/2024,"Text generation model training method and device, medium and electronic equipment","The invention discloses a text generation model training method and device, a medium and electronic equipment, and the method comprises the steps: determining a collected official document, and for each title included in the official document, determining a superior title of the title in the official document; according to the method, the prompt text of the title is determined according to the superior title, so that the text generation model can be influenced by the superior title of the title when generating the content under the title. And then, inputting the prompt text and the title into a pre-trained initial text generation model, and determining an output text. And determining a text corresponding to the title in the official document, and taking the text as a target text. According to the target text and the output text, the initial text generation model is trained to obtain the text generation model, and the accuracy of the text generated by the text generation model is improved.",ZHEJIANG LAB,CAI JINGJING;;DONG BO;;BAI JIEMING;;GE JUN;;KONG XIANGFU;;ZHOU HONGHAO,,https://lens.org/126-629-503-814-311,Patent Application,no,16,0,2,021-698-753-458-841;;126-629-503-814-311,CN,2,021-698-753-458-841;;126-629-503-814-311,CN,0,G06F40/166;;G06N20/00;;Y02D10/00,G06F40/166;;G06N20/00,,5,0,,,"CLAVIE B 等: ""Large Language Models in the Workplace: A Case Study on Prompt Engineering for Job Type Classification"", 《NATURAL LANGUAGE PROCESSING AND INFORMATION SYSTEMS: 28TH INTERNATIONAL CONFERENCE ON APPLICATIONS OF NATURAL LANGUAGE TO INFORMATION SYSTEMS》, 14 September 2023 (2023-09-14);;车蕾 等: ""面向文本结构的混合分层注意力网络的话题归类"", 《中文信息学报》, no. 05, 15 May 2019 (2019-05-15);;周云成 等: ""基于NB和CHI值的农业文本分类方法"", 《江苏农业科学》, no. 17, 25 September 2018 (2018-09-25);;王亮;: ""深度学习视角下基于多模态知识图谱的MOOC课程重构"", 《现代教育技术》, no. 10, 15 October 2018 (2018-10-15);;岳一峰 等: ""一种基于BERT的自动文本摘要模型构建方法"", 《计算机与现代化》, no. 01, 15 January 2020 (2020-01-15)",ACTIVE
358,US,A1,US 2025/0045304 A1,023-145-541-081-459,2/6/2025,2025,US 202418920579 A,10/18/2024,US 202418920579 A;;US 202418745678 A;;US 202217769700 A;;US 2019/0000053 W,10/15/2019,METHOD AND SYSTEM FOR INTERPRETING INPUTTED INFORMATION,"Methods and systems for interpreting inputted information are described herein. In some embodiments, a method comprises processing inputted information wherein processing inputted information uses one or more intelligence modules using one or more intelligence models to process the inputted information; making, by the one or more intelligence modules, one or more decisions about inputted information based on the one or more intelligence models; learning, by the one or more intelligence modules, to update the one or more intelligence models; and interpreting inputted information based on the one or more decisions.",QUATRO CONSULTING LLC,QUATRO FRANK,QUATRO CONSULTING LLC (2024-10-18),https://lens.org/023-145-541-081-459,Patent Application,yes,0,4,1,023-145-541-081-459,US,7,023-145-541-081-459;;141-305-350-664-254;;137-911-990-010-692;;186-288-109-143-023;;069-931-012-087-254;;034-405-461-724-423;;050-765-677-278-804,US;;WO;;CA,0,G06F16/288;;G06F16/254;;G06F16/2282;;G06N20/00;;G06F16/2282;;G06N20/00;;G06F16/288;;G06F16/254,G06F16/28;;G06F16/22;;G06F16/25;;G06N20/00,,0,0,,,,PENDING
359,US,B1,US 12045735 B1,055-185-359-749-43X,7/23/2024,2024,US 202318203537 A,5/30/2023,US 202318203537 A;;US 202363444162 P,2/8/2023,Interactive template for multimodal content generation,"Methods, systems, and computer programs are presented for generating multimodal content utilizing multimodal templates. One method includes presenting, in a user interface (UI), a template-selection option with one or more templates. Each template comprises a sequence of operations, where each operation comprises a prompt for creating items using generative artificial intelligence (GAI) tools. Further, each operation in the template is multimodal to be configurable to create text and configurable to create one or more images. The method further includes detecting a selection of a template in the UI. For each operation in the selected template, perform operations comprising: presenting, in the UI, the prompt associated with the operation; in response to receiving an input for the prompt, selecting a GAI tool based on a mode of the operation; providing the input to the selected GAI tool to generate the item; and presenting, in the UI, the generated item.",TYPEFACE INC,PARASNIS ABHAY;;CHEN KANG;;SRINIVASAN HARI;;MOREIRA JONATHAN;;SOOD VISHAL;;NING YUE,TYPEFACE INC (2023-08-18),https://lens.org/055-185-359-749-43X,Granted Patent,yes,39,1,5,144-304-260-041-154;;055-185-359-749-43X;;037-305-382-999-104;;041-858-994-965-698;;040-754-353-577-107,US,13,101-024-712-936-789;;055-185-359-749-43X;;140-719-340-018-551;;041-858-994-965-698;;038-024-101-354-760;;144-304-260-041-154;;170-700-138-228-895;;143-143-756-117-625;;040-754-353-577-107;;187-642-363-420-941;;147-907-512-157-164;;037-305-382-999-104;;124-442-286-055-183,US;;WO,0,G06T11/00;;G06F3/04845;;G06F40/56;;G06F40/44;;G06F40/216;;G06F40/30;;G06F40/186;;G06F3/0482;;G06F3/04812;;G06T2200/24;;G06T11/00;;G06F40/103;;G06T7/194;;G06T7/11;;G06V20/62;;G06T5/77;;G06T5/50;;G06T2207/20084;;G06F40/186;;G06N3/0475;;G06F3/0484;;G06N5/022,G06N5/022,,21,4,065-722-503-064-579;;034-056-398-351-376;;080-570-109-612-964;;095-053-794-199-504,10.1145/1821748.1821869;;10.18653/v1/n19-1164;;10.1613/jair.5477;;10.1145/3491102.3501825,"Anyword, Facebook Past Generator website, archived screenshot from Nov. 26, 2022, available at: https://web.archive.org/web/20221126225805/https://anyword.com/facebook-post-generator/. Accessed Jul. 28, 2023. 6 pages. (Year: 2022).;;Lee YS, Cho SB. Automatic weblog generation using mobile context. In Proceedings of the 7th International Conference on Advances in Mobile Computing and Multimedia Dec. 1, 20094 (pp. 622-626). (Year: 2009).;;Anyword, Instagram Caption Generator website, archived screenshot from Dec. 4, 2022, available at: https://web.archive.org/web/20221204212425/https://anyword.com/instagram-caption-generator/. Accessed Jul. 28, 2023. 8 pages. (Year: 2022).;;Wang Y, Li J, King I, Lyu MR, Shi S. Microblog hashtag generation via encoding conversation contexts. arXiv preprint arXiv: 1905.07584. May 1, 20198. (Year: 2019).;;Dutta, Debashri, How to Write a Blog Post Outline, https://web.archive.org/web/20221206180953/https://dmdutta.com/how-to-write-a-blog-post-outline/, posted Oct. 3, 2022, accessed Jul. 28, 2023. 13 pages. (Year: 2022).;;Vincent, James (May 24, 2022). “All these images were generated by Google's latest text-to-image AI”. The Verge. Vox Media. Retrieved Jul. 28, 2023. 7 pages. (Year: 2022).;;Gatt A, Krahmer E. Survey of the state of the art in natural language generation: Core tasks, applications and evaluation. Journal of Artificial Intelligence Research. Jan. 2, 20187;61:65-170. (Year: 2018).;;Vasquez S, Lewis M. Melnet: a generative model for audio in the frequency domain. arXiv preprint arXiv:1906.01083. Jun. 4, 2019. ( Year: 2019).;;Oppenlaender, Jonas. “Prompt engineering for text-based generative art.” arXiv preprint arXiv:2204.13988 (2022). (Year: 2022).;;Liu, Vivian, and Lydia B. Chilton. “Design guidelines for prompt engineering text-to-image generative models.” In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems, pp. 1-23. 2022. (Year: 2022).;;Oppenlaender, Jonas. “A taxonomy of prompt modifiers for text-to-image generation.” arXiv preprint arXiv:2204.13988v2. Jul. 31, 2022. (Year: 2022).;;U.S. Appl. No. 18/203,524, Corrected Notice of Allowability mailed Sep. 7, 2023, 5 pgs.;;U.S. Appl. No. 18/203,524, Corrected Notice of Allowability mailed Sep. 20, 2023.;;U.S. Appl. No. 18/203,524, Corrected Notice of Allowability mailed Oct. 5, 2023.;;U.S. Appl. No. 18/203,524, Notice of Allowance mailed Aug. 9, 2023.;;U.S. Appl. No. 18/203,530, Non Final Office Action mailed Aug. 31, 2023.;;U.S. Appl. No. 18/203,534, Non Final Office Action mailed Aug. 23, 2023.;;U.S. Appl. No. 18/203,530, Notice of Allowance mailed Jan. 12, 2024, 9 pgs.;;U.S. Appl. No. 18/203,530, Response filed Nov. 21, 2023 to Non Final Office Action mailed Aug. 31, 2023, 13 pgs.;;U.S. Appl. No. 18/203,534, Notice of Allowance mailed Nov. 30, 2023, 9 pgs.;;U.S. Appl. No. 18/203,534, Response filed Nov. 21, 2023 to Non Final Office Action mailed Aug. 23, 2023, 13 pgs.",ACTIVE
360,US,A1,US 2025/0078325 A1,028-559-360-167-036,3/6/2025,2025,US 202318240282 A,8/30/2023,US 202318240282 A,8/30/2023,GOAL-BASED SUB ACCOUNTS WITH DYNAMIC IMAGES,"An example operation may include one or more of storing user data in a storage device, receiving inputs via prompts displayed on a user interface of a software application, identifying a plurality of goals within the received inputs and generating a plurality of data structures corresponding to the plurality of goals, respectively, executing a generative artificial intelligence (GenAI) model on the plurality of goals and the stored user data to generate a plurality of custom images of the plurality of goals, and displaying a plurality of identifiers of the plurality of data structures corresponding to the plurality of goals on a user interface, and simultaneously display the plurality of custom images next to the plurality goals, respectively.",TORONTO DOMINION BANK,GORMLEY BREENA PATRICIA,,https://lens.org/028-559-360-167-036,Patent Application,yes,2,0,1,028-559-360-167-036,US,1,028-559-360-167-036,US,0,G06T2200/24;;G06N3/0475;;G06T11/00;;G06T11/00;;G06T2200/24;;G06N3/0475,G06T11/00;;G06N3/0475,,0,0,,,,PENDING
361,WO,A1,WO 2025/075756 A1,149-282-254-924-855,4/10/2025,2025,US 2024/0046325 W,9/12/2024,US 202418830758 A;;US 202363587735 P,10/4/2023,LARGE LANGUAGE MODELS FOR PREDICTIVE MODELING AND INVERSE DESIGN,"An inverse design system combines a large language model (LLM) with a task-specific optimizer, which includes a search function, a forward model, and a comparator. The LLM adjusts parameters of the optimizer's components in response to a design scenario. Then the optimizer processes the design scenario to produce design candidates. Optionally, the LLM learns from the design candidates in an iterative process. A stochastic predictive modeling system combines an LLM with input distributions and a forward model. The LLM adjusts one or more of the input distributions and/or the forward model in response to a forecast scenario. Then the forward model processes a sampling of the input distributions to produce a forward distribution. Optionally, the LLM informs the sampling process. Optionally, the LLM learns from the forward distribution.",X DEV LLC,LING JULIA;;MARTINEZ ALBERTO;;ANDRE DAVID;;HAHN CHRISTOPHER,,https://lens.org/149-282-254-924-855,Patent Application,yes,1,0,1,149-282-254-924-855,WO,2,020-017-526-948-733;;149-282-254-924-855,US;;WO,0,G06F40/30;;G06N20/00;;G06F30/27;;G06Q10/04;;G06F30/20,G06F30/27;;G06F40/30;;G06N20/00;;G06Q10/04,,3,1,129-870-405-422-242,10.1101/2023.07.06.547759,"CARL EDWARDS ET AL: ""SynerGPT: In-Context Learning for Personalized Drug Synergy Prediction and Drug Design"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 19 June 2023 (2023-06-19), XP091569470;;""Transformer Architecture for Policy Translation"", no. V0.0.8, 13 September 2023 (2023-09-13), pages 1 - 229, XP014471881, Retrieved from the Internet <URL:ftp://docbox.etsi.org/ISG/ENI/70-Draft/0030v311/ENI-0030v411_Trans_Archv008.zip GS ENI 3.0.5v4.0.1-revmark.docx> [retrieved on 20230913];;CHEN LING ET AL: ""Large Language Models, Natural Language Processing, Domain Specialization"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 10 July 2023 (2023-07-10), XP091562647",PENDING
362,US,A1,US 2025/0078324 A1,090-161-773-902-076,3/6/2025,2025,US 202318240275 A,8/30/2023,US 202318240275 A,8/30/2023,DYNAMIC GENERATION OF GOALS AND IMAGES,"An example operation may include one or more of establishing a network connection between a computing system and one or more external sources over a computer network, receiving a request from a user via a software application on a user device, collecting data about the user from the one or more external sources via the established network connection, executing a machine learning model on the collected data about the user to determine a goal of the user, and displaying an image of the goal via a user interface of the software application.",TORONTO DOMINION BANK,GORMLEY BREENA PATRICIA,,https://lens.org/090-161-773-902-076,Patent Application,yes,4,0,1,090-161-773-902-076,US,1,090-161-773-902-076,US,0,G06T2200/24;;G06N3/08;;G06T11/00;;G06N3/0475;;G06N20/00;;G06T11/00;;G06T2200/24;;G06N3/08;;G06N3/0475,G06T11/00;;G06N3/0475;;G06N3/08,,0,0,,,,PENDING
363,US,A1,US 2025/0078345 A1,133-446-514-032-894,3/6/2025,2025,US 202318240285 A,8/30/2023,US 202318240285 A,8/30/2023,GENERATING ADDITIONAL IMAGES FROM PREVIOUSLY GENERATED IMAGES,"An example operation may include one or more of training a generative artificial intelligence (GenAI) model to generate images based on user data using a dataset of images, executing the GenAI model based on input data from a user interface of a software application to generate an image corresponding to the input data, and displaying the image via a user interface of a software application, receiving feedback about the image via the user interface; andretraining the GenAI model based on the generated image and the received feedback about the image via the user interface.",TORONTO DOMINION BANK,GORMLEY BREENA PATRICIA,,https://lens.org/133-446-514-032-894,Patent Application,yes,3,0,1,133-446-514-032-894,US,1,133-446-514-032-894,US,0,G06T2210/28;;G06T2200/24;;G06T2211/441;;G06F40/174;;G06T11/60;;G06T11/60;;G06F40/174;;G06T2211/441;;G06T2210/28;;G06T2200/24,G06T11/60;;G06F40/174,,0,0,,,,PENDING
364,US,A1,US 2025/0078344 A1,183-654-065-966-148,3/6/2025,2025,US 202318240277 A,8/30/2023,US 202318240277 A,8/30/2023,IMAGE MODIFICATION BASED ON GOAL PROGRESSION,"An example operation may include one or more of establishing a network connection between the computing system and a data source, iteratively performing a sequence of steps comprising collecting user data from the data source, executing a generative artificial intelligence (GenAI) model on the collected user data to generate a different image segment, and filling in a different subset of pixels of an image with the generated image segment and display the partially-filled in image on a user interface.",TORONTO DOMINION BANK,GORMLEY BREENA PATRICIA,,https://lens.org/183-654-065-966-148,Patent Application,yes,7,0,1,183-654-065-966-148,US,1,183-654-065-966-148,US,0,G06T2200/24;;G06T11/60;;G06N3/0475;;G06T11/60;;G06T2200/24;;G06N3/0475,G06T11/60;;G06N3/0475,,0,0,,,,PENDING
365,US,A1,US 2025/0004557 A1,021-406-849-850-824,1/2/2025,2025,US 202418754077 A,6/25/2024,US 202418754077 A;;US 202363510423 P,6/27/2023,ADAPTIVE PROMPT CUSTOMIZATION USING BRAINWAVE ACTIVITY DATA,"A system for generating highly personalized image content with generative artificial intelligence (AI) that incorporates brainwave data collected from a Brain-Computer Interface (BCI) device worn by the user while they are immersed in their experiences. The system can identify a mood (i.e., cognitive, mental, and emotional states) felt by the user during that time. The system develops a prompt that describes the target scene and modulates the weights assigned to each parameter in the prompt based on the mood identified. The generative AI engine can then to apply the mood to the target scene by adjusting image attributes such as hue, saturation, and lighting. The outputted image can offer a visual representation not only of the objects that were in the user's environment, but also the user's general perception and experience of the occasion. The process is passive and requires no interaction from the user to define their emotional affect.",ACCENTURE GLOBAL SOLUTIONS LTD,RAMIREZ-ARISTIZABAL ADOLFO;;PABST ALEXANDRIA EMILY;;ACKERMAN JORDAN ALEXANDER,ACCENTURE GLOBAL SOLUTIONS LIMITED (2024-06-24),https://lens.org/021-406-849-850-824,Patent Application,yes,0,0,2,021-406-849-850-824;;118-241-741-951-863,US;;EP,2,021-406-849-850-824;;118-241-741-951-863,US;;EP,0,G06V40/15;;G06F3/015;;G06T11/00,G06F3/01;;G06T11/00,,0,0,,,,PENDING
366,WO,A1,WO 2025/080599 A1,173-703-443-920-733,4/17/2025,2025,US 2024/0050403 W,10/9/2024,US 202363588835 P,10/9/2023,COMPUTER-IMPLEMENTED METHODS AND SYSTEMS FOR DYNAMIC PROMPT GENERATION AND INTEGRATION WITH LARGE LANGUAGE MODELS FOR DOCUMENT REVISION,"Computer-implemented methods and systems interface with a language model (e.g., a Large Language Model (LLM)) to assist in document revision. The methods and systems allow text to be selected within a document and an action definition to be selected from an action definition library. The text and/or the action definition may be selected using a graphical user interface (GUI). An action defined by the selected action definition is applied to the selected text to generate text. For example, the selected action definition may include a prompt, and the prompt may be combined with the selected text to generate a combined prompt. The combined prompt may be provided as an input to the LLM, which may generate the generated text. The generated text may be integrated into the document.",QUABBIN PATENT HOLDINGS,PLOTKIN ROBERT,,https://lens.org/173-703-443-920-733,Patent Application,yes,5,0,1,173-703-443-920-733,WO,2,068-461-810-399-252;;173-703-443-920-733,US;;WO,0,G06F40/166;;G06F3/04842;;G06F40/131;;G06N3/0475,G06F40/166;;G06F3/04842;;G06F16/332;;G06F16/338;;G06F16/34;;G06F40/131;;G06N3/0475,,0,0,,,,PENDING
367,WO,A1,WO 2025/058613 A1,070-325-129-210-207,3/20/2025,2025,US 2023/0032384 W,9/11/2023,US 2023/0032384 W,9/11/2023,PROMPT ELEMENT GENERATION FOR USE AS INPUT IN GENERATIVE MODELS IN A WEB SEARCH ENVIRONMENT,"Example embodiments of the present disclosure provide for an example method for validation of output of machine-learned models used in conversational web search systems. The method includes transmitting a search query for retrieving search results including content items. The method can include receiving the search results which can include a first content item associated with a generative machine-learned model with an associated confidence score satisfying a selection criteria. Responsive to receiving the search results the method can include generating a shortcut that, when selected, initiates a conversation interface associated with the first content item. The method can provide the first content item and shortcut. The method can include obtaining input data comprising the selection of the shortcut. Responsive to obtaining the input data, the method includes, initiating a conversation interface associated with the content item and facilitating, using the generative machine-learned model, data transfer associated with the conversation interface.",GOOGLE LLC,SHRIVASTAVA ABHISHEK;;MARFATIA HINALI NAIMISH;;DABBIRU LAKSHMI KUMAR,,https://lens.org/070-325-129-210-207,Patent Application,yes,1,0,2,081-269-218-650-437;;070-325-129-210-207,WO;;EP,2,081-269-218-650-437;;070-325-129-210-207,WO;;EP,0,G06F16/9532;;G06F16/90332,G06F16/9032;;G06F16/9532,,0,0,,,,PENDING
368,WO,A1,WO 2024/228969 A1,070-246-986-434-496,11/7/2024,2024,US 2024/0026931 W,4/30/2024,US 202363463277 P;;US 202318286575 A,5/1/2023,AUTOMATED AUTHORING OF SOFTWARE SOLUTIONS FROM AN AI-ENHANCED MODEL,"A method or system uses Al-based enhancement to improve an initial model, such as an abstract model of a database, before the abstract model is submitted to an automated code author. The Al, which may be a generative Al, can assist with identifying parts of the abstract model (such as UML artifacts) and suggest revisions, according to a series of interactions between a developer and Al. The result of this interaction with the Al is then used to revise or augment the abstract model. Ultimately, the Al-enhanced model is consumed by a code author to generate application source code.",27 SOFTWARE U S INC DBA DXTERITY SOLUTIONS,CHARTRAND CHRISTOPHER ZEE,,https://lens.org/070-246-986-434-496,Patent Application,yes,3,2,1,070-246-986-434-496,WO,10,068-015-671-184-007;;065-857-386-449-274;;125-793-831-517-322;;116-193-995-780-826;;056-846-118-030-186;;139-537-258-686-793;;040-028-466-557-86X;;071-680-880-283-931;;038-694-757-641-706;;070-246-986-434-496,US;;WO;;EP;;CA,0,G06F8/35;;G06F8/71;;G06N20/00,G06F8/35;;G06F8/71;;G06F8/73;;G06F8/75;;G06F9/54,,0,0,,,,PENDING
369,US,A1,US 2024/0378029 A1,071-680-880-283-931,11/14/2024,2024,US 202418650155 A,4/30/2024,US 202418650155 A;;US 202318286575 A;;US 2022/0024937 W;;US 202117232444 A;;US 202117232487 A;;US 202117232520 A;;US 202363463277 P,4/16/2021,AUTOMATED AUTHORING OF SOFTWARE SOLUTIONS FROM AN AI-ENHANCED MODEL,"A method or system uses AI-based enhancement to improve an initial model, such as an abstract model of a database, before the abstract model is submitted to an automated code author. The AI, which may be a generative AI, can assist with identifying parts of the abstract model (such as UML artifacts) and suggest revisions, according to a series of interactions between a developer and AI. The result of this interaction with the AI is then used to revise or augment the abstract model. Ultimately, the AI-enhanced model is consumed by a code author to generate application source code.",27 SOFTWARE U S INC DBA DXTERITY SOLUTIONS,CHARTRAND CHRISTOPHER ZEE,27 SOFTWARE U.S. INC. DBA DXTERITY SOLUTIONS (2025-07-09);;BYGGR INC (2024-10-20),https://lens.org/071-680-880-283-931,Patent Application,yes,0,0,1,071-680-880-283-931,US,10,068-015-671-184-007;;065-857-386-449-274;;125-793-831-517-322;;116-193-995-780-826;;056-846-118-030-186;;139-537-258-686-793;;040-028-466-557-86X;;071-680-880-283-931;;038-694-757-641-706;;070-246-986-434-496,US;;WO;;EP;;CA,0,G06F8/36;;G06F8/35;;G06F8/77;;G06F8/30;;G06F8/35;;G06F8/77;;G06F8/36,G06F8/35;;G06F8/36;;G06F8/77,,0,0,,,,PENDING
370,US,A1,US 2025/0245438 A1,005-360-629-950-339,7/31/2025,2025,US 18597931,3/7/2024,TW 113103588,1/30/2024,FUNCTION MAP GENERATION METHOD AND SYSTEM,"A function map generation method and system are provided. The system executes the following steps using an artificial intelligence model. A difficulty point and first data related to the difficulty point are obtained from a first reply content of a first query corresponding to the difficulty point. A usage target and second data related to the usage target are obtained from a second reply content of a second query corresponding to the usage target. An implementation function and a target type are obtained based on the difficulty point and the usage target. A required function is obtained based on the target type. Semantic comparison between the implementation function and the required function is performed to obtain a difference set content. A function map is generated based on the target type, the implementation function, and the difference set content.",Wistron Corporation,Ping Chen Tsai;;Yin Min Lin;;Yi-Tsung Cheng,,https://lens.org/005-360-629-950-339,Patent Application,yes,0,0,1,005-360-629-950-339,US,1,005-360-629-950-339,US,0,G06F40/30,G06F40/30,,0,0,,,,UNKNOWN
371,WO,A1,WO 2024/199653 A1,085-092-682-944-417,10/3/2024,2024,EP 2023058203 W,3/29/2023,EP 2023058203 W,3/29/2023,AI-POWERED COACH,"Problem: A conventional virtual coach, which is based on predefined rules and logic, proves unfit to adapt to the individual needs and preferences of coachees. Different coachees tend to have different goals, challenges, learning styles, personalities, and feedback preferences. Hence, a rule-based virtual coach is unable to tailor its coaching approach and content to suit each user's unique situation and expectations, which may result in frustration or boredom. Ensuring data protection compliance is a significant challenge in coaching and some coachees may be hesitant to share certain information with another person. Solution: Method of coaching a user using natural language, characterized in that a client, served by a backend, receives audio input from the user, the backend processes the audio input, generates a response appropriate to the input by means of a generative, preferably autoregressive NLP model, and synthesizes an audio stream expressing the response in the natural language, and the client plays the audio stream back to the user.",COACHHUB GMBH,CABRERA PEDRO,,https://lens.org/085-092-682-944-417,Patent Application,yes,1,0,1,085-092-682-944-417,WO,1,085-092-682-944-417,WO,0,G06F40/35;;G10L13/00;;G10L15/00;;G06Q50/20,G06F40/35;;G06Q50/20;;G10L13/00;;G10L15/00;;G10L25/00,,3,1,130-272-649-645-78X,10.1007/s11613-022-00801-3,"VENTURA ROBERT GARCIA: ""How to create the smartest multilingual Virtual Assistant using AWS and ChatGPT"", 5 January 2023 (2023-01-05), XP093088936, Retrieved from the Internet <URL:https://web.archive.org/web/20230105231741/https://dev.to/aws-builders/how-to-create-the-smartest-multilingual-virtual-assistant-using-aws-and-chatgpt-4i5k> [retrieved on 20231005];;MONISH MOHD: ""ChatGPT and AWS: The Winning Combination for Conversational AI"", 9 March 2023 (2023-03-09), XP093089164, Retrieved from the Internet <URL:https://www.cloudthat.com/resources/blog/chatgpt-and-aws-the-winning-combination-for-conversational-ai> [retrieved on 20231005];;MAI, VANESSA ET AL.: ""Potenziale und Einsatzmoglichkeiten von digitalen Coaching-Begleitern und Assistenten"", ORGANISATIONSBERATUNG, SUPERVISION, COACHING., vol. 30, no. 1, 18 January 2023 (2023-01-18), pages 45 - 57",PENDING
372,WO,A1,WO 2024/249202 A1,180-624-992-554-084,12/5/2024,2024,US 2024/0030515 W,5/22/2024,US 202363469087 P,5/26/2023,ALERT-INFORMATION SYSTEM HAVING DYNAMIC EVENT-SPECIFIC INTERACTIVE ALERT-INFORMATION,"Dynamic alert-information system (DAIS) for en-masse warning systems, such as public warning systems, that alert people to the occurrent of an alert event. In some embodiments, a DAIS includes one or more instances of an event-specific dynamic user interface (UI) that an alerted user can access using a dynamic event-alert link sent to a device, such as a mobile device, of the alerted user. The event-specific dynamic UI is unique and customized to the alert event. The dynamic event-alert link may be sent to people in an alert message in a broadcast manner and/or a direct-message manner. In some embodiments, the dynamic event-alert link includes a message identification (ID) used to create the customized event-specific dynamic UI. Related methods, software, and systems are also disclosed.",EVERBRIDGE INC,BOT MENNO;;VAN DER KOLFF SOLANGE;;GIANFRANCHI RACHELE;;VOGEL KOEN,,https://lens.org/180-624-992-554-084,Patent Application,yes,3,0,1,180-624-992-554-084,WO,1,180-624-992-554-084,WO,0,H04W4/90;;G08B21/10;;H04L67/289;;H04W4/50;;H04L67/02;;H04L67/55,H04W4/90,,0,0,,,,PENDING
373,US,A1,US 2024/0386253 A1,145-350-306-416-390,11/21/2024,2024,US 202318358410 A,7/25/2023,US 202318358410 A;;US 202363502702 P,5/17/2023,METHOD TO DETECT AND FIX HALLUCINATIONS IN GENERATIVE LARGE LANGUAGE MODELS,"A system and method to detect a generative model's output to see if it is hallucinating or not, and to check the facts listed in the model. Additionally, when a hallucination or incorrect fact is detected, the correct fact can be applied as context to ask the model to regenerate the output again, taking the fact into consideration while also optionally lowering the temperature or increasing the top-k values from which to choose. A method is provided comprising: obtaining output produced by the generative model based on input provided to the generative model; performing summarization and topic extraction on the output to obtain one or more topics; performing fact checking on each of the one or more topics to produce a consolidated ground truth context; and declaring that the generative model is hallucinating or not based on the consolidated ground truth context.",CISCO TECH INC,WHITE JR DAVID C;;HAMZEH MOHAMMED IZZAT,CISCO TECHNOLOGY INC (2023-07-25),https://lens.org/145-350-306-416-390,Patent Application,yes,0,3,1,145-350-306-416-390,US,1,145-350-306-416-390,US,0,G06N3/0475;;G06F40/30;;G06F40/166;;G06F40/289;;G06F40/40;;G06N3/045;;G06F40/30;;G06F40/166;;G06F40/289;;G06N3/0475;;G06F40/40,G06N3/0475;;G06F40/166;;G06F40/289;;G06F40/30;;G06F40/40,,0,0,,,,PENDING
374,WO,A1,WO 2025/096209 A1,182-196-071-734-94X,5/8/2025,2025,US 2024/0051677 W,10/17/2024,US 202363596212 P;;US 202418592468 A,11/3/2023,INTERPRETING LARGE LANGUAGE MODELS,"Example solutions for processing LLM prompts include creating a first large language model (LLM) prompt based on an input LLM prompt. The first LLM prompt represents a first step toward generating a solution to the input LLM prompt. The first LLM prompt is submitted to an LLM as a first sub-query, thereby resulting in the generation of a first LLM output. A second LLM prompt is generated based on the input LLM prompt. The second LLM prompt represents a second step toward generating the solution. The second LLM prompt includes the first LLM output. The second LLM prompt is submitted to the LLM as a second sub-query, thereby resulting in the generation of a second LLM output. The second LLM output represents the solution to the input LLM prompt in response to the input LLM prompt.",MICROSOFT TECHNOLOGY LICENSING LLC,NORI ADITYA VITHAL;;GONZÁLEZ HERNÁNDEZ JAVIER,,https://lens.org/182-196-071-734-94X,Patent Application,yes,0,0,1,182-196-071-734-94X,WO,2,036-008-934-704-240;;182-196-071-734-94X,US;;WO,0,G06F16/3329;;G06F40/56;;G06N3/00;;G06F40/35;;G06N20/00,G06F40/35;;G06F16/3329;;G06F40/56;;G06N3/00,,4,2,017-686-033-163-655;;121-693-789-145-508,10.18653/v1/2023.findings-emnlp.114;;10.18653/v1/2022.emnlp-main.81,"WEI JASON ET AL: ""Chain-of-Thought Prompting Elicits Reasoning in Large Language Models"", 1 January 2023 (2023-01-01), XP093239310, Retrieved from the Internet <URL:https://arxiv.org/pdf/2201.11903>;;KHOT TUSHAR ET AL: ""Decomposed Prompting : A MODULAR APPROACH FOR SOLVING COMPLEX TASKS"", 11 April 2023 (2023-04-11), XP093239740, Retrieved from the Internet <URL:https://arxiv.org/pdf/2210.02406>;;DUA DHEERU ET AL: ""Successive Prompting for Decomposing Complex Questions"", PROCEEDINGS OF THE 2022 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, 8 December 2022 (2022-12-08), pages 1251 - 1265, XP093239761, Retrieved from the Internet <URL:https://arxiv.org/pdf/2212.04092> DOI: 10.18653/v1/2022.emnlp-main.81;;GONZÁLEZ JAVIER ET AL: ""Beyond Words: A Mathematical Framework for Interpreting Large Language Models"", 6 November 2023 (2023-11-06), XP093239300, Retrieved from the Internet <URL:https://arxiv.org/pdf/2311.03033>",PENDING
375,US,A1,US 2025/0156303 A1,189-266-833-906-142,5/15/2025,2025,US 202519022083 A,1/15/2025,US 202519022083 A;;US 2023/0085667 W;;US 202363548187 P;;US 202363543095 P;;US 202363540345 P;;US 202363538842 P;;US 202363439854 P;;US 202263436528 P;;US 202263435315 P,12/26/2022,Integrated AI-Driven System for Automating IT and Cybersecurity Operations,"A system for automating information technology software actions using advanced AI techniques including a processing system, storage medium, a communications interface, a user interface, a natural language processing model or neural network, operable to interface with at least one of an embedded prompt or chatbot prompt and hosted on a control node which communicates with one or more nodes comprised by a node network via the communications interface, and program instructions on storage medium that direct the processing system to receive an instruction from the user interface, process the instruction using the one or more natural language processing model or neural network, along with one or more AI agents, and execute the instruction one of locally or on a node of the node network via the communications interface.",STEVENS ALBERT,STEVENS ALBERT,AUGSTRA LLC (2025-07-16),https://lens.org/189-266-833-906-142,Patent Application,yes,7,1,1,189-266-833-906-142,US,2,066-898-808-745-899;;189-266-833-906-142,US;;WO,0,G06F11/3612;;G06F11/3612,G06F11/3604,,0,0,,,,PENDING
376,WO,A1,WO 2025/101576 A1,027-105-793-208-590,5/15/2025,2025,US 2024/0054681 W,11/6/2024,US 202363547483 P;;US 202463638177 P,11/6/2023,"SYSTEMS, METHODS AND COMPUTER-ACCESSIBLE MEDIUM FOR ADDRESSING VULNERABLE LARGE LANGUAGE MODELS","Exemplary systems, methods, and computer-accessible medium are provided that can detect misinformation, including medical misinformation, from a large language model (ELM). Thus, the exemplary systems, methods, and computer-accessible medium are provided that receive an output from a ELM. relate that output to a knowledge graph, sometimes through creation of triplets from the LEM output where the triplets comprise an origin, a relation, and a target that can be compared against knowledge triplets from the knowledge graph, and predict that information provided from the ELM contains the misinformation based on the output from the ELM related to the knowledge graph. This prediction may be made at inference time.",UNIV NEW YORK,OERMANN ERIC KARL,,https://lens.org/027-105-793-208-590,Patent Application,yes,0,0,1,027-105-793-208-590,WO,1,027-105-793-208-590,WO,0,G06N5/022;;G06F40/35;;G06F40/284,G06F40/30;;G06N5/022,,0,0,,,,PENDING
377,US,A1,US 2025/0077708 A1,161-061-823-380-17X,3/6/2025,2025,US 202418818151 A,8/28/2024,US 202418818151 A;;US 202363535624 P,8/31/2023,DATA PROCESSING SYSTEM AND METHOD FOR MASKING SENSITIVE DATA,"Method, data processing system, and computer-readable storage media for responding to a user query. Receiving query from user, query pertaining to request for information. Based on query, generate prompts by masking sensitive information in query. Receive responses from foundation models in response to inputting prompts. Based on responses, generate common result set. By validating common result set with sensitive information, generate response. By supplementing response with sensitive information, generate user response. Providing user response in response to query to the user.",ACCENTURE GLOBAL SOLUTIONS LTD,BOYNTON PAUL;;RAHMANI ARASH JOHN;;AL-SHYOUKH IBRAHIM;;DESAI VIJAY;;SUBRAMANIAN REVATHI;;MORSALI ATEFEH,ACCENTURE GLOBAL SOLUTIONS LIMITED (2024-08-21),https://lens.org/161-061-823-380-17X,Patent Application,yes,0,0,2,107-433-737-891-797;;161-061-823-380-17X,US;;JP,2,107-433-737-891-797;;161-061-823-380-17X,US;;JP,0,G06F2221/2113;;G06F2221/2141;;G06F21/6254;;G06F21/6245;;G06F21/6254;;G06F2221/2141;;G06F2221/2113,G06F21/62,,0,0,,,,PENDING
378,US,A1,US 2025/0148220 A1,036-008-934-704-240,5/8/2025,2025,US 202418592468 A,2/29/2024,US 202418592468 A;;US 202363596212 P,11/3/2023,INTERPRETING LARGE LANGUAGE MODELS,"Example solutions for processing LLM prompts include creating a first large language model (LLM) prompt based on an input LLM prompt. The first LLM prompt represents a first step toward generating a solution to the input LLM prompt. The first LLM prompt is submitted to an LLM as a first sub-query, thereby resulting in the generation of a first LLM output. A second LLM prompt is generated based on the input LLM prompt. The second LLM prompt represents a second step toward generating the solution. The second LLM prompt includes the first LLM output. The second LLM prompt is submitted to the LLM as a second sub-query, thereby resulting in the generation of a second LLM output. The second LLM output represents the solution to the input LLM prompt in response to the input LLM prompt.",MICROSOFT TECHNOLOGY LICENSING LLC,NORI ADITYA VITHAL;;GONZÁLEZ HERNÁNDEZ JAVIER,MICROSOFT TECHNOLOGY LICENSING LLC (2024-03-03),https://lens.org/036-008-934-704-240,Patent Application,yes,0,0,1,036-008-934-704-240,US,2,036-008-934-704-240;;182-196-071-734-94X,US;;WO,0,G06F40/40;;G06F40/40,G06F40/40,,0,0,,,,PENDING
379,US,A1,US 2024/0111498 A1,032-709-767-497-200,4/4/2024,2024,US 202318536299 A,12/12/2023,US 202318536299 A,12/12/2023,"Apparatus, Device, Method and Computer Program for Generating Code using an LLM","Examples relate to an apparatus, device, method and computer program for generating code. The apparatus is to obtain information on an existing application architecture of a modular application, the information on the existing application architecture comprising, for components of the existing architecture, a formal description of the functionality and usage of the component of the existing architecture, obtain a prompt of a user for generating code for implementing an additional component for the modular application, the prompt comprising a textual description of a desired functionality of the additional component, provide the information on the existing application architecture and the prompt as input for a Large Language Model (LLM), obtain an output of the LLM, the output comprising a portion of the code for implementing the additional component, and provide the code for implementing the additional component based on the output of the LLM.",INTEL CORP,VAUGHN ROBERT,INTEL CORPORATION (2023-11-21),https://lens.org/032-709-767-497-200,Patent Application,yes,0,13,1,032-709-767-497-200,US,1,032-709-767-497-200,US,0,G06F8/35;;G06F8/36;;G06F8/30;;G06F8/33;;G06F8/33,G06F8/33,,0,0,,,,PENDING
380,US,A1,US 2025/0245426 A1,000-712-557-998-441,7/31/2025,2025,US 19030549,1/17/2025,,,SYSTEMS AND METHODS FOR RELATION LABELLING PIPELINE,Systems and methods for generating an interface including recommended elements selected using generated element type relation labels are disclosed. An interface generation request including at least one element type is received and a set of recommended elements is generated based on element type relations between the at least one element type and additional element types associated with a network interface. The element type relations are generated by at least one large language model and at least one optimal relation generation prompt. An interface including the set of recommended elements is generated.,"Walmart Apollo, LLC",Jiao Chen;;Luyi Ma;;Xiaohan Li;;Nikhil Shripad Thakurdesai;;Jianpeng Xu;;Hyun Duk Cho;;Kaushiki Nag;;Evren Korpeoglu;;Sushant Kumar;;Kannan Achan,,https://lens.org/000-712-557-998-441,Patent Application,yes,0,0,1,000-712-557-998-441,US,1,000-712-557-998-441,US,0,G06F40/186;;G06F16/383;;G06Q30/0631,G06F40/186;;G06F16/383;;G06Q30/0601,,0,0,,,,UNKNOWN
381,US,A1,US 2025/0200222 A1,085-896-288-525-357,6/19/2025,2025,US 202418981911 A,12/16/2024,US 202418981911 A;;US 202363610586 P,12/15/2023,PERSONALLY IDENTIFIABLE INFORMATION SCRUBBER WITH LANGUAGE MODELS,"Sanitizing data can be a cumbersome task, particularly when the volume of data is large, the content is sensitive, and/or the type of sanitation requires contextual determinations. Sanitizing large amounts of data is tedious and may often require highly trained personnel with clearances and/or other qualifications. In the systems and methods of the present disclosure, language models (LMs) are used to solve these and other technical issues with tools that may allow sanitizing data easily, with high versatility, context awareness, and/or low demand for computational resources. In particular, some of the disclosed systems and methods use a first language model and a second language model (being less resource-intensive than the first language model) to generate sanitized output data with improved efficiency and accuracy. This dual-model approach ensures that sensitive information is handled appropriately while optimizing computer resource usage.",OPENAI OPCO LLC,MONACO JOHN V,OPENAI OPCO LLC (2025-04-29),https://lens.org/085-896-288-525-357,Patent Application,yes,11,0,1,085-896-288-525-357,US,1,085-896-288-525-357,US,0,G06F40/284;;G06F21/6254;;G06F40/284;;G06F21/6254,G06F21/62;;G06F40/284,,0,0,,,,PENDING
382,EP,A1,EP 4571626 A1,171-138-686-697-140,6/18/2025,2025,EP 24219159 A,12/11/2024,US 202318539091 A,12/13/2023,GENERATIVE ARTIFICIAL INTELLIGENCE KNOWLEDGE GRAPH IN AN ITEM LISTING SYSTEM,"Methods, systems, and computer storage media for providing a knowledge graph using a generative AI knowledge graph (KG) engine ""generative AI KG engine"" in an item listing system. The generative AI KG engine supports generating the knowledge graph using a generative AI model (e.g., an LLM). In operation, a seed product is accessed in a product listing system. Using a product knowledge graph, a plurality of candidate products associated with the seed product are identified. The product knowledge graph comprises a plurality of products as nodes and a plurality of relationships as edges. The product knowledge graph is associated with a generative AI model. Using a ranker of the product listing system, a plurality of recommended products are identified. The plurality of recommended products are a subset of the plurality of candidate products. The plurality of recommended products are communicated and caused to be generated on a graphical user interface.",EBAY INC,WANG MENGHAN;;LI MENGYI;;TALLEY JEFFREY WILLIAM;;ZHANG DUANFENG;;LI SISHU;;ZHANG XIANG;;ZHOU DANNY;;JIN JIANIAN;;SARAN SARVESH;;GUO YUCHEN;;ZHOU XUN,,https://lens.org/171-138-686-697-140,Patent Application,yes,1,0,3,072-903-182-668-887;;049-869-672-426-979;;171-138-686-697-140,US;;EP;;CN,3,072-903-182-668-887;;049-869-672-426-979;;171-138-686-697-140,US;;EP;;CN,0,G06Q30/0631;;G06N3/0455;;G06Q30/0631,G06Q30/0601,,2,0,,,"CARTA SALVATORE ET AL: ""ITERATIVE ZERO-SHOT LLM PROMPTING FOR KNOWLEDGE GRAPH CONSTRUCTION"", 3 July 2023 (2023-07-03), pages 1 - 18, XP093237790, Retrieved from the Internet <URL:https://arxiv.org/pdf/2307.01128> [retrieved on 20250109];;FAN WENQI ET AL: ""Recommender Systems in the Era of Large Language Models (LLMs)"", 5 July 2023 (2023-07-05), pages 1 - 16, XP093237937, Retrieved from the Internet <URL:https://arxiv.org/pdf/2307.02046v1> [retrieved on 20250109]",PENDING
383,US,A1,US 2025/0218554 A1,098-920-048-822-001,7/3/2025,2025,US 202418597709 A,3/6/2024,US 202418597709 A;;US 202463549342 P;;US 202363615719 P,12/28/2023,MACHINE LEARNING-DRIVEN FRAMEWORK FOR PREDICTING IONIC CONDUCTIVITY OF SOLID-STATE ELECTROLYTES,"A system and method are provided for a machine-learning drive framework for predicting ionic conductivity of solid-state electrolytes. In use, the method and/or system may include receiving, at a machine learning system, two or more molecular structures from at least one structural dataset, where the two or more molecular structures relate to ionic mobility. Additionally, atomic weights are calculated for the two or more molecular structures, and the machine learning system is trained based on the two or more molecular structures, where the training relies on at least one intrinsic atomic feature and the calculated atomic weights for the two or more molecular structures. Further, a bias-correction is applied for the two or more molecular structures to improve the training of the machine learning system. Further, one or more molecular dynamics (MD) simulations are outputted, using the machine learning system, for the two or more molecular structures.",QUANTUM GENERATIVE MAT LLC,SUMARIA VAIDISH;;VIKOREN JACOB;;SOMMER DAVID;;RAWAL TAKAT;;PRASAD DEEPTANSHU,,https://lens.org/098-920-048-822-001,Patent Application,yes,0,0,1,098-920-048-822-001,US,1,098-920-048-822-001,US,0,G16C20/70;;G16C20/20;;G16C10/00;;G16C20/30;;G16C60/00;;G16C20/20;;G16C20/70,G16C20/70;;G16C20/20,,0,0,,,,PENDING
384,US,A1,US 2025/0131280 A1,110-399-435-890-811,4/24/2025,2025,US 202418920529 A,10/18/2024,US 202418920529 A;;US 202363591326 P,10/18/2023,Meta-Reinforcement Learning Hypertransformers,Machine-learning systems for meta-reinforcement learning (Meta-RL) can include a transformer-based hypernetwork to generate policy parameters in an episodic fashion. An initial policy can be executed in a computing environment over an initial exploration episode during which the computing environment generates episode data. The episode data can be provided as an input to the hypertransformer network which generates an improved policy which is executed in the computing environment to generate episode data. This process is repeated over a predetermined number of episodes. A cumulative reward associated with execution of the policy for a final policy is optimized. The final policy can be optimized for both exploration and exploitation associated with a particular task. The final policy can include a machine-learned model and/or weights for a machine-learned model.,GOOGLE LLC,KRISTIANSEN GUS,GOOGLE LLC (2023-11-15),https://lens.org/110-399-435-890-811,Patent Application,yes,0,0,1,110-399-435-890-811,US,1,110-399-435-890-811,US,0,G06N3/092;;G06N7/01;;G06N3/092,G06N3/092,,0,0,,,,PENDING
385,US,A1,US 2025/0232190 A1,017-133-930-456-036,7/17/2025,2025,US 202418413927 A,1/16/2024,US 202418413927 A,1/16/2024,LARGE SCALE GENERATIVE ARTIFICIAL INTELLIGENCE FOR GENERATION OF CUSTOMIZED CONTENT,"A request for a customized reply is received from a requester. One or more templates stored in a selected location are retrieved based, at least in part, on at least one ontology constructed for one or more domains associated with the request for the customized reply. Information relating to the requester is input into the one or more templates to provide one or more populated templates. The customized reply to the request is generated based on the one or more populated templates and provided to the requester.",IBM,BAUGHMAN AARON K;;AKAY GOZDE;;AGARWAL RAHUL;;KARLINSKY LEONID,,https://lens.org/017-133-930-456-036,Patent Application,yes,0,0,1,017-133-930-456-036,US,1,017-133-930-456-036,US,0,G06N3/0985;;G06N5/02,G06N5/02;;G06N3/0985,,0,0,,,,PENDING
386,US,A1,US 2025/0062036 A1,158-729-485-242-952,2/20/2025,2025,US 202318452417 A,8/18/2023,US 202318452417 A,8/18/2023,GENERATING POTENTIAL BARRIERS TO A STRUCTURED PROCESS,"One embodiment of the invention provides a method for generating and ranking potential barriers that prevent completion of a structured process. The method comprises receiving a textual description of the structured process, receiving one or more templates relating to the structured process, and identifying a set of user actions required to complete the structured process based on the textual description. The method further comprises expanding the set of user actions based on general knowledge to include one or more additional actions, and updating the one or more templates based on the expanded set of user actions. The method further comprises generating, using at least one generative language model, a set of potential barriers that prevent completion of the structured process based on the one or more updated templates.",IBM,MULLIGAN NATALIA;;SBODIO MARCO LUCA;;BETTENCOURT-SILVA JOAO H;;LOPEZ GARCIA VANESSA;;PICCO GABRIELE;;MARTINEZ GALINDO MARCOS,INTERNATIONAL BUSINESS MACHINES CORPORATION (2023-08-15),https://lens.org/158-729-485-242-952,Patent Application,yes,0,0,1,158-729-485-242-952,US,1,158-729-485-242-952,US,0,G16H10/20;;G16H50/70;;G16H10/20;;G16H50/70;;G06Q10/06315,G16H50/70;;G16H10/20,,0,0,,,,PENDING
387,US,A1,US 2024/0330672 A1,152-379-510-469-599,10/3/2024,2024,US 202318129368 A,3/31/2023,US 202318129368 A,3/31/2023,AUTOMATED GENERATION OF MITIGATION INFORMATION,"A method, system, and computer program product that is configured to: train at least one model based on a corpus of historical data comprising annotated historical tickets; extract a textual sequence of a historical ticket based on the at least one trained model; determine a sentiment of the textual sequence of the historical ticket; and generate mitigation guidance to mitigate an issue in a current ticket based on the textual sequence of the historical ticket and the determined sentiment of the textual sequence of the historical ticket.",IBM,BHAVYA;;DENG YU;;CHOWDHURY MD FAISAL MAHBUB;;TORO ISAZA PAULINA;;NIDD MICHAEL ELTON;;AZAD AMAR PRAKASH;;KUMAR HARSHIT;;SHWARTZ LARISA,INTERNATIONAL BUSINESS MACHINES CORPORATION (2023-03-30),https://lens.org/152-379-510-469-599,Patent Application,yes,0,0,1,152-379-510-469-599,US,1,152-379-510-469-599,US,0,G06N3/08;;G06N5/022;;G06N20/00;;G06N5/022;;G06N3/08,G06N3/08;;G06N5/022,,0,0,,,,PENDING
388,US,A1,US 2025/0232168 A1,177-984-671-013-632,7/17/2025,2025,US 202418413670 A,1/16/2024,US 202418413670 A,1/16/2024,AutoSpec,"Apparati and methods for designing and evaluating machine learning (ML) and other computer systems at the metadata level. A unique graphical meta-level formalism for representing these systems is employed, which supports both human and machine evaluation, simulation, and evolution of alternate architectures and designs. Each graph comprises a plurality of nodes and a plurality of edges connecting the nodes. Each node represents an operation that produces at least one outbound feature, while each edge represents a set of features. The graph (or a subgraph within the graph) can be reconfigured by applying a transform operation to the graph or subgraph.",JAXON INC,HARMAN GREGORY;;JONES ROBERT,,https://lens.org/177-984-671-013-632,Patent Application,yes,0,0,1,177-984-671-013-632,US,1,177-984-671-013-632,US,0,G06N3/08;;G06N20/00,G06F30/27,,0,0,,,,PENDING
389,US,A1,US 2025/0190709 A1,007-534-390-204-456,6/12/2025,2025,US 202318531012 A,12/6/2023,US 202318531012 A,12/6/2023,PROMPT DISCOVERY WITH ATTENTION REFINEMENT,"An embodiment senses a sequence, responsive to the sensed sequence, segments the sensed sequence into a prompt and text. The embodiment generates an attention embedding representative of the text and computes an attention weight based on the attention embedding. The embodiment generates a prompt embedding representative of the prompt. The embodiment computes a relationship between the prompt embedding and the attention weight comprising correlating the attention embedding and the attention weight based on a beam search; bin packing the prompt embedding where a bin is defined by the attention embedding; matching the prompt embedding to the bin based on a Minkowski distance metric; where the bin packing causes the computing of the relationship between the prompt and the text represented by the attention weight.",IBM,BAUGHMAN AARON K;;YOGARAJ KAVITHA HASSAN;;RAHA AMIT KUMAR;;EGGENBERGER-WANG CHRISTIAN -,INTERNATIONAL BUSINESS MACHINES CORPORATION (2023-08-29),https://lens.org/007-534-390-204-456,Patent Application,yes,0,0,1,007-534-390-204-456,US,1,007-534-390-204-456,US,0,G06F40/40;;G06F40/30;;G06F40/30;;G06F40/40,G06F40/40;;G06F40/30,,0,0,,,,PENDING
390,WO,A1,WO 2025/072936 A1,021-076-574-928-151,4/3/2025,2025,US 2024/0049255 W,9/30/2024,US 202363586291 P,9/28/2023,LEVERAGING UNPAIRED DATA FOR CROSS-MODAL GENERATIVE MODELS VIA CYCLE CONSISTENCY,"A computer-implemented method includes obtaining, by a computing system that may include one or more computing devices, a text-to-image model and an image-to-text model. The method also includes, for each of one or more training iterations: accessing, by the computing system, an unpaired text input; processing, by the computing system, the unpaired text input with the text-to-image model to generate a synthetic image; processing, by the computing system, the synthetic image with the image-to-text model to generate predicted text; evaluating, by the computing system, a loss function that compares the predicted text to the unpaired text input to generate a loss value; and modifying, by the computing system, one or more parameter values of one or both of the text-to-image model and the image-to-text model based on the loss function.",GOOGLE LLC,BHARDWAJ SANGNIE;;BARBER JARRED PAUL;;LI TIANHONG;;KRISHNAN DILIP;;TIAN YONGLONG;;ZHANG HAN,,https://lens.org/021-076-574-928-151,Patent Application,yes,1,0,1,021-076-574-928-151,WO,1,021-076-574-928-151,WO,0,G06V10/82;;G06N3/047;;G06N3/0475;;G06N3/0895,G06N3/047;;G06N3/0475;;G06N3/0895;;G06V10/82,,9,3,019-897-623-501-397;;103-212-983-826-945;;084-641-049-769-580,10.1109/iccv.2019.00769;;pmc8371605;;34265844;;10.1038/s41586-021-03819-2;;10.18653/v1/2020.emnlp-main.83,"YONGSHUO ZONG ET AL: ""Self-Supervised Multimodal Learning: A Survey"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 31 March 2023 (2023-03-31), XP091473405;;MA SHUANG ET AL: ""Unpaired Image-to-Speech Synthesis With Multimodal Information Bottleneck"", 2019 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), IEEE, 27 October 2019 (2019-10-27), pages 7597 - 7606, XP033723410, DOI: 10.1109/ICCV.2019.00769;;JUN-YAN ZHU ET AL: ""Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 30 March 2017 (2017-03-30), XP081320659;;ZHOU ET AL.: ""Mixture-of Experts with Expert Choice Routing"", ARXIV:2202.09368V2, 14 October 2022 (2022-10-14);;DOSOVITSKIY ET AL.: ""An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"", ARXIV:2010.11929V2, 3 June 2021 (2021-06-03);;AGOSTINELLI ET AL.: ""MusicIM. Generating Music From Text"", ARXIV:2301.11325V1, 26 January 2023 (2023-01-26);;JUMPER ET AL.: ""Highly accurate protein structure prediction with AlphaFold"", NATURE, 26 August 2021 (2021-08-26);;VASWANI ET AL.: ""Attention Is All You Need"", ARMV: 1706.03762V7, 2 August 2023 (2023-08-02);;SAHARIA ET AL.: ""Non-Autoregressive Machine Translation with Latent Alignments"", ARXIV:2004.07437V3, 16 November 2020 (2020-11-16)",PENDING
391,US,A1,US 2024/0394641 A1,140-601-187-665-491,11/28/2024,2024,US 202318202939 A,5/28/2023,US 202318202939 A,5/28/2023,"System and method for generating employee performance reviews, goals, development plans and workforce planning, succession planning, career and professional development text and narratives using neural network machine learning models and large language AI models","The present invention relates to a system and method for generating employee performance reviews, goals, development plans, and workforce planning, succession planning, career and professional development text and narratives using neural network machine learning models and large language AI models. The inventive system and method harnesses advanced natural language generation capabilities, data-informed insights, and highly-tailored large language models prompts to automate and enhance the process of generating comprehensive and specific content for various HR functions. This allows organizations to streamline their employee management and planning processes and benefit from personalized and insightful manager-employee communications. The described invention addresses the shortcomings of existing approaches and maximizes the potential benefits of using AI in human resource management for optimizing performance evaluation, assisting in employee retention, and contributing to overall organizational success.",LOWENTHAL ALEX;;SALEMME CHRISTOPHER;;DULL KEVIN,LOWENTHAL ALEX;;SALEMME CHRISTOPHER;;DULL KEVIN,,https://lens.org/140-601-187-665-491,Patent Application,yes,5,0,1,140-601-187-665-491,US,1,140-601-187-665-491,US,0,G06Q10/06398;;G06Q10/06393;;G06Q10/06398,G06Q10/0639,,1,1,065-987-634-640-867,10.1108/ijppm-08-2020-0427,"Garg, S., Sinha, S., Kar, A.K. and Mani, M., 2022. A review of machine learning applications in human resource management. International Journal of Productivity and Performance Management, 71(5), pp.1590-1610. (Year: 2022)",PENDING
392,US,A1,US 2025/0156898 A1,105-294-500-738-719,5/15/2025,2025,US 202519019344 A,1/13/2025,US 202519019344 A;;US 202418731326 A;;US 202418668137 A;;US 202418656612 A;;US 202318354658 A;;US 202463551328 P,7/19/2023,SYSTEM AND METHOD FOR AI BASED TAILORED ADVERTISING CONTENT GENERATION,"A system and method for AI-driven advertising and content generation that integrates connectionist and symbolic AI techniques to deliver personalized, contextually relevant user experiences. The invention leverages specialized agent networks, knowledge graphs, and retrieval-augmented generation to create dynamic, adaptive content with seamlessly integrated advertisements. It employs a sophisticated ad integration layer and experience broker to ensure relevance and engagement. The system prioritizes security, traceability, and user preferences while optimizing ad placement and content delivery. By bridging connectionist and symbolic AI, the platform enables immersive, tailored interactions across multiple scenarios and time horizons, enhancing user engagement and advertiser value in an AI-driven digital landscape.",QOMPLX LLC,CRABTREE JASON;;KELLEY RICHARD;;HOPPER JASON;;PARK DAVID,QOMPLX LLC (2024-12-17),https://lens.org/105-294-500-738-719,Patent Application,yes,0,0,1,105-294-500-738-719,US,578,037-154-257-628-181;;026-779-470-212-557;;192-775-538-408-179;;051-177-220-968-114;;052-352-453-837-213;;158-783-234-553-331;;054-879-412-445-807;;133-705-672-195-350;;085-570-486-304-387;;131-181-059-848-846;;132-833-285-988-836;;008-670-386-928-50X;;170-038-557-276-089;;127-909-821-536-460;;193-256-330-379-091;;180-524-544-621-601;;125-131-656-407-907;;080-450-366-102-563;;003-842-080-904-026;;172-829-757-014-570;;153-645-799-362-009;;023-324-891-925-125;;165-772-840-997-741;;087-602-344-308-16X;;008-401-263-205-920;;181-484-588-987-501;;040-327-555-235-635;;108-602-315-004-87X;;150-224-578-671-129;;180-683-180-148-347;;169-279-819-725-473;;039-990-697-566-320;;119-836-745-834-196;;114-890-291-110-112;;154-344-527-132-119;;079-405-865-194-601;;015-812-699-933-62X;;080-215-142-304-844;;107-757-576-944-579;;048-876-789-559-846;;119-465-459-964-504;;172-790-697-398-393;;135-518-918-888-018;;197-881-544-654-764;;090-295-722-832-69X;;132-494-291-766-291;;101-765-648-888-249;;038-403-919-152-33X;;021-805-870-860-689;;077-763-435-353-163;;075-028-174-347-254;;152-853-258-831-079;;133-064-284-131-980;;125-262-596-697-50X;;063-306-274-750-632;;054-305-135-974-678;;138-722-806-573-588;;134-553-255-508-893;;128-471-135-100-790;;001-420-406-036-933;;006-140-484-263-280;;071-096-388-602-141;;134-998-818-751-494;;007-347-164-795-864;;035-410-443-521-078;;171-720-399-746-521;;175-746-154-241-630;;117-905-175-606-59X;;028-837-539-183-199;;127-262-016-473-933;;076-994-416-562-746;;143-831-828-697-438;;168-085-406-192-62X;;096-760-448-920-468;;124-872-389-039-522;;104-799-454-946-02X;;161-837-317-168-104;;103-822-902-908-489;;080-131-016-761-51X;;192-830-520-504-751;;019-088-815-151-256;;053-118-208-742-06X;;056-303-716-290-219;;131-638-342-848-769;;005-754-072-354-784;;187-297-841-980-800;;125-174-869-985-698;;180-264-763-292-192;;016-383-893-604-161;;188-288-369-132-622;;015-253-533-470-911;;197-949-044-788-406;;121-414-540-038-42X;;075-761-481-704-735;;096-041-127-373-239;;156-714-318-502-855;;181-249-118-121-535;;108-857-816-973-884;;156-184-203-979-455;;012-345-119-923-259;;111-774-031-604-805;;117-642-872-264-108;;025-847-591-070-300;;055-188-765-410-398;;070-097-015-696-892;;121-587-173-958-560;;014-453-562-149-334;;140-999-857-633-847;;055-343-015-110-465;;105-282-159-769-838;;040-564-101-493-604;;149-755-186-391-125;;130-015-728-409-753;;194-532-778-624-336;;163-595-907-546-308;;177-278-902-893-596;;145-585-587-743-588;;155-540-548-103-119;;193-934-571-047-442;;185-664-206-749-529;;127-704-477-633-915;;110-416-603-986-719;;032-786-057-601-068;;008-374-093-288-207;;108-907-809-853-481;;014-246-422-230-315;;149-940-585-858-33X;;027-061-421-057-726;;146-230-367-962-31X;;064-335-677-286-781;;115-802-053-250-762;;173-295-267-595-213;;124-201-072-441-516;;024-542-796-067-398;;147-258-217-637-838;;196-067-950-022-786;;006-058-429-744-847;;058-136-034-848-059;;125-906-404-070-886;;065-063-014-426-659;;004-461-496-948-855;;045-917-971-050-56X;;069-194-973-718-724;;091-833-359-236-851;;041-281-890-750-525;;139-937-135-074-052;;080-566-767-838-47X;;103-114-371-775-543;;118-279-455-322-111;;037-982-084-311-787;;188-674-366-808-979;;055-903-940-567-078;;110-351-467-572-989;;014-739-606-719-102;;071-988-212-130-180;;021-675-104-144-445;;111-073-595-869-372;;160-571-262-420-277;;195-650-568-942-751;;032-598-622-351-105;;147-011-126-807-569;;029-660-878-137-344;;151-696-187-988-34X;;015-328-647-228-799;;048-192-302-857-722;;117-801-500-567-584;;059-944-182-190-705;;154-860-068-782-470;;029-243-465-483-305;;107-672-595-990-826;;030-174-392-464-531;;022-847-643-542-201;;055-524-762-178-036;;107-489-943-484-626;;195-839-818-513-941;;093-208-015-729-299;;021-558-362-611-744;;160-450-640-172-266;;077-783-261-149-506;;095-377-229-980-681;;133-292-239-870-375;;154-356-244-638-409;;031-352-297-708-759;;049-056-708-944-463;;068-170-442-972-229;;182-432-926-199-498;;189-753-829-322-396;;162-131-738-285-968;;119-187-664-144-76X;;177-271-896-528-32X;;039-022-512-400-247;;043-267-234-154-815;;169-243-590-009-342;;036-028-001-089-731;;103-477-783-950-291;;153-058-907-719-786;;071-806-202-555-740;;171-546-189-945-812;;073-713-769-727-494;;136-480-712-243-666;;052-963-291-923-41X;;136-574-935-289-538;;104-638-509-577-202;;080-671-539-609-40X;;065-170-374-274-971;;026-186-698-928-734;;189-625-816-692-893;;091-371-713-692-46X;;100-783-433-341-126;;131-128-001-633-700;;166-942-852-231-992;;017-768-934-473-414;;001-317-406-379-391;;021-389-305-075-979;;151-137-309-371-284;;098-907-119-613-391;;044-191-182-507-882;;007-389-607-938-031;;123-321-763-235-770;;185-127-509-038-974;;160-715-381-644-126;;162-384-848-216-31X;;182-700-396-052-074;;129-952-794-667-401;;074-240-537-909-757;;000-597-495-310-814;;040-266-056-016-458;;155-110-500-893-086;;172-708-395-558-130;;042-934-102-630-453;;083-983-202-187-530;;004-166-358-275-953;;161-495-650-262-973;;076-637-575-690-977;;000-709-674-481-081;;087-182-225-707-637;;123-484-837-782-635;;155-910-546-986-355;;043-405-349-939-957;;103-425-520-233-843;;083-324-191-334-70X;;112-456-615-712-52X;;150-820-621-367-909;;083-903-894-483-425;;197-114-070-350-824;;049-028-516-768-655;;178-349-455-789-034;;073-430-035-592-80X;;008-064-859-265-815;;000-038-902-909-621;;133-002-373-744-021;;048-279-739-950-067;;086-485-075-219-428;;040-845-969-026-139;;070-352-069-345-700;;021-079-503-611-265;;175-495-496-188-020;;183-511-956-429-444;;065-680-750-346-802;;178-846-706-765-553;;049-890-567-654-589;;080-081-217-032-345;;027-066-977-165-899;;191-240-978-834-668;;132-133-759-842-71X;;018-088-624-287-349;;061-497-697-206-884;;126-037-593-729-516;;129-906-538-555-657;;099-264-755-545-57X;;072-247-216-528-290;;009-846-049-780-690;;045-328-154-501-02X;;079-660-520-290-41X;;154-492-113-635-386;;186-959-289-691-389;;118-724-487-120-496;;182-633-890-280-382;;076-376-030-977-668;;086-985-098-575-311;;093-141-887-021-964;;010-455-868-836-106;;065-648-185-387-723;;036-825-187-272-252;;154-230-032-513-096;;113-501-055-080-187;;174-612-974-303-470;;090-735-414-483-316;;121-801-592-381-617;;013-381-805-754-357;;013-095-413-454-913;;038-816-881-922-305;;027-329-988-277-302;;100-217-067-155-684;;014-827-400-640-212;;029-914-300-591-644;;011-562-412-366-329;;133-727-860-994-552;;101-135-325-800-138;;110-216-990-843-69X;;154-519-584-244-864;;126-611-010-718-203;;165-782-104-054-453;;148-737-413-742-728;;066-338-354-411-572;;025-060-142-473-519;;116-772-778-631-652;;104-738-742-266-791;;009-005-289-876-142;;004-434-942-408-821;;143-973-436-078-842;;164-967-662-048-677;;169-787-555-684-938;;195-227-968-704-893;;105-859-471-411-05X;;180-657-958-950-99X;;142-038-055-730-469;;064-634-698-781-255;;153-055-980-262-66X;;015-812-671-795-376;;012-017-411-640-86X;;107-754-063-563-072;;117-494-039-277-097;;024-690-213-354-681;;199-512-678-380-42X;;125-466-315-926-236;;152-494-705-574-843;;003-760-855-042-662;;085-052-960-069-32X;;141-339-840-935-585;;083-774-515-610-167;;102-978-916-788-777;;035-392-941-606-940;;019-318-746-775-604;;186-803-715-049-938;;158-393-312-453-210;;104-573-774-575-721;;182-149-428-548-452;;109-480-476-119-858;;001-639-636-991-22X;;024-395-701-195-470;;166-061-512-788-786;;087-458-637-270-456;;130-059-342-072-611;;066-682-704-432-73X;;058-075-461-036-518;;178-838-919-599-069;;187-160-099-485-495;;103-080-609-508-064;;022-448-222-186-183;;070-102-620-731-530;;139-862-995-392-954;;132-832-554-023-705;;062-196-356-634-765;;108-332-517-102-921;;145-988-468-831-661;;117-641-165-329-019;;085-210-721-709-87X;;167-909-715-949-326;;064-761-756-293-121;;108-582-708-972-032;;037-260-814-519-084;;021-295-609-309-853;;170-124-147-957-843;;072-847-784-173-124;;019-859-720-492-763;;180-694-854-374-695;;182-093-288-289-742;;023-933-112-090-776;;057-123-744-810-742;;147-597-875-076-485;;198-870-840-595-044;;136-078-534-118-76X;;000-296-368-111-872;;171-152-301-182-412;;139-710-050-486-182;;039-538-267-429-560;;136-912-601-845-732;;196-391-835-696-835;;022-915-563-273-963;;000-536-856-313-465;;133-810-480-576-815;;054-285-468-825-720;;051-647-934-342-985;;133-965-591-339-720;;089-232-307-907-363;;040-251-717-505-653;;041-876-411-976-475;;060-927-214-452-10X;;149-204-391-984-367;;027-902-066-189-831;;102-745-043-366-737;;128-846-474-291-42X;;172-901-964-435-101;;132-906-454-317-828;;027-879-065-052-099;;061-955-529-156-158;;115-450-998-992-89X;;093-783-952-647-256;;087-671-644-225-162;;082-203-791-029-269;;162-406-931-508-609;;183-065-763-307-144;;190-613-105-844-894;;070-109-425-956-71X;;179-687-548-881-946;;114-875-928-799-290;;181-309-519-837-78X;;196-041-560-476-12X;;170-229-078-848-82X;;075-282-849-667-576;;045-652-081-194-018;;198-402-416-554-06X;;194-445-489-074-002;;060-892-480-987-951;;055-085-895-924-889;;084-363-068-228-491;;170-620-942-428-927;;193-391-823-339-284;;096-702-410-515-824;;083-768-096-673-313;;114-571-787-948-076;;034-716-329-436-000;;187-063-295-984-852;;144-476-586-622-902;;093-611-777-921-084;;045-202-166-877-864;;193-422-150-038-506;;021-329-379-658-240;;097-234-496-193-062;;192-675-634-874-622;;052-059-789-553-166;;147-195-340-266-520;;071-696-457-139-904;;194-227-374-582-968;;113-501-017-599-156;;118-902-966-890-171;;070-452-081-561-244;;078-561-597-336-228;;114-488-925-608-399;;142-585-568-390-116;;056-936-930-529-366;;137-287-553-424-233;;029-189-340-565-222;;050-203-411-376-891;;008-857-479-067-163;;128-491-075-052-384;;174-310-672-604-848;;122-358-915-403-896;;062-446-755-582-201;;083-350-553-415-427;;084-094-561-358-190;;193-279-570-818-331;;116-387-661-145-676;;188-217-959-572-232;;197-886-230-839-566;;151-294-727-872-793;;071-718-147-875-265;;047-538-862-310-257;;002-385-103-394-413;;048-792-342-952-15X;;019-495-936-711-609;;125-167-199-425-708;;118-125-542-986-723;;060-510-775-281-976;;040-913-584-420-591;;025-468-821-684-384;;023-849-985-263-398;;077-090-854-196-197;;111-114-577-294-884;;085-897-643-354-041;;055-432-328-819-058;;057-315-027-521-995;;177-733-336-930-533;;196-044-725-401-358;;063-927-942-204-381;;145-050-894-270-572;;183-336-332-885-622;;127-879-776-921-09X;;017-132-357-346-699;;198-615-615-891-543;;052-792-568-847-103;;000-319-657-499-550;;027-484-045-457-746;;027-481-945-197-130;;017-390-887-154-856;;033-501-473-103-759;;179-619-578-529-367;;116-362-275-848-217;;138-542-048-114-834;;126-765-455-776-483;;156-393-972-996-170;;038-748-734-766-451;;087-679-756-879-992;;137-312-722-747-052;;104-276-098-918-424;;111-341-246-938-702;;073-508-864-364-182;;049-072-378-638-892;;061-707-666-299-734;;044-987-220-762-643;;123-930-852-651-964;;121-678-385-649-755;;022-530-649-397-986;;138-890-046-052-810;;058-768-672-787-786;;195-998-346-296-106;;018-465-551-415-290;;121-569-357-502-219;;120-768-539-121-615;;056-853-528-304-042;;000-700-770-801-419;;016-238-739-232-485;;041-102-746-837-769;;167-603-067-966-088;;023-901-754-663-920;;194-673-951-169-189;;059-927-962-068-028;;060-460-016-582-353;;182-618-894-149-220;;178-645-610-606-223;;129-164-109-835-79X;;197-077-457-073-454;;005-466-616-725-55X;;003-537-389-243-00X;;103-699-274-581-751;;129-731-022-200-191;;068-856-645-258-312;;063-147-555-951-048;;180-331-323-588-173;;135-222-397-719-848;;140-674-265-766-042;;164-132-307-319-588;;116-059-560-935-908;;138-363-646-907-419;;051-181-106-775-29X;;067-239-494-680-70X;;028-870-183-960-608;;076-700-976-390-042;;080-376-581-712-310;;095-867-167-500-428;;178-747-472-734-856;;102-602-839-299-13X;;120-886-060-343-539;;197-208-522-876-972;;126-876-084-817-670;;074-338-551-378-222;;113-564-524-220-276;;105-294-500-738-719;;124-004-714-460-784;;099-524-911-821-301;;085-797-537-316-326;;071-706-755-734-222;;044-567-921-028-686;;179-234-156-117-509;;112-703-143-713-529;;066-129-850-694-558;;138-161-071-533-827;;003-806-385-394-25X;;195-055-953-058-579;;109-759-429-228-830;;193-976-187-522-099;;127-790-040-938-082;;166-684-166-297-239;;073-718-671-991-142;;150-697-523-144-129;;002-838-097-104-449;;104-060-925-131-711;;043-394-058-432-688;;098-515-068-077-601;;089-867-569-003-195;;031-295-313-605-242;;152-249-199-790-404;;028-166-882-002-231;;150-659-573-759-677;;076-553-285-158-562;;072-737-409-579-731;;065-438-385-254-508,US;;WO;;EP;;AU;;CN,0,G06Q30/0256;;G06F16/2455;;G06Q30/0244;;G06Q30/0277;;G06Q30/0276;;G06Q30/0244;;G06F16/2455;;G06Q30/0256,G06Q30/0242;;G06F16/2455;;G06Q30/0251,,0,0,,,,PENDING
393,US,A1,US 2024/0378397 A1,147-699-194-073-26X,11/14/2024,2024,US 202318314249 A,5/9/2023,US 202318314249 A,5/9/2023,DYNAMIC CONTENT GENERATION METHOD,"A dynamic content generation method is executed by a processing module electrically connected to an input module and a communications module. The dynamic content generation method includes the following steps: generating a topic, at least one variable, and a selected writing type according to a setting command received from the input module; communicating with a natural language processing (NLP) model for receiving relevance data of the at least one variable to the topic; communicating with the NLP model for receiving a content text produced by the NLP model according to the topic, the at least one variable, the selected writing type, and the relevance data; when the content text satisfies the selected writing type, stopping receiving the content text, or else generating a correction information, applying the correction information to the relevance data, and iteratively re-generating the content text until the content text satisfies the selected writing type.",LIU JIM,LIU JIM,,https://lens.org/147-699-194-073-26X,Patent Application,yes,9,1,1,147-699-194-073-26X,US,1,147-699-194-073-26X,US,0,G06F40/106;;G06T11/206;;G06F40/174;;G06F40/40;;G06F40/30;;G06F40/186;;G06F40/166;;G06F3/0486;;G06F40/40;;G06F3/0486;;G06T11/206;;G06F40/30;;G06F40/174;;G06F40/106,G06F40/40;;G06F3/0486;;G06F40/106;;G06F40/174;;G06F40/30;;G06T11/20,,8,6,069-648-837-333-698;;030-024-444-811-168;;021-244-154-816-823;;108-178-706-326-016;;027-380-988-293-015;;055-001-356-110-965,10.32388/imzi2q;;10.18653/v1/2024.acl-long.399;;10.36227/techrxiv.22683919;;10.18653/v1/2022.naacl-main.257;;10.1145/3532106.3533533;;10.1109/ialp54817.2021.9675213,"Wang, Shuyue, and Pan Jin, ""A Brief Summary of Prompting in Using GPT Models"", April 2023, Qeios, pp. 1-14. (Year: 2023);;Salemi, Alireza, Sheshera Mysore, Michael Bendersky, and Hamed Zamani, ""LaMP: When Large Language Models Meet Personalization"", April 2023, arXiv preprint arXiv:2304.11406. (Year: 2023);;Ekin, Sabit, “Prompt Engineering For ChatGPT: A Quick Guide To Techniques, Tips, And Best Practices”, April 2023, TechRxiv. (Year: 2023);;Hariri, Walid, ""Unlocking the Potential of ChatGPT: A Comprehensive Exploration of its Applications, Advantages, Limitations, and Future Directions in Natural Language Processing"", April 2023, arXiv preprint arXiv:2304.02017. (Year: 2023);;Tang, Tianyi, Junyi Li, Wayne Xin Zhao, and Ji-Rong Wen, ""Context-Tuning: Learning Contextualized Prompts for Natural Language Generation"", October 2022, Proceedings of the 29th International Conference on Computational Linguistics, pp. 6340-6354. (Year: 2022);;Gero, Katy Ilonka, Vivian Liu, and Lydia B. Chilton, ""Sparks: Inspiration for Science Writing using Language Models"", June 2022, Proceedings of the 2022 ACM Designing Interactive Systems Conference, pp. 1002-1019. (Year: 2022);;Garbacea, Cristina, and Qiaozhu Mei, ""Why is constrained neural language generation particularly challenging?"", June 2022, arXiv preprint arXiv:2206.05395, pp. 1-22. (Year: 2022);;Ning, Xinyi, ""Topic-to-Text Generation with PMI-IR Additional Semantic Information"", December 2021, 2021 International Conference on Asian Language Processing (IALP), pp. 131-136. (Year: 2021)",PENDING
394,US,A1,US 2024/0256965 A1,114-483-936-646-996,8/1/2024,2024,US 202418424624 A,1/26/2024,SG 10202300219X A,1/27/2023,Instruction Fine-Tuning Machine-Learned Models Using Intermediate Reasoning Steps,"An example method for training a machine-learned sequence processing model includes obtaining a plurality of training examples for training the machine-learned sequence processing model. For each respective training example of the plurality of training examples, the example method includes: obtaining a respective query associated with the respective training example; inputting the respective query to the machine-learned sequence processing model; obtaining, from the machine-learned sequence processing model a response to the respective query and a trace of intermediate states from the respective query to the response; evaluating the response using a ground truth response associated with the respective training example; evaluating the trace using a ground truth trace associated with the respective training example; and updating one or more parameters of the machine-learned sequence processing model based on the evaluation of the response and based on the evaluation of the trace.",GOOGLE LLC,CHUNG HYUNG WON;;ZOPH BARRET;;ZHOU DENGYONG;;FEDUS LIAM;;LONGPRE SHAYNE;;HOU LE;;TAY YI;;WEI JASON WENG;;BRAHMA SIDDHARTHA;;LE QUOC V,GOOGLE LLC (2023-05-31),https://lens.org/114-483-936-646-996,Patent Application,yes,0,5,1,114-483-936-646-996,US,1,114-483-936-646-996,US,0,G06N20/00;;G06N20/00;;G06F16/33,G06N20/00,,0,0,,,,PENDING
395,US,A1,US 2025/0211551 A1,179-352-342-947-386,6/26/2025,2025,US 202418606029 A,3/15/2024,US 202418606029 A;;US 202318395842 A,12/26/2023,Systems and methods for cloud security system assistance utilizing custom Large Language Models (LLMs),"Systems and methods for cloud security system assistance utilizing custom Large Language Models (LLMs) include providing a cloud-based security solution for an enterprise via a cloud-based system; displaying a User Interface (UI) associated with the cloud-based security solution having a chatbot, wherein the chatbot is configured to allow a user associated with the enterprise to enter a question; and responsive to receiving a question from a user via the chatbot, generating a detailed response to the question via a custom LLM, wherein the custom LLM is trained to provide assistance to users of the cloud-based security solution.",ZSCALER INC,DANINO SHOHAM,ZSCALER INC (2024-03-14),https://lens.org/179-352-342-947-386,Patent Application,yes,4,0,1,179-352-342-947-386,US,2,179-352-342-947-386;;077-161-526-820-267,US,0,H04L51/02;;H04L51/02,H04L51/02,,0,0,,,,PENDING
396,US,A1,US 2025/0053899 A1,030-164-782-651-384,2/13/2025,2025,US 202418581439 A,2/20/2024,US 202418581439 A;;US 202363518334 P,8/9/2023,Computer-Implemented Methods and Computer Systems for Artificial Intelligence (AI) Based Automated Provision of Management Consulting,"Embodiments of the present invention provide a computer-implemented method for Artificial Intelligence (AI) based provision of management consulting. The computer-implemented method includes dividing the provision of management consulting into a plurality of tasks, the plurality of tasks defined as a plurality of respective workflows. Furthermore, the computer-implemented method includes assigning a plurality of Artificial Intelligence (AI) agents to the plurality of tasks with each one of the plurality of tasks assigned at least one AI agent. The computer-implemented method further includes providing the plurality of AI agents with characteristic reference data obtained from a plurality of data sources. Furthermore, the computer-implemented method includes providing a plurality of interfaces to the plurality of AI agents for enabling exchanges of data amongst the plurality of AI agents. The computer-implemented method also includes generating a plurality of deliverables in a plurality of user-readable formats, the plurality of deliverables constituting management consulting.",HUGHES CHASE,HUGHES CHASE,PROAI INC (2024-04-10),https://lens.org/030-164-782-651-384,Patent Application,yes,0,0,1,030-164-782-651-384,US,1,030-164-782-651-384,US,0,G06Q10/06393;;G06Q10/063118;;G06Q10/06393;;G06Q10/063118,G06Q10/0631;;G06Q10/0639,,0,0,,,,PENDING
397,US,A1,US 2024/0338361 A1,124-810-140-137-641,10/10/2024,2024,US 202418627369 A,4/4/2024,US 202418627369 A;;US 202363494221 P,4/4/2023,DATA PLATFORM USING GENERATIVE ARTIFICIAL INTELLIGENCE BASED ANALYSIS AND QUERIES APPLIED TO DATA SOURCES,"A system for querying a database may receive, from a user interface, a query request. The system may transmit, to a generative AI system, a contextualized query based on the query request and context from the database. The system may receive, from the generative AI system, a query statement in response to the transmission of the contextualized query. The system may transmit, to the database, the query statement. The system may receive, from the database, a database response comprising a set of database entries in response to the transmission of the query statement. The system may transmit, to the user interface, an indication of the database response.",CHAOSSEARCH INC,HAZEL THOMAS,CHAOSSEARCH INC (2024-04-04),https://lens.org/124-810-140-137-641,Patent Application,yes,9,1,1,124-810-140-137-641,US,1,124-810-140-137-641,US,0,G06F16/2423;;G06F16/2452;;G06F16/2228;;G06F16/243;;G06F16/2228;;G06F16/2452;;G06F16/2423,G06F16/242;;G06F16/22;;G06F16/2452,,0,0,,,,PENDING
398,US,A1,US 2025/0014089 A1,002-021-702-758-20X,1/9/2025,2025,US 202418764904 A,7/5/2024,US 202418764904 A;;US 202363512018 P,7/5/2023,SYSTEMS AND METHODS FOR PROFILE-BASED SERVICE RECOMMENDATIONS,"Systems and methods for performing profile-based recommendations including receiving a user input from a user, extracting a query from the user input, identifying at least one category based on the user input, generating a user profile representative of the query and preferences of the user, retrieving data corresponding to services in the identified at least one category from a data source and generating a service profile for each respective service, determining a match between the user profile and the service profiles, generating, in response to the query, an output dataset corresponding to one or more service profiles in the at least one category determined from the matching. The services corresponding to at least one of services of a third party service provider, a location, and an objective.",MCCLURE JONATHAN,MCCLURE JONATHAN,,https://lens.org/002-021-702-758-20X,Patent Application,yes,0,0,1,002-021-702-758-20X,US,1,002-021-702-758-20X,US,0,G06Q30/0201;;H04L67/306;;G06Q30/0631;;G06Q30/0631;;G06Q30/0201;;H04L67/306,G06Q30/0601;;G06Q30/0201;;H04L67/306,,0,0,,,,PENDING
399,US,A1,US 2024/0427902 A1,097-083-685-995-800,12/26/2024,2024,US 202418603333 A,3/13/2024,US 202418603333 A;;US 202363521964 P,6/20/2023,Automated Identification Of Vulnerable Software Components,"A computer-implemented method is presented for identifying vulnerable software from a computer system. The method includes: identifying name of a given software component in a vulnerability database by analyzing text of an entry in the vulnerability database using a large language model, where entries in the vulnerability database have known vulnerabilities; identifying a patch for the given software component in a source code repository by analyzing text of the entry in the vulnerability database using the large language model; identifying the patch for the given software component in the source code repository by analyzing text in the source code repository using the large language model; and reporting the given software component as being vulnerable in response to identifying the patch for the given software component in the source code repository.",DYNATRACE LLC,ACHLEITNER STEFAN;;AMMER SIMON;;BUZEK BENJAMIN,DYNATRACE LLC (2024-03-11),https://lens.org/097-083-685-995-800,Patent Application,yes,0,1,2,097-083-685-995-800;;022-001-958-332-306,US;;EP,2,097-083-685-995-800;;022-001-958-332-306,US;;EP,0,G06F21/577;;G06F40/295;;G06F8/65;;G06F21/563;;G06F21/577,G06F8/65;;G06F21/57;;G06F21/56;;G06F40/295,,0,0,,,,PENDING
400,US,A1,US 2025/0124067 A1,017-817-568-861-000,4/17/2025,2025,US 202418913702 A,10/11/2024,US 202418913702 A;;US 202363589393 P,10/11/2023,Method for Text Ranking with Pairwise Ranking Prompting,"Provided are computing systems, methods, and platforms that rank text with pairwise ranking prompting using a generative sequence processing model. A prompt comprising a query and sets of text associated with candidate results can be generated. The generative sequence processing model can be prompted with the prompt and perform pairwise comparisons between the sets of text in the prompt based on the query in the prompt. An output can be generated that ranks the sets of text in response to the query.",GOOGLE LLC,QIN ZHEN;;JAGERMAN ROLF;;HUI KAI;;ZHUANG HONGLEI;;WU JUNRU;;SHEN JIAMING;;LIU TIANQI;;LIU JIALU;;METZLER JR DONALD ARTHUR;;WANG XUANHUI;;BENDERSKY MICHAEL,GOOGLE LLC (2023-09-27),https://lens.org/017-817-568-861-000,Patent Application,yes,0,0,1,017-817-568-861-000,US,1,017-817-568-861-000,US,0,G06F16/338;;G06F16/338,G06F16/338,,0,0,,,,PENDING
401,WO,A1,WO 2024/220845 A1,076-110-354-634-727,10/24/2024,2024,US 2024/0025470 W,4/19/2024,IN 202321028416 A,4/19/2023,MACHINE LEARNING BASED AGENT FOR TEXT EDITING,"Provided is a computing system that includes a machine learning agent that can be requested to perform various editing tasks in, for example, a word processing application or other text-generation environments. The machine learning agent can include one or more machine-learned language models that have been trained on a set of training data that provides examples of edits performed on long-form text.",GOOGLE LLC,MENG LEI;;SHU LEI;;LIU YINXIAO;;MAK TONY;;LI CHANG;;ZHU YUN;;SHARMA ABHANSHU;;SHARIFI MATTHEW;;FITOUSSI HEN;;HOSKERE JAYAKUMAR;;TONG SIMON,,https://lens.org/076-110-354-634-727,Patent Application,yes,2,0,1,076-110-354-634-727,WO,1,076-110-354-634-727,WO,0,G06F40/169;;G06F40/30;;G06F40/166,G06F40/30;;G06F40/166;;G06F40/169,,7,3,103-212-983-826-945;;120-047-640-592-980;;084-641-049-769-580,pmc8371605;;34265844;;10.1038/s41586-021-03819-2;;10.18653/v1/d18-2012;;10.18653/v1/2020.emnlp-main.83,"ZHOU ET AL.: ""Mixture-of-Experts with Expert Choice Routing,"", ARXIV:2202.09368V2, 14 October 2022 (2022-10-14);;DOSOVITSKIY ET AL.: ""An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale,"", ARXIV:2010.1 1929V2, 3 June 2021 (2021-06-03);;AGOSTINELLI ET AL.: ""MitsicLM.- Generating Music From Text"", ARXIV:2301.11325V1, 26 January 2023 (2023-01-26);;JUMPER ET AL.: ""Highly accurate protein structure prediction with AlphaFold"", NATURE, vol. 596, 26 August 2021 (2021-08-26), pages 583, XP055888904, DOI: 10.1038/s41586-021-03819-2;;KUDO ET AL.: ""SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"", PROCEEDINGS OF THE 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (SYSTEM DEMONSTRATIONS, 4 November 2018 (2018-11-04), pages 66 - 71, Retrieved from the Internet <URL:https://aclanthology.org/D18-2012.pdf>;;VASWANI ET AL.: ""Attention Is All You Need"", ARXIV:1706.03762V7, 2 August 2023 (2023-08-02);;SAHARIA ET AL.: ""Non-Autoregressive Machine Translation with Latent Alignments"", ARXIV:2004.07437V3, 16 November 2020 (2020-11-16)",PENDING
402,US,A1,US 2024/0282404 A1,146-958-054-723-694,8/22/2024,2024,US 202418443534 A,2/16/2024,US 202418443534 A;;US 202363446545 P,2/17/2023,Protein engineering workflow using a generative model of protein families,"A retrieval-augmented framework leverages a generative protein language model of whole protein families. The model is configured and trained on homologous sequences and learns to generate sets of related proteins as sequences-of-sequences across very large numbers (e.g., tens of millions) of natural protein sequence clusters. In order to capture conditioning between sequences in an order independent manner (typically, the order of sequences within a family is arbitrary) and to generalize to large context lengths, the model leverages a transformer layer that models order-dependence between tokens within sequences and order-independence between sequences. Upon training, the model is used in protein engineering workflows, such as controllable design of protein sequences and variant effect prediction.",NE47 BIO INC,BEPLER TRISTAN;;TRUONG JR TIMOTHY F,NE47 BIO INC (2024-02-15),https://lens.org/146-958-054-723-694,Patent Application,yes,1,0,2,146-958-054-723-694;;097-561-935-461-347,US;;WO,2,146-958-054-723-694;;097-561-935-461-347,US;;WO,0,G16B15/00;;G16B40/20;;G16B40/20;;G16B15/00,G16B15/00;;G16B40/20,,5,4,121-216-615-932-585;;010-334-156-571-882;;100-540-746-228-718;;141-131-524-323-752,34180966;;10.1093/bib/bbab234;;pmc8484459;;34593817;;10.1038/s41467-021-25976-8;;pmc8668950;;10.1038/s41598-021-03431-4;;34903827;;10.1101/2022.11.21.517442,"Yamaguchi, Hideki, and Yutaka Saito. ""Evotuning protocols for Transformer-based variant effect prediction on multi-domain proteins."" Briefings in Bioinformatics 22.6 (2021): bbab234. (Year: 2021);;Luo, Yunan, et al. ""ECNet is an evolutionary context-integrated deep learning framework for protein engineering."" Nature communications 12.1 (2021): 5743. (Year: 2021);;Littmann, M., Heinzinger, M., Dallago, C. et al. Protein embeddings and deep learning predict binding residues for various ligand classes. Sci Rep 11, 23916 (2021). https://doi.org/10.1038/s41598-021-03431-4 (Year: 2021);;Zhang, Qiang, et al. ""Prompt-guided injection of conformation to pre-trained protein model."" arXiv preprint arXiv:2202.02944 (2022). (Year: 2022);;Wu, Tianqi, Weihang Cheng, and Jianlin Cheng. ""Improving protein secondary structure prediction by deep language models and transformer networks."" bioRxiv (2022): 2022-11. (Year: 2022)",PENDING
403,US,A1,US 2025/0103621 A1,000-798-008-512-20X,3/27/2025,2025,US 202318472421 A,9/22/2023,US 202318472421 A,9/22/2023,COMPUTER-BASED INTERACTIVE PROMPT VARIATION GENERATOR,"In an approach to improve prompt variations to enhance user-based experiences while interacting with artificial intelligent (AI) systems, embodiments generate variations of the prompts associated with the initial input by automatically leveraging machine learning techniques and collect the prompts from a user resulting from an interaction with an artificial intelligent (AI) system. Further, embodiments, identify a heuristic to organize suggestions and the variations of the prompts, and determine and utilize the heuristic to organize the variations of the prompts in systematic categories to produce an efficient display of the variations of the prompts, in a graphic user interface (GUI), for the user to view. Additionally, embodiments, update the variations of the prompts based on identified interaction data from the user, and dynamically output the updated variations of the prompts in response to the identified and collected user data.",IBM,PAN QIAN;;DO HYO JIN;;ASHKTORAB ZAHRA;;DESMOND MICHAEL;;JOHNSON JAMES;;DUGAN CASEY,INTERNATIONAL BUSINESS MACHINES CORPORATION (2023-09-11),https://lens.org/000-798-008-512-20X,Patent Application,yes,4,0,1,000-798-008-512-20X,US,1,000-798-008-512-20X,US,0,G06F16/3329;;G06F16/3328;;G06F16/3323;;G06F16/3323;;G06F16/3328;;G06F16/3329,G06F16/332,,0,0,,,,PENDING
404,US,A1,US 2025/0077791 A1,057-114-486-136-980,3/6/2025,2025,US 202318458142 A,8/29/2023,US 202318458142 A,8/29/2023,LARGE LANGUAGE MODEL AND DETERMINISTIC CALCULATOR SYSTEMS AND METHODS,"A first large language model (LLM) instance may be instructed to request data while being prevented from performing calculations using the data. A second LLM instance may be instructed to provide a response to the request for data based on a known complete data set. The response may be translated into a machine-readable response in a format configured for processing by a calculation engine. The calculation engine may process the machine-readable response, thereby generating a calculation engine output. A mismatch between the calculation engine output and a known result obtained using the known complete data set may be identified, and the instruction to the first LLM may be modified in response.",INTUIT INC,XU NA;;CHEN MENG;;DE PEUTER CONRAD;;KUMAR SRICHARAN KALLUR PALLI,INTUIT INC (2023-08-21),https://lens.org/057-114-486-136-980,Patent Application,yes,0,0,1,057-114-486-136-980,US,1,057-114-486-136-980,US,0,G06F40/40;;G06F40/40,G06F40/40,,0,0,,,,PENDING
405,US,A1,US 2024/0406081 A1,123-659-913-562-661,12/5/2024,2024,US 202318205063 A,6/2/2023,US 202318205063 A,6/2/2023,CONVERSATIONAL NETWORK ASSURANCE USING LARGE LANGUAGE MODELS,"In one embodiment, a device receives, at a first large language model executed by a device, textual input from a user of a network regarding a networking issue in the network. The device issues, by the first large language model and to a second large language model, one or more questions regarding the network based on the textual input. The device receives, at the first large language model and from the second large language model, one or more answers to the one or more questions. The device generates, by the first large language model, a textual response to the textual input for presentation to the user.",CISCO TECH INC,MERMOUD GRÉGORY;;VASSEUR JEAN-PHILIPPE;;SAVALLE PIERRE-ANDRÉ;;SCHORNIG EDUARD;;GARCARZ MICHAL WLADYSLAW,CISCO TECHNOLOGY INC (2023-05-30),https://lens.org/123-659-913-562-661,Patent Application,yes,0,1,1,123-659-913-562-661,US,1,123-659-913-562-661,US,0,H04L41/5067;;H04L41/5074;;H04L41/16;;H04L41/5074;;H04L41/16;;H04L41/5067,H04L41/5074;;H04L41/16;;H04L41/5067,,0,0,,,,PENDING
406,US,A1,US 2025/0068488 A1,061-833-868-891-653,2/27/2025,2025,US 202318455595 A,8/24/2023,US 202318455595 A,8/24/2023,LARGE LANGUAGE MODEL AND DETERMINISTIC CALCULATOR SYSTEMS AND METHODS,"At least one large language model (LLM) may be instructed to request data from a user while being prevented from performing calculations using the data. A user-generated response to the request for data, including at least a portion of the data, may be received. The user-generated response may be translated into a machine-readable response in a format configured for processing by a calculation engine. The calculation engine may process the machine-readable response, thereby generating a calculation engine output.",INTUIT INC,XU NA;;CHEN MENG;;DE PEUTER CONRAD,INTUIT INC (2023-08-21),https://lens.org/061-833-868-891-653,Patent Application,yes,0,0,1,061-833-868-891-653,US,1,061-833-868-891-653,US,0,G06F40/40;;G06Q40/123;;G06F9/54;;G06F9/54;;G06Q40/123;;G06F40/40,G06F9/54;;G06F40/40,,0,0,,,,PENDING
407,US,A1,US 2025/0094842 A1,073-758-706-017-689,3/20/2025,2025,US 202318370171 A,9/19/2023,US 202318370171 A,9/19/2023,INTELLIGENT ORCHESTRATION SYSTEM FOR EMOTION CONTAGION IN MULTI-HUMAN TO MULTI-AGENT INTERACTIONS,"An embodiment senses an interaction among a software agent and a plurality of humans, responsive to the sensed interaction, computes a mood pattern in a Mood Pattern Observation Component based on the sensed interaction. The embodiment computes a prevalent mood pattern in a Mood Pattern Grouping Component based on the mood pattern. The embodiment decides by an Orchestration of Agent Interactions Component based on the prevalent mood pattern to adapt a response of the software agent to influence at least one of the plurality of humans towards the prevalent mood pattern, the deciding further comprises training a Text Generation Component to generate a text sequence based on the response wherein the software agent emits the text sequence and the sensed interaction among the software agent and the plurality of humans is updated with the text sequence.",IBM,KOCH FERNANDO LUIZ;;KEEN MARTIN G;;NAHULAN JESSICA;;FOX JEREMY R,INTERNATIONAL BUSINESS MACHINES CORPORATION (2023-09-18),https://lens.org/073-758-706-017-689,Patent Application,yes,0,0,3,073-758-706-017-689;;110-339-494-215-336;;069-921-106-970-41X,US;;CN;;JP,3,073-758-706-017-689;;069-921-106-970-41X;;110-339-494-215-336,US;;CN;;JP,0,G06N5/043;;G06N20/00;;G06N5/043,G06N5/043,,0,0,,,,PENDING
408,US,A1,US 2025/0131126 A1,175-909-978-815-020,4/24/2025,2025,US 202318489361 A,10/18/2023,US 202318489361 A,10/18/2023,SYSTEM AND METHOD FOR A GENERATIVE ARTIFICIAL INTELLIGENCE MODEL GATEWAY,"According to some embodiments, systems and methods are provided, including receiving a prompt; determining, by at least one of an image component and a text component, a personal identifiable information (PII) status for the prompt; returning a PII response; receiving selection of a large language model (LLM) in a case the PII status is PII-free; determining a large language model status; transmitting the prompt to the selected LLM based on the large language model status; and receiving a large language model (LLM) output. Numerous other aspects are provided.",GNANASEKARAN SENTHILKUMAR;;KOMMANAMANCHI AGASTYA;;MISTRY SHRUJAN JYOTINDRABHAI;;THOMAS RENOI,GNANASEKARAN SENTHILKUMAR;;KOMMANAMANCHI AGASTYA;;MISTRY SHRUJAN JYOTINDRABHAI;;THOMAS RENOI,HARTFORD FIRE INSURANCE COMPANY (2023-10-18),https://lens.org/175-909-978-815-020,Patent Application,yes,5,0,1,175-909-978-815-020,US,1,175-909-978-815-020,US,0,G06F40/55;;G06F21/6254;;G06F21/6245;;G06F40/55;;G06F21/6254,G06F21/62;;G06F40/55,,1,0,,,NPL Search Terms (Year: 2025),PENDING
409,US,A1,US 2025/0111285 A1,163-096-117-322-768,4/3/2025,2025,US 202418902137 A,9/30/2024,US 202418902137 A;;US 202363586261 P,9/28/2023,Self-Supervised Learning for Temporal Counterfactual Estimation,"A machine-learned model includes an encoder having a feature block configured to embed input data into a plurality of features in an embedding space. The input data includes multiple components such as covariate, treatment, and output components. The encoder includes one or more encoding layers, each including a temporal attention block and a feature-wise attention block. The temporal attention block is configured to obtain the embedded input data and apply temporal causal attention along a time dimension in parallel for each feature of the plurality of features to generate temporal embeddings. The feature-wise attention block is configured to obtain the temporal embeddings and generate component representations such as a covariate representation, a treatment representation, and an output representation.",GOOGLE LLC,LIU YAN;;MENG CHUIZHENG;;DONG YIHE;;ARIK SERCAN OMER;;PFISTER TOMAS,GOOGLE LLC (2023-10-06),https://lens.org/163-096-117-322-768,Patent Application,yes,0,0,1,163-096-117-322-768,US,1,163-096-117-322-768,US,0,G06N20/00;;G06N3/045;;G06N3/084;;G06N3/044;;G06N20/00,G06N20/00,,0,0,,,,PENDING
410,US,A1,US 2025/0037340 A1,039-255-925-767-618,1/30/2025,2025,US 202318360698 A,7/27/2023,US 202318360698 A,7/27/2023,AUTOMATICALLY GENERATING A VIDEO IN WHICH A PERSON SEES AND HEARS A REPRESENTATION OF THEMSELF DELIVERING A POSITIVE MESSAGE TAILORED TO NEGATIVE FEELINGS THEY ARE PRESENTLY EXPERIENCING,"A facility for generating an audio-video sequence is described. The facility accesses one or more digital visual artifacts captured from the person's head, and uses them to create an animatable avatar. The facility receives input describing the person's emotional state, and generates a textual script conveying a positive message with respect to the person's described emotional state. The facility subjects the script to a text-to-speech tool to obtain a speech audio sequence reciting the script, and animates the avatar in a manner coordinated with the speech audio sequence to obtain a video sequence. The facility combines the speech audio sequence and the video sequence to obtain an audio-video sequence, and makes the audio-video sequence available to the person.",PROVIDENCE ST JOSEPH HEALTH,SRINIVASA SRINATH MALUR;;NAGUBANDI SAI RAHUL;;RIOS CATHLYN FRAGUELA,PROVIDENCE ST. JOSEPH HEALTH (2023-07-05),https://lens.org/039-255-925-767-618,Patent Application,yes,0,0,2,039-255-925-767-618;;150-746-343-357-360,US;;WO,2,039-255-925-767-618;;150-746-343-357-360,US;;WO,0,G06V40/30;;G06F40/56;;G10L13/00;;G06F40/30;;G10L13/02;;G16H20/70;;G16H40/63;;G16H40/67;;G16H10/20;;G16H50/20;;G16H50/70;;G06T13/205;;G06T13/40;;G10L13/02;;G06F40/56;;G06V40/30,G06T13/20;;G06F40/56;;G06T13/40;;G06V40/30;;G10L13/02,,0,0,,,,PENDING
411,US,A1,US 2025/0157242 A1,081-606-372-872-163,5/15/2025,2025,US 202418656440 A,5/6/2024,US 202418656440 A;;US 202318506929 A,11/10/2023,DOMAIN-SPECIFIC PROCESSING AND INFORMATION MANAGEMENT USING MACHINE LEARNING AND ARTIFICIAL INTELLIGENCE MODELS,"Systems and techniques are provided for automatically analyzing and processing domain-specific image artifacts and document images. A process can include obtaining a plurality of document images comprising visual representations of structured text. An OCR-free machine learning model can be trained to automatically extract text data values from different types or classes of document image, based on using a corresponding region of interest (ROI) template corresponding to the structure of the document image type for at least initial rounds of annotations and training. The extracted information included in an inference prediction of the trained OCR-free machine learning model can be reviewed and validated or corrected correspondingly before being written to a database for use by one or more downstream analytical tasks.",32HEALTH INC,RAMASWAMY DEEPAK;;KOMPELLA RAVINDRA;;PUTHUSSERY SHAJU,32HEALTH INC (2024-03-02),https://lens.org/081-606-372-872-163,Patent Application,yes,3,0,3,081-606-372-872-163;;019-539-876-925-403;;090-641-292-641-461,US,3,090-641-292-641-461;;019-539-876-925-403;;081-606-372-872-163,US,0,G06V30/19173;;G06N3/08;;G06N3/045;;G06V30/412;;G06V30/1448;;G06V30/19167;;G06V30/19147;;G06V30/147;;G06V10/82;;G06V30/191;;G06V30/414;;G06V30/147;;G06F2218/08;;G06N20/00;;G06T2207/20081;;G06V10/22;;G06V10/82,G06V30/414;;G06N20/00;;G06V10/22;;G06V10/82;;G06V30/146;;G06V30/19,,1,0,,,(Donut: Document Understanding Transformer without OCR) (Year: 2021),ACTIVE
412,WO,A1,WO 2025/102041 A1,039-794-398-080-955,5/15/2025,2025,US 2024/0055364 W,11/11/2024,US 202363597956 P,11/10/2023,USER EMBEDDING MODELS FOR PERSONALIZATION OF SEQUENCE PROCESSING MODELS,A machine-learned system for modeling contextual data such as long user historical data is provided. The system includes a machine-learned embedding model and a machine-learned sequence processing model. The machine-learned embedding model is configured to receive contextual data comprising a plurality of items associated with a user and generate a plurality of embeddings representing the plurality of items. The machine-learned sequence processing model is configured to receive a task instruction and generate one or more embeddings representing the task instruction. The sequence processing model is configured to process an input comprising the plurality of embeddings representing the plurality of items and the one or more embeddings representing the task instruction to generate an output for the task instruction that is based on the input.,GOOGLE LLC,AGGARWAL VIKRAM;;SODHI SUKHDEEP SINGH;;JASH AMBARISH;;KUZMIN DMYTRO VIKTOROVYCH;;DODDAPANENI SUMANTH;;SAYANA KRISHNA,,https://lens.org/039-794-398-080-955,Patent Application,yes,1,0,1,039-794-398-080-955,WO,1,039-794-398-080-955,WO,0,G06F40/30;;G06N3/08;;G06N3/084;;G06N3/044;;G06N3/045,G06F40/30;;G06N3/08;;G06N3/084,,9,5,030-024-444-811-168;;117-929-228-389-733;;103-212-983-826-945;;120-047-640-592-980;;084-641-049-769-580,10.18653/v1/2024.acl-long.399;;10.18653/v1/2021.emnlp-main.243;;pmc8371605;;34265844;;10.1038/s41586-021-03819-2;;10.18653/v1/d18-2012;;10.18653/v1/2020.emnlp-main.83,"SALEMI ALIREZA ET AL: ""LaMP: When Large Language Models Meet Personalization"", PROCEEDINGS OF THE 62ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (VOLUME 1: LONG PAPERS), 19 May 2023 (2023-05-19), pages 7370 - 7392, XP093250784, DOI: 10.18653/v1/2024.acl-long.399;;LESTER BRIAN ET AL: ""The Power of Scale for Parameter-Efficient Prompt Tuning"", PROCEEDINGS OF THE 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, 2 September 2021 (2021-09-02), pages 3045 - 3059, XP093196098, Retrieved from the Internet <URL:https://arxiv.org/pdf/2104.08691> [retrieved on 20250217], DOI: 10.18653/v1/2021.emnlp-main.243;;ZHOU ET AL.: ""Mixture-of-Experts with Expert Choice Routing"", ARXIV: 2202.09368V2, 14 October 2022 (2022-10-14);;DOSOVITSKIY ET AL.: ""An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"", ARXIV-.2010.11929N-2, 3 June 2021 (2021-06-03);;AGOSTINELLI ET AL.: ""MusicLM: Generating Music From Text"", ARXIV:2301.11325V1, 26 January 2023 (2023-01-26);;JUMPER ET AL.: ""Highly accurate protein structure prediction with AlphaFold"", NATURE, vol. 596, 26 August 2021 (2021-08-26), pages 583, XP055888904, DOI: 10.1038/s41586-021-03819-2;;KUDO ET AL.: ""SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"", PROCEEDINGS OR TIIE 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (SYSTEM DEMONSTRATIONS, 31 October 2018 (2018-10-31), pages 66 - 71;;VASWANI ET AL.: ""Attention Is All You Need"", ARXIV: 1706.03762V7, 2 August 2023 (2023-08-02);;SAHARIA ET AL.: ""Non-Autoregressive Machine Translation with Latent Alignments"", ARXRV:2004.07437V3, 16 November 2020 (2020-11-16)",PENDING
413,WO,A1,WO 2024/207009 A1,046-206-981-621-827,10/3/2024,2024,US 2024/0022528 W,4/1/2024,US 202363456300 P,3/31/2023,EFFICIENT USE OF TOOLS BY LANGUAGE MODELS,"Provided are computer systems that enable machine-learned language models to choose the correct structural tools to leverage when solving challenging tasks. In particular, current language models rely heavily on internal knowledge to solve all downstream tasks, which causes hallucination and ungrounded answers. In contrast, proposed herein is a new tool-using framework for language models, which enables the language models to smartly route a query to the most relevant pre-defined skills.",GOOGLE LLC,DAI ANDREW MINGBO;;LIU RUIBO;;CHU ERIC;;ZHOU DENGYONG;;WEI JASON WENG,,https://lens.org/046-206-981-621-827,Patent Application,yes,1,0,1,046-206-981-621-827,WO,1,046-206-981-621-827,WO,0,G06F40/30;;G06F40/216;;G06F40/279;;G06F16/243,G06F16/33;;G06F40/00;;G06F40/284;;G06F40/40,,0,0,,,,PENDING
414,US,A1,US 2025/0244960 A1,015-946-496-742-202,7/31/2025,2025,US 18427278,1/30/2024,,,Generative Model Integration with Code Editing,Aspects of the disclosed technology include computer-implemented systems and methods for integrating machine-learned generative models with code editing tools. A code editor is configured to execute computer-executable code within code cells of a code editor interface including a first interface portion and a second interface portion. The interface portion is configured to receive user input for defining and editing a set of code cells within the first interface portion. Each code cell of the set of code cells is independently executable by the code editor application. The second interface portion is configured to receive user input for defining and submitting user queries to a machine-learned generative model. The code editor is configured to modify at least one code cell of the set of cells based at least in part on an output of the machine-learned generative model in response to a user query.,Google LLC,Piyush Arora;;Zi Yun;;Karthik Kumar Ramachandran;;Salem Elie Haykal,,https://lens.org/015-946-496-742-202,Patent Application,yes,0,0,1,015-946-496-742-202,US,1,015-946-496-742-202,US,0,G06F8/33,G06F8/33,,0,0,,,,UNKNOWN
415,US,A1,US 2024/0143296 A1,183-909-362-922-047,5/2/2024,2024,US 202318393473 A,12/21/2023,US 202318393473 A,12/21/2023,METHODS AND APPARATUS FOR COMBINING CODE LARGE LANGUAGE MODELS (LLMs) WITH COMPILERS,"Example apparatus disclosed includes interface circuitry, machine readable instructions, and programmable circuitry to at least one of instantiate or execute the machine readable instructions to receive an input source code by a code large language model (LLM), generate one or more code representations of the input source code, analyze the one or more code representations of the input source code, and compile the one or more code representations of the input source code into one or more computer executable instructions.",INTEL CORP,HASABNIS NIRANJAN,INTEL CORPORATION (2023-12-21),https://lens.org/183-909-362-922-047,Patent Application,yes,0,6,2,095-240-281-429-718;;183-909-362-922-047,US;;DE,2,095-240-281-429-718;;183-909-362-922-047,US;;DE,0,G06F8/41;;G06F8/41,G06F8/41,,0,0,,,,PENDING
416,US,B2,US 12354146 B2,095-580-504-783-628,7/8/2025,2025,US 202418441731 A,2/14/2024,US 202418441731 A;;US 202318173449 A;;US 202263433559 P,12/19/2022,Search with machine-learned model-generated queries,"Systems and methods for searching using machine-learned model-generated outputs can provide a user with a medium for generating a theoretical dataset that can then be matched to a real world example. The systems and methods can include selecting a plurality of terms, which can be utilized to generate a prompt input that can be processed by a dataset generation model to generate a plurality of model-generated datasets. A selection can then be received that selects a particular model-generated database to utilize to query a database.",GOOGLE LLC,SADR ARASH;;QUAN ALICE AU,,https://lens.org/095-580-504-783-628,Granted Patent,yes,32,0,7,147-336-821-419-299;;020-856-785-910-18X;;095-580-504-783-628;;152-670-532-953-473;;001-894-058-473-612;;018-837-623-583-440;;064-972-251-294-567,US;;KR;;JP,25,092-752-140-357-87X;;101-536-351-310-156;;147-336-821-419-299;;020-856-785-910-18X;;064-972-251-294-567;;018-820-943-665-188;;152-670-532-953-473;;128-168-808-809-998;;137-535-001-045-358;;194-753-328-201-183;;018-837-623-583-440;;183-025-609-848-026;;128-593-066-611-591;;037-334-632-529-459;;001-894-058-473-612;;072-371-957-579-835;;083-629-119-266-148;;129-033-279-526-770;;055-945-487-841-432;;139-505-968-682-678;;095-580-504-783-628;;022-721-660-809-533;;008-899-978-097-856;;018-878-195-791-630;;026-017-993-832-519,US;;WO;;EP;;KR;;CN;;JP,0,G06Q30/0621;;G06Q30/0643;;G06Q30/0627;;G06F16/532;;G06F16/538;;G06F16/54;;G06F16/5854;;G06N3/0475;;G06Q30/0621;;G06Q30/0643;;G06Q30/0627,G06Q30/00;;G06Q30/0601,,11,0,,,"Sheoran, Nikhil, et al. “Conditional generative model based predicate-aware query approximation.” Proceedings of the AAAI Conference on Artificial Intelligence. vol. 36. No. 8. 2022. (Year: 2022).;;Saharia, Chitwan, et al. “Photorealistic text-to-image diffusion models with deep language understanding.” Advances in neural information processing systems 35 (2022) (Year: 2022).;;Chang, C-C., C-C. Lin, and Y-H. Chen. “Reversible data-embedding scheme using differences between original and predicted pixel values.” IET Information Security 2.2 (2008): 35-46. (Year: 2008).;;Google Research, “Imagen: Text-to-Image Diffusion Models”, Nov. 25, 2022, https://imagen.research.google/, Retrieved on Feb. 23, 2023, 18 pages.;;Google Research, “DALL-E 2”, Apr. 6, 2022, https://openai.com/dall-e-2/, Retrieved on Feb. 23, 2023, 16 pages.;;Google Research, “MUM: A new AI milestone for understanding information”, May 18, 2021, https://blog.google/products/search/introducing-mum/, Retrieved on Feb. 23, 2023, 4 pages.;;International Search Report and Written Opinion for Application No. PCT/US2023/080345, mailed Mar. 21, 2024, 16 pages.;;Kang et al., “Investigating the Potential of GAN-based Interactive Image Editing for Novel Image Search”, SSRN Electronic Journal, 16 pages.;;Tautkute et al., “I Want This Product but Different: Multimodal Retrieval with Synthetic Query Expansion”, arXiv:2102.08871v1, 10 pages.;;Strobelt et al., “Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models”, arXiv:2208.07852v1, 11 pages.;;Chinese Search Report Corresponding to Application No. 2023800212799 on Nov. 11, 2024.",ACTIVE
417,WO,A1,WO 2025/101978 A1,142-999-737-685-59X,5/15/2025,2025,US 2024/0055235 W,11/8/2024,US 202363598037 P,11/10/2023,AI-ASSISTED MEDICAL IMAGE REPORT GENERATION DISPLAY AND WORKFLOW,"Disclosed herein are systems, media, and methods for medical report generation or evaluation. Natural language processing, computer vision, large language models, or other software may be used to facilitate accurate, efficient evaluation of contemporary or historical medical reports. The present disclosure may provide particular utility in patient health diagnostics, prognostics, treatment, or monitoring.",SIRONA MEDICAL INC,LONGO MARK D;;KUCHERLAPATI SUMEDHA;;KOVALENKO KATHRYN;;DREW TRAFTON;;XIA TIANXIAO;;HAMRIC BRANDON;;THIRUNAVUKKARASU RAMASAMY;;AYERS NATHAN;;CASTNER RYAN;;HAYRE NATHA ROBERT,,https://lens.org/142-999-737-685-59X,Patent Application,yes,3,0,1,142-999-737-685-59X,WO,1,142-999-737-685-59X,WO,0,G16H15/00;;G16H30/20;;G16H10/60;;G16H30/40;;G16H50/20,G16H15/00;;G16H10/60;;G16H30/20,,0,0,,,,PENDING
418,WO,A1,WO 2024/233828 A1,003-912-148-161-275,11/14/2024,2024,US 2024/0028661 W,5/9/2024,US 202363501191 P,5/10/2023,ASSET PERFORMANCE DETERMINATION SYSTEM,"Techniques for determining a performance value of a media asset are presented herein. The performance value can be determined by the system without the system having to serve the media asset in a communication campaign. The system can include a machine-learned model that is configured to determine the performance value for the media asset. The system can receive the media asset for a communication campaign of a client account. The client account can have a plurality of features. The system can process, using a first embedding model, the media asset to generate an asset embedding vector. The system can process, using a second embedding model, the plurality of features associated with the client account to generate a feature embedding vector. The system can process, using the machine-learned model, the asset embedding vector and the feature embedding vector to generate a performance value for the media asset.",GOOGLE LLC,BOYD CHARLES BAXTER;;DAI CHENYANG,,https://lens.org/003-912-148-161-275,Patent Application,yes,7,0,10,027-155-027-138-939;;128-571-713-601-676;;039-284-787-835-354;;081-646-266-370-182;;118-582-742-376-368;;186-307-504-527-52X;;003-912-148-161-275;;006-135-388-853-102;;162-613-969-661-774;;023-103-101-057-353,US;;WO;;EP;;KR;;CN,10,027-155-027-138-939;;039-284-787-835-354;;128-571-713-601-676;;081-646-266-370-182;;118-582-742-376-368;;186-307-504-527-52X;;003-912-148-161-275;;006-135-388-853-102;;162-613-969-661-774;;023-103-101-057-353,US;;WO;;EP;;KR;;CN,0,G06Q30/0242;;G06T11/60;;G06F16/958;;G06Q30/0201;;G06Q30/0269;;G06Q50/01;;G06Q2220/00;;G06Q30/0242;;G06T11/60;;G06F16/958;;G06F16/9535;;G06Q30/0201;;G06Q30/0245;;G06Q30/0269;;G06Q50/01;;G06T1/20;;G06N3/0475;;G06Q30/0276;;G06Q2220/00;;G06T2210/12;;G06F16/9535;;G06Q30/0245,G06Q30/0241;;G06F16/583;;G06Q30/0242;;G06Q90/00,,3,1,103-212-983-826-945,pmc8371605;;34265844;;10.1038/s41586-021-03819-2,"DOSOVITSKIY ET AL.: ""An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"", ARX1V:2010.11929V2, 3 June 2021 (2021-06-03);;AGOSTINELLI ET AL.: ""MusicLM.- Generating Music From Text"", ARXIV:2301.11325V1, 26 January 2023 (2023-01-26);;JUMPER ET AL.: ""Highly accurate protein structure prediction with AlphaFold"", NATURE, vol. 596, 26 August 2021 (2021-08-26), pages 583, XP055888904, DOI: 10.1038/s41586-021-03819-2",PENDING
419,WO,A1,WO 2025/160559 A1,162-868-072-440-795,7/31/2025,2025,US US2025/013225,1/27/2025,"US 63/6/025,444",1/26/2024,"SYSTEMS, METHODS, AND COMPUTER-ACCESSIBLE MEDIUM FOR PROVIDING AND/OR GENERATING CHARACTERISTIC ANALYSIS OF GENAI SYSTEMS","Exemplary systems, methods, and computer-accessible medium are provided that can explain generative Al (""gen AI) system behavior. Thus, the exemplary systems, methods, and computer-accessible medium can be provided that supply a prompt to a genAI system, determine at least one characteristic in an output generated by the genAI system, and determine at least one unit within the prompt that caused the characteristic(s) to be present in the output.","NEW YORK UNIVERSITY;;PROVOST, Foster;;SEDOC, João",,,https://lens.org/162-868-072-440-795,Patent Application,yes,0,0,1,162-868-072-440-795,WO,1,162-868-072-440-795,WO,0,,G06N3/08;;G06N5/022;;G06N3/006;;G06N3/045,,0,0,,,,UNKNOWN
420,EP,A1,EP 4567633 A1,048-215-968-794-296,6/11/2025,2025,EP 24216555 A,11/29/2024,US 202318533604 A,12/8/2023,MODIFIED WEBPAGE CODE GENERATION FOR CUSTOMIZED HOMEPAGES,"Some aspects relate to technologies for using a generative model to customize homepages. In accordance with some aspects, webpage code for a home page is accessed. Additionally, a prompt is received to modify the homepage to provide a customized homepage. A generative model is caused to generate modified webpage code using the prompt and the webpage code. The modified webpage code is transmitted, over a network to a client device, for rendering the customized homepage on the client device.",EBAY INC,KHADIVI SHAHRAM;;HEROLD CHRISTIAN KLAUS,,https://lens.org/048-215-968-794-296,Patent Application,yes,1,0,3,048-215-968-794-296;;196-812-039-361-375;;147-595-377-262-93X,US;;EP;;CN,3,048-215-968-794-296;;196-812-039-361-375;;147-595-377-262-93X,US;;EP;;CN,0,G06F16/9577;;G06F16/986;;G06F8/35;;G06F11/3624,G06F16/957;;G06F16/958,,0,0,,,,PENDING
421,US,A1,US 2025/0094820 A1,060-370-569-020-394,3/20/2025,2025,US 202418824166 A,9/4/2024,US 202418824166 A;;US 202363538671 P,9/15/2023,ENABLING DEVICE CONTROL PLANNING CAPABILITIES OF SMALL LANGUAGE MODEL,"A method for enabling an improved device control capability of a small language model (SLM) transferrable to a hub device configured to be operable by a user in an environment, is disclosed. The method includes performing a fine-tuning the SLM based on a data set including base plans and contrastive plans; generating computer codes corresponding to the fine-tuned SLM; and transferring the generated computer codes to the hub device to be connected with a group of the electronic devices in the environment.",SAMSUNG ELECTRONICS CO LTD,PAUL SUDIPTA;;ZHANG LINGYU;;SHEN YILIN;;JIN HONGXIA,SAMSUNG ELECTRONICS CO. LTD (2024-08-28),https://lens.org/060-370-569-020-394,Patent Application,yes,0,0,2,060-370-569-020-394;;106-466-572-701-100,US;;WO,2,060-370-569-020-394;;106-466-572-701-100,US;;WO,0,G06N3/096;;G06N3/096,G06N3/096,,0,0,,,,PENDING
422,US,A1,US 2025/0200440 A1,013-410-880-469-177,6/19/2025,2025,US 202418981061 A,12/13/2024,US 202418981061 A;;US 202363610866 P,12/15/2023,Aligning Sequence Processing Models with Recommendation Knowledge,"The present disclosure provides systems and methods that align sequence processing models with recommendation knowledge. Example training systems can generate natural language prompts, which can be referred to as ‘auxiliary prompts’, that encode different types of recommendation-related knowledge, such as item attributes and user preferences. These auxiliary prompts encode into natural language format various operations and losses that can be used to impart recommendation knowledge to a sequence processing model, including item embedding, Bayesian personalized ranking (BPR), and masked item modeling.",GOOGLE LLC,SATHIAMOORTHY MAHESWARAN;;MEHTA NIKHIL;;YI XINYANG;;CAO YUWEI;;HULIKAL KESHAVAN RAGHUNANDAN;;HONG LICHAN;;HELDT LUKASZ ANDRZEJ;;CHI ED HUAI-HSIN,GOOGLE LLC (2024-01-31),https://lens.org/013-410-880-469-177,Patent Application,yes,0,0,2,013-410-880-469-177;;165-604-008-767-179,US;;CN,2,013-410-880-469-177;;165-604-008-767-179,US;;CN,0,G06N20/00;;G06N20/00,G06N20/00,,0,0,,,,PENDING
423,US,A1,US 2025/0077204 A1,168-383-364-605-70X,3/6/2025,2025,US 202318458926 A,8/30/2023,US 202318458926 A,8/30/2023,SOFTWARE LIBRARY USAGE OPTIMIZATION,"An example operation may include one or more of training a generative artificial intelligence (GenAI) model based on execution of the GenAI model on software libraries and descriptions of intent of the software libraries, receiving a first set of software libraries and a second set of software libraries, identifying a first software library within the first set of software libraries that includes redundant functionality with a second software library within the second set of software libraries based on execution of a generative artificial intelligence (GenAI) model on the first and second sets of libraries, and displaying an identifier of the first and second software libraries via a user interface.",TORONTO DOMINION BANK,GUTTRIDGE FRANCIS JAMES ALEXANDER;;D'AGOSTINO DINO PAUL;;PRATTEN A WARREN;;MOHAMMED SHAHZAD;;CHIKKALAVALASA ARVIND;;NAWAZ WAQAS,,https://lens.org/168-383-364-605-70X,Patent Application,yes,4,1,1,168-383-364-605-70X,US,1,168-383-364-605-70X,US,0,G06F8/75;;G06F8/4435;;G06F8/36;;G06F8/75;;G06F8/4435,G06F8/41;;G06F8/75,,0,0,,,,PENDING
424,US,A1,US 2025/0077189 A1,012-842-313-264-733,3/6/2025,2025,US 202318458950 A,8/30/2023,US 202318458950 A,8/30/2023,SERVICE DESIGN COORDINATION AMONG DEVELOPERS,"An example operation may include one or more of receiving a first code base and a second code base from a software repository, wherein each of the first and second code bases comprise source code of a plurality of different software programs, identifying a source code within the first code base that is interdependent with a source code within the second code base based on execution of a generative artificial intelligence (GenAI) model on the first and second code bases, determining a software component to connect the source code within the first code base to the source code within the second code base, and displaying an identifier of the software component via a user interface.",TORONTO DOMINION BANK,GUTTRIDGE FRANCIS JAMES ALEXANDER;;D'AGOSTINO DINO PAUL;;PRATTEN A WARREN;;MOHAMMED SHAHZAD;;CHIKKALAVALASA ARVIND;;NAWAZ WAQAS,,https://lens.org/012-842-313-264-733,Patent Application,yes,24,0,1,012-842-313-264-733,US,1,012-842-313-264-733,US,0,G06F8/77;;G06F8/20;;G06F8/36;;G06F8/77;;G06F8/20,G06F8/20;;G06F8/77,,0,0,,,,PENDING
425,WO,A1,WO 2025/006089 A1,030-716-526-103-429,1/2/2025,2025,US 2024/0030374 W,5/21/2024,US 202318217313 A,6/30/2023,MULTIMODAL DIALOGS USING LARGE LANGUAGE MODEL(S) AND VISUAL LANGUAGE MODEL(S),"Implementations relate to leveraging large language model(s) (LLMs) and vision language model(s) (VLMs) to facilitate human-to-computer dialogs. In various implementations, one or more digital images may be processed using one or more VLMs to generate VLM output indicative of a state of an environment. An LLM prompt may be assembled based on the VLM output and a natural language input. The LLM prompt may be processed using one or more LLMs to generate content that is responsive to the natural language input. The content that is responsive to the natural language input may subsequently be rendered at one or more output devices.",GOOGLE LLC,NGUYEN TUAN;;VOLNOV SERGEI;;TRUONG WILLIAM A;;YE YUNFAN;;MITHANI SANA;;JOSHI NEEL;;GALATA ALEXEY;;CHUANG TZU-CHAN;;CHEN LIANG-YU;;HUANG QIONG;;SHAH KRUNAL;;CHITTURU SAI ADITYA,,https://lens.org/030-716-526-103-429,Patent Application,yes,0,0,2,163-097-549-162-686;;030-716-526-103-429,US;;WO,2,163-097-549-162-686;;030-716-526-103-429,US;;WO,0,G06F40/35;;G06F40/284;;G06F40/216;;G06V10/82;;G06F40/40;;G06F40/30;;G06V10/82;;G06F40/35,G06F40/35;;G06F40/216;;G06F40/284;;G06V10/82,,4,0,,,"ANDY ZENG ET AL: ""Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 27 May 2022 (2022-05-27), XP091225344;;AHN MICHAEL ET AL: ""Do as i can and not as i say: grounding language in robotic affordances"", ARXIV (CORNELL UNIVERSITY), 16 August 2022 (2022-08-16), Ithaca, XP093107123, Retrieved from the Internet <URL:https://arxiv.org/abs/2204.01691v2> [retrieved on 20231129], DOI: 10.48550/ARXIV.2204.01691;;YAOBO LIANG ET AL: ""TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 29 March 2023 (2023-03-29), XP091470912;;EVAN KING ET AL: """"Get ready for a party"": Exploring smarter smart spaces with help from large language models"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 24 March 2023 (2023-03-24), XP091467921",PENDING
426,US,A1,US 2025/0139417 A1,063-422-482-607-003,5/1/2025,2025,US 202318495172 A,10/26/2023,US 202318495172 A,10/26/2023,WORKFLOW ASSISTANT WITH GENERATIVE ARTIFICIAL INTELLIGENCE,"Certain aspects of the disclosure pertain to workflow creation assistance with generative artificial intelligence. A problem statement can be received that is specified by a user in a natural language. At least one machine learning model can infer a workflow template that maps to the problem statement. Workflow template parameters can be determined, and parameter values generated based on the problem statement. Additional interaction with the user in the natural language can be performed to request and receive further data associated with the workflow template with the at least one machine-learning model. Subsequently, the workflow template can be populated with generated parameter values and provided to a workflow system that generates a workflow based on the workflow template.",INTUIT INC,TRIPATHY SHYAMALENDU;;MONDAL BIDISHA;;TOLANI BHAVISHYA;;AGARWAL YASH;;BAKE MAHAMED ZUBAIR,INTUIT INC (2024-02-08),https://lens.org/063-422-482-607-003,Patent Application,yes,0,0,1,063-422-482-607-003,US,1,063-422-482-607-003,US,0,G06N3/047;;G06N20/00;;G06N3/047,G06N3/047,,0,0,,,,PENDING
427,WO,A1,WO 2025/072932 A1,192-392-422-385-990,4/3/2025,2025,US 2024/0049246 W,9/30/2024,US 202363586200 P,9/28/2023,MULTIMODAL AUTOREGRESSIVE MODEL FOR TIME-ALIGNED AND CONTEXTUAL MODALITIES,"The present disclosure provides multimodal processing models that decouple the multimodal modeling, dividing it into separate, focused autoregressive models, processing the inputs according to the characteristics of the modalities and their sampling rates. More specifically, example aspects of the present disclosure are directed a multimodal processing model that includes an autoregressive component for input data belonging to time-synchronized modalities, and an autoregressive component for input data belonging to modalities which are not necessarily aligned in time but are still sequential.",GOOGLE LLC,NOBLE ISAAC;;PIERGIOVANNI ANTHONY J;;KIM DAHUN;;RYOO MICHAEL SAHNGWON;;ANGELOVA ANELIA,,https://lens.org/192-392-422-385-990,Patent Application,yes,2,0,1,192-392-422-385-990,WO,1,192-392-422-385-990,WO,0,G06N3/045;;G06N5/01;;G06N20/00;;G06N3/084;;G06N3/044,G06N3/045;;G06N3/084;;G06N5/01;;G06N20/00,,9,4,019-897-623-501-397;;103-212-983-826-945;;120-047-640-592-980;;084-641-049-769-580,10.1109/iccv.2019.00769;;pmc8371605;;34265844;;10.1038/s41586-021-03819-2;;10.18653/v1/d18-2012;;10.18653/v1/2020.emnlp-main.83,"HASSAN AKBARI ET AL: ""VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 13 August 2021 (2021-08-13), XP091025255;;MA SHUANG ET AL: ""Unpaired Image-to-Speech Synthesis With Multimodal Information Bottleneck"", 2019 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), IEEE, 27 October 2019 (2019-10-27), pages 7597 - 7606, XP033723410, DOI: 10.1109/ICCV.2019.00769;;ZHOU ET AL.: ""Mixture-of Experts with Expert Choice Routing"", ARXIV:2202.09368V2, 14 October 2022 (2022-10-14);;DOSOVITSKIY ET AL.: ""An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"", ARXIV:2010.11929V2, 3 June 2021 (2021-06-03);;AGOSTINELLI ET AL.: ""MusicIM. Generating Music From Text"", ARXIV:2301.11325V1, 26 January 2023 (2023-01-26);;JUMPER ET AL.: ""Highly accurate protein structure prediction with AlphaFold"", 596 NATURE 583, 26 August 2021 (2021-08-26);;KUDO ET AL.: ""SentencePiece: A simple and language independent subword tokenizer and detokenizerfor Neural Text Processing"", PROCEEDINGS OF THE 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, 31 October 2018 (2018-10-31), pages 66 - 71, Retrieved from the Internet <URL:https://aclanthology.org/D18-2012.pdf>;;VASWANI ET AL., ATTENTION IS ALL YOU NEED, ARMV, 2 August 2023 (2023-08-02);;SAHARIA ET AL.: ""Non-Autoregressive Machine Translation with Latent Alignments"", ARXIV:2004.07437V3, 16 November 2020 (2020-11-16)",PENDING
428,US,A1,US 2024/0354321 A1,100-579-062-745-624,10/24/2024,2024,US 202318360431 A,7/27/2023,US 202318360431 A;;US 202363496763 P,4/18/2023,TOOL FOR PROVIDING CONTEXTUAL DATA FOR NATURAL LANGUAGE QUERIES,"Techniques and systems are described that perform automated identification and retrieval of contextual information for quick and accurate processing of user queries by artificial intelligence generative models. The techniques include receiving a natural language (NL) query associated with a user identifier (ID) and obtaining, using a first NL generative model, contextual data that is pertinent to the NL query and is associated with the user ID. The techniques further include generating an augmented NL query that is based on the NL query and the contextual data. The techniques include communicating the augmented NL query to a recipient that includes the first NL generative model, a second NL generative model, or a user session associated with the user ID.",TWILIO INC,KUNDEL DOMINIK;;MORICH IAN;;PARTRIDGE BRIAN,TWILIO INC (2023-08-08),https://lens.org/100-579-062-745-624,Patent Application,yes,39,0,1,100-579-062-745-624,US,1,100-579-062-745-624,US,0,G06F16/3344;;G06F16/3344,G06F16/33,,0,0,,,,PENDING
429,US,B2,US 12300274 B2,184-573-031-161-378,5/13/2025,2025,US 202318449801 A,8/15/2023,US 202318449801 A;;US 202318149492 A,1/3/2023,Content system with user-input based video content generation feature,"In one aspect, an example method includes (i) obtaining a first segment of video content; (ii) outputting for presentation, the obtained first segment; (iii) after outputting for presentation the obtained first segment, causing a user to be prompted for user-input data; (iv) receiving user-input data provided in response to the prompting; (v) using at least the received user-input data to synthetically generate a second segment of the video content, wherein the generated second segment is static, non-interactive content; and (vi) outputting for presentation, the generated second segment.",ROKU INC,LUCAS KATIE LAUREN;;RAMESH SUNIL;;CUTTER MICHAEL;;PINKERTON CHARLES BRIAN;;LEVITIAN KARINA,ROKU INC (2022-12-21),https://lens.org/184-573-031-161-378,Granted Patent,yes,13,0,3,197-719-302-327-896;;190-083-001-986-497;;184-573-031-161-378,US,3,197-719-302-327-896;;190-083-001-986-497;;184-573-031-161-378,US,0,H04N21/8456;;H04N21/854;;H04N21/4667;;H04N21/4755;;H04N21/4532;;G06N20/00;;H04N21/251;;G11B27/031;;G11B27/031;;H04N21/8456;;H04N21/4667;;H04N21/4532;;H04N21/4755,G11B27/031;;H04N21/45;;H04N21/466;;H04N21/475;;H04N21/845,,0,0,,,,ACTIVE
430,US,A1,US 2025/0246207 A1,049-406-147-525-820,7/31/2025,2025,US 19184738,4/21/2025,,,Content System with User-Input Based Video Content Generation Feature,"In one aspect, an example method includes (i) obtaining a first segment of video content; (ii) outputting for presentation, the obtained first segment; (iii) after outputting for presentation the obtained first segment, causing a user to be prompted for user-input data; (iv) receiving user-input data provided in response to the prompting; (v) using at least the received user-input data to synthetically generate a second segment of the video content, wherein the generated second segment is static, non-interactive content; and (vi) outputting for presentation, the generated second segment.","Roku, Inc.",Katie Lauren Lucas;;Sunil Ramesh;;Michael Cutter;;Charles Brian Pinkerton;;Karina Levitian,,https://lens.org/049-406-147-525-820,Patent Application,yes,0,0,1,049-406-147-525-820,US,1,049-406-147-525-820,US,0,G11B27/031;;H04N21/4532;;H04N21/4667;;H04N21/4755;;H04N21/8456,G11B27/031;;H04N21/45;;H04N21/466;;H04N21/475;;H04N21/845,,0,0,,,,UNKNOWN
431,US,A1,US 2025/0117479 A1,054-649-346-589-875,4/10/2025,2025,US 202318377710 A,10/6/2023,US 202318377710 A,10/6/2023,Automatic Binary Code Understanding,"The description relates to automated binary code summarization. In one example, a binary code summarization tool receives binary code and combines the received binary code with natural language in a prompt for a large language model (LLM). The binary code summarization tool receives a semantic summarization from the LLM relating to the received binary code and evaluates the new semantic summarization for malicious functionality in the received binary code.",MICROSOFT TECHNOLOGY LICENSING LLC,YANG WEIWEI;;JIN XIN;;LARSON JONATHAN KARL;;WALKER MICHAEL T;;FRAZE DUSTIN RICHARD,MICROSOFT TECHNOLOGY LICENSING LLC (2023-10-18),https://lens.org/054-649-346-589-875,Patent Application,yes,3,0,2,054-649-346-589-875;;045-601-426-743-837,US;;WO,2,054-649-346-589-875;;045-601-426-743-837,US;;WO,0,G06N20/00;;G06F40/00;;G06F21/562;;G06F8/75;;G06F8/74;;G06F8/73;;G06F21/563;;G06F21/577;;G06N3/08;;G06F21/563,G06F21/56,,1,1,192-634-364-205-929,10.1109/ase56229.2023.00099,"Xiong Jiaqi et al “HexT5: Unified Pre-Training for Stripped Binary Code Information Inference” 09/11/2023 2023 38th IEEE/ACM International Conference on Automated Software Engineering, IEEE pg.774-798 https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10298504&tag=1 (Year: 2023)",PENDING
432,US,B1,US 12124932 B1,077-869-383-900-326,10/22/2024,2024,US 202418599955 A,3/8/2024,US 202418599955 A,3/8/2024,Systems and methods for aligning large multimodal models (LMMs) or large language models (LLMs) with domain-specific principles,A system and method aligns generative artificial intelligence (a large language model (LLM) or a large multimodal model (LMM) with the principles of a specific domain so that the generative artificial intelligence is better able to respond to a user query in the specific domain. The system and method may post-train an already trained generative artificial intelligence system or fine tune the training of the generative artificial intelligence system to align that generative artificial intelligence system with the principles of the specific domain. The system and method may be used to align the generative artificial intelligence system to a plurality of different domains.,SEEKR TECH INC,POULIS STEFANOS;;CLARK ROBIN J;;CONDO PATRICK C,SEEKR TECHNOLOGIES INC (2024-03-25),https://lens.org/077-869-383-900-326,Granted Patent,yes,79,1,1,077-869-383-900-326,US,3,176-778-748-892-548;;077-869-383-900-326;;053-361-459-194-969,US,0,G06N20/00;;G06N3/045;;G06N3/08;;G06N20/00,G06N20/00,,35,8,061-422-655-369-830;;188-602-268-229-356;;112-553-588-148-808;;178-391-712-947-101;;119-264-444-547-811;;117-249-951-482-372;;040-308-993-975-429;;007-036-730-433-852,10.1162/tacl_a_00530;;10.25172/smustlr.27.1.3;;10.1145/3630106.3658979;;10.18653/v1/2023.findings-emnlp.68;;10.18653/v1/2023.trustnlp-1.12;;10.2139/ssrn.4874670;;10.18653/v1/2023.findings-emnlp.97;;10.18653/v1/2023.findings-emnlp.182,"Sun, “Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision”, 37th Conference on Neural Information Processing Systems, 2023. (Year: 2023).;;Siriwardhana, “Improving the Domain Adaptation of Retrieval Augmented Generation (RAG) Models for Open Domain Question Answering”, Transactions of the Association for Computational Linguistics, vol. 11, pp. 1-17, 2023. (Year: 2023).;;Baulepur, “Aligning Language Models with Factuality and Truthfulness” Thesis submitted in partial fulfillment of Bachelor of Science in Computer Science, University of Illinois At Urbana-Champaign, 2023, 50 pages.;;Azaria, et al., “The Internal State of an LLM Knows When its Lying”, School of Computer Science, Ariel University, Israel and Machine Learning Dept., Carnegie Mellon University, Pittsburgh, PA, Apr. 2023, 10 pages.;;Lee, et al., “Linguistic Properties of Truthful Response,” University of Pennsylvania, PA, USA., Jun. 2023, 6 pages.;;Poulis, “Algorithms for Interactive Machine Learning”, Dissertation submitted in partial fulfillment of degree of Doctor of Philosophy in Computer Science, University of California, San Diego, 2019, 148 pages.;;Yang, et al., “RefGPT: Reference—Truthful & Customized Dialogues Generation by GPTs and for GPTs”, Shanghai Jiao Tong University, Hong Kong Polytechnical University, Beijing University of Posts and Telecommunications, May 2023, 20 pages.;;Pan, et al., “On the Risk of Misinformation Pollution with Large Language Models”, National University of Singapore, University of California, Santa Barbara, University of Waterloo, MBZUAI, Zhejiang University, May 2023, 14 pages.;;McKenna, et al., “Sources of Hallucination by Large Language Models on Inference Tasks”, University of Edinburgh, Google Research, Macquarie University, May 2023, 17 pages.;;Shen, “Large Language Model Alignment: A Survey”, 2023.;;Mitra, “Agentinstruct: Toward Generative Teaching with Agentic Flows”, 2024.;;Dawson, “Algorithmic Adjudication and Constitutional AI—The Promise of A Better AI Decision Making Future?”, 2024.;;Balepur, “Aligning Language Models With Factuality And Truthfulness” 2023.;;Huang, “Collective Constitutional AI: Aligning a Language Model with Public Input”, 2024.;;Bai, “Constitutional AI: Harmlessness from AI Feedback”, 2022.;;Azaria, “The Internal State of an LLM KnowsWhen its Lying”, 2023.;;Lee, “Linguistic Properties of Truthful Response”, 2023.;;Poulis, “Algorithms for Interactive Machine Learning”, 2019.;;Abiri , “Public Constitutional AI”, 2024.;;Yang, “RefGPT: Reference→Truthful & Customized Dialogues Generation by GPTs and for GPTs”, 2023.;;Pan, “On the Risk of Misinformation Pollution with Large Language Models”, 2023.;;McKenna, “Sources of Hallucination by Large Language Models on Inference Tasks”, 2023.;;Claude, “Collective Constitutional AI: Aligning a Language Model with Public Input”, 2023. Webpage: file:///Collective%20Constitutional%20AI_%20.;;“A Survey on Knowledge Distillation of Large Language Models” https://arxiv.org/pdf/2402.13116.;;“AgentInstruct: Toward Generative Teaching with Agentic Flows” https://arxiv.org/pdf/2407.03502.;;“A Closer Look at the Limitations of Instruction Tuning” https://arxiv.org/abs/2402.05119.;;“Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?” https://arxiv.org/abs/2405.05904.;;“Injecting New Knowledge into Large Language Models via Supervised Fine-Tuning” https://arxiv.org/abs/2404.00213.;;“Self-Tuning: Instructing LLMs to Effectively Acquire New Knowledge through Self-Teaching” https://arxiv.org/abs/2406.06326.;;“Knowledge Editing in Language Models via Adapted Direct Preference Optimization” https://arxiv.org/abs/2406.09920.;;“Qilin-Med: Multi-stage Knowledge Injection Advanced Medical Large Language Model”.;;“Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs” https://arxiv.org/abs/2312.05934.;;“FanOutQA: A Multi-Hop, Multi-Document Question Answering Benchmark for Large Language Models” https://arxiv.org/abs/2402.14116.;;“Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge” https://arxiv.org/abs/2403.01432.;;“RAFT: Adapting Language Model to Domain Specific RAG” https://arxiv.org/abs/2403.10131.",ACTIVE
433,US,A1,US 2025/0165238 A1,132-859-073-430-086,5/22/2025,2025,US 202418949662 A,11/15/2024,US 202418949662 A;;US 202363599662 P,11/16/2023,SYSTEM AND METHOD FOR AI-SUPPORTED DEPLOYMENT OF COMPUTING ENVIRONMENTS,"Disclosed herein are methods and systems for automated deployment of a computing environment. A natural language description of a target computing environment is received from a user. A follow-up question to the user regarding a requirement of the target computing environment is generated. The natural language description and a response to the follow-up question are transformed to a prompt for a generative model, the prompt requesting a deployment data structure defining deployment parameters of the target computing environment.",ROYAL BANK OF CANADA,JIANG KEVIN XIAOZENG;;AGRAWAL MANOJ,ROYAL BANK OF CANADA (2024-11-20),https://lens.org/132-859-073-430-086,Patent Application,yes,0,0,1,132-859-073-430-086,US,1,132-859-073-430-086,US,0,G06F8/60;;G06F8/60,G06F8/60,,0,0,,,,PENDING
434,US,A1,US 2025/0245493 A1,040-223-685-275-874,7/31/2025,2025,US 19042368,1/31/2025,,,STYLING A DIGITAL SPACE USING MULTI-MODAL IMAGE GENERATIVE ARTIFICIAL INTELLIGENCE,"A system including a processor and a non-transitory computer-readable media storing computing instructions that, when executed on the processor, cause the processor to perform certain operations: obtaining an image of a digital space; extracting a depth map and a segmentation map of the image; passing each of the depth map and the segmentation map through a respective model of two parallel image diffusion models using stable diffusion with controlled image generation; prompting a selection of a target style for the digital space; segmenting, using image segmentation, the image in a target stylized digital space; and determining, using dominant color filtering, visual images of complementary items. Other embodiments are described.","Walmart Apollo, LLC",Rushikesh Dudhat;;Nima Eshraghi;;Himani Saini;;Vadivel Palaniappan;;Deepa Mohan,,https://lens.org/040-223-685-275-874,Patent Application,yes,0,0,1,040-223-685-275-874,US,1,040-223-685-275-874,US,0,G06N3/0475;;G06N3/096,G06N3/0475;;G06N3/096,,0,0,,,,UNKNOWN
435,WO,A1,WO 2024/242745 A1,108-573-064-671-415,11/28/2024,2024,US 2024/0020607 W,3/19/2024,US 202363504424 P,5/25/2023,MULTI-MODAL HEALTH DATA ANALYSIS AND RESPONSE GENERATION SYSTEM,"Provided is a system for generating responses to health-related queries based on multi-modal health features of a patient. The responses generated by the system are conditioned on multi-modal health features associated with the patient, which can include one or more features from each of a plurality of modalities.",GOOGLE LLC,BELYAEVA ANASTASIYA;;MCLEAN CORY YUEN FU;;LEE TSZ HO;;HORMOZDIARI FARHAD;;MCDUFF DANIEL;;CUI JIAN;;CONSENTINO JUSTIN THOMAS;;SCHNEIDER LOGAN DOUGLAS;;FURLOTTE NICHOLAS A;;SHETTY SHRAVYA RAMESH;;PRABHAKARA SHRUTHI;;PATEL SHWETAK;;LIU XIN;;PATEL YOJAN;;YANG ZHUN,,https://lens.org/108-573-064-671-415,Patent Application,yes,2,0,2,108-573-064-671-415;;090-320-360-361-633,WO,2,108-573-064-671-415;;090-320-360-361-633,WO,0,G06F16/35;;G06N3/0455;;G06N3/091;;G16H50/30;;G16H50/20;;G16H50/70;;G06F16/906;;G06N3/045,G06F16/35;;G06N3/0455;;G06N3/091;;G16H50/20;;G16H50/30,,9,2,103-212-983-826-945;;084-641-049-769-580,pmc8371605;;34265844;;10.1038/s41586-021-03819-2;;10.18653/v1/2020.emnlp-main.83,"XIN LIU: ""Large Language Models are Few-Shot Health Learners"", 24 May 2023 (2023-05-24), XP093164022, Retrieved from the Internet <URL:https://arxiv.org/pdf/2305.15525> [retrieved on 20240517], DOI: 10.48550/arxiv.2305.15525;;HARSHA NORI: ""Capabilities of GPT-4 on medical challenge problems [PREPRINT]"", 12 April 2023 (2023-04-12), XP093164294, Retrieved from the Internet <URL:https://arxiv.org/pdf/2303.13375> [retrieved on 20240517], DOI: 10.48550/arXiv.2303.13375;;SIYUAN CHEN: ""LLM-empowered Chatbots for Psychiatrist and Patient Simulation: Application and Evaluation"", 23 May 2023 (2023-05-23), XP093164297, Retrieved from the Internet <URL:https://arxiv.org/pdf/2305.13614> [retrieved on 20240517], DOI: 10.48550/arxiv.2305.13614;;ZHOU ET AL., MIXTURE-OF-EXPERTS WITH EXPERT CHOICE ROUTING, X :2202.09368 2, 14 October 2022 (2022-10-14);;DOSOVITSKIY ET AL.: ""An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"", XIV:2010.1 1929 2, 3 June 2021 (2021-06-03);;AGOSTINELLI ET AL.: ""MitsicLM.- Generating Music From Text."", X :2301.11325 1, 26 January 2023 (2023-01-26);;JUMPER ET AL.: ""Highly accurate protein structure prediction with AlphaFold"", NATURE, 26 August 2021 (2021-08-26), pages 583, XP055888904, DOI: 10.1038/s41586-021-03819-2;;VASWANI ET AL., ATTENTION IS ALL YOU NEED, RXIV:1706.03762 7, 2 August 2023 (2023-08-02);;SAHARIA ET AL.: ""Non-Autoregressive Machine Translation with Latent Alignments"", RXIV:2004.07437V3, 16 November 2020 (2020-11-16)",PENDING
436,US,A1,US 2025/0139387 A1,101-670-233-376-151,5/1/2025,2025,US 202418931573 A,10/30/2024,US 202418931573 A;;US 202363594381 P,10/30/2023,SYSTEMS AND METHODS FOR TARGETED INTERACTIONS WITH COMPUTATIONAL MODELS,"Accurate prompting improves the operation, efficiency, and output of computer models, such as language models. The disclosed systems and methods improve interaction with computer models by facilitating the generation of accurate prompts for targeted interactions with computer models. For example, disclosed systems can be configured to store prompts and responses generated with computer models in session memories. The system can use information in session memories to generate combined prompts when receiving prompts that refer to previous prompts or answers. The system improves prompt accuracy by generating combined prompts—formed by combining the context from the stored information (e.g., in context sub-prompts) and instructions in the new prompt (e.g., in instructions sub-prompts). The system can generate responses based on the combined prompts allowing the computer models to leverage the context in previous interactions, without burdensome or complicated prompts, for more meaningful or accurate responses.",OPENAI OPCO LLC,JANG JUNGWON;;OUYANG WARREN;;SILBER IAN,,https://lens.org/101-670-233-376-151,Patent Application,yes,1,1,1,101-670-233-376-151,US,1,101-670-233-376-151,US,0,G06F40/289;;G06F40/284;;G06F40/40;;G06F40/40;;G06F3/0484;;G06F40/284;;G06F40/289,G06F40/40;;G06F3/0484;;G06F40/284;;G06F40/289,,0,0,,,,PENDING
437,US,A1,US 2025/0085700 A1,181-185-770-494-391,3/13/2025,2025,US 202318462661 A,9/7/2023,US 202318462661 A,9/7/2023,GENERATIVE AI FOR INDUSTRIAL AUTOMATION DESIGN ENVIRONMENT,"An integrated development environment (IDE) for designing, programming, and configuring aspects of an industrial automation system uses a generative artificial intelligence (AI) model and associated neural networks to generate portions of an industrial automation project in accordance with functional requirements provided to the industrial IDE system in intuitive formats, such as spoken or written plain language text. The system uses generative AI to translate plain language requests or functional specifications into industrial control code, human-machine interface (HMI) applications, device configuration settings, or other aspects of an industrial control project.",ROCKWELL AUTOMATION TECH INC,CARRARA ANTHONY;;OHLSEN MICHAEL J;;ANAND ASHISH;;MASARIK MATTHEW T;;GREGORY ADAM J;;WENGATZ JUSTIN;;RICHTER DANIEL T;;BAHADER OMAR A;;MAJEWSKI LORENZO;;NADER ELIE;;FERNANDES FABIANO;;JOSIPOVIC SRDJAN,ROCKWELL AUTOMATION TECHNOLOGIES INC (2023-08-21),https://lens.org/181-185-770-494-391,Patent Application,yes,0,0,1,181-185-770-494-391,US,1,181-185-770-494-391,US,0,G05B19/4183;;G05B19/41885;;G05B19/4183;;G05B19/41885,G05B19/418,,0,0,,,,PENDING
438,US,A1,US 2025/0077847 A1,170-282-488-246-517,3/6/2025,2025,US 202318459822 A,9/1/2023,US 202318459822 A,9/1/2023,GENERATIVE AI FOR INDUSTRIAL AUTOMATION CONTROL DESIGN ENVIRONMENT,"An integrated development environment (IDE) for designing, programming, and configuring aspects of an industrial automation system uses a generative artificial intelligence (AI) model and associated neural networks to generate portions of an industrial automation project in accordance with functional requirements provided to the industrial IDE system in intuitive formats, such as spoken or written plain language text. The system uses generative AI to translate plain language requests or functional specifications into industrial control code, human-machine interface (HMI) applications, device configuration settings, or other aspects of an industrial control project.",ROCKWELL AUTOMATION TECH INC,CARRARA ANTHONY;;PATEL RAHUL P;;OHLSEN MICHAEL J;;ANAND ASHISH;;MASARIK MATTHEW T;;GREGORY ADAM J;;MATHSON KURT E;;WENGATZ JUSTIN;;RICHTER DANIEL T;;BAHADER OMAR A;;MAJEWSKI LORENZO;;NADER ELIE;;FERNANDES FABIANO;;JOSIPOVIC SRDJAN,ROCKWELL AUTOMATION TECHNOLOGIES INC (2023-08-21),https://lens.org/170-282-488-246-517,Patent Application,yes,0,0,1,170-282-488-246-517,US,1,170-282-488-246-517,US,0,G05B2219/36133;;G05B19/409;;G06N3/0475;;G06N3/0475;;G05B2219/36133;;G05B19/409,G06N3/0475;;G05B19/409,,0,0,,,,PENDING
439,WO,A1,WO 2024/112887 A1,044-610-807-252-888,5/30/2024,2024,US 2023/0080910 W,11/22/2023,US 202263427332 P,11/22/2022,FORWARD-FORWARD TRAINING FOR MACHINE LEARNING,"Example implementations provide a computer-implemented method for training a machine-learned model, the method comprising: processing, using a layer of the machine-learned model, positive input data in a first forward pass; updating one or more weights of the layer to adjust, in a first direction, a goodness metric of the layer for the first forward pass; processing, using the layer, negative input data in a second forward pass; and updating the one or more weights to adjust, in a second direction, the goodness metric of the layer for the second forward pass.",GOOGLE LLC,HINTON GEOFFREY EVEREST,,https://lens.org/044-610-807-252-888,Patent Application,yes,1,2,3,160-905-397-822-078;;113-518-610-382-071;;044-610-807-252-888,WO;;EP;;CN,3,160-905-397-822-078;;113-518-610-382-071;;044-610-807-252-888,WO;;EP;;CN,0,G06N3/084;;G06N3/09;;G06N3/094;;G06N3/0475;;G06N3/047;;G06N3/045;;G06N3/048;;G06N3/0464;;G06N3/088;;G06N3/0442;;G06N5/01;;G06N7/01;;G06N20/10;;G06N3/092,G06N3/084;;G06N3/09;;G06N3/094,,4,0,,,"MUFENG TANG ET AL: ""Biologically Plausible Training Mechanisms for Self-Supervised Learning in Deep Networks"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 30 September 2021 (2021-09-30), XP091061517;;N KLAND ARILD ET AL: ""Training neural networks with local error signals"", ARXIV.ORG, 20 January 2019 (2019-01-20), Ithaca, XP093131732, Retrieved from the Internet <URL:https://proceedings.mlr.press/v97/nokland19a/nokland19a.pdf> [retrieved on 20240215], DOI: 10.48550/arXiv.1901.06656;;DELLAFERRERA GIORGIA ET AL: ""Error-driven Input Modulation: Solving the Credit Assignment Problem without a Backward Pass"", ARXIV (CORNELL UNIVERSITY), 27 January 2022 (2022-01-27), Ithaca, XP093131764, Retrieved from the Internet <URL:https://proceedings.mlr.press/v162/dellaferrera22a/dellaferrera22a.pdf> [retrieved on 20240215], DOI: 10.48550/arxiv.2201.11665;;ZHOU ET AL.: ""Mixture-of-Experts with Expert Choice Routing"", ARXIV:2202.09368V2, 14 October 2022 (2022-10-14)",PENDING
440,US,A1,US 2025/0085931 A1,041-457-432-625-678,3/13/2025,2025,US 202318462674 A,9/7/2023,US 202318462674 A,9/7/2023,GENERATIVE AI INDUSTRIAL DESIGN CODE CONVERSION,"An integrated development environment (IDE) for designing, programming, and configuring aspects of an industrial automation system uses a generative artificial intelligence (AI) model and associated neural networks to generate portions of an industrial automation project in accordance with functional requirements provided to the industrial IDE system in intuitive formats, such as spoken or written plain language text. The system uses generative AI to translate plain language requests or functional specifications into industrial control code, human-machine interface (HMI) applications, device configuration settings, or other aspects of an industrial control project.",ROCKWELL AUTOMATION TECH INC,CARRARA ANTHONY;;PATEL RAHUL P;;OHLSEN MICHAEL J;;ANAND ASHISH;;MASARIK MATTHEW T;;GREGORY ADAM J;;WENGATZ JUSTIN;;BAHADER OMAR A;;MAJEWSKI LORENZO;;NADER ELIE;;FERNANDES FABIANO,ROCKWELL AUTOMATION TECHNOLOGIES INC (2023-08-21),https://lens.org/041-457-432-625-678,Patent Application,yes,7,0,1,041-457-432-625-678,US,1,041-457-432-625-678,US,0,G06F8/33;;G06F8/35;;G06F8/311;;G06F8/33;;G06F8/311;;G06F8/35;;G06N5/00,G06F8/33;;G06F8/30;;G06F8/35,,0,0,,,,PENDING
441,WO,A1,WO 2025/085059 A1,088-947-489-029-591,4/24/2025,2025,US 2023/0035416 W,10/18/2023,US 2023/0035416 W,10/18/2023,ENHANCED TASK FUNCTIONALITY FOR SEQUENCE PROCESSING MODELS,"A machine-learned system includes a first sequence processing model configured to leverage a second sequence processing model to assist in task learning associated with a user query. The user query can be provided as input to the first sequence processing model and the system can obtain, as output of the model, a sequence processing query seeking information for performing a task associated with the user query. The system can transmit the sequence processing query to a computing system storing a second sequence processing model and obtain an output of the second sequence processing model. The system can provide the output of the second sequence processing model as input to the first sequence processing model and generate one or more responses to the user query based at least in part on an output of the first sequence processing model in response to the output of the second sequence processing model.",GOOGLE LLC,CARBUNE VICTOR;;HARTMANN FLORIAN NILS;;SHARIFI MATTHEW,,https://lens.org/088-947-489-029-591,Patent Application,yes,2,0,1,088-947-489-029-591,WO,1,088-947-489-029-591,WO,0,G06F16/243;;G06F16/3329;;G06F21/6254;;G06F40/30;;G06F40/237;;G06F40/40,G06F16/242;;G06F16/332;;G06F21/62;;G06F40/30,,7,3,103-212-983-826-945;;120-047-640-592-980;;084-641-049-769-580,pmc8371605;;34265844;;10.1038/s41586-021-03819-2;;10.18653/v1/d18-2012;;10.18653/v1/2020.emnlp-main.83,"ZHOU ET AL.: ""Mixture-of-Experts with Expert Choice Routing"", ARXIV:2202.09368V2, 14 October 2022 (2022-10-14);;DOSOVITSKIY ET AL.: ""An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"", ARXIV:2010.11929V2, 3 June 2021 (2021-06-03);;AGOSTINELLI ET AL.: ""MusicLM. Generating Music From Text"", ARXIV:2301.11325V1, 26 January 2023 (2023-01-26);;JUMPER ET AL.: ""Highly accurate protein structure prediction with AlphaFold"", NATURE, vol. 596, 26 August 2021 (2021-08-26), pages 583, XP055888904, DOI: 10.1038/s41586-021-03819-2;;KUDO ET AL.: ""SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"", PROCEEDINGS OF THE 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (SYSTEM DEMONSTRATIONS, 31 October 2018 (2018-10-31), pages 66 - 71, Retrieved from the Internet <URL:https://aclanthology.org/D18-2012.pdf>;;VASWANI ET AL.: ""Attention Is All You Need"", ARXIV:1706.03762V7, 2 August 2023 (2023-08-02);;SAHARIA ET AL.: ""Non-Autoregressive Machine Translation with Latent Alignments"", ARXLV:2004.07437V3, 16 November 2020 (2020-11-16)",PENDING
442,US,A1,US 2025/0104306 A1,155-338-365-320-859,3/27/2025,2025,US 202318472032 A,9/21/2023,US 202318472032 A,9/21/2023,DYNAMICALLY EVOLVING IMAGE BASED ON FEATURE ACTIVATION,"An example operation may include one or more of generating an image of an object based on execution of a generative artificial intelligence (GenAI) model and displaying the image via a user interface of a software application, receiving inputs via the user interface, determining that a new feature of the software application has been activated by a user account of the software application based on the received inputs, and in response to the activation of the new feature, adding additional content to the image of the object based on execution of the GenAI model on information associated with the new feature and refreshing a display of the image of the object within the user interface of the software application.",TORONTO DOMINION BANK,MASHKEVICH JESSICA,THE TORONTO-DOMINION BANK (2023-10-03),https://lens.org/155-338-365-320-859,Patent Application,yes,0,0,1,155-338-365-320-859,US,1,155-338-365-320-859,US,0,H04L9/50;;G06T11/60;;G06T13/80;;G06T11/60;;G06T13/80;;H04L9/50,G06T11/60;;G06T13/80;;H04L9/00,,0,0,,,,PENDING
443,WO,A1,WO 2024/254674 A1,054-130-144-604-036,12/19/2024,2024,CA 2024050357 W,3/22/2024,US 202363507568 P,6/12/2023,DYNAMIC NATURAL LANGUAGE PROCESSING SYSTEM FOR IMPROVED CONTEXTUAL UNDERSTANDING AND INTERACTIVE RESPONSE,"Systems and methods for contextual inference and response generation in natural language processing are disclosed. A data structure containing Knowledge Records, terms, and Relationship Types is accessed to facilitate interaction and inference. Knowledge states and uses relationship properties are employed for inference, classifying terms to generate responses. Logic and inference mechanism link Knowledge Records and Terms for response generation. Responses are tailored based on Criteria-Value Rating Pairs and user Traits, with the system adapting through learnings from user interactions and external data. The method includes storing interaction graphs and features modules for natural language understanding, interaction, response generation, and user engagement, executed on a processing unit. The system dynamically updates its Knowledgebase and refines response mechanisms, offering personalized and contextually relevant interactions in natural language. Additionally, the system provides structured contextual and criteria-value data to third-party systems such as Large Language Models (LLM)s via APIs, enhancing contextual understanding and interaction.",KAMAZOOIE DEV CORPORATION,RITCHIE BRIAN DOUGLAS;;WANG CHENGYOU;;LI KAIYANG;;CARRILLO SEIJAS GABRIEL ATILIO;;DARABIHA BEHROOZ,,https://lens.org/054-130-144-604-036,Patent Application,yes,2,0,2,054-130-144-604-036;;182-813-148-273-83X,US;;WO,2,054-130-144-604-036;;182-813-148-273-83X,US;;WO,0,G06F40/232;;G06F40/226;;G06F40/232;;G06F40/226,G06F40/35;;G06F18/241;;G06F40/56;;G06N5/04,,0,0,,,,PENDING
444,US,A1,US 2025/0111169 A1,130-110-013-396-173,4/3/2025,2025,US 202418900078 A,9/27/2024,US 202418900078 A;;US 202363586299 P,9/28/2023,MULTI-LARGE LANGUAGE MODEL SYSTEM AND METHOD,"Methods, systems, and devices for processing prompts by an array of large language models (LLMs). The system may provide the prompt to multiple LLMs. The multiple LLMs are trained on different datasets and have different knowledge and capabilities. The system receives multiple responses from the multiple LLMs, determines a rank for each of the multiple responses, the rank indicating a level of confidence of the corresponding response representing a ground truth, compares the ranks of the multiple responses, and selects the response having the best rank as the most probable ground truth response.",VERIFAI INC,SRINIVASAN SANDEEP;;SUVARNA ROHIT UDAY;;MATUS ETHAN F,VERIFAI INC (2024-08-28),https://lens.org/130-110-013-396-173,Patent Application,yes,0,0,1,130-110-013-396-173,US,1,130-110-013-396-173,US,0,G06N3/0895;;G06F40/40;;G06N3/045;;G06F40/30;;G06N3/08;;G06N3/0895;;G06F40/40,G06F40/40;;G06N3/0895,,0,0,,,,PENDING
445,US,A1,US 2025/0104059 A1,130-180-261-122-415,3/27/2025,2025,US 202318472131 A,9/21/2023,US 202318472131 A,9/21/2023,PARTIAL NFT TRANSFER BASED ON DYNAMIC USER ACTIVITY,"An example operation may include one or more of generating a dynamically-modifiable image comprising a plurality of pieces of interconnected content via an image generating model and displaying the dynamically-modifiable image via a user interface of a software application, installing a smart contract that includes an identifier of an owner of the dynamically-modifiable image on a blockchain ledger, detecting removal of a piece of content from among the plurality of pieces of interconnected content based on user inputs via the user interface, detecting addition of the removed piece of content to a different dynamically-modifiable image of a different user, and in response to the detected addition, executing an electronic payment transaction to transfer value from the owner of the dynamically-modifiable image to the different user based on the smart contract installed on the blockchain ledger.",TORONTO DOMINION BANK,MASHKEVICH JESSICA,THE TORONTO-DOMINION BANK (2023-10-03),https://lens.org/130-180-261-122-415,Patent Application,yes,5,0,1,130-180-261-122-415,US,1,130-180-261-122-415,US,0,G06N20/00;;G06Q20/363;;G06Q20/389;;G06Q20/1235;;G06N3/045;;G06F21/64;;H04L9/50;;H04L9/0891;;G06Q20/36;;G06Q20/389;;G06Q20/382,G06Q20/38;;G06Q20/36,,1,1,000-684-743-215-724,10.1109/access.2022.3215660,"Battah, Ammar, et al. ""Blockchain and NFTs for trusted ownership, trading, and access of AI models."" IEEE Access 10 (2022): 112230-112249. (Year: 2022)",PENDING
446,US,A1,US 2025/0076836 A1,005-784-965-571-847,3/6/2025,2025,US 202318459847 A,9/1/2023,US 202318459847 A,9/1/2023,GENERATIVE AI FOR INDUSTRIAL AUTOMATION DESIGN ENVIRONMENT TROUBLESHOOTING,"An integrated development environment (IDE) for designing, programming, and configuring aspects of an industrial automation system uses a generative artificial intelligence (AI) model and associated neural networks to generate portions of an industrial automation project in accordance with functional requirements provided to the industrial IDE system in intuitive formats, such as spoken or written plain language text. The system uses generative AI to translate plain language requests or functional specifications into industrial control code, human-machine interface (HMI) applications, device configuration settings, or other aspects of an industrial control project.",ROCKWELL AUTOMATION TECH INC,CARRARA ANTHONY;;PATEL RAHUL P;;ANAND ASHISH;;MASARIK MATTHEW T;;GREGORY ADAM J;;MATHSON KURT E;;WENGATZ JUSTIN;;BAHADER OMAR A;;MAJEWSKI LORENZO;;NADER ELIE;;FERNANDES FABIANO;;JOSIPOVIC SRDJAN,ROCKWELL AUTOMATION TECHNOLOGIES INC (2023-08-21),https://lens.org/005-784-965-571-847,Patent Application,yes,0,1,1,005-784-965-571-847,US,1,005-784-965-571-847,US,0,G05B19/054;;G05B19/056;;G05B19/058;;G05B19/042;;G05B19/056;;G05B19/058;;G05B19/054,G05B19/05,,0,0,,,,PENDING
447,US,A1,US 2025/0166241 A1,017-963-509-896-276,5/22/2025,2025,US 202418950898 A,11/18/2024,US 202418950898 A;;US 202363600642 P,11/17/2023,GENERATING IMAGES BY EXPANDING PROMPTS USING GENERATIVE NEURAL NETWORKS,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for generating images. In one aspect, a method comprises: obtaining an input query comprising text; processing, using prompt expansion model, a model input comprising at least the input query to generate a set of expanded prompts of the input query, wherein each of the expanded prompts describes an image in more detail than the input query; and for one or more of the expanded prompts in the set, generating, using an image generation model, a respective image that represents the expanded prompt.",GOOGLE LLC,RAMACHANDRAN DEEPAK;;KU ALEXANDER;;ANDERSON PETER JAMES;;DATTA SIDDHARTHA,GOOGLE LLC (2024-12-21),https://lens.org/017-963-509-896-276,Patent Application,yes,0,0,1,017-963-509-896-276,US,1,017-963-509-896-276,US,0,G06F16/3338;;G06T11/00;;G06F16/3338;;G06T11/00,G06T11/00;;G06F16/33,,0,0,,,,PENDING
448,US,A1,US 2024/0330796 A1,175-184-666-147-793,10/3/2024,2024,US 202318207338 A,6/8/2023,US 202318207338 A;;US 202363493800 P,4/3/2023,QUESTION GENERATION FOR GROUPS,"Methods, systems, and computer programs are presented for generating a question for a group and prompting the user to post that question. One method includes determining, for one or more groups of a user network, at least one group skill associated with the groups. A prompt is generated based on one or more user skills of a first user, including inserting at least one user skill into a prompt template to generate the prompt, where the prompt template includes a request to generate questions for the respective group. The prompt is provided as input into a generative artificial intelligence (GAI) model, a question is selected from the output of the GAI model, and a group is selected for based on the user skill inserted into the prompt template and the group skills associated with the groups. The selected question and the selected group are presented on a user interface.",MICROSOFT TECHNOLOGY LICENSING LLC,PANDEY AKANKSHA;;PATEL MIPSABEN P;;JANNU NIKHIL N;;ALANGARA RAJ SHIBU LIJACK;;DASTIDER SURJODOY GHOSH;;SETH YASHU,MICROSOFT TECHNOLOGY LICENSING LLC (2023-06-06),https://lens.org/175-184-666-147-793,Patent Application,yes,0,2,1,175-184-666-147-793,US,1,175-184-666-147-793,US,0,G06Q10/063112;;G06F40/279;;G06Q10/0639;;G06Q10/1053;;G06Q10/063112;;G06F40/279;;G06Q10/0639,G06Q10/0631;;G06F40/279;;G06Q10/0639,,0,0,,,,PENDING
449,US,A1,US 2024/0370769 A1,112-698-212-848-213,11/7/2024,2024,US 202318312518 A,5/4/2023,US 202318312518 A,5/4/2023,HALLUCINATON PREVENTION FOR LARGE LANGUAGE MODELS,"Methods and systems are disclosed herein for preventing hallucinations in machine learning models by enabling query responses based on a predefined ground truth defined by a corpus of information. The system may use multiple machine learning models. In particular, the system may receive a user query and use a machine learning model to split the user query into multiple sub-queries that would ask component questions for the query. The component questions may then be used to get accurate information for responding to the query. Once the information is identified, the hallucination prevention system may input that information into another machine learning model (for example, a large language model) with instructions to deliver the response to the query based on the identified information, but put it into a specific, desired form. In some embodiments, another machine learning model may be used to identify undesired responses based on policy and/or other requirements.",TEAM5 INC D/B/A SUPERFOCUS,SHETH TUSHAR;;COLE JORDAN;;GUPTA RAHUL;;MCWHORTER RYAN,,https://lens.org/112-698-212-848-213,Patent Application,yes,0,6,1,112-698-212-848-213,US,1,112-698-212-848-213,US,0,G06F16/243;;G06N20/00;;G06F16/243;;G06N20/00,G06N20/00;;G06F16/242,,0,0,,,,PENDING
450,WO,A1,WO 2025/144923 A1,182-809-317-956-403,7/3/2025,2025,US 2024/0061945 W,12/26/2024,US 202363616454 P,12/29/2023,ANNEALED POLICIES FOR FINETUNING SEQUENCE PROCESSING MODELS,"Provided are techniques for training sequence processing models such as, for example, so-called large language models, with improved computational efficiency. In particular, the present disclosure provides a number of training frameworks which can be referred to as annealed language policies (ALP). ALP can operate to maximize a total reward while not deviating too much from a reference model. In particular, a hyperparameter, referred to as alpha, can control a trade-off between a reward term and a regularization term included in a loss function. The alpha hyperparameter can be ""annealed"" throughout the training process.",GOOGLE LLC,FERRET JOHAN;;BACHEM OLIVIER FRÉDÉRIC;;HUSSENOT LÉONARD;;DADASHI-TAZEHOZI ROBERT;;GEIST MATTHIEU FLORENT;;PIETQUIN OLIVIER CLAUDE;;LEURENT EDOUARD;;SESSA PIER GIUSEPPE;;VIEILLARD NINO JEAN;;CIDERON GEOFFREY VIRGIL;;JACQ ALEXIS DAVID;;MOMCHEV NIKOLA MOMCHEV;;STANCZYK PIOTR MICHAŁ;;GIRGIN SERTAN;;RAMOS GAREA SABELA;;SINOPALNIKOV DANILA;;HÉLIOU AMÉLIE CATHERINE,,https://lens.org/182-809-317-956-403,Patent Application,yes,2,0,1,182-809-317-956-403,WO,1,182-809-317-956-403,WO,0,G06N3/084;;G06N3/09;;G06N3/0499;;G06N3/0475;;G06N3/0464;;G06N3/0442,G06N3/084;;G06N3/0442;;G06N3/0464;;G06N3/0475;;G06N3/09,,9,0,,,"ALEXANDRE GALASHOV ET AL: ""Information asymmetry in KL-regularized RL"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 3 May 2019 (2019-05-03), XP081271991;;ZEKUN WANG ET AL: ""Interactive Natural Language Processing"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 22 May 2023 (2023-05-22), XP091515405;;PAUL ROIT ET AL: ""Factually Consistent Summarization via Reinforcement Learning with Textual Entailment Feedback"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 31 May 2023 (2023-05-31), XP091525312;;ZHOU ET AL.: ""Mixture-of Experts with Expert Choice Routing"", ARXIV:2202.09368V2, 14 October 2022 (2022-10-14);;DOSOVITSKIY ET AL.: ""An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"", ARXIV:2010.11929V2, 3 June 2021 (2021-06-03);;AGOSTINELLI ET AL.: ""MusicIM. Generating Music From Text"", ARXIV:2301.11325V1, 26 January 2023 (2023-01-26);;JUMPER ET AL.: ""Highly accurate protein structure prediction with AlphaFold"", NATURE, vol. 583, 26 August 2021 (2021-08-26);;VASWANI ET AL.: ""Attention Is All You Need"", ARMV: 1706.03762V7, 2 August 2023 (2023-08-02);;SAHARIA ET AL.: ""Non-Autoregressive Machine Translation with Latent Alignments"", ARXIV:2004.07437V3, 16 November 2020 (2020-11-16)",PENDING
451,US,A1,US 2025/0104050 A1,013-058-262-597-489,3/27/2025,2025,US 202318472091 A,9/21/2023,US 202318472091 A,9/21/2023,DYNAMICALLY EVOLVING IMAGE BASED ON PURSUIT OF GOALS,"An example operation may include one or more of generating a unique image based on execution of an image generating model and displaying the unique image via a user interface of a software application, assigning a segment of the unique image to a goal at a first point in time based on user inputs via a user interface of the software application, monitoring account activity of a user within the software application, determining, at a second point in time, that the user is closer to the goal based on the monitored account activity of the user within the software application, and in response to the determination, increasing a size of the segment of the unique image assigned to the goal of the user.",TORONTO DOMINION BANK,MASHKEVICH JESSICA,THE TORONTO-DOMINION BANK (2023-10-03),https://lens.org/013-058-262-597-489,Patent Application,yes,31,0,1,013-058-262-597-489,US,1,013-058-262-597-489,US,0,G06T2200/24;;G06T3/40;;G06T11/00;;G06Q20/3676;;G06Q20/3274;;G06Q20/3676;;G06T2200/24;;G06T3/40;;G06T11/00,G06Q20/36;;G06T3/40;;G06T11/00,,3,1,048-484-454-101-996,10.1007/978-1-4842-6694-6_19,"Slideegg Goal Tree PowerPoint Presentation Template and Google Slides. (January 01, 2023). retrieved online 04/07/2025. https://www.slideegg.com/goal-tree-template?srsltid=AfmBOoqPKPxzzCiHiAshyTWfpabIv909iuPW-H8dvc5uvr99Lpe8cWo7 (Year: 2023);;VISME. “Goal Completion - Gauge Chart Template.” (Feb 02 2021). Retrieved online 04/07/2025. https://www.visme.co/templates/charts/goal-completion-gauge-chart-1425284141/ (Year: 2021);;CauseVox. “Fundraising Thermometer Creator.” (Aug 03, 2021). Retrieved online 04/07/2025. https://www.causevox.com/fundraising-thermometer/ (Year: 2021)",PENDING
452,US,A1,US 2025/0156567 A1,123-717-268-115-22X,5/15/2025,2025,US 202318388588 A,11/10/2023,US 202318388588 A,11/10/2023,Method for Classifying and Controlling Transmission of a File,"A method and system for classifying a video file within an environment in which the file is located and when a file is classified as sensitive, controlling transmission of the file outside the environment. Classifying the video comprises analysing, using at least one machine learning model, the video to recognise any individuals in the video; obtaining a transcript of any speech in the video and generating, using the analysis, obtained transcript and a database of individuals linked to the environment, a labelled transcript which identifies each individual linked to the environment that is in the video. Information about each identified individual may be obtained from a connected database. A first generative AI model generates a text-based summary of the video by using the labelled transcript and information about identified individuals as prompts. A second generative AI model then determines a sensitivity classification of the video using the generated text-based summary.",VARONIS SYSTEMS INC,BELGI AMIR;;SNEH RON;;NEYSTADT JOHN EUGENE;;KADEC ORR,VARONIS SYSTEMS INC (2023-11-03),https://lens.org/123-717-268-115-22X,Patent Application,yes,0,0,3,182-888-960-384-385;;057-483-126-396-352;;123-717-268-115-22X,US;;WO;;AU,3,182-888-960-384-385;;057-483-126-396-352;;123-717-268-115-22X,US;;WO;;AU,0,G06N3/045;;G10L15/26;;G06F16/784;;G06F16/75;;G06F21/6218,G06F21/62;;G06F16/75;;G06F16/783,,0,0,,,,PENDING
453,US,A1,US 2025/0077391 A1,179-581-263-867-707,3/6/2025,2025,US 202318459881 A,9/1/2023,US 202318459881 A,9/1/2023,GENERATIVE AI FOR INDUSTRIAL AUTOMATION DESIGN ENVIRONMENT TEST,"An integrated development environment (IDE) for designing, programming, and configuring aspects of an industrial automation system uses a generative artificial intelligence (AI) model and associated neural networks to generate portions of an industrial automation project in accordance with functional requirements provided to the industrial IDE system in intuitive formats, such as spoken or written plain language text. The system uses generative AI to translate plain language requests or functional specifications into industrial control code, human-machine interface (HMI) applications, device configuration settings, or other aspects of an industrial control project.",ROCKWELL AUTOMATION TECH INC,CARRARA ANTHONY;;ANAND ASHISH;;GREGORY ADAM J;;WENGATZ JUSTIN;;BAHADER OMAR A;;MAJEWSKI LORENZO;;NADER ELIE;;FERNANDES FABIANO,ROCKWELL AUTOMATION TECHNOLOGIES INC (2023-08-21),https://lens.org/179-581-263-867-707,Patent Application,yes,0,1,1,179-581-263-867-707,US,1,179-581-263-867-707,US,0,G06F11/3684;;G06F11/3688;;G06F11/3698;;G06F11/3672;;G06F11/3672,G06F11/36,,0,0,,,,PENDING
454,WO,A1,WO 2025/095958 A1,088-315-591-364-163,5/8/2025,2025,US 2023/0036793 W,11/3/2023,US 2023/0036793 W,11/3/2023,DOWNSTREAM ADAPTATIONS OF SEQUENCE PROCESSING MODELS,Aspects of the disclosed technology include computer-implemented systems and methods for updating machine-learned models while preserving adaptations of the models by downstream applications. The system can obtain data indicative of a respective adapter implemented by each of a plurality of downstream applications for a first version of a machine-learned sequence processing model. The system can generate a first training loss based on processing a set of training data by a second version of the machine-learned sequence processing model. The system can generate a second training loss based on processing the set of training data using the respective adapter implemented by each of the plurality of downstream applications. The system can modify at least a portion of the second version of the core sequence processing model using the first training loss and the second training loss.,GOOGLE LLC,CARBUNE VICTOR;;SHARIFI MATTHEW,,https://lens.org/088-315-591-364-163,Patent Application,yes,1,0,1,088-315-591-364-163,WO,1,088-315-591-364-163,WO,0,G06N3/045;;G06N3/09;;G06N3/096;;G06N3/084,G06N3/045;;G06N3/09,,7,2,103-212-983-826-945;;084-641-049-769-580,pmc8371605;;34265844;;10.1038/s41586-021-03819-2;;10.18653/v1/2020.emnlp-main.83,"ZHOU ET AL.: ""Mixture-of-Experts with Expert Choice Routing"", X)V2202 09368V2, 14 October 2022 (2022-10-14);;DOSOVITSKIY ET AL.: ""An image is Worth 16x16 Words: Transformers for Image Recognition crt Scale"", XIV:2010.1 1929 2, 3 June 2021 (2021-06-03);;AGOSTINELLI ET AL.: ""MusicLM: Genera ing Music From Tex"", X :2301.11325V1, 26 January 2023 (2023-01-26);;JUMPER ET AL.: ""Highly accurate protein structure prediction with AlphaFold"", NATURE, vol. 596, 26 August 2021 (2021-08-26), pages 583, XP055888904, DOI: 10.1038/s41586-021-03819-2;;KUDO: ""SentencePiece: A simple and language independent subword tokenizer and cleW kenizen for Neural Text Processing"", EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (SYSTEM DEMONSTRATIONS, 4 November 2018 (2018-11-04), pages 66 - 71, Retrieved from the Internet <URL:https://aclanthology.org/Dlβ-2012pdf>;;VASWANI ET AL.: ""Attention Is All You Need"", XIV: 1706.03762V7, 2 August 2023 (2023-08-02);;SAHARIA ET AL.: ""Non-Autoregressive Machine Translation with Latent Alignments"", XIV:2004.07437V3, 16 November 2020 (2020-11-16)",PENDING
455,WO,A1,WO 2025/087712 A1,155-003-271-652-428,5/1/2025,2025,EP 2024078850 W,10/14/2024,US 202363593273 P;;EP 23207840 A,10/26/2023,GENERATING A PROMPT FOR A LARGE LANGUAGE MODEL BASED ON TEXTUAL USER INPUT FOR CONTROLLING A LIGHTING SYSTEM,"A method of generating a prompt for a large language model comprises receiving (101) a textual user input for controlling a lighting system, obtaining (103) contextual information indicative of one or more contextual characteristics of a context of the user, selecting (105), based on the contextual characteristics, a subset of configuration data which is related to the context of the user and/or a subset of examples of lighting control behavior which are related to the context of the user. The method further comprises generating (107) the prompt for the large language model and transmitting (109) the prompt to the large language model. The prompt comprises the textual user input and the selected subset or subsets. The prompt excludes configuration data not part of the selected subset of configuration data and excludes examples not part of the selected subset of examples.",SIGNIFY HOLDING BV,DEIXLER PETER;;MAES JÉRÔME;;ALIAKSEYEU DZMITRY;;DE VREEZE PIETER,,https://lens.org/155-003-271-652-428,Patent Application,yes,0,0,1,155-003-271-652-428,WO,1,155-003-271-652-428,WO,0,G06F16/3338;;H05B47/197,G06F16/33;;G06F16/332;;H05B47/12,,3,0,,,"EVAN KING ET AL: """"Get ready for a party"": Exploring smarter smart spaces with help from large language models"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 24 March 2023 (2023-03-24), XP091467921;;EVAN KING ET AL: ""Sasha: creative goal-oriented reasoning in smart homes with large language models"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 16 May 2023 (2023-05-16), XP091510750;;JIANGMENG LI: ""arXiv:2205.11100"", article ""Supporting Vision-Language Model Inference with Causality-pruning Knowledge Prompt""",PENDING
456,US,A1,US 2025/0124622 A1,015-884-489-577-703,4/17/2025,2025,US 202318484512 A,10/11/2023,US 202318484512 A,10/11/2023,PIPELINE FOR GENERATING EDITABLE GRAPHIC DESIGNS FROM NATURAL LANGUAGE PROMPTS,"A device includes a processor, and a memory storing executable instructions which, when executed by the processor, cause the processor alone or in combination with other processors to perform the following functions: receive textual user input from a user describing a design to be generated; implement a first prompt generator to generate a first prompt for a Large Language Model (LLM) to restructure the user input; and implement a second prompt generator to generate a second prompt for a text-to-image model using output of the LLM to produce, the second prompt to prompt the text-to-image model to produce a proposed design based on the user input. The proposed design is provided to the user via an application comprising controls for further editing the proposed design.",MICROSOFT TECHNOLOGY LICENSING LLC,BHAKTHAVATSALAM SUMITHRA;;TENDOLKAR GAURAV VINAYAK,MICROSOFT TECHNOLOGY LICENSING LLC (2023-10-10),https://lens.org/015-884-489-577-703,Patent Application,yes,0,0,1,015-884-489-577-703,US,1,015-884-489-577-703,US,0,G06F40/40;;G06T11/60;;G06V30/19;;G06F40/30;;G06F40/186;;G06F40/56;;G06T11/60;;G06F40/30;;G06F40/40;;G06V30/19,G06T11/60;;G06F40/30;;G06F40/40;;G06V30/19,,0,0,,,,PENDING
457,US,A1,US 2025/0104047 A1,152-333-965-715-545,3/27/2025,2025,US 202318472113 A,9/21/2023,US 202318472113 A,9/21/2023,PARTIAL EXCHANGE OF NFT VIA NFT INTERACTION,"An example operation may include one or more of generating a unique image comprising a plurality of image segments via an image generating model and displaying the unique image via a user interface of a software application, installing a smart contract associated with the unique image on a blockchain ledger, detecting a command to move an image segment from among the plurality of image segments based on user inputs via the user interface of the software application, removing the image segment from the unique image and adding the image segment to a different image based on the detected command, and transmitting the different image to a user account of the software application.",TORONTO DOMINION BANK,MASHKEVICH JESSICA,THE TORONTO-DOMINION BANK (2023-10-03),https://lens.org/152-333-965-715-545,Patent Application,yes,3,0,1,152-333-965-715-545,US,1,152-333-965-715-545,US,0,G06T2200/24;;G06T11/60;;G06F3/04845;;G06F3/04842;;G06F3/04883;;G06Q20/389;;H04L9/50;;H04L9/3239;;G06Q20/36;;G06Q20/3672;;G06Q20/123;;G06Q40/06;;G06Q20/3672;;G06T11/60;;G06Q20/389;;G06F3/0488;;G06F3/04845;;G06T2200/24;;G06F3/04842,G06Q20/36;;G06F3/04842;;G06F3/04845;;G06F3/0488;;G06Q20/38;;G06T11/60,,1,0,,,SYSTEMS AND METHODS FOR REPORTING TOKEN INTERACTIONS (Year: 2022),PENDING
458,WO,A1,WO 2024/044273 A1,071-335-441-692-277,2/29/2024,2024,US 2023/0030961 W,8/23/2023,US 202263400158 P,8/23/2022,AN ELECTRONIC BINDER SYSTEM (EBINDER) FOR PROCESSING SOURCE DATA TO EDC SYSTEMS,"The present invention provides a method and system for automatically and seamlessly processing clinical trial source data into electronic data capture (EDC) systems. In one embodiment, a file structure is defined for an electronic binder system (eBinder); source data is uploaded to the eBinder; the source data is encrypted, Patient Identifiable Information in the source data is masked; the source data is converted into machine readable plain text in the JavaScript Object Notation (JSON) format using Natural Language Processing (NPL) technologies; the JSON data is converted into tabulated machine readable data in the HyperText Markup Language (HTML) format using NPL technologies; the HTML data is converted into machine understandable data using NPL technologies; the machine understandable data is populated into EDC datasets using NPL technologies; the source data and converted data are displayed side-by-side for source data verification; and a platform is provided for regulatory data verification or auditing.",XIE TAI;;XUE RICHARD,XIE TAI;;XUE RICHARD,,https://lens.org/071-335-441-692-277,Patent Application,yes,3,0,3,168-849-424-367-857;;014-997-290-140-031;;071-335-441-692-277,WO;;EP;;KR,3,168-849-424-367-857;;014-997-290-140-031;;071-335-441-692-277,WO;;EP;;KR,0,G16H10/60;;G06F21/602;;G06F21/6254;;G16H15/00;;G16H10/20;;G06F21/602;;G06F21/6254;;G16H10/60;;G16H15/00;;G16H10/20,G06F21/60;;G06F21/62;;G16H10/60,,0,0,,,,PENDING
459,EP,A1,EP 4343624 A1,100-049-128-630-611,3/27/2024,2024,EP 23196998 A,9/12/2023,GR 20220100775 A,9/22/2022,METHOD AND APPARATUS FOR VISION-LANGUAGE UNDERSTANDING,"Broadly speaking, embodiments of the present techniques provide provides a method and apparatus for vision-language understanding. In particular, the present application provides a method for training a vision-language model to classify images using novel classes, and a method for using a trained vision-language model to classify images for a range of downstream tasks.",SAMSUNG ELECTRONICS CO LTD,BULAT ADRIAN;;TZIMIROPOULOS GEORGIOS,,https://lens.org/100-049-128-630-611,Patent Application,yes,0,2,4,055-339-462-417-424;;086-357-211-414-863;;173-119-960-694-938;;100-049-128-630-611,US;;WO;;EP;;CN,4,055-339-462-417-424;;086-357-211-414-863;;173-119-960-694-938;;100-049-128-630-611,US;;WO;;EP;;CN,0,G06N3/096;;G06N3/0455;;G06N3/088;;G06F40/56;;G06V10/761;;G06V10/776;;G06V10/764,G06N3/045;;G06N3/096,,19,10,062-190-727-639-26X;;009-268-236-053-390;;164-779-328-437-695;;160-841-866-680-704;;020-386-383-871-372;;044-237-430-224-39X;;048-857-935-225-059;;007-404-308-406-134;;115-725-112-822-171;;018-016-561-200-126,10.1016/j.patcog.2022.108578;;10.1007/s11263-022-01653-1;;10.1109/cvpr52688.2022.01631;;10.1109/cvprw.2009.5206848;;10.1109/cvpr.2004.383;;10.1109/iccvw.2013.77;;10.1109/icvgip.2008.47;;10.1007/978-3-319-10599-4_29;;10.1109/cvpr.2010.5539970;;10.1109/jstars.2019.2918242,"BEIER ZHU ET AL: ""Prompt-aligned Gradient for Prompt Tuning"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 30 May 2022 (2022-05-30), XP091234552;;KAIYANG ZHOU ET AL: ""Learning to Prompt for Vision-Language Models"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 12 August 2022 (2022-08-12), XP091292953, DOI: 10.1007/S11263-022-01653-1;;NIV COHEN ET AL: """"This is my unicorn, Fluffy"": Personalizing frozen vision-language representations"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 13 June 2022 (2022-06-13), XP091245346;;WANG HAO ET AL: ""Decomposing generation networks with structure prediction for recipe generation"", PATTERN RECOGNITION, ELSEVIER, GB, vol. 126, 7 February 2022 (2022-02-07), XP086996526, ISSN: 0031-3203, [retrieved on 20220207], DOI: 10.1016/J.PATCOG.2022.108578;;ALEC RADFORDJONG WOOK KIMCHRIS HALLACYADITYA RAMESHGABRIEL GOHSANDHINI AGARWALGIRISH SASTRYAMANDA ASKELLPAMELA MISHKINJACK CLARK E: ""International Conference on Machine Learning"", 2021, PMLR, article ""Learning transferable visual models from natural language supervision"", pages: 8748 - 8763;;KAIYANG ZHOUJINGKANG YANGCHEN CHANGE LOYZIWEI LIU: ""Learning to prompt for vision-language models"", INTERNATIONAL JOURNAL OF COMPUTER VISION, vol. 130, no. 9, 2022, pages 2337 - 2348;;KAIYANG ZHOUJINGKANG YANGCHEN CHANGE LOYZIWEI LIU: ""Conditional prompt learning for vision-language models"", PROCEEDINGS OF THE IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, 2022, pages 16816 - 16825;;RADFORD ET AL.: ""Language models are unsupervised multitask learners"", OPENAI BLOG, vol. 1, no. 8, 2019, pages 9;;JIA DENGWEI DONGRICHARD SOCHERLI-JIA LIKAI LILI FEI-FEI: ""Imagenet: A large-scale hierarchical image database"", 2009 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, 2009, pages 248 - 255;;LI FEI-FEIROB FERGUSPIETRO PERONA: ""2004 conference on computer vision and pattern recognition workshop"", 2004, IEEE, article ""Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories"", pages: 178 - 178;;OMKAR M PARKHIANDREA VEDALDIANDREW ZISSERMANCV JAWAHAR: ""2012 IEEE conference on computer vision and pattern recognition"", 2012, IEEE, article ""Cats and dogs"", pages: 3498 - 3505;;JONATHAN KRAUSEMICHAEL STARKJIA DENGLI FEI-FEI: ""3d object representations for fine-grained categorization"", PROCEEDINGS OF THE IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS, 2013, pages 554 - 561, XP032575682, DOI: 10.1109/ICCVW.2013.77;;MARIA-ELENA NILSBACKANDREW ZISSERMAN: ""2008 Sixth Indian Conference on Computer Vision, Graphics & Image Processing"", 2008, IEEE, article ""Automated flower classification over a large number of classes"", pages: 722 - 729;;LUKAS BOSSARDMATTHIEU GUILLAUMINLUC VAN GOOL: ""European conference on computer vision"", 2014, SPRINGER, article ""Food-101-mining discriminative components with random forests"", pages: 446 - 461;;JIANXIONG XIAOJAMES HAYSKRISTA A EHINGERAUDE OLIVAANTONIO TORRALBA: ""2010 IEEE computer society conference on computer vision and pattern recognition"", 2010, IEEE, article ""Sun database: Large-scale scene recognition from abbey to zoo"", pages: 3485 - 3492;;MIRCEA CIMPOISUBHRANSU MAJILASONAS KOKKINOSSAMMY MOHAMEDANDREA VEDALDI: ""Describing textures in the wild"", PROCEEDINGS OF THE IEEE CONFERENCE;;PATRICK HELBERBENJAMIN BISCHKEANDREAS DENGELDAMIAN BORTH: ""Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification"", IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING, vol. 12, no. 7, 2019, pages 2217 - 2226, XP011738382, DOI: 10.1109/JSTARS.2019.2918242;;KHURRAM SOOMROAMIR ROSHAN ZAMIRMUBARAK SHAH: ""Ucf101: A dataset of 101 human actions classes from videos in the wild"", ARXIV PREPRINT ARXIV:1212.0402, 2012;;YUNING LUJIANZHUANG LIUYONGGANG ZHANGYAJING LIUXINMEI TIAN: ""Prompt distribution learning"", IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, 2022",PENDING
460,WO,A1,WO 2025/117024 A1,139-461-754-130-358,6/5/2025,2025,US 2024/0049807 W,10/3/2024,US 202318523552 A,11/29/2023,CODE GENERATION USING MACHINE LEARNING MODELS,"Systems and techniques are described for performing code generating using machine learning models (e.g., large language models). For example, a computing device can generate, based on input data, second input data for a machine learning model. The computing device can generate, based on the second input data, a prompt. The computing device can apply a beam search with sampling on the prompt to generate a set of output samples. The computing device can further apply a static analysis to the set of output samples to generate a set of samples and can output the set of samples.",QUALCOMM INC,ZENG WEILIANG;;EZICK JAMES RANDALL;;LOTT CHRISTOPHER;;SORIAGA JOSEPH BINAMIRA;;ZAPPI PIERO;;LEE MINGU;;SANTHANAM ARVIND VARDARAJAN,,https://lens.org/139-461-754-130-358,Patent Application,yes,3,0,2,074-581-443-891-096;;139-461-754-130-358,US;;WO,2,074-581-443-891-096;;139-461-754-130-358,US;;WO,0,G06F8/30;;G06N20/00;;G06N3/02;;G06N3/08;;G06F8/33,G06F8/30;;G06N3/02;;G06N20/00,,3,2,083-449-940-348-930;;111-707-941-881-14X,10.1145/3560815;;10.1007/978-3-031-23190-2_2,"JACOB AUSTIN ET AL: ""Program Synthesis with Large Language Models"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 16 August 2021 (2021-08-16), XP091033638;;LIU PENGFEI ET AL: ""Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, vol. 55, no. 9, 13 January 2023 (2023-01-13), pages 1 - 35, XP058984101, DOI: 10.1145/3560815;;GERHARD PAASS ET AL: ""Foundation Models for Natural Language Processing -- Pre-trained Language Models Integrating Media"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 16 February 2023 (2023-02-16), XP091441629",PENDING
461,US,A1,US 2025/0077792 A1,071-891-170-171-302,3/6/2025,2025,US 202318459290 A,8/31/2023,US 202318459290 A,8/31/2023,FINE-TUNING LARGE LANGUAGE MODELS FOR DOMAIN-SPECIFIC ENVIRONMENTS,"Embodiments of the disclosed technologies are capable of a training pipeline to fine-tune a machine learning model given a limited set of domain-specific data. The embodiments describe using a first machine learning model to generate a pseudo label associated with a domain-specific training document. The pseudo label comprises a machine-generated text of a content type extracted from the domain-specific training document. The embodiments further describe fine-tuning a second machine learning model using the pseudo label, the domain-specific training document, a first low-rank weight matrix, and a second low-rank weight matrix. The fine-tuned second machine learning model generates text of the content type from a domain-specific document.",MICROSOFT TECHNOLOGY LICENSING LLC,CHEN XILUN;;KUO TZU MING;;LUO XIAOQIANG;;MELAMED ILYA DAN;;YAN JI;;ZHONG PEIDE,MICROSOFT TECHNOLOGY LICENSING LLC (2023-09-01),https://lens.org/071-891-170-171-302,Patent Application,yes,0,0,1,071-891-170-171-302,US,1,071-891-170-171-302,US,0,G06N20/20;;G06F40/40;;G06N3/045;;G06N20/20;;G06F40/40,G06F40/40;;G06N20/20,,0,0,,,,PENDING
462,US,A1,US 2025/0005050 A1,052-889-503-973-185,1/2/2025,2025,US 202318216553 A,6/29/2023,US 202318216553 A,6/29/2023,GENERATIVE SUMMARIZATION DIALOG-BASED INFORMATION RETRIEVAL SYSTEM,"Embodiments of the disclosed technologies include generating a search prompt based on an input portion of an online dialog involving a user of a computing device. The search prompt includes a dialog summarization instruction configured to instruct a generative artificial intelligence model to generate and output a dialog summary. The search prompt is sent to a first generative model. In response to the search prompt, a search query is generated and output by the first generative model based on the dialog summary. The search query is sent to a search system. Search result data is determined based on an execution of the search query by the search system. At least some of the search result data is included in an output portion of the online dialog. The output portion is configured to be displayed at the computing device in response to the input portion of the online dialog.",MICROSOFT TECHNOLOGY LICENSING LLC,KRISHNAN APARNA;;LLOYD II CHRISTOPHER WRIGHT;;OWEN JEREMY K;;FONG CHRISTOPHER J;;SUNDARESH SUMAN;;SHAH LAVISH;;KHURRAM MUHAMMAD BASIT;;JILLINGS MICHAELA,MICROSOFT TECHNOLOGY LICENSING LLC (2023-07-18),https://lens.org/052-889-503-973-185,Patent Application,yes,20,7,4,152-926-986-824-381;;194-212-523-024-029;;052-889-503-973-185;;009-453-022-290-918,US;;WO,4,152-926-986-824-381;;194-212-523-024-029;;052-889-503-973-185;;009-453-022-290-918,US;;WO,0,G06F16/9535;;G06F16/3329;;G06F16/243;;G06F16/90332;;G06F16/334;;G06F16/3329;;G06F16/338,G06F16/332;;G06F16/33;;G06F16/338,,0,0,,,,ACTIVE
463,WO,A1,WO 2025/151190 A1,011-985-685-860-079,7/17/2025,2025,US 2024/0055734 W,11/13/2024,US 202463619632 P,1/10/2024,SYSTEMS AND METHODS FOR MULTI-REWARD REINFORCEMENT LEARNING FRAMEWORK FOR TEXT-TO-IMAGE GENERATION,"Systems and methods for multi-reward reinforcement learning framework for text-to-image generation are disclosed. The method includes training, in tandem, a prompt expansion model and an image generation model using a multi-reward reinforcement learning model by: processing, by the prompt expansion model, a training query and training context data to generate an expanded training query; generating, by the image generation model, a training set of image data based on the expanded training query; generating a set of reward scores for each image datum within the training set of image data using a set of reward models, wherein generating the set of reward scores comprises generating at least one reward score for each reward criterion within a plurality of reward criteria; and adjusting weights and biases associated with the plurality of reward criteria based on the set of reward scores using the multi-reward reinforcement learning model.",GOOGLE LLC,LEE SEUNG HYUN;;YANG FENG;;LI YINXIAO;;KE JUNJIE;;YOO INNFARN;;ZHANG HAN;;YU JIAHUI;;WANG QIFEI;;DENG FEI;;ENTIS GLENN MICHAEL;;HE JUNFENG;;LI GANG;;ESSA IRFAN AZIZ,,https://lens.org/011-985-685-860-079,Patent Application,yes,0,0,1,011-985-685-860-079,WO,1,011-985-685-860-079,WO,0,G06N3/092;;G06N3/084;;G06N3/0464;;G06N3/0475;;G06N3/0442,G06N3/0442;;G06N3/0464;;G06N3/0475;;G06N3/084;;G06N3/092,,10,0,,,"CAO TINGFENG ET AL: ""BeautifulPrompt: Towards Automatic Prompt Engineering for Text-to-Image Synthesis"", PROCEEDINGS OF THE 2023 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: INDUSTRY TRACK, 12 November 2023 (2023-11-12), pages 1 - 11, XP093248299, DOI: 10.18653/v1/2023.emnlp-industry.1;;ALEXANDRE RAME ET AL: ""Rewarded soups: towards Pareto-optimal alignment by interpolating weights fine-tuned on diverse rewards"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 7 June 2023 (2023-06-07), XP091532398;;XI LIN ET AL: ""Pareto Set Learning for Expensive Multi-Objective Optimization"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 16 October 2022 (2022-10-16), XP091345437;;TIMO M DEIST ET AL: ""Multi-Objective Learning to Predict Pareto Fronts Using Hypervolume Maximization"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 19 October 2021 (2021-10-19), XP091066906;;ZHOU ET AL.: ""Mixture-of-Experts with Expert Choice Routing"", ARXIV:2202.09368V2, 14 October 2022 (2022-10-14);;DOSOVITSKIY ET AL.: ""An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"", ARXIV:2010.11929V2, 3 June 2021 (2021-06-03);;AGOSTINELLI ET AL.: ""MusicLM.- Generating Music From Text,"", ARXIV:2301.11325V1, 26 January 2023 (2023-01-26);;JUMPER ET AL.: ""Highly accurate protein structure prediction with AlphaFold, 596"", NATURE, 26 August 2021 (2021-08-26), pages 583, XP055888904, DOI: 10.1038/s41586-021-03819-2;;VASWANI ET AL.: ""Attention Is All You Need,"", ARXIV: 1706.03762V7, 2 August 2023 (2023-08-02);;SAHARIA ET AL.: ""Non-Autoregressive Machine Translation with Latent Alignments"", ARXIV:2004.07437V3, 16 November 2020 (2020-11-16)",PENDING
464,US,B2,US 12316715 B2,106-471-730-539-708,5/27/2025,2025,US 202318481973 A,10/5/2023,US 202318481973 A,10/5/2023,Dynamic push notifications,"An example operation may include one or more of storing a database of payment card data, receiving an identifier of a product from a digital wallet on a user device, identifying one or more payment cards stored within the digital wallet on the user device, determining the benefits that will be obtained by using each of the one or more payment cards to purchase the product via execution of an LLM on the identifier of the product and the database of payment card data; and displaying a chat message within a chat window on the user device with a description of the determined benefits that will be obtained.",TORONTO DOMINION BANK,TAHERI SHAHRIAR;;ALAVI-HARATI ASHKAN,THE TORONTO-DOMINION BANK (2023-10-26),https://lens.org/106-471-730-539-708,Granted Patent,yes,232,0,2,106-471-730-539-708;;066-693-437-494-250,US,2,106-471-730-539-708;;066-693-437-494-250,US,0,G06Q30/0631;;H04L67/55;;H04L51/02;;H04W4/029;;H04L51/222;;H04L67/55;;H04L51/02;;G06Q30/0631;;H04W4/029,G06F15/16;;G06Q30/0601;;H04L51/02;;H04L67/55;;H04W4/029,,0,0,,,,ACTIVE
465,US,A1,US 2025/0124066 A1,192-408-493-332-398,4/17/2025,2025,US 202418917941 A,10/16/2024,US 202418917941 A;;US 202363544366 P,10/16/2023,RETRIEVAL-AUGMENTED CONTENT GENERATION FOR LEGAL RESEARCH,"Embodiments support systems and methods for large language model (LLM)-assisted research tools that support retrieval-augmented content generation. In an aspect, the disclosed systems and methods may provide functionality for receiving, by one or more processors, a set of search criteria via a graphical user interface. The systems and methods may also include functionality for providing, by the one or more processors, the set of search criteria or information derived from the set of search criteria as one or more prompts to one or more LLMs, and for generating, by the one or more LLMs, textual content based on the one or more prompts. The textual content may include information associated with one or more legal issues associated with the set of search criteria.",THOMSON REUTERS ENTPR CENTRE GMBH,MCELVAIN GAYLE,THOMSON REUTERS ENTERPRISE CENTRE GMBH (2025-04-18),https://lens.org/192-408-493-332-398,Patent Application,yes,0,0,2,073-819-219-298-803;;192-408-493-332-398,US;;WO,2,073-819-219-298-803;;192-408-493-332-398,US;;WO,0,G06F16/338;;G06F16/335;;G06F16/338;;G06F16/335,G06F16/335;;G06F16/338,,0,0,,,,PENDING
466,US,A1,US 2025/0156300 A1,116-765-133-489-462,5/15/2025,2025,US 202318835683 A,12/4/2023,US 202318835683 A;;US 202263430296 P;;US 2023/0082282 W,12/5/2022,Confusion Matrix Estimation in Distributed Computation Environments,"An example method includes: serving content to a plurality of client devices associated with a plurality of tag values; predicting, using a prediction system, a plurality of attributes respectively associated with the plurality of tag values; generating a data sketch descriptive of the plurality of predicted attributes; noising the data sketch, wherein the noised data sketch satisfies a differential privacy criterion; transmitting the noised data sketch to a reference system; and receiving, from the reference system, estimated performance data associated with the predicted attributes, wherein the estimated performance data is based on an evaluation of: reference attribute data associated with one or more of the plurality of tag values and the predicted attributes for the one or more of the plurality of tag values.",GOOGLE LLC,PENG JIAYU;;MIRISOLA RAIMUNDO;;SKVORTSOV EVGENY,GOOGLE LLC (2023-01-27),https://lens.org/116-765-133-489-462,Patent Application,yes,0,0,2,116-765-133-489-462;;024-320-129-816-443,US;;WO,2,116-765-133-489-462;;024-320-129-816-443,US;;WO,0,G06N20/00;;G06N3/084;;G06N3/092;;H04L63/0428;;G06F21/6254;;G06N3/098;;G06F16/2255;;G06F11/3452,G06F11/34;;G06F16/22,,0,0,,,,PENDING
467,US,A1,US 2025/0117836 A1,003-857-307-232-60X,4/10/2025,2025,US 202318481933 A,10/5/2023,US 202318481933 A,10/5/2023,PROACTIVE BENEFIT SCAN,"An example operation may include one or more of receiving an identifier of a product from a digital wallet on a user device, identifying one or more payment cards stored within the digital wallet on the user device, determining benefits that will be obtained by using each of the one or more payment cards to purchase the product via execution of an LLM on the identifier of the product and a corpus of credit card documents, and displaying a chat message within a chat window on the user device with a description of the determined benefits that will be obtained.",TORONTO DOMINION BANK,TAHERI SHAHRIAR;;ALAVI-HARATI ASHKAN,,https://lens.org/003-857-307-232-60X,Patent Application,yes,0,0,1,003-857-307-232-60X,US,1,003-857-307-232-60X,US,0,G06Q30/0223;;G06F40/40;;G06Q30/0222;;G06F40/35;;G06Q30/0613;;G06N20/00;;G06Q20/227;;G06Q20/326;;G06Q20/34;;G06Q20/386;;G06N3/045;;G06Q30/0613;;G06Q30/0222;;G06F40/35;;G06Q20/227;;G06F40/40;;G06Q30/0223,G06Q30/0601;;G06F40/35;;G06F40/40;;G06Q20/22;;G06Q30/0207,,0,0,,,,PENDING
468,WO,A1,WO 2024/233241 A1,036-190-402-616-761,11/14/2024,2024,US 2024/0027354 W,5/2/2024,US 202363500998 P,5/9/2023,RESOURCE LOCATOR PREDICTION FOR SHORTCUT GENERATION,"In one example aspect, the present disclosure provides an example computer-implemented method for implementing a machine-learned action prediction model. The example method can include transmitting, by a computing system and to a search system, a search query for retrieving search results indicating web resources related to the search query. The example method can include receiving, by the computing system and from the search system, the search results. The example method can include determining, by the computing system and using a machine-learned action prediction model, based on context data associated with the search query, a resource locator of an action interface of a web resource associated with at least one search result. The example method can include generating, by the computing system, a shortcut to the action interface using the resource locator.",GOOGLE LLC,DABBIRU LAKSHMI KUMAR;;HARIRAMASAMY SENTHIL,,https://lens.org/036-190-402-616-761,Patent Application,yes,3,0,2,036-190-402-616-761;;159-122-501-831-024,WO;;EP,2,036-190-402-616-761;;159-122-501-831-024,WO;;EP,0,G06F16/9535,G06F16/9535,,7,4,178-180-048-885-335;;103-212-983-826-945;;120-047-640-592-980;;084-641-049-769-580,10.1109/cvpr52688.2022.00988;;pmc8371605;;34265844;;10.1038/s41586-021-03819-2;;10.18653/v1/d18-2012;;10.18653/v1/2020.emnlp-main.83,"CHENG ANDA ET AL: ""Differentially Private Federated Learning with Local Regularization and Sparsification"", 2022 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR), 2 June 2022 (2022-06-02), pages 10112 - 10121, XP093178749, Retrieved from the Internet <URL:https://arxiv.org/pdf/2203.03106> [retrieved on 20240625], DOI: 10.1109/CVPR52688.2022.00988;;DOSOVITSKIY ET AL.: ""An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"", ARXIV:2010.11929V2, 3 June 2021 (2021-06-03);;AGOSTINELLI ET AL.: ""MusicLM: Generating Music From Text"", ARXIV:2301.11325V1, 26 January 2023 (2023-01-26);;JUMPER ET AL.: ""Highly accurate protein structure prediction with AlphaFold"", NATURE, vol. 596, 26 August 2021 (2021-08-26), pages 583, XP055888904, DOI: 10.1038/s41586-021-03819-2;;KUDO ET AL.: ""SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"", PROCEEDINGS OF THE 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (SYSTEM DEMONSTRATIONS, 31 October 2018 (2018-10-31), pages 66 - 71;;VASWANI ET AL.: ""Attention Is All You Need"", ARXIV:1706.03762V7, 2 August 2023 (2023-08-02);;SAHARIA ET AL.: ""Non-Autoregressive Machine Translation with Latent Alignments"", ARXIV:2004.07437V3, 16 November 2020 (2020-11-16)",PENDING
469,US,A1,US 2025/0217938 A1,198-115-308-352-290,7/3/2025,2025,US 202418985490 A,12/18/2024,US 202418985490 A;;US 202363616451 P,12/29/2023,Weighting Functions and Adaptive Noise Schedule for Training Noise-Based Machine-Learned Models,"Weighting functions and adaptive noise distributions are provided for training a machine-learned model (e.g., image generation model) based on noised image data. A training image can be noised according to a noise distribution, which can be an adaptive noise distribution. A machine-learned model can process the noised training image to generate an output. A training system can update the machine-learned model based on a weighted loss, which can be based on the output and a weighting function. The weighting function can be monotonically non-increasing with respect to a signal-to-noise ratio. In some instances, the weighting function can have an approximately sigmoidal shape.",GOOGLE LLC,KINGMA DIEDERIK PIETER;;GAO RUIQI,,https://lens.org/198-115-308-352-290,Patent Application,yes,0,0,1,198-115-308-352-290,US,1,198-115-308-352-290,US,0,G06T2207/20081;;G06T5/70;;G06T5/60;;G06T2207/20081;;G06T5/73,G06T5/60;;G06T5/73,,0,0,,,,PENDING
470,WO,A1,WO 2025/128464 A1,144-238-181-790-269,6/19/2025,2025,US 2024/0059142 W,12/9/2024,US 202363610674 P,12/15/2023,EFFICIENT GENERATION OF MULTIMODAL SEQUENCES USING BETWEEN-FRAME AND WITHIN-FRAME MACHINE-LEARNED MODELS,"A multimodal sequence can be generated on a frame-by-frame basis, where each frame can be associated with a multi-token portion of the sequence. A first machine-learned model (a ""frame model"") can generate a frame token representative of an entire frame (e.g. a time frame), and one or more additional models (""depth models"") can generate individual tokens associated with the frame based on the frame token.",GOOGLE LLC,MCWILLIAMS BRIAN VICTOR;;ORSINI EMANUEL RENÉ JACQUES;;BORSOS ZALÁN;;TUDOR ALEXANDRU;;VINCENT DAMIEN;;TAGLIASACCHI MARCO,,https://lens.org/144-238-181-790-269,Patent Application,yes,0,0,1,144-238-181-790-269,WO,1,144-238-181-790-269,WO,0,G06N3/045;;G06N3/08,G06N3/045;;G06N3/08,,10,3,103-212-983-826-945;;120-047-640-592-980;;084-641-049-769-580,pmc8371605;;34265844;;10.1038/s41586-021-03819-2;;10.18653/v1/d18-2012;;10.18653/v1/2020.emnlp-main.83,"YANG ZHEN ET AL: ""TEAL: TOKENIZE AND EMBED ALL FOR MULTI-MODAL LARGE LANGUAGE MODELS"", 14 November 2023 (2023-11-14), pages 1 - 15, XP093249075, Retrieved from the Internet <URL:https://arxiv.org/pdf/2311.04589v2> [retrieved on 20250211];;JIAMING WANG ET AL: ""LauraGPT: Listen, Attend, Understand, and Regenerate Audio with GPT"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 11 October 2023 (2023-10-11), XP091632081;;ZAL\'AN BORSOS ET AL: ""AudioLM: a Language Modeling Approach to Audio Generation"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 26 July 2023 (2023-07-26), XP091572843;;ZHOU ET AL.: ""Mixture-of-Experts with Expert Choice Routing"", ARXIV:2202.09368V2, 14 October 2022 (2022-10-14);;DOSOVITSKIY ET AL.: ""An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"", ARXIV:2010.11929V2, 3 June 2021 (2021-06-03);;AGOSTINELLI ET AL.: ""MusicLM.' Generating Music From Text"", ARX1V:2301.11325V1, 26 January 2023 (2023-01-26);;JUMPER ET AL.: ""Highly accurate protein structure prediction with AlphaFold"", NATURE, vol. 596, 26 August 2021 (2021-08-26), pages 583, XP055888904, DOI: 10.1038/s41586-021-03819-2;;KUDO ET AL.: ""PROCEEDINGS OF THE 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (System Demonstrations"", 31 October 2018, article ""SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"", pages: 66 - 71;;VASWANI ET AL.: ""Attention Is All You Need"", ARXIV: 1706.03762V7, 2 August 2023 (2023-08-02);;SAHARIA ET AL.: ""Non-Autoregressive Machine Translation with Latent Alignments"", ARXIV:2004.07437V3, 16 November 2020 (2020-11-16)",PENDING
471,US,A1,US 2025/0061312 A1,003-686-978-736-151,2/20/2025,2025,US 202418764501 A,7/5/2024,IN 202321054722 A,8/15/2023,Knowledge Graphs for Dynamically Generating Content Using a Machine-Learned Content Generation Model,"Example aspects of the present disclosure provide an example method. In some implementations, the example method can include receiving request data indicating a request for content. In some implementations, the example method can include determining a request context associated with the request data, wherein the request context is based on account data for a user device associated with the request. In some implementations, the example method can include determining, based on the request and the request context, a data object from a knowledge graph, wherein the data object comprises a subject and one or more attributes for the subject. In some implementations, the example method can include generating, using a machine-learned content generation model, content descriptive of the subject, the content generated based on the request, the request context, and the data object.",GOOGLE LLC,HEILER MATTHIAS;;BENT III SYLVANUS GARNET;;KOC MEHMET LEVENT;;MOTARWAR SNEHAL SUNILKUMAR;;RAGHUVEER ARAVINDAN;;GROVER SAACHI;;GUPTA NIDHI;;NEMA PREKSHA;;SHARMA DURGA DEEPTHI SINGH;;KHANDELWAL ABHINAV,GOOGLE LLC (2024-02-14),https://lens.org/003-686-978-736-151,Patent Application,yes,0,0,1,003-686-978-736-151,US,1,003-686-978-736-151,US,0,G06N3/0475;;G06N5/022;;G06N3/0475,G06N3/0475,,0,0,,,,PENDING
472,WO,A1,WO 2024/073087 A1,169-555-287-939-881,4/4/2024,2024,US 2023/0034184 W,9/29/2023,US 202263411428 P,9/29/2022,REVISION OF AND ATTRIBUTION FOR OUTPUT OF TEXT GENERATION MODELS,"Existing language models (LMs) can excel at some tasks such as question answering, reasoning, and dialog. However, they can sometimes generate unsupported or inaccurate content. Therefore, in the present disclosure, systems and methods are provided for improving the reliability of LMs' generated output. First, systems and methods are provided for editing LMs' generated content based on a machine-learned comparison between the generated content and related evidence snippets, which can be retrieved and extracted using a machine-learned query generation model and a machine-learned relevance model. Second, systems and methods are provided for attributing parts of LM-generated content (e.g. factual claims) to related evidence snippets. Thus, the present disclosure can improve the reliability of LM output, both by increasing the factual accuracy of edited content and by allowing a user or computing system to know whether parts of the generated content are supported or contradicted by external evidence.",GOOGLE LLC,GU KELVIN;;DAI ZHUYUN;;CHAGANTY ARUN TEJASVI;;ZHAO YUZHE;;PASUPAT PANUPONG;;FAN YICHENG;;JUAN DA-CHENG;;LAO NI;;LEE HONG RAE;;CHEN ANTHONY WAH;;GAO LUYU,,https://lens.org/169-555-287-939-881,Patent Application,yes,3,7,2,083-122-634-921-116;;169-555-287-939-881,WO;;CN,2,083-122-634-921-116;;169-555-287-939-881,WO;;CN,0,G06F16/3329;;G06F16/90332;;G06F40/169;;G06F40/216;;G06F40/30,G06F16/332;;G06F16/9032,,7,3,103-212-983-826-945;;120-047-640-592-980;;084-641-049-769-580,pmc8371605;;34265844;;10.1038/s41586-021-03819-2;;10.18653/v1/d18-2012;;10.18653/v1/2020.emnlp-main.83,"ZHOU ET AL., MIXTURE-OF-EXPERTS WITH EXPERT CHOICE ROUTING, 14 October 2022 (2022-10-14);;DOSOVITSKIY ET AL.: ""An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"", ARXIV:2010.1 1929V2, 3 June 2021 (2021-06-03);;AGOSTINELLI ET AL.: ""MusicLM: Generating Music From Text"", AΣTXM:23U1.11325V1, 26 January 2023 (2023-01-26);;JUMPER ET AL.: ""Highly accurate protein structure prediction with AlphaFold"", NATURE, vol. 596, 26 August 2021 (2021-08-26), pages 583, XP055888904, DOI: 10.1038/s41586-021-03819-2;;KUDO ET AL.: ""SentencePiece: A simple and language independent subword tokenizer and detokenizerfor Neural Text Processing"", PROCEEDINGS OF THE 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL. LANGUAGE PROCESSING (SYSTEM DEMONSTRATIONS, 31 October 2018 (2018-10-31), pages 66 - 71, Retrieved from the Internet <URL:https://aclanthology.org/D18-2012.pdf>;;VASWANI ET AL.: ""Attention Is All Yore Need"", ARXIV:1706.03762V7, 2 August 2023 (2023-08-02);;SAHARIA ET AL.: ""Non-Autoregressive Machine Translation with Latent Alignments"", ARXTV:2004.07437V3, 16 November 2020 (2020-11-16)",PENDING
473,US,A1,US 2024/0346799 A1,171-631-911-095-445,10/17/2024,2024,US 202418634560 A,4/12/2024,CN 202310396073 A,4/13/2023,"METHOD, APPARATUS, DEVICE AND STORAGE MEDIUM FOR IMAGE SEGMENTATION","Embodiments of the disclosure provides technologies for image segmentation. The method includes: extracting an image feature representation of a target image using a trained image encoder; for each of a plurality of classes, generating, using a trained text encoder, a text feature representation corresponding to a name of the class, and determining a candidate segmentation map for the target image and a class confidence of the class based on the image feature representation and the text feature representation; selecting, from the plurality of classes, at least one class related to the target image based on a plurality of class confidences determined respectively for the plurality of classes; and determining a target segmentation map for the target image based on the at least one candidate segmentation map and the at least one class confidence determined for the at least one selected class.",BEIJING YOUZHUJU NETWORK TECH CO LTD,YANG CHENG;;CUI QUAN;;YI MUYANG;;WU HAO,,https://lens.org/171-631-911-095-445,Patent Application,yes,0,0,2,171-631-911-095-445;;040-683-510-093-777,US;;CN,2,171-631-911-095-445;;040-683-510-093-777,US;;CN,0,G06V10/26;;G06V10/764;;G06V10/82;;G06N3/045;;G06V10/764;;G06V20/70;;G06V10/50;;G06V10/7753;;G06T3/40;;G06V10/26;;G06V10/82;;G06V20/70;;G06V10/50;;G06V10/26;;G06V10/764;;G06V10/7753;;G06T3/40,G06V10/26;;G06T3/40;;G06V10/50;;G06V10/764;;G06V10/774;;G06V20/70,,0,0,,,,PENDING
474,US,A1,US 2025/0086096 A1,097-694-014-060-775,3/13/2025,2025,US 202318466792 A,9/13/2023,US 202318466792 A,9/13/2023,AUTOMATED GENERATION OF TEST DATA,"An example operation may include one or more of storing a repository of test data, receiving a request for new test data to be generated for a software program, where the request comprises a text-based description of the new test data, identifying one or more code modules included on the software program based on source code of the software program stored in the memory, executing a generative artificial intelligence (GenAI) model on the text-based description of the new test data and the one or more code modules to generate test data for testing the one or more code modules, and storing the test data in the repository of test data.",TORONTO DOMINION BANK,GUTTRIDGE FRANCIS JAMES ALEXANDER;;D'AGOSTINO DINO PAUL;;PRATTEN A WARREN;;MOHAMMED SHAHZAD;;CHIKKALAVALASA ARVIND;;NAWAZ WAQAS,,https://lens.org/097-694-014-060-775,Patent Application,yes,8,0,1,097-694-014-060-775,US,1,097-694-014-060-775,US,0,G06F11/3684;;G06F11/3696;;G06F11/3688,G06F11/36,,0,0,,,,PENDING
475,US,A1,US 2025/0157284 A1,007-982-852-093-033,5/15/2025,2025,US 202418794858 A,8/5/2024,US 202418794858 A;;US 202363597851 P,11/10/2023,PREDICTIVE GAMING INSIGHT PLATFORM,"A system and method(s) to perform operations that include aggregating gaming data associated with a casino network; training, via exploratory data analysis of the aggregated gaming data, a set of developed machine learning models that most accurately predict a target variable output. The operations further include predicting, using a deployed one of the developed machine learning models to analyze user-specific gaming data associated with a specific user account, a user-specific output value. The operations further include determining, via the deployed machine learning model using the user-specific output value, user-specific system-based content to present via a presentation device associated with a location of the specific user account (e.g., via a player interface device that the user account is logged into, via a personal mobile device associated with a user of the user account, etc.). The operations further include presenting (e.g., rendering, animating, etc.), via the presentation device, the user-specific system-based content.",LNW GAMING INC,WOLFE JON CHRISTIAN;;BALA SUNDARAM LEKHA SREE;;RAMAMOORTHY RAJKUMAR;;KRISHNAMURTHY SELVAGANESAN;;KARTHICK DHANAPAL;;DHANABALAN SANJAYRAJ;;SARANYA MOHAN;;KHANNA AKSHATA;;SETT KAUSHIK;;SUBRAMANI MOHAN RAJ;;SELVAM SUDHAKAR;;RAVI SINGARAVELU PRAVEEN KUMAR;;SELVARAJ UTHISTRAN;;SUBRAMANIAM VASANTH KUMAR;;JACOB LINI MARY;;ARUMUGAM PAUL;;PERIYASAMY GOWRISHANKAR;;BAJPAI ARPIT;;CHAVAN PRAVIN;;SAKTHIVELU THANGARASU;;SHARMA ARINDAM;;VENKATACHALAM BALASUBRAMANIAN;;SURRATT CARCEL BROOK;;VENKATARAMAN MURALI;;SINGH SACHIN;;MASON JOHN;;YANEZ JAY;;DUENAS SAMUEL;;CHANDRAN JAYANTHI;;JORAPUR HARIPRIYA;;ADNAN MOHAMMED;;KASA BABITHA,LNW GAMING INC (2024-07-22),https://lens.org/007-982-852-093-033,Patent Application,yes,0,0,1,007-982-852-093-033,US,3,121-132-275-891-255;;007-982-852-093-033;;165-835-636-067-841,US;;AU,0,G07F17/323;;G07F17/3237;;G07F17/3213;;G07F17/3234;;G07F17/3206;;G06N20/00;;G07F17/3213;;G07F17/3237;;G06N20/00;;G07F17/3206;;G07F17/3234;;G07F17/323,G07F17/32;;G06N20/00,,0,0,,,,PENDING
476,US,A1,US 2025/0086451 A1,092-099-183-340-702,3/13/2025,2025,US 202318466767 A,9/13/2023,US 202318466767 A,9/13/2023,CONTINUOUSLY EVOLVING USER TRAINING MANUAL,"An example operation may include one or more of storing a plurality of digital training manuals that comprise policies which are to be followed by users, detecting an occurrence of a triggering condition, in response to the detection of the occurrence of the triggering condition, retrieving the plurality of digital training manuals from the memory and generating a user manual based on execution of a generative artificial intelligence (GenAI) model on the plurality of digital training manuals, and storing the user manual in the memory.",TORONTO DOMINION BANK,GUTTRIDGE FRANCIS JAMES ALEXANDER;;D'AGOSTINO DINO PAUL;;PRATTEN A WARREN;;MOHAMMED SHAHZAD;;CHIKKALAVALASA ARVIND;;NAWAZ WAQAS,,https://lens.org/092-099-183-340-702,Patent Application,yes,0,0,1,092-099-183-340-702,US,1,092-099-183-340-702,US,0,G06N3/08;;G06N3/08,G06N3/08,,0,0,,,,PENDING
477,US,A1,US 2025/0085936 A1,099-343-015-569-379,3/13/2025,2025,US 202318466782 A,9/13/2023,US 202318466782 A,9/13/2023,SYSTEM ARCHITECTURE WITH GENERATIVE AI,"An example operation may include one or more of storing software architecture documents which include text-based descriptions of architecture components, training a generative artificial intelligence (GenAI) model to understand the architecture components based on the software architecture documents in the memory, receiving an input comprising a description of a software architecture implemented by a computing platform, executing the GenAI model based on the description of the software architecture to generate a description of a change to be made to the software architecture, and outputting the description of the change on a user interface.",TORONTO DOMINION BANK,GUTTRIDGE FRANCIS JAMES ALEXANDER;;D'AGOSTINO DINO PAUL;;PRATTEN A WARREN;;MOHAMMED SHAHZAD;;CHIKKALAVALASA ARVIND;;NAWAZ WAQAS,,https://lens.org/099-343-015-569-379,Patent Application,yes,0,1,1,099-343-015-569-379,US,1,099-343-015-569-379,US,0,G06F8/35;;G06F8/10;;G06F8/10;;G06F8/35,G06F8/35;;G06F8/10,,0,0,,,,PENDING
478,US,A1,US 2025/0139519 A1,054-263-059-859-287,5/1/2025,2025,US 202418911497 A,10/10/2024,US 202418911497 A;;US 202363595021 P,11/1/2023,UPTIME BOT,"An industrial alarm monitoring system leverages generative artificial intelligence (AI) to perform dynamic monitoring and analysis of a customer's industrial processes, identify potential or active performance issues or alarm conditions, and assist users in resolving these issues. The system monitors and collects operational and status data from industrial devices and assets of industrial automation systems and stores information regarding active and historical alarm conditions indicated by this data in an alarm repository. Users can submit natural language requests for assistance with, or information about, active or historical alarms to the system, which leverages trained custom models and a generative AI model to process these requests. The system can formulate natural language alarm resolution guidance based on analysis of the user's request, content of the custom models, responses prompted from the generative AI model, and relevant information about the alarm condition obtained from the alarm repository.",ROCKWELL AUTOMATION TECH INC,KANSARA KRUTIKA;;MATURANA FRANCISCO P;;KHAN SHAHRUKH;;TAVADARE KIRAN;;SWAMI RAHUL;;ROUT PRATYUSH,ROCKWELL AUTOMATION TECHNOLOGIES INC (2024-09-27),https://lens.org/054-263-059-859-287,Patent Application,yes,0,0,1,054-263-059-859-287,US,1,054-263-059-859-287,US,0,G06N20/00;;G06N20/00,G06N20/00,,0,0,,,,PENDING
479,EP,A1,EP 4538905 A1,062-759-119-280-859,4/16/2025,2025,EP 24202181 A,9/24/2024,US 202363543655 P;;US 202318399452 A,10/11/2023,PIVOT GROUP GENERATION FOR SEARCH AND RECOMMENDATION SYSTEMS,"Some aspects relate to technologies for generating pivots using a generative model and grouping items into pivot groups using the pivots. Pivots are generated by obtaining item information for items, generating a prompt using the item information, and causing a generative model to use the prompt to generate text for the pivots, including a pivot name and pivot description for each pivot. A pivot embedding is also generated for each pivot. When items are to be returned to a user device (e.g., as recommended items or search result items), item embeddings for the items and the pivot embeddings for the pivots are used to assign each item to a particular pivot to generate pivot groups that each includes a pivot name, a pivot description, and assigned items. User interface information is provided to present at least a portion of the pivot groups on a user device.",EBAY INC,WU GAOMIN;;SCHONFELD DANIEL RYAN;;QU XINGMING;;GALSURKAR JONATHAN FRANK;;XUE CHEN,,https://lens.org/062-759-119-280-859,Patent Application,yes,1,0,3,008-087-612-715-070;;191-970-322-086-817;;062-759-119-280-859,US;;EP;;CN,3,191-970-322-086-817;;008-087-612-715-070;;062-759-119-280-859,US;;EP;;CN,0,G06F16/906;;G06F16/9038;;G06Q30/0623;;G06Q30/0631,G06F16/9038;;G06F16/906,,0,0,,,,PENDING
480,WO,A1,WO 2024/207020 A1,051-371-477-871-982,10/3/2024,2024,US 2024/0022548 W,4/1/2024,US 202363493349 P,3/31/2023,POSITIONAL ENCODING FOR NEURAL NETWORK ATTENTION,"An example computer-implemented method for image view synthesis is provided. The example method includes obtaining, by a computing system, a query associated with a target view of a scene; determining, by the computing system, a plurality of source poses associated with a plurality of source images of the scene; generating, by the computing system and based on the query, a plurality of pose-augmented queries, each respective pose-augmented query encoding pose information relative to a respective source pose associated with a respective source image of the plurality of source images; processing, by the computing system, the plurality of pose-augmented queries respectively with a plurality of attention streams of a machine-learned image view synthesis model; and generating, by the computing system and based on the plurality of attention streams, an output image of the scene associated with the target view.",GOOGLE LLC,SAJJADI SEYED MOHAMMAD MEHDI;;SAFIN ALEKSANDR;;DUCKWORTH DANIEL CHRISTOPHER,,https://lens.org/051-371-477-871-982,Patent Application,yes,1,0,1,051-371-477-871-982,WO,1,051-371-477-871-982,WO,0,G06T15/20;;G06T15/08,G06T15/08;;G06T7/70;;G06T15/20,,12,6,011-749-559-864-672;;177-862-846-996-007;;095-746-897-157-325;;103-212-983-826-945;;120-047-640-592-980;;084-641-049-769-580,10.1007/978-3-030-69538-5_42;;10.1109/cvpr52688.2022.00613;;10.1109/cvpr52729.2023.01659;;pmc8371605;;34265844;;10.1038/s41586-021-03819-2;;10.18653/v1/d18-2012;;10.18653/v1/2020.emnlp-main.83,"""Sequential View Synthesis with Transformer : 15th Asian Conference on Computer Vision, Kyoto, Japan, November 30 - December 4, 2020, Revised Selected Papers, Part IV"", vol. 12625, 30 November 2020, SPRINGER INTERNATIONAL PUBLISHING, article NGUYEN-HA PHONG ET AL: ""Sequential View Synthesis with Transformer : 15th Asian Conference on Computer Vision, Kyoto, Japan, November 30 - December 4, 2020, Revised Selected Papers, Part IV"", pages: 695 - 711, XP055964200, DOI: 10.1007/978-3-030-69538-5_42;;MEHDI S M SAJJADI ET AL: ""Scene Representation Transformer: Geometry-Free Novel View Synthesis Through Set-Latent Scene Representations"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 25 November 2021 (2021-11-25), XP091103658;;MEHDI S. M. SAJJADIHENNING MEYERETIENNE POTURS BERGMANNKLAUS GREFFNOHA RADWANSUHANI VORAMARIO LUCICDANIEL DUCKWORTHALEXEY DOSOVITS: ""Scene Representation Transformer: Geometry-Free Novel View Synthesis Through Set-Latent Scene Representations"", ARXIV:2111.13152V3, 29 March 2022 (2022-03-29);;MEHDI S. M. SAJJADIDANIEL DUCKWORTHARAVINDH MAHENDRANSJOERD VAN STEENKISTEFILIP PAVETICMARIO LUCICLEONIDAS J. GUIBASKLAUS GREFFTHO: ""Object Scene Representation Transformer"", ARXIV:2206.06922V2, 12 October 2022 (2022-10-12), Retrieved from the Internet <URL:https://doi.org/10.48550/arXiv.2206.06922>;;MEHDI S. M. SAJJADIARAVINDH MAHENDRANTHOMAS KIPFETIENNE POTDANIEL DUCKWORTHMARIO LUCICKLAUS GREFF: ""RUST: Latent Neural Scene Representations from Unposed Imagery"", ARXIV:2211.14306V2, 24 March 2023 (2023-03-24), Retrieved from the Internet <URL:https://doi.org/10.48550/arXiv.2211.14306>;;VASWANI ET AL.: ""Attention Is All You Need"", ARXIV:1706.03762V7, 2 August 2023 (2023-08-02);;ZHOU ET AL.: ""Mixture-of-Experts with Expert Choice Routing"", ARXIV:2202.09368V2, 14 October 2022 (2022-10-14);;DOSOVITSKIY ET AL.: ""An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"", ARXIV:2010.11929V2, 3 June 2021 (2021-06-03);;AGOSTINELLI ET AL.: ""MusicLM: Generating Music From Text"", ARXIV:2301.11325V1, 26 January 2023 (2023-01-26);;JUMPER ET AL.: ""Highly accurate protein structure prediction with AlphaFold"", 596 NATURE, 26 August 2021 (2021-08-26), pages 583, XP055888904, DOI: 10.1038/s41586-021-03819-2;;KUDO ET AL.: ""SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"", PROCEEDINGS OF THE 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (SYSTEM, 31 October 2018 (2018-10-31), pages 66 - 71, Retrieved from the Internet <URL:https://aclanthology.org/D18-2012.pdf>;;SAHARIA ET AL.: ""Non-Autoregressive Machine Translation with Latent Alignments"", ARXIV:2004.07437V3, 16 November 2020 (2020-11-16)",PENDING
481,US,A1,US 2025/0217708 A1,062-854-964-327-234,7/3/2025,2025,US 202419000011 A,12/23/2024,US 202419000011 A;;US 202363616411 P,12/29/2023,Wrapper for Machine-Learned Model for Interactive Input Acquisition,"Systems and methods are provided for wrapping a machine-learned model to facilitate interactive input acquisition. One or more computing devices can obtain a machine-learned model configured to generate a prediction based at least in part on input feature data. The computing device(s) can obtain a first input value for a first input feature of the first machine-learned model. Based at least in part on the first input value, the computing device(s) can determine an estimated value of obtaining at least one additional input value for a second input feature of the first machine-learned model. Based on the estimated value, the computing device(s) can determine whether to obtain the at least one additional input value. Using the first machine-learned model, the computing device(s) can determine a prediction based at least on the first input value.",GOOGLE LLC,MACWILLIAMS PATRICIA LEIGH;;GUHA ROY ABHIJIT;;FREYBERG JAN;;SPITZ TERRY;;TELANG UMESH RAMESH;;DVIJOTHAM DJ,,https://lens.org/062-854-964-327-234,Patent Application,yes,0,0,1,062-854-964-327-234,US,1,062-854-964-327-234,US,0,G06N20/00;;G06N20/20;;G06N3/045;;G06N5/01;;G06N20/00,G06N20/00,,0,0,,,,PENDING
482,US,A1,US 2024/0362467 A1,129-965-524-229-48X,10/31/2024,2024,US 202318375923 A,10/2/2023,US 202318375923 A;;US 202363527534 P;;US 202363463049 P,4/30/2023,AI-INFORMED WORKFLOW PROCESSING,"A method for processing content management system workflows. Systems and subsystems are established for configuring a content management system to implement workflow processes wherein the content management system (CMS) exposes instances of stored content objects to a plurality of user devices through an electronic interface. Further systems and subsystem are established for identifying metadata maintained by the CMS for the stored content objects, and for identifying a generative AI entity (GAIE) to interact with the CMS. On an ongoing basis, the foregoing systems and subsystems carry out steps for (1) forming a GAIE prompt, wherein the GAIE prompt comprises at least a portion of the metadata identified from the CMS for the stored content objects, (2) receiving a response from the GAIE, wherein the response corresponds to the GAIE prompt; and (3) using, by the CMS, the response from the GAIE to implement processing of a content management system workflow.",BOX INC,DEO NACHIKET;;GANESH IYER NIRMAL;;GUPTA VIRENDER;;KUS BENJAMIN JOHN;;GRENADER DENIS,BOX INC (2023-09-29),https://lens.org/129-965-524-229-48X,Patent Application,yes,0,3,1,129-965-524-229-48X,US,8,160-066-196-031-873;;104-422-345-292-266;;088-011-995-027-697;;160-843-729-530-59X;;129-965-524-229-48X;;003-620-165-625-065;;061-122-977-680-555;;100-607-359-543-623,US;;WO,0,G06N3/0475;;G06N3/0475,G06N3/0475,,0,0,,,,PENDING
483,WO,A1,WO 2025/145185 A1,010-459-103-575-205,7/3/2025,2025,US 2024/0062324 W,12/30/2024,US 202363616545 P,12/30/2023,LARGE LANGUAGE MODEL (LLM) DRIVEN PROACTIVE SCHEDULING,"Large Language Model (LLM) driven proactive scheduling may be provided. First, a proactive feedback module may be used that gathers user requests and device feedback. Next, an instructive interpreter module may be used that receives the user requests and the device feedback and produces instructive prompts based on the user requests and the device feedback. Then a user-reinforced scheduling optimization module may be used that receives responses to the instructive prompts and continuously enhances bandwidth scheduling based on the receives responses.",CISCO TECH INC,SUN PENGFEI;;SHAO QIHONG,,https://lens.org/010-459-103-575-205,Patent Application,yes,1,0,2,010-459-103-575-205;;134-637-591-984-360,US;;WO,2,010-459-103-575-205;;134-637-591-984-360,US;;WO,0,H04B7/0452;;H04W72/542;;H04W84/12;;G06N3/08;;H04W72/50;;H04B7/0413;;H04W24/02;;H04W72/12;;H04W84/12,H04B7/0452;;H04W72/542,,0,0,,,,PENDING
484,US,A1,US 2025/0045530 A1,034-713-936-504-77X,2/6/2025,2025,US 202318229459 A,8/2/2023,US 202318229459 A,8/2/2023,CUSTOM-DOMAIN CONTROLLER FOR LARGE LANGUAGE MODELS,"A database of text associated with different domains is maintained. Large language models (LLMs) are prepared for use in the different domains by providing the associated text to an instance of an LLM. Thus, using multiple instances of the same pre-trained LLM, domain-specific LLMs are generated. The text provided to the LLM instance may be selected based on an account identifier of the user accessing the LLM, the tenant accessing the LLM, a user selection of a domain, or any suitable combination thereof. A pool of prepared LLM instances may be generated before the access request is received. If a response provided by an LLM instance in a domain to a prompt was rejected by a user and additional information was received during the session to improve the response of the LLM instance, the additional information may be to the text used to prepare future LLM instances for the domain.",SAP SE,REDDY SRINIVASA BYAIAH RAMACHANDRA;;MONDAL DEBDUTT,SAP SE (2023-07-25),https://lens.org/034-713-936-504-77X,Patent Application,yes,0,0,1,034-713-936-504-77X,US,1,034-713-936-504-77X,US,0,G06F40/279;;G06F40/40;;G06F16/3328;;G06F40/40;;G06F40/279;;G06F16/3328,G06F40/40;;G06F16/332;;G06F40/279,,0,0,,,,PENDING
485,WO,A1,WO 2024/238371 A1,071-871-570-339-989,11/21/2024,2024,US 2024/0028893 W,5/10/2024,US 202318318362 A,5/16/2023,GENERATING AN ARTIFICIAL INTELLIGENCE CHATBOT THAT SPECIALIZES IN A SPECIFIC DOMAIN,"Methods, computing systems, and technology for generating an artificial intelligent chatbot that specializes in a specific domain are present. The system can receive, from a user device of a first user, a request for a chatbot that specializes in a specific domain. The request can include domain-specific data. Additionally, the system can select, based on the domain-specific data, a selected chatbot for the specific domain from a plurality of pretrained chatbot. The selected chatbot can be associated with a pretrained machine-learned model. Moreover, the system can access, based on the selected chatbot and the request, user-specific data. Furthermore, the system can modify, based on the user-specific data, one or more parameters of the pretrained machine-learned model to generate a customized machine-learned model. Subsequently, in response to the request, the system can deploy an expert chatbot having the customized machine-learned model to interact with the first user.",GOOGLE LLC,PEDERSEN ZEBEDEE;;DE JORGE LADRERO LUIS;;KIRKLAND PHOEBE;;STRUDWICK KATHRYN JANE,,https://lens.org/071-871-570-339-989,Patent Application,yes,3,0,3,100-128-573-878-928;;109-291-794-304-482;;071-871-570-339-989,US;;WO;;EP,3,100-128-573-878-928;;109-291-794-304-482;;071-871-570-339-989,US;;WO;;EP,0,G06F40/35;;G06F40/30;;G06F40/216;;G06N20/00,G06F40/35;;G06F40/216;;G06F40/30,,1,0,,,"JINGFENG YANG ET AL: ""Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 26 April 2023 (2023-04-26), XP091495534",PENDING
486,US,A1,US 2024/0419920 A1,073-041-326-289-457,12/19/2024,2024,US 202318335745 A,6/15/2023,US 202318335745 A,6/15/2023,NATURAL LANGUAGE-BASED MANAGEMENT OF COMPUTING RESOURCES EXECUTING RADIO ACCESS NETWORK WORKLOADS,"The techniques disclosed herein manage computing environments associated with radio access networks using a natural language interface. This is achieved through utilizing natural language processing to analyze user generated inputs and generate robust large language model queries. In various examples, the queries can include radio access network documentation, diagnostic data, and past interactions to provide custom context to the large language model. Accordingly, the query can cause the large language model to generate an operation sequence comprising a plurality of commands to interface with a resource management tool and control computing resources and supporting components. In this way, the present techniques can alleviate the technical burden on end users and minimize the risk of errors.",MICROSOFT TECHNOLOGY LICENSING LLC,MEHROTRA SANJEEV;;KALIA ANUJ;;KOTARU MANIKANTA,MICROSOFT TECHNOLOGY LICENSING LLC (2023-06-20),https://lens.org/073-041-326-289-457,Patent Application,yes,3,0,1,073-041-326-289-457,US,1,073-041-326-289-457,US,0,H04W24/02;;G06F40/40;;H04W24/02;;G06F40/40,G06F40/40;;H04W24/02,,0,0,,,,PENDING
487,US,A1,US 2025/0209355 A1,034-095-004-478-940,6/26/2025,2025,US 202418990227 A,12/20/2024,US 202418990227 A;;US 202363613424 P,12/21/2023,Fast Speculative Decoding Using Multiple Parallel Drafts,"Systems and methods are provided for low-latency autoregressive generation of sequence output based on a plurality of parallel draft sequences. A lower-latency machine-learned model (e.g., having a smaller number of parameters than a model of interest) can generate a plurality of draft sequences comprising a plurality of draft tokens per sequence. A machine-learned model of interest (e.g., having a high latency per token) can evaluate a plurality of respective conditional probabilities for the respective draft tokens in parallel. An output sequence comprising one or more accepted draft tokens, corrected tokens, and/or additional tokens can be generated based on the draft tokens and conditional probabilities.",GOOGLE LLC,SUN ZITENG;;SURESH ANANDA THEERTHA;;RO JAE HUN;;BEIRAMI AHMAD;;JAIN HIMANSHU;;YU XINNAN;;RILEY MICHAEL DENNIS;;KUMAR SANJIV,GOOGLE LLC (2025-02-12),https://lens.org/034-095-004-478-940,Patent Application,yes,0,0,1,034-095-004-478-940,US,1,034-095-004-478-940,US,0,G06N7/01;;G06N7/01,G06N7/01,,0,0,,,,PENDING
488,US,A1,US 2024/0169662 A1,192-983-565-488-30X,5/23/2024,2024,US 202318517190 A,11/22/2023,US 202318517190 A;;US 202263427475 P,11/23/2022,Latent Pose Queries for Machine-Learned Image View Synthesis,"An example method includes obtaining, by a computing system, one or more source images of a scene; obtaining, by the computing system, a query associated with a target view of the scene, wherein at least a portion of the query is parameterized in a latent pose space; and generating, by the computing system and using a machine-learned image view synthesis model, an output image of the scene associated with the target view.",GOOGLE LLC,SAJJADI SEYED MOHAMMAD MEHDI;;GREFF KLAUS;;POT ETIENNE FRANÇOIS RÉGIS;;DUCKWORTH DANIEL CHRISTOPHER;;LUCIC MARIO;;MAHENDRAN ARAVINDH;;KIPF THOMAS,GOOGLE LLC (2023-01-10),https://lens.org/192-983-565-488-30X,Patent Application,yes,0,3,1,192-983-565-488-30X,US,1,192-983-565-488-30X,US,0,G06T7/73;;G06T15/205;;G06T15/205;;G06T7/73;;G06T2207/20084;;G06T2207/20081;;B25J9/1697,G06T15/20;;B25J9/16;;G06T7/73,,0,0,,,,PENDING
489,WO,A1,WO 2025/038639 A1,192-186-004-308-012,2/20/2025,2025,US 2024/0042117 W,8/13/2024,US 202363519985 P,8/16/2023,CUSTOMIZED ON-DEVICE NETWORK BASED ON A SHARED FOUNDATION NETWORK,"A method includes hosting, by a device, a foundation network that is shared by a plurality of applications. The method also includes receiving, by the device, a notification from a particular application of the plurality of applications. The notification indicates that the particular application will use the foundation network. The method also includes retrieving, by the device, a subnetwork associated with the particular application in response to receiving the notification from the particular application. The method also includes generating, by the device, a customized network for the particular application at least in part by inserting the subnetwork into the foundation network.",GOOGLE LLC,WANG JINGTAO;;WANG XUSONG;;HU SHIYU;;LACOMBE OLIVIER;;BUTLER MICHAEL;;WANG MIAO;;MARCHIORI EUGENIO;;YAN CHENGJI,,https://lens.org/192-186-004-308-012,Patent Application,yes,0,0,1,192-186-004-308-012,WO,1,192-186-004-308-012,WO,0,G06N3/045;;G06N3/082;;G06N3/063,G06N3/045;;G06N3/082,,1,0,,,"HOULSBY NEIL ET AL: ""Parameter-Efficient Transfer Learning for NLP"", 13 June 2019 (2019-06-13), pages 1 - 13, XP093225297, Retrieved from the Internet <URL:https://arxiv.org/pdf/1902.00751> [retrieved on 20241119]",PENDING
490,US,A1,US 2025/0086441 A1,168-938-002-908-961,3/13/2025,2025,US 202318466771 A,9/13/2023,US 202318466771 A,9/13/2023,ANSWERING SOFTWARE-RELATED QUESTIONS WITH GENERATIVE AI,"An example operation may include one or more of storing web pages with content about a software program, receiving a natural language input with a question about the software program from an input field of a user interface, generating an answer to the question about the software program based on execution of a generative artificial intelligence (GenAI) model on the question from the input field and the plurality of web pages stored in the memory, and displaying the answer to the question via the user interface.",TORONTO DOMINION BANK,GUTTRIDGE FRANCIS JAMES ALEXANDER;;D'AGOSTINO DINO PAUL;;PRATTEN A WARREN;;MOHAMMED SHAHZAD;;CHIKKALAVALASA ARVIND;;NAWAZ WAQAS,,https://lens.org/168-938-002-908-961,Patent Application,yes,0,0,1,168-938-002-908-961,US,1,168-938-002-908-961,US,0,G06N3/0475;;G06N3/0455;;G06N3/08;;G06N3/0475;;G06N3/0455;;G06N3/08,G06N3/0475;;G06N3/0455;;G06N3/08,,0,0,,,,PENDING
491,US,A1,US 2025/0217588 A1,152-502-500-474-213,7/3/2025,2025,US 202318400715 A,12/29/2023,US 202318400715 A,12/29/2023,GENERATIVE NEURAL NETWORK MODEL STYLE GUIDE MANAGEMENT,"A method for style guide management is described. A first user input is received from a user via a graphical user interface (GUI). The first user input identifies a writing sample having a textual style. A style guide is generated, based on the writing sample, having a description of a target style, based on the textual style, for input to a generative neural network model (GNNM). A profile representing the style guide and comprising a natural language format description is sent for display in the GUI. The style guide is modified based on an explicit indication of a style preference. A request for drafting assistance is sent to the GNNM, the request including the style guide for text generation according to the style guide by the GNNM. An output generated by the GNNM in response to the request is obtained. The output is sent to be displayed within the GUI.",MICROSOFT TECHNOLOGY LICENSING LLC,RAMOS GONZALO A;;NG SHIQIAN RACHEL;;HUNTINGTON ANDREW JAMES;;BANKS RICHARD MALCOLM;;TROY ADAM D;;YEH CATHERINE,,https://lens.org/152-502-500-474-213,Patent Application,yes,0,0,1,152-502-500-474-213,US,1,152-502-500-474-213,US,0,G06F40/253;;G06F3/0484;;G06F40/253,G06F40/253;;G06F3/0484,,0,0,,,,PENDING
492,US,A1,US 2025/0190290 A1,003-802-461-020-455,6/12/2025,2025,US 202418939214 A,11/6/2024,US 202418939214 A;;US 202363609286 P,12/12/2023,GENERATIVE ARTIFICIAL INTELLIGENCE USING A SERVER SIDE PROMPT PROGRAM,"Generative artificial intelligence (AI) using a server-side prompt program is disclosed. In various embodiments, an API call comprising a request is received from a remote system. A server-side prompt program comprising or otherwise associated with one or both of the API call and the request is executed, including by sending two or more prompts to a generative AI service. A final result obtained by sending the two or more prompts to the generative AI service is received and returned to the remote system in response to the API call.",CRYSTAL COMPUTING CORP,KISSANE COLE L,CRYSTAL COMPUTING CORP (2025-01-15),https://lens.org/003-802-461-020-455,Patent Application,yes,1,0,1,003-802-461-020-455,US,1,003-802-461-020-455,US,0,G06N20/00;;G06F9/547;;G06F9/5005;;G06F2209/541;;G06F9/45512;;G06F8/36;;G06F9/547,G06F9/54,,0,0,,,,PENDING
493,US,A1,US 2024/0362492 A1,185-233-220-160-679,10/31/2024,2024,US 202418646234 A,4/25/2024,US 202418646234 A;;US 202363461663 P,4/25/2023,"SYSTEMS, METHODS, AND COMPUTER-ACCESSIBLE MEDIUM FOR PROVIDING HUMAN-MODEL ALIGNMENT USING METADATA AND ARTIFACTS, PATIENT INFORMATION, OR SYNTHETIC DATA","Exemplary systems, methods, and computer-accessible medium are provided that can train a language model for a medical use or performing a medically-related procedure. Thus, exemplary systems, methods, and computer-accessible medium can be provided that can model a reward neural network on one or more physician preferences and train the language model by applying the reward neural network modeled on the physician preference(s) as feedback to guide the language model to learn the physician preference(s). The reward neural network can rely on an artificial intelligent (AI) model as a surrogate reward function for a physician feedback, and can obtain the physician preference(s) implicitly from electronic health records and/or other sources of medical data.",UNIV NEW YORK,OERMANN ERIC KARL,NEW YORK UNIVERSITY (2023-05-04),https://lens.org/185-233-220-160-679,Patent Application,yes,0,2,1,185-233-220-160-679,US,1,185-233-220-160-679,US,0,G06N3/092;;G16H50/20;;G06N3/045;;G16H50/70;;G16H15/00;;G16H10/20;;G06N3/09;;G06N3/0475;;G16H10/60;;G06N3/092,G06N3/092;;G16H10/60,,0,0,,,,PENDING
494,US,A1,US 2025/0209308 A1,100-329-803-847-037,6/26/2025,2025,US 202318394480 A,12/22/2023,US 202318394480 A,12/22/2023,Risk Analysis and Visualization for Sequence Processing Models,"Aspects of the disclosed technology include computer-implemented systems and methods for moderating generative content produced by machine-learned generative models and providing outputs indicative of query and response validity for a target domain. The system can generate a query association based on a user query and domain artifacts of a target domain and generate a response association based on generative content and the domain artifacts. The system can embed the domain artifacts in a vector embedding space and/or train a machine-learned model using the domain artifacts. The system can determine the validity of queries and responses for the target domain using the vector embeddings and the machine-learned model. The system can moderate content, such as by filtering queries and/or generative content that does not satisfy association criteria for a target domain. The system can generate outputs such as visualizations of query and response distance relative to a target domain.",GOOGLE LLC,NAMER ASSAF;;MALTZMAN BRANDON;;MILLER JAMES SCOTT;;BUDDHDEV TANAY NARENDRA,GOOGLE LLC (2023-12-19),https://lens.org/100-329-803-847-037,Patent Application,yes,0,0,1,100-329-803-847-037,US,1,100-329-803-847-037,US,0,G06N3/0455;;G06N3/0475;;G06F16/953;;G06N3/045;;G06N3/0455;;G06N3/0475;;G06F16/953,G06N3/0455;;G06F16/953;;G06N3/0475,,0,0,,,,PENDING
495,US,A1,US 2024/0265174 A1,137-506-593-824-407,8/8/2024,2024,US 202418434053 A,2/6/2024,US 202418434053 A;;US 202363443602 P,2/6/2023,"SYSTEMS, METHODS AND COMPUTER-ACCESSIBLE MEDIUM FOR PROVIDING A LANGUAGE MODEL POPULATION SIMULATOR","Exemplary systems, methods, and computer-accessible medium are provided that that can leverage a large language model (LLM) to determine a prediction of a population level response to presented information. Thus, the exemplary systems, methods, and computer-accessible medium are provided that condition at least one large language model (LLM) agent on a plurality of population or group features using in-weight training or in-context tokens, record an initial memory state of the at least one large language model (LLM) agent, retrieve one or more entries of an LLM agent output from an LLM agent memory to include in the next planning step, plan an LLM agent response to an environment for the presented information, send one or more conditioned intra-agent communications to a plurality of additional LLM agents, receive the one or more conditioned intra-agent communications from the plurality of additional LLM agents, record an updated memory state of the LLM agent based on the one or more sent and received conditioned intra-agent communications, and generate the prediction based on the updated memory state.",UNIV NEW YORK,OERMANN ERIC KARL,NEW YORK UNIVERSITY (2023-05-04),https://lens.org/137-506-593-824-407,Patent Application,yes,0,0,1,137-506-593-824-407,US,1,137-506-593-824-407,US,0,G06F30/27;;G06F30/27,G06F30/27,,0,0,,,,PENDING
496,US,B1,US 12367213 B1,155-637-130-563-32X,7/22/2025,2025,US 202418893699 A,9/23/2024,US 202418893699 A,9/23/2024,Generating structured data from unstructured data using metadata from a large language model,"Disclosed are methods and systems for generating structured data from unstructured data using metadata received from a large language model (LLM). An exemplary method includes: receiving computing prompts from a source; receiving a first vector embedding for a first computing prompt from an LLM; receiving a second vector embedding for a second computing prompt from the LLM; generating a computing prompt group comprising the first computing prompt and the second computing prompt; determining at least one first file from a vector database that corresponds with the first computing prompt; determining at least one second file from the vector database that corresponds with the second computing prompt; receiving processed data from the LLM based on the computing prompt group, the at least one first file, and the at least one second file; and generating structured data comprising the processed data and computing indicators.",ARAVO SOLUTIONS INC,HENSLEY ERIC B;;WOLOCHUK MARK C,,https://lens.org/155-637-130-563-32X,Granted Patent,yes,37,0,1,155-637-130-563-32X,US,1,155-637-130-563-32X,US,0,G06F16/2237;;G06F16/258,G06F16/25;;G06F16/22,,11,0,,,"De Bellis, A., Structuring the unstructured: an LLM-guided transition, Doctoral Consortium at ISWC 2023 co-located with 22st International Semantic Web Conference (ISWC 2023), pp. 1-8. (Year: 2023).;;Aishwarya, V, A Prompt Engineering Approach for Structured Data Extraction from Unstructured Text Using Conversational LLMs, ACAI 2023: 2023 6th International Conference on Algorithms, Computing and Artificial Intelligence Sanya China Dec. 22-24, 2023. (Year: 2023).;;Peng et al., Embedding-based Retrieval with LLM for Effective Agriculture Information Extracting from Unstructured Data, R. Peng, K. Liu, P. Yang, Z. Yuan, and S. Li, “Embedding-based retrieval with LLM for effective agriculture information extracting from unstructured data,” 2023, arXiv:2308.03107 (Year: 2023).;;Notice of Allowance dated Dec. 2, 2024 in connection with U.S. Appl. No. 18/893,710, 8 pages.;;Final Office Action dated Feb. 6, 2025 in connection with U.S. Appl. No. 18/893,703, 41 pages.;;Notice of Allowance dated Dec. 18, 2024 in connection with U.S. Appl. No. 18/893,706, 9 pages.;;Daqqah, Bilal H. “Leveraging Large Language Models (LLMs) for Automated Extraction and Processing of Complex Ordering Forms.” PhD diss., Massachusetts Institute of Technology, May 2024, 67 pages.;;Liu, Xiaoxia, et al. “Prompting Frameworks for Large Language Models: A Survey.” arXiv:2311.12785v1, Nov. 21, 2023, 34 pages.;;Wedholm, William. “Exploring the Influence of Data Formats on the Consistency of Large Language Models Outputs” Jun. 10, 2024, 34 pages.;;Schilling-Wilhelmi, Mara, et al. “From Text to Insight: Large Language Models for Materials Science Data Extraction” arXiv:2407.16867v1, Jul. 23, 2024, 51 pages.;;Non-Final Office Action dated Dec. 5, 2024 in connection with U.S. Appl. No. 18/893,703, 32 pages.",ACTIVE
497,US,A1,US 2025/0086394 A1,006-397-322-424-049,3/13/2025,2025,US 202318243570 A,9/7/2023,US 202318243570 A,9/7/2023,DIGITAL ASSISTANT GENERATION VIA LARGE LANGUAGE MODELS,"Automated digital assistant generation can be implemented via large language models. Domain-specific documents can be loaded into a large language model that is then prompted to generate intents, entities, exemplar utterances, and the like. Such configuration components can then be assembled into a digital assistant definition that can then be deployed as a digital assistant for the domain in question. Skills can be aggregated so that the digital assistant can address the domain along with other domains, whether closely related or not.",SAP SE,REDDY SRINIVASA BYAIAH RAMACHANDRA,SAP SE (2023-08-16),https://lens.org/006-397-322-424-049,Patent Application,yes,0,4,1,006-397-322-424-049,US,1,006-397-322-424-049,US,0,G06N20/00;;G06F40/40;;G06F40/30;;G06F40/279;;G06F40/35;;G06F40/40;;G06F40/279;;G06F40/30;;G06N20/00,G06F40/30;;G06F40/279;;G06F40/40;;G06N20/00,,0,0,,,,PENDING
498,US,A1,US 2025/0245218 A1,065-348-723-132-513,7/31/2025,2025,US 19042824,1/31/2025,,,METHODS AND APPARATUS FOR A RETRIEVAL AUGMENTED GENERATIVE (RAG) ARTIFICIAL INTELLIGENCE (AI) SYSTEM,"A non-transitory, processor-readable medium storing instructions that when executed by a processor, cause the processor to receive data artifacts, encode the artifacts to a standard data type, and compute, for each artifact, a hash function. The hash functions and encoded documents are stored in a first database. The processor is caused to tokenize the encoded artifacts, to produce tokens associated with natural-language identifiers extracted from the encoded artifacts. The processor is caused to transform, using an embedding model, the tokens to produce vectors that are stored in a second database and classified based on categories. The second database is configured to be queried to perform a semantic search in response to receiving a request from a user operating a user compute device. The processor is caused to retrieve, from the semantic search, a subset of vectors from the second database to be displayed on the user compute device.","FEDDATA HOLDINGS, LLC",Gianluca LONGONI,,https://lens.org/065-348-723-132-513,Patent Application,yes,0,0,1,065-348-723-132-513,US,1,065-348-723-132-513,US,0,G06F16/245;;G06F16/2255;;G06F16/24578;;G06F16/248,G06F16/245;;G06F16/22;;G06F16/2457;;G06F16/248,,0,0,,,,UNKNOWN
499,EP,A1,EP 4528544 A1,196-029-911-215-086,3/26/2025,2025,EP 24193549 A,8/8/2024,US 202363539772 P;;US 202418611980 A,9/21/2023,PRACTICAL FACT CHECKING SYSTEM FOR LLMS,A system for creating generated descriptive text is provided. A prompt having first facts for an item is received and parsed to extract a first fact in a format. Second facts are generated where the first fact and the second facts are output in the format. A search query is generated that includes the first fact and the second facts and then a search is conducted using the search query. An output is generated based on the results. The output includes a suggested description of the item using at least one first fact of the first facts and the second facts. The output also has a summarization of the plurality of first facts and the second facts along with differences between the first facts and the second facts. A distribution of the plurality of first facts and the second facts in the results is provided in the output.,EBAY INC,FUCHS GILAD ELIYAHU;;IDO BEN-SHAUL,,https://lens.org/196-029-911-215-086,Patent Application,yes,0,0,2,148-986-144-700-040;;196-029-911-215-086,EP;;CN,2,148-986-144-700-040;;196-029-911-215-086,EP;;CN,0,G06F16/9532;;G06F16/90332,G06F16/9032;;G06F16/9532,,1,0,,,"GEORGIOS PEIKOS ET AL: ""Utilizing ChatGPT to Enhance Clinical Trial Enrollment"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 3 June 2023 (2023-06-03), XP091529292",DISCONTINUED
500,EP,A1,EP 4521366 A1,110-068-567-453-705,3/12/2025,2025,EP 23306497 A,9/8/2023,EP 23306497 A,9/8/2023,NOTETAKING IN ELECTRONIC DOCUMENTS,"The invention relates to a computer-implemented method and a computing device (DV1) for processing an electronic document (FL1). The method may comprise: displaying a handwritten text block (BL1) of the electronic document; detecting a user selection of a first portion (PR1) of the handwritten text block (BL1); recognizing as text content the selected first portion (PR1) of the handwritten text block and a second portion (PR2), including handwritten text other than the selected first portion, of the handwritten text block (BL1) by handwriting recognition based on said handwritten text block; and obtaining first information (IF1) related to the recognised text (TX1) of the first portion (PR1) of the handwritten text block as an output of a trained predictive model (ML1) using the recognised text (TX2) of the second portion (PR2) of the handwritten text bock as context of the recognised text (TX1) of the first portion.",MYSCRIPT,LIOUMBIS ALEXANDROS,,https://lens.org/110-068-567-453-705,Patent Application,yes,3,0,2,189-286-745-325-928;;110-068-567-453-705,WO;;EP,2,189-286-745-325-928;;110-068-567-453-705,WO;;EP,0,G06V30/40;;G06V10/82;;G06V30/1456;;G06F40/10,G06V30/14;;G06V30/40,,0,0,,,,PENDING
501,US,A1,US 2025/0077227 A1,119-649-263-517-338,3/6/2025,2025,US 202318459323 A,8/31/2023,US 202318459323 A,8/31/2023,GAP IDENTIFICATION AND SOLUTION RECOMMENDATION FOR COMPLEX SOFTWARE ARCHITECTURE,"An example operation may include one or more of receiving a plurality of architecture documents of a plurality of different domains of a software architecture, identifying a missing component that is missing from within the software architecture between a first domain and a second domain among the plurality of domains based on execution of a generative artificial intelligence (GenAI) model based on the plurality of architecture documents of the software architecture, generating a recommended modification to the software architecture based on the identified missing component, and displaying the recommended modification via a user interface.",TORONTO DOMINION BANK,GUTTRIDGE FRANCIS JAMES ALEXANDER;;D'AGOSTINO DINO PAUL;;PRATTEN A WARREN;;MOHAMMED SHAHZAD;;CHIKKALAVALASA ARVIND;;NAWAZ WAQAS,,https://lens.org/119-649-263-517-338,Patent Application,yes,0,0,1,119-649-263-517-338,US,1,119-649-263-517-338,US,0,G06F8/75;;G06F8/10;;G06F8/73;;G06F8/10;;G06F8/75,G06F8/75;;G06F8/10,,0,0,,,,PENDING
502,US,B1,US 12182678 B1,176-778-748-892-548,12/31/2024,2024,US 202418646104 A,4/25/2024,US 202418646104 A;;US 202418599955 A,3/8/2024,Systems and methods for aligning large multimodal models (LMMs) or large language models (LLMs) with domain-specific principles,A system and method aligns generative artificial intelligence (a large language model (LLM) or a large multimodal model (LMM) with the principles of a specific domain so that the generative artificial intelligence is better able to respond to a user query in the specific domain. The system and method may post-train an already trained generative artificial intelligence system or fine tune the training of the generative artificial intelligence system to align that generative artificial intelligence system with the principles of the specific domain. The system and method may be used to align the generative artificial intelligence system to a plurality of different domains.,SEEKR TECH INC,POULIS STEFANOS;;CLARK ROBIN J;;CONDO PATRICK C,SEEKR TECHNOLOGIES INC (2024-04-25),https://lens.org/176-778-748-892-548,Granted Patent,yes,79,1,1,176-778-748-892-548,US,3,176-778-748-892-548;;077-869-383-900-326;;053-361-459-194-969,US,0,G06N3/045;;G06N3/08;;G06N20/00;;G06N20/00,G06N20/00,,35,8,061-422-655-369-830;;188-602-268-229-356;;112-553-588-148-808;;178-391-712-947-101;;119-264-444-547-811;;117-249-951-482-372;;040-308-993-975-429;;007-036-730-433-852,10.1162/tacl_a_00530;;10.25172/smustlr.27.1.3;;10.1145/3630106.3658979;;10.18653/v1/2023.findings-emnlp.68;;10.18653/v1/2023.trustnlp-1.12;;10.2139/ssrn.4874670;;10.18653/v1/2023.findings-emnlp.97;;10.18653/v1/2023.findings-emnlp.182,"Sun, “Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision”, 37th Conference on Neural Information Processing Systems, 2023. (Previously supplied). (Year: 2023).;;Siriwardhana, “Improving the Domain Adaptation of Retrieval Augmented Generation (RAG) Models for Open Domain Question Answering”, Transactions of the Association for Computational Linguistics, vol. 11, pp. 1-17, 2023. (Previously supplied). (Year: 2023).;;Shen, “Large Language Model Alignment: A Survey”, 2023. (Year: 2023).;;Baulepur, “Aligning Language Models with Factuality and Truthfulness” Thesis submitted in partial fulfillment of Bachelor of Science in Computer Science, University of Illinois At Urbana-Champaign, 2023, 50 pages.;;Azaria, et al., “The Internal State of an LLM Knows When its Lying”, School of Computer Science, Ariel University, Israel and Machine Learning Dept., Carnegie Mellon University, Pittsburgh, PA, Apr. 2023, 10 pages.;;Lee, et al., “Linguistic Properties of Truthful Response,” University of Pennsylvania, PA, USA., Jun. 2023, 6 pages.;;Poulis, “Algorithms for Interactive Machine Learning”, Dissertation submitted in partial fulfillment of degree of Doctor of Philosophy in Computer Science, University of California, San Diego, 2019, 148 pages.;;Yang, et al., “RefGPT: Reference—Truthful & Customized Dialogues Generation by GPTs and for GPTs”, Shanghai Jiao Tong University, Hong Kong Polytechnical University, Beijing University of Posts and Telecommunications, May 2023, 20 pages.;;Pan, et al., “On the Risk of Misinformation Pollution with Large Language Models”, National University of Singapore, University of California, Santa Barbara, University of Waterloo, Mbzuai, Zhejiang University, May 2023, 14 pages.;;McKenna, et al., “Sources of Hallucination by Large Language Models on Inference Tasks”, University of Edinburgh, Google Research, Macquarie University, May 2023, 17 pages.;;Mitra, AgentInstruct: Toward Generative Teaching with Agentic Flows, 2024.;;Dawson, “Algorithmic Adjudication and Constitutional AI—The Promise of A Better AI Decision Making Future?”, 2024.;;Balepur, “Aligning Language Models With Factuality And Truthfulness”, 2023.;;Huang, “Collective Constitutional AI: Aligning a Language Model with Public Input”, 2024.;;Bai, “Constitutional AI: Harmlessness from AI Feedback”, 2022.;;Azaria, “The Internal State of an LLM Knows When its Lying”, 2023.;;Lee, “Linguistic Properties of Truthful Response”, 2023.;;Poulis, “Algorithms for Interactive Machine Learning”, 2019.;;Abiri, “Public Constitutional AI”, 2024.;;Yang, “RefGPT: Reference -> Truthful & Customized Dialogues Generation by GPTs and for GPTs”, 2023.;;Pan, “On the Risk of Misinformation Pollution with Large Language Models”, 2023.;;McKenna, “Sources of Hallucination by Large Language Models on Inference Tasks”, 2023.;;Claude, “Collective Constitutional AI: Aligning a Language Model with Public Input”, 2023. Webpage: file///Collective%20 Constitutional%20 AI_%20.;;“A Survey on Knowledge Distillation of Large Language Models” https://arxiv.org/pdf/2402.13116.;;“AgentInstruct: Toward Generative Teaching with Agentic Flows” https://arxiv.org/pdf/2407.03502.;;“A Closer Look at the Limitations of Instruction Tuning” https://arxiv.org/abs/2402.05119.;;“Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?” https://arxiv.org/abs/2405.05904.;;“Injecting New Knowledge into Large Language Models via Supervised Fine-Tuning” https://arxiv.org/abs/2404.00213.;;“Self-Tuning: Instructing LLMs to Effectively Acquire New Knowledge through Self-Teaching” https://arxiv.org/abs/2406.06326.;;“Knowledge Editing in Language Models via Adapted Direct Preference Optimization” https://arxiv.org/abs/2406.09920.;;“Qilin Med: Multi-stage Knowledge Injection Advanced Medical Large Language Model”, 2024.;;“Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs” https://arxiv.org/abs/2312.05934.;;“FanOutQA: A Multi-Hop, Multi-Document Question Answering Benchmark for Large Language Models” https://arxiv.org/abs/2402.14116.;;“Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge” https://arxiv.org/abs/2403.01432.;;“RAFT: Adapting Language Model to Domain Specific RAG” https://arxiv.org/abs/2403.10131.",ACTIVE
503,US,A1,US 2025/0111153 A1,036-167-803-553-305,4/3/2025,2025,US 202318374625 A,9/28/2023,US 202318374625 A,9/28/2023,METHOD AND APPARATUS FOR TRANSLATING TEXT INTO A SEQUENCE OF CHARACTERS INCLUDING GRAPHICAL SYMBOLS,"A computer-implemented method for translating an input text element into a sequence of characters comprising a set of graphical symbols. The method comprises the steps of: selecting (12) one or more words out of the input text element as pre-processed or unprocessed to be translated to obtain a word selection; marking (12) the word selection; translating (13) the word selection identified by the marking into at least a set of graphical symbols by using an artificial intelligence language model considering the context of the word selection in the pre-processed text element to dynamically translate the word selection based on the context to obtain a translated word selection, wherein a given word in the word selection is translated into a sequence of at least two graphical symbols; and displaying (15) the input text element as translated to a user, wherein the input text element as translated comprises the translated word selection.",ECOLE POLYTECHNIQUE FED LAUSANNE EPFL,WEST ROBERT;;KLEIN LARS;;AYDIN ROLAND,ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE (EPFL) (2023-09-14),https://lens.org/036-167-803-553-305,Patent Application,yes,6,0,2,036-167-803-553-305;;083-274-939-151-08X,US;;EP,2,036-167-803-553-305;;083-274-939-151-08X,US;;EP,0,G06F40/30;;G06F40/103;;G06F40/279;;G06F40/274,G06F40/274;;G06F40/279,,3,0,,,"Monti et al., Emojitaliano: A Social and Crowdsourcing Experiment of the Creation of a Visual International Language, 2021, HCII 2021, LNCS 12779, pp. 426-441 (Year: 2021);;Zheng et al., Judging LLM-as-a-judge with MT-Bench and Chatbot Arena, 9 June 2023, arXiv:2306.05685v1 (Year: 2023);;Daniel K and Anoir Ben Tangous, MouseTooltipTranslator, Github repository, 29 Jun. 2023 (Year: 2023)",PENDING
504,US,A1,US 2025/0077190 A1,116-550-353-961-45X,3/6/2025,2025,US 202318458985 A,8/30/2023,US 202318458985 A,8/30/2023,REAL-TIME VISUALIZATION OF COMPLEX SOFTWARE ARCHITECTURE,"An example operation may include one or more of storing software architecture diagrams in a data store, receiving runtime data from a plurality of different software systems within a software architecture, the runtime data comprising descriptions of events that occur during runtime between the different software systems of the software architecture, generating a diagram of the software architecture based on execution of a multi-modal generative artificial intelligence (GenAI) model on the runtime data and the software architecture diagrams stored in the data store, and displaying the diagram of the software architecture via a user interface.",TORONTO DOMINION BANK,GUTTRIDGE FRANCIS JAMES ALEXANDER;;D'AGOSTINO DINO PAUL;;PRATTEN A WARREN;;MOHAMMED SHAHZAD;;CHIKKALAVALASA ARVIND;;NAWAZ WAQAS,,https://lens.org/116-550-353-961-45X,Patent Application,yes,1,0,1,116-550-353-961-45X,US,1,116-550-353-961-45X,US,0,G06N3/0475;;G06F8/20;;G06F8/35;;G06F8/10;;G06N3/0475;;G06F8/20,G06F8/20;;G06N3/0475,,0,0,,,,PENDING
505,US,A1,US 2025/0077187 A1,098-589-883-371-876,3/6/2025,2025,US 202318458972 A,8/30/2023,US 202318458972 A,8/30/2023,GENERATING SOFTWARE ARCHITECTURE FROM CONVERSATION,"An example operation may include one or more of receiving and recording electronic communications that occur between users of an organization within a data store, receiving an input via a user interface, retrieving the electronic communications of the organization and software architecture documents from the data store in response to receipt of the input, generating a diagram of a software architecture of the organization based on execution of a generative artificial intelligence (GenAI) model on the electronic communications of the organization and the software architecture documents, and displaying the diagram of the software architecture via a user interface.",TORONTO DOMINION BANK,GUTTRIDGE FRANCIS JAMES ALEXANDER;;D'AGOSTINO DINO PAUL;;PRATTEN A WARREN;;MOHAMMED SHAHZAD;;CHIKKALAVALASA ARVIND;;NAWAZ WAQAS,THE TORONTO-DOMINION BANK (2023-09-21),https://lens.org/098-589-883-371-876,Patent Application,yes,13,0,1,098-589-883-371-876,US,1,098-589-883-371-876,US,0,G06F8/10;;G06F8/10,G06F8/10,,5,4,102-873-702-983-074;;075-589-047-299-27X;;010-534-047-358-333;;017-650-266-888-716,10.1109/vissoft60811.2023.00014;;10.1109/punecon63413.2024.10895089;;10.1109/jiot.2024.3420696;;10.1145/3662739.3673681,"Santos et al, ""Impacts of the Usage of Generative Artificial Intelligence on Software Development Process"", ACM, pp 1-9 (Year: 2024);;Heidrich et al, ""Visualizing Source Code as Comics Using Generative AI"", IEEE, pp 1-5 (Year: 2023);;Arun, ""A Software Architectural Model for Generative Artificial Intelligence with Reinforcement Learning"", IEEE, pp 1-6 (Year: 2024);;He et al, ""Securing Federated Diffusion Model With Dynamic Quantization for Generative AI Services in Multiple-Access Artificial Intelligence of Things"", IEEE, pp 1-14 (Year: 2024);;Zhang et al, ""Application Research on Artificial Intelligence Generated Content in Architectural Design"", ACM, pp 1-10 (Year: 2024)",PENDING
506,US,A1,US 2025/0077188 A1,154-202-646-162-78X,3/6/2025,2025,US 202318458900 A,8/30/2023,US 202318458900 A,8/30/2023,CREATING A MODEL OF SOFTWARE ARCHITECTURE,"An example operation may include one or more of training a generative artificial intelligence (GenAI) model via execution of the GenAI model on descriptions and diagrams of a software architecture, receiving a plurality of different architecture views from a plurality of different domains of the software architecture, generating an architecture diagram of the plurality of domains of the software architecture in combination based on execution of the GenAI model on the plurality of different architecture views from the plurality of different domains, and displaying the architecture diagram of the plurality of domains of the software architecture via a user interface.",TORONTO DOMINION BANK,GUTTRIDGE FRANCIS JAMES ALEXANDER;;D'AGOSTINO DINO PAUL;;PRATTEN A WARREN;;MOHAMMED SHAHZAD;;CHIKKALAVALASA ARVIND;;NAWAZ WAQAS,,https://lens.org/154-202-646-162-78X,Patent Application,yes,0,0,1,154-202-646-162-78X,US,1,154-202-646-162-78X,US,0,G06F8/20;;G06F8/20,G06F8/20,,0,0,,,,PENDING
507,US,A1,US 2025/0077556 A1,116-408-493-973-80X,3/6/2025,2025,US 202318458886 A,8/30/2023,US 202318458886 A,8/30/2023,LEVERAGING AN ARCHITECTURE BLUEPRINT TO DETERMINE INFORMATION,"An example operation may include one or more of training a generative artificial intelligence (GenAI) model based on architecture diagrams of a software architecture and descriptions of the architecture diagrams, displaying one or more prompts on a user interface, receiving one or more natural language responses associated with the software architecture in response to the one or more prompts, generating a text-based response to the natural language query submitted via the user interface based on execution of the GenAI model on the one or more prompts and the one or more natural language responses associated with the software architecture, and displaying the text-based response via the user interface.",TORONTO DOMINION BANK,GUTTRIDGE FRANCIS JAMES ALEXANDER;;D'AGOSTINO DINO PAUL;;PRATTEN A WARREN;;MOHAMMED SHAHZAD;;NAWAZ WAQAS,,https://lens.org/116-408-493-973-80X,Patent Application,yes,0,0,1,116-408-493-973-80X,US,1,116-408-493-973-80X,US,0,G06T11/60;;G06F16/3344;;G06T11/60;;G06F16/3344,G06F16/33;;G06T11/60,,0,0,,,,PENDING
508,US,A1,US 2025/0139539 A1,144-101-329-129-956,5/1/2025,2025,US 202318496007 A,10/27/2023,US 202318496007 A,10/27/2023,GENERATION OF EXECUTABLE PROCEDURE USING NATURAL LANGUAGE,"Systems and methods include input of a description of a procedure to a large language model to determine a domain of the description, determination of modifiers to the description based on the domain, determination of example procedure models and descriptions corresponding to the example procedure models based on the domain, generation of a procedure model prompt based on the description, the modifiers, the example procedure models and corresponding descriptions, provision of the procedure model prompt to the large language model, reception, in response to the prompt, of a generated procedure model from the large language model, and storage of the generated procedure model for execution by a workflow automation system.",SAP SE,GAUTAM PRASHANT;;ROUTH MANNA;;RAZAK MD,SAP SE (2023-10-26),https://lens.org/144-101-329-129-956,Patent Application,yes,0,0,1,144-101-329-129-956,US,1,144-101-329-129-956,US,0,G06F16/3344;;G06F8/41;;G06F40/40;;G06F40/30;;G06Q10/06;;G06F16/345;;G06F8/10;;G06Q10/0633;;G06Q10/06;;G06F40/30;;G06F8/41;;G06F16/3344;;G06F16/345;;G06F40/40,G06Q10/06;;G06F8/41;;G06F16/33;;G06F16/34;;G06F40/30;;G06F40/40,,0,0,,,,PENDING
509,US,A1,US 2025/0245274 A1,121-434-220-212-685,7/31/2025,2025,US 18429360,1/31/2024,,,AUTOMATIC ONBOARDING TO A COMPUTER APPLICATION BY SCRAPING WEBSITE DATA,"Systems and methods for automating onboarding to a computer application are provided. Onboarding to the computer application is automated by a novel combination of capturing an entity's website, scraping the website for entity data, and using a large language model to extract relevant information. The extracted relevant information is auto-populated on a display. The entity user can update or confirm the displayed information. Therefore, the cognitive strain and inefficiencies associated with switching between computer applications is significantly reduced.",INTUIT INC.,James DUTCZAK;;Deepakkumar PRABHAKARAN;;Jimmy HO;;Gopal JAYARAM;;Siwei YU;;Alexandra ROHRER;;Jennifer Lee HONG,,https://lens.org/121-434-220-212-685,Patent Application,yes,0,0,1,121-434-220-212-685,US,1,121-434-220-212-685,US,0,G06F16/951;;G06F40/20,G06F16/951;;G06F40/20,,0,0,,,,UNKNOWN
510,US,A1,US 2024/0333699 A1,142-523-325-116-637,10/3/2024,2024,US 202418620449 A,3/28/2024,US 202418620449 A;;US 202363455365 P,3/29/2023,DYNAMIC ONE-TIME USE KNOWLEDGE-BASED AUTHENTICATION VIA MULTI-SOURCED PRIVATE DATA USING ARTIFICIAL INTELLIGENCE TECHNIQUES,"Exemplary systems and methods utilize unique knowledge-based authentication techniques involving private and/or recent data. Via use of the disclosed concepts, authentication is made more robust, and is hardened against compromise techniques such as those drawing from prior data breaches, public records, and the like. In this manner, simpler and more reliable authentication is achieved.",MATRIXED IP HOLDINGS LLC,NARENDRANATHAN AGASTHYA P;;DZIERZANOWSKI JAMES M,MATRIXED IP HOLDINGS LLC (2024-03-28),https://lens.org/142-523-325-116-637,Patent Application,yes,0,1,1,142-523-325-116-637,US,1,142-523-325-116-637,US,0,G06F40/40;;H04L63/08;;G06F40/279;;H04L63/08;;G06F40/40;;G06F40/279;;G06F21/31,H04L9/40;;G06F40/279;;G06F40/40,,0,0,,,,PENDING
511,US,A1,US 2024/0362286 A1,192-538-743-066-367,10/31/2024,2024,US 202318141194 A,4/28/2023,US 202318141194 A,4/28/2023,SEMANTIC SEARCH AND SUMMARIZATION FOR ELECTRONIC DOCUMENTS,Techniques for an artificial intelligence (AI) platform to search a document collection are described. Embodiments may use AI and machine learning techniques within a framework of an electronic document management system to perform semantic searching of an electronic document or a collection of electronic documents for certain types of information. The AI platform may summarize the information in a natural language representation of a human language. Other embodiments are described and claimed.,DOCUSIGN INC,HE YAN;;ZAKHVATOV ALEXEY;;LAM YAN PUI;;SRIVASTAVA SOUMYA;;GREBELSKI MARIO M;;HASAN SOULEIMAN;;SHARMA ABHINAV U,DOCUSIGN INC (2023-08-10),https://lens.org/192-538-743-066-367,Patent Application,yes,24,10,1,192-538-743-066-367,US,3,105-637-329-268-21X;;120-932-291-917-151;;192-538-743-066-367,US;;WO,0,G06F16/901;;G06N3/08;;G06F16/93;;G06F16/9538;;G06N5/022;;G06N3/045;;G06N3/088;;G06F16/9538;;G06F16/93;;G06N3/08;;G06N5/022;;G06F16/901,G06F16/9538;;G06F16/901;;G06F16/93;;G06N3/08;;G06N5/022,,0,0,,,,PENDING
512,US,A1,US 2024/0256964 A1,031-211-286-681-483,8/1/2024,2024,US 202418424031 A,1/26/2024,SG 10202300220Q A,1/27/2023,Pretraining Already-Pretrained Models for Diverse Downstream Tasks,"An example method includes obtaining a pretrained machine-learned model that was initially pretrained using a pretraining dataset and further pretraining the model by generating, using a pretraining objective framework, a plurality of corrupted training examples from one or more training examples obtained from the pretraining dataset. A first set of one or more training examples can be corrupted according to a first set of configuration parameters of the pretraining objective framework. A second set can be corrupted according to a second set of configuration parameters of the pretraining objective framework. The example method includes inputting the plurality of corrupted training examples into model; obtaining from the model, a plurality of outputs respectively generated by model based on the plurality of corrupted training examples; and updating one or more parameters of model based on an evaluation of the plurality of outputs.",GOOGLE LLC,TAY YI;;DEHGHANI MOSTAFA,GOOGLE LLC (2023-04-26),https://lens.org/031-211-286-681-483,Patent Application,yes,0,3,1,031-211-286-681-483,US,1,031-211-286-681-483,US,0,G06F7/483;;G06N20/00;;G06N3/045;;G06F7/483;;G06N20/00,G06F7/483;;G06N20/00,,0,0,,,,PENDING
513,US,A1,US 2025/0077397 A1,077-106-167-265-289,3/6/2025,2025,US 202318462363 A,9/6/2023,US 202318462363 A,9/6/2023,LARGE LANGUAGE MODEL TRAINING FOR TEST CASE GENERATION,"An example operation may include one or more of generating a large language model via a user interface, executing the large language model on a repository of software test cases and requirements of the software test cases to train the large language model to understand connections between test case components and test case requirements, receiving a description of features of a software program to be tested, and in response to receiving the description of the features, generating a software test case based on execution of the large language model on the received descriptions, and displaying the software test case via the user interface.",TORONTO DOMINION BANK,SEN GOPENDU,THE TORONTO-DOMINION BANK (2023-09-21),https://lens.org/077-106-167-265-289,Patent Application,yes,8,0,1,077-106-167-265-289,US,1,077-106-167-265-289,US,0,G06F11/3688;;G06F11/3692;;G06F11/3698;;G06F11/3684;;G06N20/00;;G06F11/3688;;G06F11/3684,G06F11/36,,0,0,,,,PENDING
514,US,A1,US 2025/0124256 A1,175-555-557-727-895,4/17/2025,2025,US 202318486792 A,10/13/2023,US 202318486792 A,10/13/2023,Efficient Knowledge Distillation Framework for Training Machine-Learned Models,"An example method is provided for training a machine-learned student sequence processing model, the method comprising: obtaining a respective input; obtaining, from the student machine-learned sequence processing model, a respective output corresponding to the respective input; generating a multiscale refinement objective configured to jointly distill knowledge from a teacher machine-learned sequence processing model and reinforce preferred behavior of the student machine-learned sequence processing model, wherein the multiscale refinement objective comprises: a first component based on a divergence metric characterizing, for the respective input, a comparison of a plurality of predictions of the student machine-learned sequence processing model to a plurality of predictions of the teacher machine-learned sequence processing model; and a second component based on a reinforcement learning signal associated with the respective output; and updating the machine-learned student sequence processing model based on the multiscale refinement objective.",GOOGLE LLC,AGARWAL RISHABH;;VIEILLARD NINO JEAN;;GEIST MATTHIEU FLORENT;;BACHEM OLIVIER FRÉDÉRIC,GOOGLE LLC (2023-11-08),https://lens.org/175-555-557-727-895,Patent Application,yes,0,0,2,175-555-557-727-895;;193-355-585-544-566,US;;DE,2,175-555-557-727-895;;193-355-585-544-566,US;;DE,0,G06N20/00;;G06N3/006;;G06N3/096;;G06N7/01;;G06N3/045;;G06N3/08;;G06N3/084;;G06N3/092;;G06N3/044;;G06N3/0455;;G06N3/092,G06N3/0455;;G06N3/092,,0,0,,,,PENDING
515,WO,A1,WO 2025/144398 A1,111-966-423-763-334,7/3/2025,2025,US 2023/0086077 W,12/27/2023,US 2023/0086077 W,12/27/2023,SEMANTIC CLUSTERING FOR UNLIMITED CONTEXT WINDOW SIZES FOR SEQUENCE PROCESSING MODELS,"Systems and methods are provided for semantic clustering for arbitrarily long context windows for machine-learned sequence processing models. A computing system can obtain a context sequence. The computing system can determine a plurality of subsequences of the context sequence. The computing system can determine, using a machine-learned semantic embedding model, a semantic embedding for each subsequence. The computing system can determine, based on the semantic embedding, a plurality of semantic clusters. The computing system can generate, using a machine-learned sequence generation model and based at least in part on the semantic clusters, an output sequence.",GOOGLE LLC,BIGNELL ADAM JOSHUA,,https://lens.org/111-966-423-763-334,Patent Application,yes,0,0,1,111-966-423-763-334,WO,1,111-966-423-763-334,WO,0,G06N3/0455;;G06N20/00;;G06N3/084;;G06N3/0499;;G06N3/0442;;G06N3/0464;;G06N3/0475;;G06N3/047;;G06N3/09;;G06N3/0895;;G06N3/088,G06N3/0455;;G06N3/0442;;G06N3/0464;;G06N3/047;;G06N3/0475;;G06N3/0499;;G06N3/084;;G06N3/088;;G06N3/0895;;G06N3/09;;G06N20/00,,10,0,,,"SHUOHANG WANG ET AL: ""Cluster-Former: Clustering-based Sparse Transformer for Long-Range Dependency Encoding"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 7 June 2021 (2021-06-07), XP081976285;;FEI WEIZHI ET AL: ""Extending Context Window of Large Language Models via Semantic Compression"", 15 December 2023 (2023-12-15), pages 1 - 12, XP093175915, Retrieved from the Internet <URL:https://arxiv.org/pdf/2312.09571>;;DEREK MILLER: ""Leveraging BERT for Extractive Text Summarization on Lectures"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 7 June 2019 (2019-06-07), XP081375507;;ZHOU ET AL.: ""Mixture-of Experts with Expert Choice Routing"", ARXIV:2202.09368V2, 14 October 2022 (2022-10-14);;DOSOVITSKIY ET AL.: ""An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"", ARXIV:2010.1 1929V2, 3 June 2021 (2021-06-03);;AGOSTINELLI ET AL.: ""MusicLM:Generating Music From Text"", ARXIV:2301.11325V1, 26 January 2023 (2023-01-26);;JUMPER ET AL.: ""Highly accurate protein structure prediction with AlphaFold"", NATURE, 26 August 2021 (2021-08-26), pages 583, XP055888904, DOI: 10.1038/s41586-021-03819-2;;KUDO ET AL.: ""SentencePiece: A simple and language independent subword tokenizer and detokenizerfor Neural Text Processing"", PROCEEDINGS OF THE 2018, 31 October 2018 (2018-10-31), pages 66 - 71;;VASWANI ET AL.: ""Attention Is All You Need"", ARXIV: 1706.03762V7, 2 August 2023 (2023-08-02);;SAHARIA ET AL.: ""Non-Autoregressive Machine Translation with Latent Alignments"", ARXIV:2004.07437V3, 16 November 2020 (2020-11-16)",PENDING
516,WO,A1,WO 2025/049586 A1,148-220-058-417-688,3/6/2025,2025,US 2024/0044202 W,8/28/2024,US 202363579251 P,8/28/2023,GENERATIVE SEQUENCE PROCESSING MODELS FOR CYBERSECURITY,"Provided is a generative sequence processing model that is specifically finetuned for cybersecurity applications. This specialized generative sequence processing model can be finetuned on a comprehensive range of cybersecurity data and associated finetuning tasks, providing the model with rich capabilities for analyzing, understanding, describing, and taking action with respect to the real-time cybersecurity data generated by one or more cybersecurity operations tools. Thus, the creation and use of the generative sequence processing model represents a solution to the technical challenge of usefully analyzing and acting upon a large volume of data generated by a number of disparate cybersecurity operations tools deployed by an organization.",GOOGLE LLC,COULL SCOTT ERIC;;SMITH NICHOLAS TODD;;KRISILOFF DAVID BENJAMIN;;JOHNS JEFFREY THOMAS;;WRIGHT EVAN CHARLES;;SHANKAR UMESH,,https://lens.org/148-220-058-417-688,Patent Application,yes,0,1,1,148-220-058-417-688,WO,1,148-220-058-417-688,WO,0,G06F21/577;;G06N3/008;;G06N3/006;;G06N20/00,G06F21/57;;G06N3/008,,10,4,177-864-189-880-993;;103-212-983-826-945;;120-047-640-592-980;;084-641-049-769-580,10.1109/bigdata52589.2021.9671824;;pmc8371605;;34265844;;10.1038/s41586-021-03819-2;;10.18653/v1/d18-2012;;10.18653/v1/2020.emnlp-main.83,"RANADE PRIYANKA ET AL: ""CyBERT: Contextualized Embeddings for the Cybersecurity Domain"", 2021 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), IEEE, 15 December 2021 (2021-12-15), pages 3334 - 3342, XP034065387, DOI: 10.1109/BIGDATA52589.2021.9671824;;EHSAN AGHAEI ET AL: ""SecureBERT: A Domain-Specific Language Model for Cybersecurity"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 20 October 2022 (2022-10-20), XP091349992;;ANDREI KUCHARAVY ET AL: ""Fundamentals of Generative Large Language Models and Perspectives in Cyber-Defense"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 21 March 2023 (2023-03-21), XP091465996;;ZHOU ET AL.: ""Mixture-of Experts with Expert Choice Routing"", ARX1V:2202.09368V2, 14 October 2022 (2022-10-14);;DOSOVITSKIY ET AL.: ""An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"", ARXIV:2010.11929V2, 3 June 2021 (2021-06-03);;AGOSTINELLI ET AL.: ""MusicIM. Generating Music From Text"", ARXIV:2301.11325V1, 26 January 2023 (2023-01-26);;JUMPER ET AL.: ""Highly accurate protein structure prediction with AlphaFold"", 596 NATURE, 26 August 2021 (2021-08-26), pages 583, XP055888904, DOI: 10.1038/s41586-021-03819-2;;KUDO ET AL.: ""SentencePiece: A simple and language independent subword tokenizer and detokenizerfor Neural Text Processing"", PROCEEDINGS OF THE 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, 31 October 2018 (2018-10-31), pages 66 - 71, Retrieved from the Internet <URL:https://aclanthology.org/D18-2012.pdf>;;VASWANI ET AL.: ""Attention Is All You Need"", ARMV: 1706.03762V7, 2 August 2023 (2023-08-02);;SAHARIA ET AL.: ""Non-Autoregressive Machine Translation with Latent Alignments"", ARXIV:2004.07437V3, 16 November 2020 (2020-11-16)",PENDING
517,US,A1,US 2025/0077396 A1,178-017-982-239-885,3/6/2025,2025,US 202318462353 A,9/6/2023,US 202318462353 A,9/6/2023,TEST CASE GENERATION USING GENERATING ARTIFICIAL INTELLIGENCE,"An example operation may include one or more of receiving a request to test a software program from a user device, the request comprising a description of requirements of the software program, generating a plurality of testing elements based on execution of a generative artificial intelligence (GenAI) model on the description of the requirements of the software program and a repository of test cases, generating a test case for testing the software program where the test case comprises the plurality of testing elements generated by the GenAI model, and storing the test case within a storage device.",TORONTO DOMINION BANK,SEN GOPENDU,THE TORONTO-DOMINION BANK (2023-09-21),https://lens.org/178-017-982-239-885,Patent Application,yes,0,2,1,178-017-982-239-885,US,1,178-017-982-239-885,US,0,G06F11/3684;;G06F11/3688;;G06F11/3692;;G06F11/3698;;G06N20/00;;G06F11/3684;;G06F11/3688;;G06F11/3692,G06F11/36,,0,0,,,,PENDING
518,US,A1,US 2025/0150345 A1,037-023-518-125-241,5/8/2025,2025,US 202318502771 A,11/6/2023,US 202318502771 A,11/6/2023,INTELLIGENT AUTO-PROMPT ENGINE FOR NETWORK MANAGEMENT,"A unified prompt-based network management system that involves an intelligent auto-prompt engine generating contextualized prompts for an artificial intelligence model. The artificial intelligence model generates instructions and/or solutions and adapts to different application scenarios based on an enterprise network knowledge and reverse inference(s). Specifically, methods are provided that involve obtaining input data related to a configuration or an operation of one or more assets in an enterprise network and generating a contextualized prompt based on the input data, network knowledge information of the enterprise network, and at least one reverse inference generated using an artificial intelligence model. The methods further involve providing the contextualized prompt to the artificial intelligence model for generating a tailored response to the input data, wherein the tailored response includes a set of actionable tasks to be performed with respect to the one or more assets of the enterprise network.",CISCO TECH INC,SUN PENGFEI;;LIANG ERIC SIYUAN;;SHAO QIHONG;;MURPHY ELISSA E,CISCO TECHNOLOGY INC (2023-11-03),https://lens.org/037-023-518-125-241,Patent Application,yes,2,0,1,037-023-518-125-241,US,1,037-023-518-125-241,US,0,H04L41/16;;H04L41/0813;;H04L41/0886;;H04L41/12;;H04L41/145;;H04L41/0886;;H04L41/16;;H04L41/12;;H04L41/0813,H04L41/08;;H04L41/0813;;H04L41/12;;H04L41/16,,0,0,,,,PENDING
519,US,A1,US 2023/0177810 A1,100-704-864-608-867,6/8/2023,2023,US 202217853631 A,6/29/2022,US 202217853631 A;;US 202163287440 P,12/8/2021,PERFORMING SEMANTIC SEGMENTATION TRAINING WITH IMAGE/TEXT PAIRS,"Semantic segmentation includes the task of providing pixel-wise annotations for a provided image. To train a machine learning environment to perform semantic segmentation, image/caption pairs are retrieved from one or more databases. These image/caption pairs each include an image and associated textual caption. The image portion of each image/caption pair is passed to an image encoder of the machine learning environment that outputs potential pixel groupings (e.g., potential segments of pixels) within each image, while nouns are extracted from the caption portion and are converted to text prompts which are then passed to a text encoder that outputs a corresponding text representation. Contrastive loss operations are then performed on features extracted from these pixel groupings and text representations to determine an extracted feature for each noun of each caption that most closely matches the extracted features for the associated image.",NVIDIA CORP,XU JIARUI;;DE MELLO SHALINI;;LIU SIFEI;;BYEON WONMIN;;BREUEL THOMAS;;KAUTZ JAN,NVIDIA CORPORATION (2022-04-15),https://lens.org/100-704-864-608-867,Patent Application,yes,0,12,3,100-704-864-608-867;;113-976-990-617-677;;067-374-179-744-218,US;;DE;;CN,3,100-704-864-608-867;;113-976-990-617-677;;067-374-179-744-218,US;;DE;;CN,0,G06V10/26;;G06V20/70;;G06V20/635;;G06V10/764;;G06V10/82;;G06V10/774;;G06V10/26;;G06V10/26;;G06V10/774,G06V10/774;;G06V10/26,,3,2,084-897-497-404-103;;185-806-735-996-518,10.1109/iccvw.2019.00549;;10.1109/cvpr52688.2022.01139,"Sawatzky, J. et al., Harvesting Information from Captions for Weakly Supervised Semantic Segmentation, 2019 (Year: 2019);;Radford, A. et al., Learning Transferable Visual Models From Natural Language Supervision, 2021 (Year: 2021);;Wang, Z et al., CRIS: CLIP-Driven Referring Image Segmentation, 2021 (Year: 2021)",PENDING
520,US,A1,US 2025/0238628 A1,151-462-686-667-215,7/24/2025,2025,US 202418418272 A,1/21/2024,US 202418418272 A,1/21/2024,HEURISTIC EXPRESSIONS FOR FLOW BUILDER CONDITIONALS,"In one aspect, a computerized method comprising: providing a user-specified condition, wherein the user-specified condition comprises a flow builder conditional that the user specifies what is to be tested for on a heuristic basis; with a condition optimizer; obtains a user input, wherein the user input is obtained from the user specified condition, wherein the user-specified condition is in a freeform, and optimizes the user-specified condition by rewriting the user-specified condition in a form that is most likely generate an output of a prediction with a highest accuracy; with the optimized form of the user-specified condition, structuring a conditional prompt; passing the conditional prompt to a large language model (LLM), wherein the conditional prompt comprises the information that is input into the LLM to obtain an LLM output; and with the LLM, performing a model that makes an inference about the conditional prompt along with a base prompt for asking a large language model for prediction to obtain a predicted evaluation.",SHARMA NIKHIL;;PRIYA VIDHU,SHARMA NIKHIL;;PRIYA VIDHU,,https://lens.org/151-462-686-667-215,Patent Application,yes,0,0,1,151-462-686-667-215,US,1,151-462-686-667-215,US,0,G06F40/40,G06F40/40,,0,0,,,,PENDING
521,WO,A1,WO 2024/095270 A1,065-326-638-796-684,5/10/2024,2024,IL 2023051131 W,11/2/2023,US 202263382270 P,11/3/2022,SYSTEM AND METHOD OF SOFTWARE BEHAVIOR ANALYSIS,"There are provided a method and a system of software behavior analysis. The method comprises: retrieving data sources related to a software program and mapping a list of behaviors characterizing the software program. Additionally, the method can comprise analyzing the list of behaviors to obtain at least one trait of at least one of the behaviors, and/or transcoding the list of behaviors to corresponding natural language descriptions and presenting the natural language descriptions of the list of behaviors to a user on a Graphical user interface (GUI). There are further provided a method and a system of testing changes between different versions of a software program based on the software behavior mapping and analysis.",CODIUM LTD,ZIMERMAN GADI;;FRIEDMAN ITAMAR;;GEVA SHAI,,https://lens.org/065-326-638-796-684,Patent Application,yes,4,0,1,065-326-638-796-684,WO,1,065-326-638-796-684,WO,0,G06F40/56;;G06F40/186;;G06F40/30;;G06F11/3684;;G06F11/3604,G06F11/36;;G06F40/186;;G06F40/56,,0,0,,,,PENDING
522,WO,A1,WO 2025/104675 A1,033-387-900-248-439,5/22/2025,2025,IB 2024061372 W,11/14/2024,US 202363598892 P,11/14/2023,"DEVIATION DETECTION AKA PLAYBOOK COMPARISON, SUMMARY FOR LEGAL TEAM","This disclosure provides systems, methods, and devices for automatic comparison, analysis, and modification of documents using artificial intelligence and natural language processing-based techniques. In a first aspect, a method includes identifying a first set of document portions in a first document. The method includes generating a set of matched candidate pairs based on the first set of document portions and a set of pre-determined document portions distinct from the first set of document portions. The method includes quantifying relationships between the set of matched candidate pairs. The method includes modifying the first document to produce a second document including one or more new document portions, where the new documents portions correspond to one or more of the set of pre-determined document portions and replace at least one of the first set of documents portions.",THOMSON REUTERS ENTPR CENTRE GMBH,RANKIN ROBERT,,https://lens.org/033-387-900-248-439,Patent Application,yes,3,0,2,129-858-584-497-968;;033-387-900-248-439,US;;WO,2,129-858-584-497-968;;033-387-900-248-439,US;;WO,0,G06F40/194;;G06F40/166;;G06N3/045;;G06F16/93;;G06F40/289;;G06F40/56;;G06F16/93;;G06F40/284;;G06F40/166,G06F40/166;;G06F16/93;;G06F40/194;;G06F40/56;;G06N3/045,,0,0,,,,PENDING
523,WO,A1,WO 2025/129408 A1,048-942-647-743-579,6/26/2025,2025,CN 2023139606 W,12/18/2023,CN 2023139606 W,12/18/2023,DEVICE AND METHOD FOR TRAINING A MACHINE LEARNING MODEL TO EXTRACT TEXT ITEMS FROM TEXT PHOTOS,"Aspects concern a method for training a machine learning model to extract text items from text photos, comprising extracting a text item from a text photo using the machine learning model, determining a correspondence between the extracted text item and an image including a region of the text photo showing text from which the machine learning model has extracted the text item by means of a generative artificial intelligence model and adjusting the machine learning model depending on the determined correspondence.",GRABTAXI HOLDINGS PTE LTD;;GRAB TECH BEIJING CO LTD,LIU YISHUN;;LI XIANG;;COLLARD CHRISTOPHER LUKAS;;TAY JO ANNE SHU LYNN;;TAN SEI YEE;;TANG WAI TENG,,https://lens.org/048-942-647-743-579,Patent Application,yes,4,0,1,048-942-647-743-579,WO,1,048-942-647-743-579,WO,0,G06F8/30;;G06N3/08;;G06N3/045;;G06N3/047,G06F9/451,,0,0,,,,PENDING
524,US,A1,US 2025/0077681 A1,160-774-577-207-059,3/6/2025,2025,US 202318462369 A,9/6/2023,US 202318462369 A,9/6/2023,CORRECTING SECURITY VULNERABILITIES WITH GENERATIVE ARTIFICIAL,"An example operation may include one or more of monitoring communications that occur with user devices over a shared computer network, detecting a security threat from the monitored communications, generating a software program to simulate the security threat over the shared computer network based on execution of a generative artificial intelligence (GenAI) model on a description of the security threat and a repository of source code, installing the source code for simulating the security threat on a system associated with the computer network, and executing the source code for simulating the security threat via the system.",TORONTO DOMINION BANK,SEN GOPENDU,THE TORONTO-DOMINION BANK (2023-09-21),https://lens.org/160-774-577-207-059,Patent Application,yes,2,0,1,160-774-577-207-059,US,1,160-774-577-207-059,US,0,G06F21/577;;G06N3/0455;;G06F21/53;;G06F2221/033;;G06N3/0475;;G06F8/61;;G06N20/00;;G06F21/577;;G06N3/0455;;G06F2221/033;;G06F21/53;;G06F8/61;;G06N3/0475,G06F21/57;;G06F8/61;;G06F21/53;;G06N3/0455;;G06N3/0475,,0,0,,,,PENDING
525,US,A1,US 2025/0077400 A1,069-914-973-426-644,3/6/2025,2025,US 202318462366 A,9/6/2023,US 202318462366 A,9/6/2023,SECURITY TESTING BASED ON GENERATIVE ARTIFICIAL INTELLIGENCE,"An example operation may include one or more of executing tests on a software application via a test environment of a test platform and logging results of the tests in a log file, identifying a new feature to be added to the software application based on execution of a machine learning model on logged results of the tests stored in the log file, generating source code for the new feature to be added to the software application based on execution of a generative artificial intelligence (GenAI) model on the new feature and a repository of source code, and displaying the generated source code via a user interface of the software application.",TORONTO DOMINION BANK,SEN GOPENDU,THE TORONTO-DOMINION BANK (2023-09-21),https://lens.org/069-914-973-426-644,Patent Application,yes,0,1,1,069-914-973-426-644,US,1,069-914-973-426-644,US,0,G06F11/3684;;G06F11/3688;;G06F11/3698;;G06F11/3688;;G06F11/3698,G06F11/36,,0,0,,,,PENDING
526,US,A1,US 2025/0077399 A1,167-459-051-725-825,3/6/2025,2025,US 202318462358 A,9/6/2023,US 202318462358 A,9/6/2023,GENERATION OF AUTOMATION TEST SCRIPT USING GENERATIVE ARTIFICIAL INTELLIGENCE,"An example operation may include one or more of receiving a description of a plurality of testing elements for testing a software program and storing the software test within a storage device, generating an automation script for automating execution of the software test based on execution of a generative artificial intelligence model (GenAI) model on the plurality of testing elements and a repository of automation scripts, attaching the automation script to the software test within the storage device, and in response to a request to execute the software test, executing the plurality of testing elements within the software test based on the attached automation script.",TORONTO DOMINION BANK,SEN GOPENDU,THE TORONTO-DOMINION BANK (2023-09-21),https://lens.org/167-459-051-725-825,Patent Application,yes,0,0,1,167-459-051-725-825,US,1,167-459-051-725-825,US,0,G06F11/3688;;G06F11/3684;;G06F11/3688;;G06F11/328;;G06F11/3684,G06F11/36;;G06F11/32,,0,0,,,,PENDING
527,US,A1,US 2025/0094833 A1,097-329-075-918-40X,3/20/2025,2025,US 202218571196 A,12/9/2022,CN 202210955108 A;;CN 2022137938 W,8/10/2022,"FINE-TUNING METHOD, DEVICE AND APPLICATION FOR CLASSIFICATION MODEL OF KNOWLEDGE REPRESENTATION DECOUPLING","The present invention discloses fine-tuning method, device, and application classification model of knowledge representation decoupling, decoupling knowledge representation and classification model, storing them in the knowledge base, and performing matching aggregation based on retrieval during application, this limits the rote memorization of the learning model and improves its generalization ability. At the same time, KNN is used to retrieve adjacent instance phrases from the knowledge base as continuous neural examples, and neural examples are used to guide classification model training and correct classification model predictions, improving the ability of the classification model in small and zero sample scenarios, when the amount of data is sufficient, the knowledge base also has better and richer information, and the classification model performs very well in fully supervised scenarios.",UNIV ZHEJIANG,ZHANG NINGYU;;LI LEI;;CHEN XIANG;;CHEN HUAJUN,ZHEJIANG UNIVERSITY (2023-11-20),https://lens.org/097-329-075-918-40X,Patent Application,yes,0,0,3,101-658-674-818-320;;136-430-408-671-660;;097-329-075-918-40X,US;;WO;;CN,3,101-658-674-818-320;;136-430-408-671-660;;097-329-075-918-40X,US;;WO;;CN,0,G06N5/02;;G06N5/022;;G06N3/045;;G06N3/0475;;G06N3/042;;G06N3/09;;G06N5/022,G06N5/022,,0,0,,,,PENDING
528,WO,A1,WO 2025/124752 A1,105-024-507-115-733,6/19/2025,2025,EP 2024072710 W,8/12/2024,EP 23216161 A,12/13/2023,"COMPUTER-READABLE DATA CARRIER, VEHICLE, APPARATUS, COMPUTER PROGRAM AND METHODS FOR ADAPTING A USER INTERFACE OF A VEHICLE","The present disclosure relates to a computer-readable data carrier, a vehicle, an apparatus, a computer program, and methods for adapting a user interface of a vehicle. In particular, the concept proposed herein relates to speech-based user interface adaption using artificial intelligence. The method comprises obtaining information on a voice input of a user, determining configuration data from the voice input to adapt the user interface using a machine-learning-based model, and adapting the user interface based on the configuration data.",ELEKTROBIT AUTOMOTIVE GMBH,SCHUSTER STEPHAN;;SCHMUNK SERGEJ,,https://lens.org/105-024-507-115-733,Patent Application,yes,2,0,1,105-024-507-115-733,WO,1,105-024-507-115-733,WO,0,G06F3/167,G06F3/16,,0,0,,,,PENDING
529,US,A1,US 2025/0077682 A1,185-224-300-219-437,3/6/2025,2025,US 202318462372 A,9/6/2023,US 202318462372 A,9/6/2023,DYNAMIC GENERATION OF FEATURES BASED ON SOFTWARE TESTING,"An example operation may include one or more of receiving, via a user interface, a request to test a software program, reading source code of the software program and identifying a vulnerability in the source code based on the reading, generating repair code for fixing the identified vulnerability based on execution of a generative artificial intelligence (GenAI) model on the source code and a repository of repair code used to repair previous vulnerabilities, and displaying information about the repair code via the user interface.",TORONTO DOMINION BANK,GUTTRIDGE FRANCIS JAMES ALEXANDER;;D'AGOSTINO DINO PAUL;;PRATTEN A WARREN;;MOHAMMED SHAHZAD;;CHIKKALAVALASA ARVIND;;NAWAZ WAQAS,,https://lens.org/185-224-300-219-437,Patent Application,yes,0,0,1,185-224-300-219-437,US,1,185-224-300-219-437,US,0,G06F21/577;;G06F11/3684;;G06F11/3688;;G06F11/3698;;G06F11/3692;;G06N20/00;;G06N3/045;;G06F21/577;;G06F11/3698,G06F11/36;;G06F21/57,,0,0,,,,PENDING
530,US,A1,US 2025/0218551 A1,179-659-889-060-507,7/3/2025,2025,US 202318397993 A,12/27/2023,US 202318397993 A;;US 202418889237 A;;US 202418600486 A;;US 202463574141 P;;US 202463571281 P,12/27/2023,GENERATIVE ATOMISTIC DESIGN OF MATERIALS,"A system and method are provided for generative atomistic design of materials. The disclosure herein includes a machine learning system for generating a new material, using multiple predictive machine learning models for atomic level properties to create training data, and/or then using the same predictive machine learning models to refine the output of a generative machine learning system. In use, one or more datasets are received at at least one computing device corresponding to a desired material. Additionally, using at least two machine learning models associated with the at least one computing device, a new dataset is created for the desired material. Further, the at least two machine learning models are trained, using at least semi-supervised learning, based on the one or more datasets, to model properties of the desired material. Still yet, using the at least one computing device, a prediction is outputted comprising the desired material.",QUANTUM GENERATIVE MAT LLC,VIKOREN JACOB;;PRASAD DEEPTANSHU;;SOMMER DAVID;;SUMARIA VAIDISH,,https://lens.org/179-659-889-060-507,Patent Application,yes,0,0,2,003-393-129-145-876;;179-659-889-060-507,US,4,179-659-889-060-507;;070-012-856-470-120;;003-393-129-145-876;;158-671-170-691-957,US,0,G16C20/70;;G06F30/27;;G16C60/00;;H04B7/18519;;G06N20/10;;G16C20/30;;G06F40/30;;G06N3/047;;G06N3/044;;G06F40/20;;G06N5/01;;G06N3/045;;G06N3/08;;G16C10/00;;G06N3/084;;G06N7/01;;G06N3/0442;;G06F40/279;;G06N20/00;;G06N10/60;;G06F40/30;;H04B7/18519;;G06N20/10;;G16C20/30;;G16C60/00;;G16C20/70;;G06F30/27,G16C20/30;;G16C20/70,,6,0,,,"Antoniuk, Evan R et al. “Predicting the Synthesizability of Crystalline Inorganic Materials from the Data of Known Material Compositions.” npj computational materials 9.1 (2023): 155–11. Web. (Year: 2023);;Ramprasad, Rampi et al. “Machine Learning in Materials Informatics: Recent Applications and Prospects.” npj computational materials 3.1 (2017): 1–13. Web. (Year: 2017);;Fedik, Nikita et al. “Extending Machine Learning beyond Interatomic Potentials for Predicting Molecular Properties.” Nature reviews. Chemistry 6.9 (2022): 653–672. Web. (Year: 2022);;Ceriotti, Michele. “Beyond Potentials: Integrated Machine Learning Models for Materials.” MRS bulletin 47.10 (2022): 1045–1053. Web. (Year: 2022);;Bogojeski, Mihail et al. “Quantum Chemical Accuracy from Density Functional Approximations via Machine Learning.” Nature communications 11.1 (2020): 5223–5223. Web. (Year: 2020);;Huang, Guannan et al. “Application of Machine Learning in Material Synthesis and Property Prediction.” Materials 16.17 (2023): 5977-. Web. (Year: 2023)",PENDING
531,WO,A1,WO 2025/106768 A1,102-265-976-379-852,5/22/2025,2025,US 2024/0056058 W,11/15/2024,US 202363599846 P,11/16/2023,GRAPH LANGUAGE MODELS: DISTILLING RELIABLE KNOWLEDGE GRAPHS FROM HIGH-QUALITY TEXT,"Disclosed are techniques for training a graph language model (GEM). The techniques generally include training the GEM on a training corpus, expanding a current training knowledge graph into an expanded knowledge graph by distilling semantic information from the training corpus using neural inversion. The knowledge graph is only expanded when there is new data, and if convergence has not been reached, the method may include updating the training corpus by injecting the expanded knowledge graph into the training corpus, thereby making the expanded knowledge graph the current training knowledge graph. The training, expanding, and updating steps are repeated until convergence. The training corpus may be formed by parsing a dataset into chain graphs, where syntactic language information is represented as a chain sequence of one or more root nodes, and where semantic information from the seed knowledge graph is added as leaf nodes around each root node.",UNIV PRINCETON,TULI SHIKHAR;;BELOVA MARGARITA;;BHAT SUMA;;JHA NIRAJ,,https://lens.org/102-265-976-379-852,Patent Application,yes,4,0,1,102-265-976-379-852,WO,1,102-265-976-379-852,WO,0,G06N5/022;;G06F40/216;;G06N3/02;;G06N5/02;;G06F16/901;;G06N3/084,G06N5/02;;G06F16/901;;G06F40/216;;G06N3/02;;G06N5/022,,0,0,,,,PENDING
532,US,A1,US 2020/0250897 A1,102-809-319-006-055,8/6/2020,2020,US 201916263728 A,1/31/2019,US 201916263728 A,1/31/2019,INTELLIGENT PROGNOSTICS AND HEALTH MANAGEMENT SYSTEM AND METHOD,"The present invention relates to an intelligent prognostics and health management system and method, the system comprises an analytic engine service manager module, an intelligent prognostics and health management object analytics tree module, a machine learning library module, and a file system module. After the analytic engine service manager module defines an analytics tree according to components of a to-be-monitored machine, the intelligent prognostics and health management object analytics tree module is controlled by the analytic engine service manager module to obtain monitoring data of the to-be-monitored machine. One of default reference hypothesis model sets with the highest similarity of the system is selected for modeling, thereby a model selection and disposition are quickly complete.",MARKETECH INT CORP,WEI CHIEN-MING MARTIN;;FAN GUO-YAN;;HU WEI-HUAN,MARKETECH INTERNATIONAL CORP (2018-09-21),https://lens.org/102-809-319-006-055,Patent Application,yes,0,10,1,102-809-319-006-055,US,1,102-809-319-006-055,US,0,G07C3/08;;G06N5/022;;G06N20/00;;G06Q10/04;;G07C3/14;;G01M13/00;;G01M99/005;;G05B23/024;;G06N3/08;;G06N20/00;;G06Q10/04,G07C3/14;;G06N3/08;;G06N20/00,,0,0,,,,DISCONTINUED
533,US,A1,US 2025/0147992 A1,119-851-233-754-497,5/8/2025,2025,US 202418935495 A,11/2/2024,US 202418935495 A;;US 202363595835 P,11/3/2023,OptiSenseGPT: Context-Aware Anomaly Detection with Natural Language Alerts and ActionableRecommendations for Distributed Fiber Optic Sensing Applications,"Disclosed are integrated systems and methods providing intelligent anomaly detection for DFOS systems and applications, the systems and methods utilizing a natural language processing model, such as ChatGPT, to generate real-time alerts with actionable recommendations and potential consequences based on detected anomalies. Our innovative solution—OptiSenseGPT—solves problems left uncured by traditional methods by delivering easily understandable alerts in natural language, enabling timely response by relevant personnel. Our integrated OptiSenseGPT systems and methods disclosed provide context-aware recommendations and consequences, enhancing decision-making and improving overall performance and safety of a monitored infrastructure or environment. Our OptiSenseGPT systems and methods advantageously provide integration of natural language processing; context-aware recommendations; presentation of potential consequences; adaptability and customization; and seamless integration.",NEC LAB AMERICA INC,DING YANGMIN;;WANG TING,NEC LABORATORIES AMERICA INC (2025-01-06),https://lens.org/119-851-233-754-497,Patent Application,yes,0,0,2,119-851-233-754-497;;096-067-067-889-510,US;;WO,2,119-851-233-754-497;;096-067-067-889-510,US;;WO,0,G06F16/3329;;G06F16/345;;G06F16/345;;G06F16/3329,G06F16/332;;G06F16/34,,0,0,,,,PENDING
534,US,A1,US 2025/0148293 A1,067-619-411-568-013,5/8/2025,2025,US 202418934676 A,11/1/2024,US 202418934676 A;;US 202363595904 P,11/3/2023,MULTI-SOURCE DOMAIN ADAPTATION VIA PROMPT-BASED META-LEARNING,"Methods and systems include adapting an initial prompt to a target domain corresponding to an input time series to generate an adapted prompt. The adapted prompt and the input time series are combined. The input time series is processed with the adapted prompt using a modular transformer encoder that has a plurality of sub-encoders, with a policy network selecting a subset of the plurality of encoders that are applied to the input time series and the adapted prompt.",NEC LAB AMERICA INC,WANG JUNXIANG;;CHENG WEI;;CHEN HAIFENG,NEC LABORATORIES AMERICA INC (2024-10-18),https://lens.org/067-619-411-568-013,Patent Application,yes,0,0,1,067-619-411-568-013,US,1,067-619-411-568-013,US,0,G06N3/094;;G06N3/045;;G06N3/096;;G06N3/094,G06N3/094,,0,0,,,,PENDING
535,US,A1,US 2025/0138991 A1,125-886-202-123-702,5/1/2025,2025,US 202318531540 A,12/6/2023,US 202318531540 A;;US 202363545820 P,10/26/2023,DARWINIAN ELO FRAMEWORKS FOR CHATBOT EVALUATION,"In one aspect, a computerized method for Darwinian Elo frameworks for chatbot evaluation comprising: implementing an ad-hoc development testing, wherein the ad-hoc development testing comprises a first phase of chatbot evaluation; implementing a response generation, wherein once a model version used for response generation is ready by flagging the model version for evaluation arena candidacy; implementing a simulated Elo evaluation, wherein once one or more generations of models are generated for the candidate model, each candidate model is evaluated in a simulated evaluation arena, and wherein each of the one or more generations of models undergo regular matches against one another; and implementing a live Elo evaluation, wherein a set of top models are used in a live environment.",SHARMA NIKHIL,SHARMA NIKHIL,,https://lens.org/125-886-202-123-702,Patent Application,yes,0,0,1,125-886-202-123-702,US,1,125-886-202-123-702,US,0,G06F11/3696;;G06F11/3696,G06F11/36,,0,0,,,,PENDING
536,US,A1,US 2025/0190479 A1,073-474-672-338-198,6/12/2025,2025,US 202418808952 A,8/19/2024,KR 20230179501 A,12/12/2023,METHOD AND SYSTEM FOR REFINING SEARCH RESULTS BASED ON QUERY COMPLEXITY FOR GENERATIVE SEARCH,"Disclosed is a method and system for readjusting granularity of search results according to complexity of a query for generative search. An inference method may include extracting a length-by-length phrase from a document retrieved for a query of a user; determining a ranking of the length-by-length phrase in consideration of complexity of the query; and configuring a prompt for input to a generative language model based on the determined ranking. Here, the ranking of the length-by-length phrase may be determined such that a relatively long phrase has a higher ranking according to an increase in the complexity of the query.",NOTA INC,KIM GEONMIN,NOTA INC (2024-08-12),https://lens.org/073-474-672-338-198,Patent Application,yes,3,0,2,179-562-243-947-79X;;073-474-672-338-198,US;;KR,2,179-562-243-947-79X;;073-474-672-338-198,US;;KR,0,G06F16/383;;G06F16/332;;G06F40/289;;G06F16/383;;G06F16/332;;G06F40/289,G06F16/383;;G06F16/332;;G06F40/289,,0,0,,,,PENDING
537,US,A1,US 2025/0190466 A1,098-825-890-404-80X,6/12/2025,2025,US 202318532426 A,12/7/2023,US 202318532426 A,12/7/2023,LLM LATENCY REDUCTION VIA BRIDGING MULTIPLE LLMS OF DIFFERING SIZES,"Implementations utilize a smaller LLM to generate content responsive to a user query and cause a portion of the generated content to be rendered as an immediate response to the user query. Implementations further utilize a larger LLM to generate content that starts with the portion of the generated content and that includes a refined portion succeeding the portion of the generated content. The refined portion can be rendered succeeding the portion of the generated content. In some implementations, instead of using the smaller LLM, alternatively, the portion of the generated content rendered as the immediate response can be generated based on a default text string or a template, where the template can be determined/selected from a plurality of predefined templates based on a natural language understanding of the user query.",GOOGLE LLC,BARROS BRETT,GOOGLE LLC (2023-12-06),https://lens.org/098-825-890-404-80X,Patent Application,yes,0,0,2,098-825-890-404-80X;;001-642-129-850-155,US;;WO,2,098-825-890-404-80X;;001-642-129-850-155,US;;WO,0,G06F16/3325;;G06F16/33295;;G06F16/3344;;G06F16/338;;G06F40/35;;G06F40/289;;G06N3/0475,G06F16/33;;G06F16/338;;G06N3/0475,,0,0,,,,PENDING
538,US,A1,US 2025/0225375 A1,116-005-227-259-746,7/10/2025,2025,US 202418409250 A,1/10/2024,US 202418409250 A,1/10/2024,MACHINE LEARNING SYSTEMS AND TECHNIQUES FOR AUDIENCE-TARGETED CONTENT GENERATION,"Embodiments are generally directed to extending artificial intelligence (AI) and machine learning (ML) techniques to generate content predicted to elicit a performance response from an intended recipient of a target audience. One method of generating content includes determining content generation information from a user prompt, the content generation information comprising a subject, an audience segment, and a performance indicator; and providing the content generation information to a content generation model to generate at least one item of audience-targeted content corresponding to the subject targeted to the audience segment to elicit a response defined by the performance indicator, wherein the content generation module comprises a natural language processing (NLP) model trained, via a content generation training module, using reinforcement learning based on a reward of a performance prediction determined by a performance prediction model based on historical performance data.",ADOBE INC,LOHIYA SHUBHAM;;M Y MEGHANATH;;SANKAR VARSHA;;TEIXEIRA MAYKOT LUIZ FERNANDO;;BASU DEBRAJ DEBASHISH;;PAI DEEPAK,,https://lens.org/116-005-227-259-746,Patent Application,yes,0,0,1,116-005-227-259-746,US,1,116-005-227-259-746,US,0,G06N3/0455;;G06F40/40;;G06N3/092,G06N3/0455;;G06F40/40;;G06N3/092,,0,0,,,,PENDING
539,US,A1,US 2025/0209266 A1,165-636-327-900-674,6/26/2025,2025,US 202318394915 A,12/22/2023,US 202318394915 A,12/22/2023,EVALUATING TYPEAHEAD SUGGESTIONS USING A LARGE LANGUAGE MODEL,"Embodiments of the disclosed technologies are capable of evaluating typeahead suggestions using a partial search query. The embodiments describe obtaining a typeahead suggestion responsive to a partial search query. The embodiments further describe creating a prompt based on the typeahead suggestion. The embodiments further describe causing a large language model (LLM) to evaluate the typeahead suggestion based on the prompt. The embodiments further describe providing, to a computing device, an evaluation output by the LLM in response to the prompt.",MICROSOFT TECHNOLOGY LICENSING LLC,LU XUEYING;;HOOSHMAND ALI;;DONG FAN;;YIN JIADONG;;MUTHUREGUNATHAN RAGHAVAN,MICROSOFT TECHNOLOGY LICENSING LLC (2024-01-02),https://lens.org/165-636-327-900-674,Patent Application,yes,0,0,1,165-636-327-900-674,US,1,165-636-327-900-674,US,0,G06F40/274;;G06F40/40;;G06F40/40;;G06F40/274,G06F40/274;;G06F40/40,,0,0,,,,PENDING
540,WO,A1,WO 2025/096086 A1,199-319-328-234-479,5/8/2025,2025,US 2024/0048046 W,9/24/2024,US 202318385859 A,10/31/2023,FRAMEWORK FOR ANALYZING PROPERTIES OF CHEMICAL MATERIALS,"The techniques disclosed herein enable an autonomous agent to interpret an input dataset and orchestrate a suite of software modules to perform a computational task on a representation of a chemical material. The input dataset includes a prompt defining a computational task to be performed on a chemical material. Moreover, the input dataset includes data defining a chemical included in the chemical material, molecular descriptors describing the chemical and/or the chemical material, and an external variable. The agent analyzes the benefits and drawbacks of each model within the context of the computational task to determine a technique for performing the computational task. Accordingly, the agent formulates a chain of calls invoking the functionality of data processing tools and models to perform the computational task responsive to the prompt.",MICROSOFT TECHNOLOGY LICENSING LLC,MAUA SARA MALVAR;;SHARP MORRIS ELI;;NUNES LEONARDO DE OLIVEIRA;;DE LUIS BALAGUER MARIA ANGELS;;SHARMA SWATI,,https://lens.org/199-319-328-234-479,Patent Application,yes,1,0,2,110-458-106-007-239;;199-319-328-234-479,US;;WO,2,110-458-106-007-239;;199-319-328-234-479,US;;WO,0,G16C60/00;;G16C20/30;;G16C20/70;;G06N3/00;;G06N20/00;;G16C20/70;;G16C20/90;;G16C20/20;;G16C20/30,G16C20/30;;G06N3/00;;G16C20/70;;G16C60/00,,7,3,142-142-859-186-577;;015-923-025-384-814;;011-739-551-946-404,10.1080/27660400.2023.2260300;;37798813;;10.1002/anie.202311983;;10.1093/bioadv/vbad001;;pmc9950855;;36845200,"HATAKEYAMA-SATO K. ET AL: ""Prompt engineering of GPT-4 for chemical research: what can/cannot be done?"", SCIENCE AND TECHNOLOGY OF ADVANCED MATERIALS: METHODS, vol. 3, no. 1, 2260300, 9 October 2023 (2023-10-09), XP093239388, ISSN: 2766-0400, DOI: 10.1080/27660400.2023.2260300;;ZHENG Z. ET AL: ""A GPT-4 Reticular Chemist for Guiding MOF Discovery**"", ANGEWANDTE CHEMIE INTERNATIONAL EDITION, vol. 62, no. 46, 13 October 2023 (2023-10-13), Hoboken, USA, XP093239390, ISSN: 1433-7851, Retrieved from the Internet <URL:https://onlinelibrary.wiley.com/doi/am-pdf/10.1002/anie.202311983> DOI: 10.1002/anie.202311983;;JABLONKA K. M. ET AL: ""Leveraging Large Language Models for Predictive Chemistry"", CHEMRXIV.ORG, 17 October 2023 (2023-10-17), XP093239755, Retrieved from the Internet <URL:https://chemrxiv.org/engage/chemrxiv/article-details/652e50b98bab5d2055852dde> DOI: 10.26434/chemrxiv-2023-fw8n4-v3;;ZHANG X. ET AL: ""Artificial Intelligence for Science in Quantum, Atomistic, and Continuum Systems"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 17 July 2023 (2023-07-17), XP091565254;;ZHAO X. ET AL: ""Automatic Model Selection with Large Language Models for Reasoning"", ARXIV.ORG, 23 May 2023 (2023-05-23), XP093240248, Retrieved from the Internet <URL:https://arxiv.org/abs/2305.14333> DOI: 10.48550/arXiv.2305.14333;;COLEY C. W. ET AL: ""Autonomous discovery in the chemical sciences part II: Outlook"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 30 March 2020 (2020-03-30), XP081634757, DOI: 10.1002/ANIE.201909989;;ZHANG S. ET AL: ""Applications of transformer-based language models in bioinformatics: a survey"", BIOINFORMATICS ADVANCES, vol. 3, no. 1, VBAD001, 11 January 2023 (2023-01-11), XP093236187, ISSN: 2635-0041, Retrieved from the Internet <URL:https://doi.org/10.1093/bioadv/vbad001> DOI: 10.1093/bioadv/vbad001",PENDING
541,WO,A1,WO 2025/101175 A1,033-025-377-756-915,5/15/2025,2025,US 2023/0037014 W,11/8/2023,US 2023/0037014 W,11/8/2023,LLM-CENTRIC AGILE IMAGE CLASSIFICATION,"An example method can include obtaining a textual description of an image category. The example method can include obtaining a plurality of images based on the textual description. The example method can include generating one or more vision language model prompts using one or more machine-learned language models. The example method can include generating, using one or more machine-learned vision language models, one or more responses based on the one or more vision language model prompts. The method can include generating, based on the responses and using one or more machine-learned language models, a plurality of machine-generated labels, wherein each machine-generated label is associated with a corresponding image of the plurality of images and is indicative of whether the corresponding image belongs to the image category.",GOOGLE LLC,AVINASH ADITYA;;ALLDRIN NEIL GORDON;;ZHOU WENLEI;;TOUBAL IMAD EDDINE;;ZHOU ZHEN HAO;;XIONG HAO;;HATA ALEXANDER KENJI;;FUXMAN ARIEL DAMIAN;;DUERIG TOM JOSEPH;;DLABAL JAN,,https://lens.org/033-025-377-756-915,Patent Application,yes,1,0,1,033-025-377-756-915,WO,1,033-025-377-756-915,WO,0,G06V10/774;;G06F18/2413,G06F18/2413;;G06V10/774,,9,3,103-212-983-826-945;;120-047-640-592-980;;084-641-049-769-580,pmc8371605;;34265844;;10.1038/s41586-021-03819-2;;10.18653/v1/d18-2012;;10.18653/v1/2020.emnlp-main.83,"ZHANG ZHUOSHENG ET AL: ""Automatic Chain of Thought Prompting in Large Language Models"", ARXIV (CORNELL UNIVERSITY), 7 October 2022 (2022-10-07), Ithaca, XP093141448, Retrieved from the Internet <URL:https://arxiv.org/pdf/2210.03493.pdf> [retrieved on 20240314], DOI: 10.48550/arxiv.2210.03493;;JIE GUO ET AL: ""MVP-SEG: Multi-View Prompt Learning for Open-Vocabulary Semantic Segmentation"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 14 April 2023 (2023-04-14), XP091484814;;ZHOU ET AL.: ""Mixture-of Experts with Expert Choice Routing"", ARXIV:2202.09368V2, 14 October 2022 (2022-10-14);;DOSOVITSKIY ET AL.: ""An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"", ARXIV:2010.11929V2, 3 June 2021 (2021-06-03);;AGOSTINELLI ET AL.: ""MusicLM: Generating Music From Text"", ARXIV:2301.11325V1, 26 January 2023 (2023-01-26);;JUMPER ET AL.: ""Highly accurate protein structure prediction with AlphaFold"", NATURE, vol. 596, 26 August 2021 (2021-08-26), pages 583, XP055888904, DOI: 10.1038/s41586-021-03819-2;;KUDO ET AL.: ""SentencePiece: A simple and language independent subword tokenizer and detokenizerfor Neural Text Processing"", PROCEEDINGS OF THE 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (SYSTEM DEMONSTRATIONS, 31 October 2018 (2018-10-31), pages 66 - 71;;VASWANI ET AL.: ""Attention Is All You Need"", ARXTV:1706.03762V7, 2 August 2023 (2023-08-02);;SAHARIA ET AL.: ""Non-Autoregressive Machine Translation with Latent Alignments"", ARXIV:2004.07437V3, 16 November 2020 (2020-11-16)",PENDING
542,US,A1,US 2024/0386202 A1,070-144-651-174-795,11/21/2024,2024,US 202418653146 A,5/2/2024,US 202418653146 A;;US 202363502848 P,5/17/2023,TUNING GENERATIVE MODELS USING LATENT-VARIABLE INFERENCE,Systems and methods for generative language model tuning can include training the generative language model to generate sets of output text tokens with set of intermediary text tokens with training examples that include input and output pairs. The training can include processing the input with the language model to determine a predicted output and a predicted set of intermediary text tokens. The predicted set of intermediary text tokens can then be evaluated based at least in part on the output associated with the input and the predicted output.,GOOGLE LLC,HOFFMAN MATTHEW DOUGLAS;;SUTTON CHARLES ALOYSIUS;;DOHAN DAVID MARTIN;;DOUGLAS SHOLTO FRANCIS ALEXANDRE;;LE TUAN ANH;;PHAN VAN DU;;PARISI AARON THOMAS;;RIFKIN RYAN MICHAEL;;SOUNTSOV PAVEL;;VIKRAM SHARAD,GOOGLE LLC (2023-06-14),https://lens.org/070-144-651-174-795,Patent Application,yes,0,4,3,167-374-553-819-482;;070-144-651-174-795;;007-980-048-415-637,US;;GB,4,186-877-265-698-130;;007-980-048-415-637;;070-144-651-174-795;;167-374-553-819-482,US;;GB;;CN,0,G06F40/284;;G06F40/30;;G06F40/56;;G06F40/35;;G06F40/284,G06F40/284,,0,0,,,,PENDING
543,WO,A1,WO 2025/111609 A1,073-453-787-848-195,5/30/2025,2025,US 2024/0057333 W,11/25/2024,US 202363602508 P,11/24/2023,SYSTEMS AND METHODS FOR GENETIC TEST SELECTION THROUGH ARTIFICIAL INTELLIGENCE AND/OR LARGE LANGUAGE MODELS,"The following relates generally to solutions built utilizing LLMs, generative Al, and ML- based methods to facilitate recommendations for the appropriate genetic test for a patient. In some embodiments, one or more processors: (1) receive a patient identifier (ID) of the patient and test code identifier of the genetic test ordered for the patient; (2) extract from multiple databases, previous testing histories, relevant concurrent tests, family history, internal notes, reason for testing, as well as other data elements associated with the ordered test to be evaluated; (3) extract from a patient database, patient features based on the patient ID; (4) generate a condensed phenotypic description of the patient using contextualized targeted clinical documents; (5) generate a list of relevant phenotype ontology terms based on the condensed phenotypic description of the patient; and (6) enable genetic test validation of the existing test order(s) or inform new genetic test recommendations.",MAYO FOUND MEDICAL EDUCATION & RES,MARCOU CHERISSE A;;HART STEVEN N;;KLEE ERIC W,,https://lens.org/073-453-787-848-195,Patent Application,yes,0,0,1,073-453-787-848-195,WO,1,073-453-787-848-195,WO,0,G16H50/20;;H04L51/02;;H04L51/046,G16H50/20;;H04L51/02,,4,3,074-902-539-627-091;;196-795-914-613-664;;126-701-156-167-538,10.1016/j.patter.2023.100887;;pmc10801236;;38264716;;10.1101/2023.11.16.23298615;;10.1002/hcs2.61;;38939520;;pmc11080827,"WENG CHUNHUA ET AL: ""Phenotype-Driven Molecular Genetic Test Recommendation for Diagnosing Pediatric Rare Disorders"", RESEARCH SQUARE, 10 November 2023 (2023-11-10), XP093253440, Retrieved from the Internet <URL:https://pmc.ncbi.nlm.nih.gov/articles/PMC10690317/pdf/nihpp-rs3593490v1.pdf> DOI: 10.21203/rs.3.rs-3593490/v1;;JINGYE YANG ET AL: ""Enhancing Phenotype Recognition in Clinical Notes Using Large Language Models: PhenoBCBERT and PhenoGPT"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 11 August 2023 (2023-08-11), XP091591593;;KAFKAS SENAY ET AL: ""The application of Large Language Models to the phenotype-based prioritization of causative genes in rare disease patients"", MEDRXIV, 16 November 2023 (2023-11-16), XP093253455, Retrieved from the Internet <URL:https://www.medrxiv.org/content/10.1101/2023.11.16.23298615v1.full.pdf> DOI: 10.1101/2023.11.16.23298615;;YANG RUI ET AL: ""Large language models in health care: Development, applications, and challenges"", HEALTH CARE SCIENCE, vol. 2, no. 4, 24 July 2023 (2023-07-24), pages 255 - 263, XP093234060, ISSN: 2771-1757, DOI: 10.1002/hcs2.61",PENDING
544,US,A1,US 2025/0094704 A1,078-143-390-244-869,3/20/2025,2025,US 202418627860 A,4/5/2024,US 202418627860 A;;US 202363538663 P,9/15/2023,LLM FINE-TUNING FOR TEXT SUMMARIZATION,"Systems, methods, and other embodiments associated with automated fine-tuning of text summarization for large language models are described herein. In one embodiment, a method accesses a collection of text samples. The text samples include a body of text and an example summary. The method fine-tunes a large language model (LLM) based on a loss function that compares the example summary and a generated summary generated by the LLM. The example and generated summaries are compared at sentence, paragraph, and/or article levels. The method generates an evaluation score for performance of the tuned LLM as a text summarizer based on a further comparison of a reference summary and a summary generated by the tuned LLM. The method then automatically determines to deploy the tuned LLM to a text summarization task in response to the evaluation score satisfying a threshold.",ORACLE INT CORP,HU YAZHE;;GUO MENGQING;;WANG ZHENG;;SHENG TAO;;QIAN JUN;;MAMTANI VINOD,ORACLE INTERNATIONAL CORPORATION (2024-03-27),https://lens.org/078-143-390-244-869,Patent Application,yes,0,0,4,078-143-390-244-869;;039-770-606-359-234;;103-757-771-485-560;;028-538-744-391-94X,US,4,078-143-390-244-869;;103-757-771-485-560;;039-770-606-359-234;;028-538-744-391-94X,US,0,G06N3/091;;G06F40/226;;H04L51/04;;H04L51/02;;G06N3/0895;;G06F8/35;;G06F40/30;;G06F40/56;;G06F40/35;;G06F8/36;;H04L51/04;;H04L51/02;;G06F40/226;;G06N3/0895;;G06F8/35;;G06N3/091,G06F40/226,,0,0,,,,PENDING
545,US,A1,US 2025/0117893 A1,172-963-919-543-748,4/10/2025,2025,US 202418908549 A,10/7/2024,US 202418908549 A;;US 202363588483 P,10/6/2023,Self Supervised Training of Machine-Learned Image Processing Models for Histopathology,"An example computer-implemented method for self-supervised training of an image processing model for histopathology images is provided. The example method includes obtaining a reference histopathology image; generating an augmented histopathology image, wherein generating the augmented histopathology image comprises performing, for an input image, at least one of the following augmentations: applying a blur to the input image and injecting noise artifacts into the blurred input image; or cropping a plurality of portions from the input image, wherein the plurality of portions are determined based on a minimum overlap criterion that has been updated over one or more iterations; and training the image processing model based on a similarity of latent representations generated by the image processing model respectively for the reference histopathology image and the augmented histopathology image.",GOOGLE LLC,STEINER DAVID;;WULCZYN ELLERY ALYOSHA;;CHEN PO-HSUAN;;JAROENSRI RONNACHAI;;VIJAY SUPRIYA;;LAI JEREMY;;AGARWAL SALONI;;LIU YUN;;AHMED FARUK,GOOGLE LLC (2023-11-07),https://lens.org/172-963-919-543-748,Patent Application,yes,0,0,1,172-963-919-543-748,US,1,172-963-919-543-748,US,0,G06T2207/20081;;G06T3/40;;G06T5/77;;G06T5/50;;G06T5/60;;G06T2207/20084;;G06T2207/10056;;G06T2207/30024;;G06T5/60;;G06T2207/20081;;G06T3/40;;G06T5/50,G06T5/60;;G06T3/40;;G06T5/50,,0,0,,,,PENDING
546,US,A1,US 2024/0319965 A1,102-953-640-018-948,9/26/2024,2024,US 202318505935 A,11/9/2023,US 202318505935 A;;US 202363502351 P;;US 202363492194 P,3/24/2023,Systems And Methods For Automating Analyses Of User Experience Tests With Generative Language Models,"Techniques are described herein for using artificial intelligence (AI) and machine learning (ML) to automate, accelerate, and enhance various aspects of user experience testing. Embodiments incorporate generative language models into user experience testing applications to extract key findings for improving product designs and driving product optimizations. In some embodiments, programmatic processes conduct a dialogue with a generative language model by engineering a set of input prompts as a function of prompt fragments, user experience test results, and test contexts. The AI-generated findings may drive actions directed to optimizing product designs and improving user experiences.",WEVO INC,GARVEY DUSTIN;;SHAER NITZAN;;MUTO JANET;;STEWART ALEXA;;CHIANG FRANK;;SIEBER HANNAH;;HOANG CHARLIE;;BARZA ALEXANDER,WEVO INC (2023-11-07),https://lens.org/102-953-640-018-948,Patent Application,yes,11,0,3,163-770-656-783-91X;;048-346-950-328-369;;102-953-640-018-948,US,3,163-770-656-783-91X;;048-346-950-328-369;;102-953-640-018-948,US,0,G06Q10/0637;;G06Q30/0203;;G06F30/27;;G06F40/40;;G06F16/345;;G06F8/20;;G06F40/56;;G06F40/30;;G06F11/3438;;G06Q10/0637;;G06F16/345;;G06Q30/0203;;G06F11/3438;;G06F30/27;;G06F40/40;;G06F8/20,G06F8/20;;G06F40/40,,0,0,,,,DISCONTINUED
547,US,A1,US 2025/0131321 A1,176-827-284-293-675,4/24/2025,2025,US 202318489503 A,10/18/2023,US 202318489503 A,10/18/2023,Efficient Training Mixture Calibration for Training Machine-Learned Models,"Systems and methods are provided for efficiently calibrating a data mixture for training machine-learned models (e.g., machine-learned sequence processing models, such as transformer-based models). For example, machine-learned models can be trained over a broad dataset that can include multiple different categories of data. The mixture of data categories within the dataset can influence model performance. To improve the performance of machine-learned models, example implementations of the present disclosure can learn a distribution of data categories using a lightweight proxy model before initiating training of a large primary model. In this manner, for instance, example implementations can obtain an improved training data distribution with less computational expense and can leverage the learned training data distribution to better train a large primary model.",GOOGLE LLC,YU WEI;;XIE SANG;;PHAM HIEU HY;;LE QUOC V,GOOGLE LLC (2023-12-12),https://lens.org/176-827-284-293-675,Patent Application,yes,0,1,1,176-827-284-293-675,US,1,176-827-284-293-675,US,0,G06N20/00;;G06N5/01;;G06N20/00,G06N20/00,,0,0,,,,PENDING
548,US,A1,US 2025/0117769 A1,072-506-946-599-414,4/10/2025,2025,US 202318481971 A,10/5/2023,US 202318481971 A,10/5/2023,GenAI LETTER OF CONFIRMATION OF BENEFITS,"An example operation may include one or more of storing a data store of credit card documentation, conversing with a user via a chatbot within a chat window of a software application, wherein the conversing comprises receiving natural language inputs with requests for information about a payment card, identifying a benefit obtained by the user based on the conversation, executing a large language model (LLM) on the identified benefit and the data store of the credit card documentation to generate a letter of confirmation, and generating an electronic message with the letter of confirmation attached, and transmitting the electronic message to a user device.",TORONTO DOMINION BANK,TAHERI SHAHRIAR,,https://lens.org/072-506-946-599-414,Patent Application,yes,2,0,1,072-506-946-599-414,US,1,072-506-946-599-414,US,0,G06F40/20;;G06N20/00;;G06Q20/34;;G06Q20/227;;G06Q20/12;;G06Q20/326;;G06Q20/386;;G06F40/20;;G06Q20/24,G06Q20/24;;G06F40/20,,1,0,,,IP.COM NPL Search History,PENDING
549,US,A1,US 2024/0145056 A1,098-826-567-963-534,5/2/2024,2024,US 202318496525 A,10/27/2023,US 202318496525 A;;US 202263419756 P,10/27/2022,SYSTEM AND PROCESS FOR FEATURE EXTRACTION FROM THERAPY NOTES,"A method implemented via a computing device. The method may include receiving, by the computing device, treatment data associated with a subject. The treatment data associated with the subject may include behavior data, mood data, emotions data, goals data, instruction data, or combinations thereof. The method may also include evaluating, by the computing device, the treatment data associated with the subject via a therapy notes (TN) model. The TN model may evaluate the treatment data associated with the subject to generate one or more therapy note features.",MONTERAD/B/A FORTA,MAHARJAN JENISH;;GARIKIPATI ANURAG;;SINGH NAVAN PREET;;CIOBANU MADALINA;;MAO QINGQING,,https://lens.org/098-826-567-963-534,Patent Application,yes,0,3,1,098-826-567-963-534,US,1,098-826-567-963-534,US,0,G16H15/00;;G16H20/70;;G16H15/00;;G16H20/70;;G16H10/60;;G16H80/00;;G16H20/30,G16H15/00;;G16H10/60;;G16H20/30;;G16H20/70;;G16H80/00,,0,0,,,,PENDING
550,US,A1,US 2023/0311335 A1,180-233-210-341-933,10/5/2023,2023,US 202318128953 A,3/30/2023,US 202318128953 A;;US 202263326080 P;;US 202263325556 P,3/30/2022,NATURAL LANGUAGE CONTROL OF A ROBOT,"Implementations process, using a large language model, a free-form natural language (NL) instruction to generate to generate LLM output. Those implementations generate, based on the LLM output and a NL skill description of a robotic skill, a task-grounding measure that reflects a probability of the skill description in the probability distribution of the LLM output. Those implementations further generate, based on the robotic skill and current environmental state data, a world-grounding measure that reflects a probability of the robotic skill being successful based on the current environmental state data. Those implementations further determine, based on both the task-grounding measure and the world-grounding measure, whether to implement the robotic skill.",GOOGLE LLC,HAUSMAN KAROL;;ICHTER BRIAN;;LEVINE SERGEY;;TOSHEV ALEXANDER;;XIA FEI;;PARADA CAROLINA,GOOGLE LLC (2023-03-29),https://lens.org/180-233-210-341-933,Patent Application,yes,8,44,6,180-233-210-341-933;;074-750-738-128-578;;135-604-797-253-972;;099-704-497-073-632;;176-475-694-602-171;;167-592-770-459-730,US;;WO;;EP;;AU;;KR;;JP,7,180-233-210-341-933;;032-213-691-318-579;;167-592-770-459-730;;074-750-738-128-578;;135-604-797-253-972;;099-704-497-073-632;;176-475-694-602-171,US;;WO;;EP;;AU;;CN;;KR;;JP,0,G05B2219/40202;;G05B2219/40411;;G10L15/18;;B25J5/007;;B25J9/1697;;B25J9/1679;;G06F40/30;;B25J11/0005;;B25J13/003;;B25J11/008;;B25J13/003;;B25J9/1697;;B25J9/1679;;B25J9/163;;B25J11/0005;;B25J11/008;;B25J5/007;;G10L15/18;;G06F40/30;;G05B2219/40202;;G05B2219/40411;;G06F40/40;;B25J9/161;;B25J9/163;;B25J11/0005;;B25J13/003,B25J13/00;;B25J9/16;;B25J11/00;;G06F40/40,,0,0,,,,PENDING
551,US,A1,US 2025/0117595 A1,047-312-919-207-92X,4/10/2025,2025,US 202318481948 A,10/5/2023,US 202318481948 A,10/5/2023,DYNAMIC PROMPTING BASED ON CONVERSATION CONTEXT,"An example operation may include one or more of receiving a sequence of inputs from a user during a conversation between the user and a chatbot within a chat window of a software application, executing a large language model (LLM) on each input from the user to determine a next prompt to output via the chatbot, respectively, wherein each execution of the LLM includes a new chat input from the user and a most-recent state of the conversation between the user and the chatbot within the chat window, and displaying the next prompt within a chat window on a user device.",TORONTO DOMINION BANK,TAHERI SHAHRIAR,,https://lens.org/047-312-919-207-92X,Patent Application,yes,0,1,1,047-312-919-207-92X,US,1,047-312-919-207-92X,US,0,G06F40/35;;G06F40/40;;G06F40/35;;G06F40/40,G06F40/40;;G06F40/35,,0,0,,,,PENDING
552,US,A1,US 2024/0028312 A1,125-306-585-630-942,1/25/2024,2024,US 202318375371 A,9/29/2023,US 202318375371 A;;US 202117158681 A;;US 202263411898 P,1/26/2021,METHODS AND SYSTEMS FOR AUTOMATICALLY GENERATING AND EXECUTING COMPUTER CODE USING A NATURAL LANGUAGE DESCRIPTION OF A DATA MANIPULATION TO BE PERFORMED ON A DATA SET,"A method for automatically generating and executing computer code includes receiving, by a machine learning engine, a user-specified data set and a user-specified task. The machine learning engine analyzes at least one characteristic of the user-specified data set and at least one characteristic of the user-specified task and generates at least one machine learning model for processing the user-specified data set. The machine learning model generates a first output by processing the user-specified data set. The machine learning engine receives a natural language description of a user-requested data transformation task for execution with a subset of the first output and directs a large language model to identify an archetype of the user-requested data transformation task. The large language model applies the user-requested data transformation task to the subset of the first output using the archetype to generate a second output.",AKKIO INC,GILLMAN NATE;;LAHLAF NADIA;;PARANGI APERAHAMA;;REILLY JONATHON;;WIES NATHAN,AKKIO INC (2023-09-21),https://lens.org/125-306-585-630-942,Patent Application,yes,3,7,1,125-306-585-630-942,US,2,161-563-961-646-837;;125-306-585-630-942,US;;WO,0,G06N3/0455;;G06N3/045;;G06N3/0464;;G06N3/047;;G06N20/10;;G06N5/01;;G06F40/30;;G06F40/40;;G06F8/35;;G06N20/00,G06F8/35,,1,0,,,"Chen, Mark, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards et al. ""Evaluating large language models trained on code."" arXiv preprint arXiv:2107.03374 (2021). (Year: 2021)",PENDING
553,US,B1,US 12147513 B1,101-393-155-626-043,11/19/2024,2024,US 202418633293 A,4/11/2024,US 202418633293 A,4/11/2024,Dynamic evaluation of language model prompts for model selection and output validation and methods and systems of the same,"The systems and methods disclosed herein relate to a model validation platform that enables dynamic validation of a user's prompt for a large language model (LLM) in order to evaluate the validity of the prompt and the suitability of a large language model for processing the prompt. For example, the platform enables an estimation of the resource allocation associated with processing the prompt with a given LLM, as well as a modification of the prompt, prior to the processing the prompt with the selected LLM. The platform can further validate the output prior to transmitting the output to a server system for display to the user. By doing so, the platform enables dynamic evaluation of a request to execute an LLM, as well as evaluation of resulting outputs, for accuracy and efficiency improvements in data processing or software development pipelines.",CITIBANK NA,JAIN PAYAL;;MAONAH TARIQ HUSAYN;;SATERNUS MARIUSZ;;LEWANDOWSKI DANIEL;;RATH BIRAJ KRUSHNA;;MURRAY STUART;;DAVIES PHILIP,CITIBANK N.A (2024-05-14),https://lens.org/101-393-155-626-043,Granted Patent,yes,21,1,1,101-393-155-626-043,US,36,166-860-055-274-237;;192-529-172-020-159;;117-165-481-521-817;;062-084-390-952-648;;009-332-012-767-769;;130-711-467-813-772;;150-084-174-776-205;;134-859-487-724-028;;136-076-696-451-742;;174-498-778-674-614;;135-411-020-650-37X;;082-042-370-293-809;;081-164-654-051-886;;126-999-415-386-749;;101-393-155-626-043;;028-517-317-595-400;;183-393-311-078-435;;120-491-497-842-713;;071-444-314-653-665;;151-710-271-944-022;;169-310-367-816-659;;114-332-483-825-36X;;176-222-606-932-299;;109-693-731-347-460;;187-959-165-043-749;;165-235-788-605-427;;184-797-936-150-334;;129-627-428-962-735;;132-864-126-338-301;;147-316-129-152-657;;087-574-341-939-358;;052-233-397-211-176;;154-552-332-382-958;;158-104-528-887-831;;122-629-432-281-208;;053-045-267-490-224,US;;WO;;EP,0,G06F40/20;;G06F21/31;;G06F21/6218;;G06F21/31;;G06F40/20;;G06F21/6218,G06F21/31;;G06F21/62;;G06F40/20,,4,0,,,"Generative machine learning models; IPCCOM000272835D, Aug. 17, 2023. (Year: 2023).;;Hu, Q., J., et al., “ROUTERBENCH: A Benchmark for Multi-LLM Routing System,” arXiv:2403.12031v2 [cs.LG] Mar. 28, 2024, 16 pages.;;Peers, M., “What California AI Bill Could Mean,” The Briefing, published and retrieved Aug. 30, 2024, 8 pages, https://www.theinformation.com/articles/what-california-ai-bill-could-mean.;;“Empower Your Team with a Compliance Co-Pilot”, Sedric, retrieved on Sep. 25, 2024. https://www.sedric.ai/.",ACTIVE
554,WO,A1,WO 2024/238919 A1,126-877-089-893-597,11/21/2024,2024,US 2024/0029936 W,5/17/2024,US 202363502882 P,5/17/2023,AUTOMATED TOOL GENERATION FOR MACHINE-LEARNED MODEL,"An example method includes receiving, by a computing system, a tool request for a tool for performing a task. The example method includes generating, by the computing system and using a primary machine-learned model, the tool based on the tool request by generating tool code. The example method includes validating, by the computing system, the tool. The example method includes outputting, by the computing system, the tool to a tool repository that is accessible by a toolkit interface of a downstream system to use the tool in conjunction with a secondary machine-learned model.",GOOGLE LLC,WANG XUEZHI;;ZHOU DENGYONG;;CAI TIANLE;;CHEN XINYUN,,https://lens.org/126-877-089-893-597,Patent Application,yes,1,2,1,126-877-089-893-597,WO,1,126-877-089-893-597,WO,0,G06N20/00,G06N20/00,,8,4,190-051-831-582-321;;103-212-983-826-945;;120-047-640-592-980;;084-641-049-769-580,10.1109/icse48619.2023.00129;;pmc8371605;;34265844;;10.1038/s41586-021-03819-2;;10.18653/v1/d18-2012;;10.18653/v1/2020.emnlp-main.83,"PARANJAPE BHARGAVI ET AL: ""ART: Automatic multi-step reasoning and tool-use for large language models"", ARXIV (CORNELL UNIVERSITY), 16 March 2023 (2023-03-16), XP093195847, Retrieved from the Internet <URL:https://arxiv.org/pdf/2303.09014> [retrieved on 20240816], DOI: 10.48550/arxiv.2303.09014;;XIA CHUNQIU STEVEN ET AL: ""Automated Program Repair in the Era of Large Pre-trained Language Models"", 2023 IEEE/ACM 45TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), IEEE, 14 May 2023 (2023-05-14), pages 1482 - 1494, XP034376775, DOI: 10.1109/ICSE48619.2023.00129;;DOSOVITSKIY ET AL.: ""An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"", ARXRV:20 10. 11929V2, 3 June 2021 (2021-06-03);;AGOSTINELLI ET AL.: ""MusicLM.- Generating Music From Text"", ARX1V:2301.11325V1, 26 January 2023 (2023-01-26);;JUMPER ET AL.: ""Highly accurate protein structure prediction with AlphaFold"", NATURE, vol. 596, 26 August 2021 (2021-08-26), pages 583, XP055888904, DOI: 10.1038/s41586-021-03819-2;;KUDO ET AL.: ""SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"", PROCEEDINGS OR TIIE, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (SYSTEM DEMONSTRATIONS, 31 October 2018 (2018-10-31), pages 66 - 71, Retrieved from the Internet <URL:https://aclanthology.org/DI8-2012.pdf>;;VASWANI ET AL.: ""Attention Is All You Need"", ARXIV: 1706.03762N,7, 2 August 2023 (2023-08-02);;SAHARIA ET AL.: ""Non-Autoregressive Machine Translation with Latent Alignments"", ARXRV:2004.07437V3, 16 November 2020 (2020-11-16)",PENDING
555,US,A1,US 2025/0148205 A1,034-414-403-216-476,5/8/2025,2025,US 202318387445 A,11/6/2023,US 202318387445 A,11/6/2023,COMBINING IN-CONTEXT LEARNING AND INSTRUCTION TUNING TO ENHANCE LARGE LANGUAGE MODELS,"Embodiments described herein provide systems and techniques for training large language models. In one aspect, a process for performing in-context few-shot training for a transformer-based language model is disclosed. This process may begin by receiving the transformer-based language model having a context window of a predetermined size, as well as a training dataset comprising a set of prompt/completion examples. The process then constructs a training sequence based on the training dataset. Next, the process performs a single forward pass using the training sequence as input. The process subsequently performs a set of backward passes from a subset of examples in the training sequence, wherein each backward pass is conditioned on a selected subset of prompt/completion examples in the training sequence. Performing multiple backward passes conditioned on selected prompt/completion examples improves the language model's ability to generate a higher quality conditional probability distribution for next token without incurring additional training time.",SAMBANOVA SYSTEMS INC,CSAKI ZOLTAN;;LI BO;;THAKKER URMISH AJIT;;SRINIVASAN VENKAT KRISHNA,SAMBANOVA SYSTEMS INC (2023-11-02),https://lens.org/034-414-403-216-476,Patent Application,yes,0,0,1,034-414-403-216-476,US,1,034-414-403-216-476,US,0,G06F40/284;;G06F40/284,G06F40/284,,0,0,,,,PENDING
556,WO,A1,WO 2024/163363 A1,026-584-319-851-321,8/8/2024,2024,US 2024/0013384 W,1/29/2024,US 202363442338 P,1/31/2023,SYSTEMS AND METHODS FOR CHAIN OF THOUGHT META-PROMPTING FOR MACHINE LEARNING MODELS,"A method, apparatus, and system for performing a task using a chain of thought model. An initiation prompt for execution by at least one machine learning model is provided, including an objective and instructions to define a plurality of agents for achieving the objective and an arrangement of the plurality of agents. A response to the initiation prompt is received defining the plurality of agents and the arrangement of the plurality of agents. The arrangement comprises a hypergraph in which a plurality of nodes represents the plurality of agents, respectively, and a plurality of edges represents data connections between the plurality of agents. A first agent and a second agent are instantiated based on the response. The first agent is represented by a first node of the plurality of nodes in the hypergraph. The second agent is represented by a second node. An output of the second agent is obtained.",THINKABLE HOLDINGS INC,KHYATTI MOHAMED REDA,,https://lens.org/026-584-319-851-321,Patent Application,yes,0,1,1,026-584-319-851-321,WO,1,026-584-319-851-321,WO,0,G06N3/004;;G06N3/0475,G06N3/0475,,2,1,055-966-873-815-972,10.1109/mmar55195.2022.9874265,"SHUNYU YAO ET AL: ""ReAct: Synergizing Reasoning and Acting in Language Models"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 27 November 2022 (2022-11-27), XP091379411;;SIJS JORIS ET AL: ""On a hypergraph structuring semantic information for robots navigating and conducting their task in real-world, indoor environments"", 2022 26TH INTERNATIONAL CONFERENCE ON METHODS AND MODELS IN AUTOMATION AND ROBOTICS (MMAR), IEEE, 22 August 2022 (2022-08-22), pages 430 - 435, XP034183776, DOI: 10.1109/MMAR55195.2022.9874265",PENDING
557,US,A1,US 2025/0173938 A1,054-834-394-010-084,5/29/2025,2025,US 202318521310 A,11/28/2023,US 202318521310 A,11/28/2023,EXPRESSING EMOTION IN SPEECH FOR CONVERSATIONAL AI SYSTEMS AND APPLICATIONS,"In various examples, expressing emotion in speech for conversational AI systems and applications is described. Systems and methods are disclosed that use a machine learning model(s) (e.g., one or more large language models (LLMs)) to determine both an emotional state associated with speech output by a character and one or more values for one or more variables associated with the emotional state and/or the speech. For example, the variable(s) may include an intensity of the emotional state and/or a pitch, a rate, a volume, an emphasis, and/or the like of the speech. In some examples, the machine learning model(s) may determine the emotional state and/or the value(s) of the variable(s) using various types of inputs in addition to the text of the speech, such as user data and/or character data. The character may then output the speech in a way that expresses the emotional state.",NVIDIA CORP,HOSSEINI ASL EHSAN;;SRIHARI NIKHIL;;OLABIYI OLUWATOBI;;HAZARE AKSHAY,NVIDIA CORPORATION (2023-11-30),https://lens.org/054-834-394-010-084,Patent Application,yes,0,0,3,054-834-394-010-084;;080-683-418-108-439;;012-318-771-843-213,US;;DE;;CN,3,054-834-394-010-084;;080-683-418-108-439;;012-318-771-843-213,US;;DE;;CN,0,G06F40/30;;G10L13/033;;G06T13/205;;G06T13/40,G06T13/40;;G06T13/20,,0,0,,,,PENDING
558,US,A1,US 2025/0117596 A1,099-505-018-840-215,4/10/2025,2025,US 202318481954 A,10/5/2023,US 202318481954 A,10/5/2023,AI ENGINE FOR TRAINING CREDIT CARD CHATBOT,"An example operation may include one or more of training a large language model (LLM) to learn credit card data via execution of the LLM on content from one or more credit card documents, executing the LLM to generate a sequence of prompts which are output to a user via a chatbot within a chat window of a software application, receiving responses to the sequence of prompts for the user via the chat window of the software application, and retraining the LLM model to further learn credit card data via execution of the LLM on a combination of the sequence of prompts and the received responses.",TORONTO DOMINION BANK,TAHERI SHAHRIAR,,https://lens.org/099-505-018-840-215,Patent Application,yes,5,1,1,099-505-018-840-215,US,1,099-505-018-840-215,US,0,G06F40/35;;G06N3/091;;G06F40/40;;G06N20/00;;G06F40/40;;G06N3/091;;G06F40/35,G06F40/40;;G06F40/35;;G06N3/091,,0,0,,,,PENDING
559,WO,A2,WO 2024/168357 A2,051-922-636-225-864,8/15/2024,2024,US 2024/0023519 W,4/8/2024,US 202318106840 A,2/7/2023,SYSTEM AND METHODS FOR INTERACTIVE PLANT CARE MONITORING SYSTEM WITH DYNAMIC DIGITAL ANIMATION INTERFACE,"The present invention relates to systems and methods designed to facilitate plant care through the translation of environmental and plant phenotyping data, into dynamic digital animations to represent the plants conditions, facilitating human understanding of the plant care needs. Through the integration with plant monitoring devices, the application collects a set of parameters, including but not limited to, temperature, soil moisture, light exposure, and plant growth indicators. The collected data is then transmitted to a specialized software module, which employs algorithms to interpret the plant's condition. The distinctive feature of this invention is its capability to translate plant monitoring data into dynamic digital animations in a very interactive and entertaining way. These animations simulate behaviors, emotions, movements, expressions, communicative actions presenting the plants as digital living beings. This personification technique revolutionizes human-plants interaction fostering improved plant care and deepens the connection to the natural world.",NETTO LEONARDO,NETTO LEONARDO,,https://lens.org/051-922-636-225-864,Patent Application,yes,0,0,2,135-019-669-198-916;;051-922-636-225-864,WO,2,135-019-669-198-916;;051-922-636-225-864,WO,0,G06N20/00;;G16H40/67;;G16H50/50;;G16H50/20;;G16H20/00,G16B20/00;;G06N20/00,,0,0,,,,PENDING
560,US,A1,US 2024/0403904 A1,018-095-913-223-785,12/5/2024,2024,US 202318325561 A,5/30/2023,US 202318325561 A,5/30/2023,Obtaining Actionable Application Feedback via Generation of LLM-Based Survey Prompts and Application Insights,"A computer-implemented method for obtaining actionable application feedback includes executing an application on remote computing systems and, during execution of the application on each computing system: surfacing a UI including a survey UI element on the display of the computing system; surfacing a first survey prompt via the survey UI element; receiving user input including a response to the first survey prompt, inputting the user input to an LLM; generating, via the LLM, a second survey prompt based on the provided user input; surfacing the second survey prompt via the survey UI element; receiving user input including a verbatim response to the second survey prompt; and generating, via the LLM, topic tag(s) corresponding to the verbatim response. The method includes aggregating the verbatim responses received via the computing systems according to the corresponding topic tag(s), as well as generating, via the LLM, application insights based on the aggregated verbatim responses.",MICROSOFT TECHNOLOGY LICENSING LLC,LEVITAN DAVID BENJAMIN;;SHARMA ISHITA;;KOMMU RAJESHKUMAR;;DUNNING JOSHUA MICHAEL;;SHAJARI SEYEDEH HODA;;MCANALLEN JULIA S,MICROSOFT TECHNOLOGY LICENSING LLC (2023-05-26),https://lens.org/018-095-913-223-785,Patent Application,yes,2,4,1,018-095-913-223-785,US,1,018-095-913-223-785,US,0,G06Q30/0203;;G06Q30/0203,G06Q30/0203,,0,0,,,,PENDING
561,US,B1,US 12243066 B1,026-986-586-975-486,3/4/2025,2025,US 202418766833 A,7/9/2024,US 202418766833 A,7/9/2024,Natural language survey system,"Systems and methods for a natural language survey system are provided. The natural language survey system may harness generative artificial intelligence (“AI”) and machine learning to enhance survey question generation, survey participance and completed survey analysis and research. The natural language survey system may include a dynamic interactive platform. The dynamic interactive platform may enable a researcher to create a survey using natural language. The dynamic interactive platform may enable a researcher to directly identify survey goals instead of creating a plurality of goal-oriented specific questions. The dynamic interactive platform may enable a plurality of participants to participate in the survey. The dynamic interactive platform may provide reports and insights to the researcher upon completion of the survey by the participants.",PRIME RES SOLUTIONS LLC,ROBINSON JONATHAN;;LITMAN LEONID;;PARIS REUBEN,PRIME RESEARCH SOLUTIONS LLC (2024-07-04),https://lens.org/026-986-586-975-486,Granted Patent,yes,11,0,1,026-986-586-975-486,US,3,140-546-249-663-178;;007-343-792-077-080;;026-986-586-975-486,US,0,G06F40/40;;G06F40/166;;G06Q30/0203;;G06F40/279;;G06F40/30;;G06Q30/0203;;G06F40/279;;G06F40/166;;G06F40/40,G06Q30/0203;;G06F40/166;;G06F40/279;;G06F40/40,,1,1,092-181-670-623-323,10.1145/3652988.3673929,"Yun, H. S., Arjmand, M., Sherlock, P. R., Paasche-Orlow, M., Griffith, J. W., & Bickmore, T. (2023). Keeping users engaged during repeated administration of the same questionnaire: Using large language models to reliably diversify questions [arXiv] arXiv. (Year: 2023).",ACTIVE
562,US,A1,US 2024/0338870 A1,042-836-438-407-360,10/10/2024,2024,US 202318479379 A,10/2/2023,US 202318479379 A;;US 202363495194 P,4/10/2023,GENERATIVE AI BASED TEXT EFFECTS WITH CONSISTENT STYLING,"A method, apparatus, and non-transitory computer readable medium for image generation are described. Embodiments of the present disclosure obtain, via a user interface, an input text. The user interface also obtains a text effect prompt that describes a text effect for the input text. An image generation model generates an output image depicting the input text with the text effect described by the text effect prompt.",ADOBE INC,IYER SIDDHARTH;;BOURGIN DAVID DAVENPORT;;KATAKOL SUDEEP;;DARABI ALIAKBAR,ADOBE INC (2023-08-10),https://lens.org/042-836-438-407-360,Patent Application,yes,2,0,1,042-836-438-407-360,US,7,035-823-420-155-226;;042-836-438-407-360;;077-008-991-867-158;;146-657-757-424-747;;060-762-969-436-674;;059-462-643-225-789;;144-634-615-922-455,US;;GB;;DE;;AU;;CN,0,G06T2200/24;;G06T11/60;;G06T11/001;;G06T2200/24;;G06T11/60,G06T11/60,,3,2,010-770-573-330-925;;031-768-179-628-642,10.1109/mipr51284.2021.00062;;10.1016/j.heliyon.2023.e16757;;37292268;;pmc10245047,"Ma et al, Text Style Transfer With Decorative Elements, 2021, 2021 IEEE 4th International Conference on Multimedia Information Processing and Retrieval (MIPR), p. 330-336, https://doi.org/10.1145/3544903.3544906 (Year: 2021);;Xie et al, SmartBrush: Text and Shape Guided Object Inpainting with Diffusion Model, 2022, arXiv, p. 1-10, https://doi.org/10.48550/arXiv.2212.05034 (Year: 2022);;Dehouche et al, What is in a Text-to-Image Prompt: The Potential of Stable Diffusion in Visual Arts Education, 2023, arXiv, p.1-11, https://doi.org/10.48550/arXiv.2301.01902 (Year: 2023)",PENDING
563,US,A1,US 2025/0104399 A1,132-158-664-977-321,3/27/2025,2025,US 202318473603 A,9/25/2023,US 202318473603 A,9/25/2023,DATA ATTRIBUTION FOR DIFFUSION MODELS,"Embodiments of the present disclosure perform training attribution by identifying a synthesized image and a training image, where the synthesized image was generated by an image generation model that was trained with the training image. A machine learning model computes first attribution features for the synthesized image using a first mapping layer and second attribution features for the training image using a second mapping layer that is different from the first mapping layer. Then, an attribution score is generated based on the first attribution features and the second attribution features, where the attribution score indicates a degree of influence for the training image on generating the synthesized image.",ADOBE INC,WANG SHENG-YU;;EFROS ALEXEI A;;ZHU JUNYAN;;ZHANG RICHARD,ADOBE INC (2023-08-09),https://lens.org/132-158-664-977-321,Patent Application,yes,0,0,1,132-158-664-977-321,US,1,132-158-664-977-321,US,0,G06V10/7715;;G06N3/0895;;G06V10/774;;G06V10/82;;G06V10/761;;G06N3/045;;G06V10/7715;;G06V10/774;;G06V10/82;;G06N3/0895;;G06V10/761,G06V10/77;;G06N3/0895;;G06V10/74;;G06V10/774;;G06V10/82,,0,0,,,,PENDING
564,US,B1,US 12106318 B1,158-476-747-294-347,10/1/2024,2024,US 202318457178 A,8/28/2023,US 202318457178 A;;US 202363497029 P,4/19/2023,Prompt management systems for moderating generative artificial intelligence operations,"Operations of a prompt management system are disclosed. The operations may include: receiving a prompt for performing a set of tasks, assigning an agent group that includes a plurality of agents to perform a set of roles associated with a dataset in support of the set of tasks, causing the plurality of agents to perform the set of roles using a first machine-learning model, receiving a set of role results from the plurality of agents responsive to performing the set of roles, performing the set of tasks using at least a second machine-learning model, and providing a task result for display on a user interface device. The set of tasks may include executing an operation on the set of role results using the second machine-learning model, and generating a task result that includes a product of the operation executed on the set of role results.",WEVO INC,CHIANG FRANK;;GARVEY DUSTIN;;BARZA ALEXANDER;;STEWART ALEXA;;HOANG CHARLIE;;ANDREWS JON;;SIEBER HANNAH;;YAU JESSICA;;KORESH SHACHAR;;MUTO JANET;;SHAER NITZAN,WEVO INC (2023-08-23),https://lens.org/158-476-747-294-347,Granted Patent,yes,6,5,2,158-476-747-294-347;;021-841-983-905-60X,US,2,158-476-747-294-347;;021-841-983-905-60X,US,0,G06Q10/063112;;G06Q30/0204;;G06Q30/016;;G06Q10/063112;;G06Q30/0204,G06Q30/0204;;G06Q10/0631,,0,0,,,,ACTIVE
565,US,A1,US 2025/0225277 A1,011-103-149-602-466,7/10/2025,2025,US 202519055968 A,2/18/2025,US 202519055968 A,2/18/2025,SENSITIVE DATA PROTECTION,A method and system is disclosed which enable sensitive data to be protected during interactions with a generative model.,BUBBLR INC,MORRIS STEPHEN,,https://lens.org/011-103-149-602-466,Patent Application,yes,0,0,1,011-103-149-602-466,US,1,011-103-149-602-466,US,0,G06F21/6254,G06F21/62,,0,0,,,,PENDING
566,US,A1,US 2025/0117630 A1,043-761-032-410-327,4/10/2025,2025,US 202318481957 A,10/5/2023,US 202318481957 A,10/5/2023,CHATBOT WITH LLM AND VECTORIZED DATABASE,"An example operation may include one or more of receiving an input from a user during a conversation that includes a plurality of prompts between the user and a chatbot within a chat window of a software application, converting text content within the received input into a vector, executing a large language model (LLM) on the vector and a database of vectorized responses to identify a vectorized response to output from among the plurality of vectorized responses within the database, converting the vectorized response into a text response, and displaying the text response output by the chatbot within the chat window of the software application.",TORONTO DOMINION BANK,TAHERI SHAHRIAR,,https://lens.org/043-761-032-410-327,Patent Application,yes,0,0,1,043-761-032-410-327,US,1,043-761-032-410-327,US,0,G06N3/0895;;G06N3/0475;;G06N3/0895;;G06N3/0475,G06N3/0475;;G06N3/0895,,0,0,,,,PENDING
567,US,B1,US 12346314 B1,129-709-578-614-225,7/1/2025,2025,US 202418774702 A,7/16/2024,US 202418774702 A,7/16/2024,Intelligent query response in ERP systems using generative AI,"A computer-implemented method for intelligent query response in an enterprise resource planning (ERP) system is disclosed. The method can receive, from a user interface of the ERP system, a natural language user query for processing data of a target object and invoke a function call through an application programming interface of the ERP system based on the user query. Invoking the function call includes extract denormalized data from one or more database tables, generating a prompt using a prompt template and the denormalized data, prompting a large language model using the prompt, and receiving a response generated by the large language model. The method can generate an output on the user interface based on the response generated by the large language model. Related systems and software for implementing the method are also disclosed.",SAP SE,GUERRA RODRIGO;;WENZLER RUDOLF,,https://lens.org/129-709-578-614-225,Granted Patent,yes,6,0,1,129-709-578-614-225,US,1,129-709-578-614-225,US,0,G06F16/2428;;G06F16/235;;G06F16/243;;G06F16/3329;;G06F16/2428;;G06F16/235;;G06F16/243,G06F7/00;;G06F16/23;;G06F16/242,,2,0,,,"Reiss, “SAP UX Innovations in Public Cloud Products, Joule, AI, Entry Points, Apple Vision Pro and more,” https://community.sap.com/t5/technology-blogs-by-sap/sap-ux-innovations-in-public-cloud-products-joule-ai-entry-points-apple/ba-p/1359454, 55 pages, Jun. 2, 2024.;;Artificial Intelligence, Joule, https://www.sap.com/products/artificial-intelligence/ai-assistant.html, 9 pages (accessed Jun. 6, 2024).",ACTIVE
568,US,B1,US 12314969 B1,140-546-249-663-178,5/27/2025,2025,US 202418934448 A,11/1/2024,US 202418934448 A;;US 202418766833 A,7/9/2024,Natural language survey system,"Systems and methods for a natural language survey system are provided. The natural language survey system may harness generative artificial intelligence (“AI”) and machine learning to enhance survey question generation, survey participant and completed survey analysis and research. The natural language survey system may include a dynamic interactive platform. The dynamic interactive platform may enable a researcher to create a survey using natural language. The dynamic interactive platform may enable a researcher to directly identify survey goals instead of creating a plurality of goal-oriented specific questions. The dynamic interactive platform may enable a plurality of participants to participate in the survey. The dynamic interactive platform may provide reports and insights to the researcher upon completion of the survey by the participants.",PRIME RES SOLUTIONS LLC,ROBINSON JONATHAN;;LITMAN LEONID;;PARIS REUBEN,PRIME RESEARCH SOLUTIONS LLC (2024-11-01),https://lens.org/140-546-249-663-178,Granted Patent,yes,11,0,1,140-546-249-663-178,US,3,140-546-249-663-178;;007-343-792-077-080;;026-986-586-975-486,US,0,G06F40/166;;G06F40/279;;G06F40/30;;G06F40/40;;G06Q30/0203;;G06F40/186;;G06F40/58;;G06Q50/22;;G06Q50/20;;G06Q10/105;;G06F40/58;;G06F40/186;;G06Q30/0203,G06Q30/0203;;G06F40/186;;G06F40/58,,2,1,092-181-670-623-323,10.1145/3652988.3673929,"Translation for KR-20230084635-A (Year: 2023).;;Yun et al., “Keeping Users Engaged During Repeated Administration of the Same Questionnaire: Using Large Language Models to Reliably Diversify Questions,” arXiv, Nov. 21, 2023.",ACTIVE
569,US,A1,US 2025/0148276 A1,173-624-912-844-863,5/8/2025,2025,US 202318387152 A,11/6/2023,US 202318387152 A,11/6/2023,ALL-SHOT TRAINING OF LARGE LANGUAGE MODELS,"Embodiments described herein provide systems and techniques for training large language models. In one aspect, a process for performing in-context training of a language model is disclosed. This process may begin by receiving a language model that includes a context window of a predetermined size, as well as receiving a set of in-context prompt/completion pairs prepared for a target task. The process then constructs a first token sequence based on the set of in-context prompt/completion pairs. Next, the process fits the first token sequence into the context window. The process subsequently performs a first in-context training pass using the first token sequence to train the language model to generate a next token in accordance with the target task.",SAMBANOVA SYSTEMS INC,CSAKI ZOLTAN;;LI BO;;THAKKER URMISH AJIT;;SRINIVASAN VENKAT KRISHNA,SAMBANOVA SYSTEMS INC (2023-11-02),https://lens.org/173-624-912-844-863,Patent Application,yes,0,0,1,173-624-912-844-863,US,1,173-624-912-844-863,US,0,G06N3/08;;G06N3/084;;G06N3/08;;G06F16/53,G06N3/08,,0,0,,,,PENDING
570,US,A1,US 2024/0221370 A1,066-059-576-976-163,7/4/2024,2024,US 202318543699 A,12/18/2023,DE 102023200021 A,1/3/2023,COMPUTER-IMPLEMENTED METHOD AND SYSTEM FOR ASCERTAINING A MISCLASSIFICATION VALUE DURING THE CLASSIFICATION OF IMAGES INTO AT LEAST ONE IMAGE CATEGORY BY A CLASSIFICATION ALGORITHM,"A computer-implemented method for ascertaining a misclassification value during classification of images into at least one image category by a classification algorithm. The method includes: providing an input text file, which includes a keyword using which the input text file is assigned to a predetermined image category of a plurality of image categories, the input text file including indications relating to at least one image feature for the predetermined image category and at least one value indication for the at least one image feature; generating at least one image file using a text-into-image generation algorithm, the image file including a synthetic image that is assigned to the predetermined image category and has the at least one image feature and the at least one value indication; classifying the generated, synthetic image using the classification algorithm into at least one of the plurality of image categories; and ascertaining the misclassification value.",BOSCH GMBH ROBERT,METZEN JAN HENDRIK,ROBERT BOSCH GMBH (2024-01-03),https://lens.org/066-059-576-976-163,Patent Application,yes,0,0,3,159-120-928-456-981;;040-228-723-869-79X;;066-059-576-976-163,US;;DE;;CN,3,040-228-723-869-79X;;159-120-928-456-981;;066-059-576-976-163,US;;DE;;CN,0,G06V30/19173;;G06V10/7715;;G06V10/774;;G06V10/776;;G06V10/764;;G06F40/279;;G06V10/776;;G06V10/7715;;G06F40/279;;G06V10/774;;G06V10/764,G06V10/776;;G06F40/279;;G06V10/764;;G06V10/77;;G06V10/774,,0,0,,,,PENDING
571,EP,A1,EP 4524780 A1,141-543-195-991-426,3/19/2025,2025,EP 23197535 A,9/14/2023,EP 23197535 A,9/14/2023,TRAINING METHOD FOR CATEGORY-LEVEL OBJECT POSE ESTIMATION,"A computer-implemented training method for a category-level pose estimation model is provided. the method comprises: (S10) training a first neural network of the model to generate a pose estimation of an object based on an input image of a scene comprising the object, the input image comprising depth information of the object and color information of the object; (S20) training a second neural network of the model to generate a surface normal estimation of the object based on the color information and on polarization information of the object; and (S30) refining the pose estimation of the object by fine-tuning the first neural network using a first self-supervision signal based on the surface normal estimation of the object and on rendered surface normals derived from the pose estimation and a latent code representative of a shape of the object.",TOYOTA MOTOR CO LTD;;TECHNICAL UNIV OF MUNICH,GARATTONI LORENZO;;MEIER SVEN;;WANG PENGYUAN;;BUSAM BENJAMIN,,https://lens.org/141-543-195-991-426,Patent Application,yes,0,0,1,141-543-195-991-426,EP,1,141-543-195-991-426,EP,0,G06F18/27;;G06V10/82;;G06V20/64,G06F18/27;;G06V10/82;;G06V20/64,,19,10,081-059-355-359-27X;;129-389-752-924-940;;129-389-752-924-940;;174-875-912-179-51X;;148-671-047-796-160;;081-059-355-359-27X;;177-133-876-427-438;;099-143-127-708-429;;057-371-593-698-054;;145-012-695-646-824,10.1007/978-3-030-58586-0_33;;10.1109/cvpr46437.2021.00163;;10.1109/cvpr46437.2021.00163;;10.1007/978-3-031-20077-9_43;;10.1109/cvpr.2019.00275;;10.1007/978-3-030-58586-0_33;;10.1145/3528223.3530099;;10.1109/cvpr52733.2024.02123;;10.1109/iccv48922.2021.01196;;10.1109/cvpr.2018.00030,"WANG PENGYUAN ET AL: ""CroCPS: Addressing Photometric Challenges in Self-Supervised Category-Level 6D Object Poses with Cross-Modal Learning"", 21 November 2022 (2022-11-21), XP093111042, Retrieved from the Internet <URL:https://bmvc2022.mpi-inf.mpg.de/0390.pdf> [retrieved on 20231211];;BA YUNHAO ET AL: ""Computer Vision - ECCV 2020 : 16th European Conference, Glasgow, UK, August 23-28, 2020, Proceedings, Part XXIV"", vol. 12369, 23 August 2020 (2020-08-23), Cham, pages 554 - 571, XP093111180, ISSN: 0302-9743, ISBN: 978-3-030-58586-0, Retrieved from the Internet <URL:https://link.springer.com/content/pdf/10.1007/978-3-030-58586-0.pdf>;;CHEN WEI ET AL: ""FS-Net: Fast Shape-based Network for Category-Level 6D Object Pose Estimation with Decoupled Rotation Mechanism"", 2021 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR), IEEE, 20 June 2021 (2021-06-20), pages 1581 - 1590, XP034006492, DOI: 10.1109/CVPR46437.2021.00163;;CHENWEIJIAXICHANGHYUNG JIN ET AL.: ""Fs-net: Fast shape-based network for category-level 6d object pose estimation with decoupled rotation mechanism"", PROCEEDINGS OF THE IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, 2021, pages 1581 - 1590;;GAO, DAOYILI, YITONGRUHKAMP, PATRICK ET AL.: ""Proceedings, Part IX. Cham"", 23 October 2022, SPRINGER NATURE SWITZERLAND, article ""Polarimetric pose prediction. In : Computer Vision-ECCV 2022: 17th European Conference"", pages: 735 - 752;;MANHARDT, FABIANWANG, GUBUSAM, BENJAMIN ET AL.: ""CPS++: Improving class-level 6D pose and shape estimation from monocular images with self-supervised learning"", ARXIV PREPRINT ARXIV:2003.05848, 2020;;WANG, HESRIDHAR, SRINATHHUANG, JINGWEI ET AL.: ""Normalized object coordinate space for category-level 6d object pose and size estimation"", PROCEEDINGS OF THE IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, 2019, pages 2642 - 2651;;WANG, PENGYUANGARATTONI, LORENZOMEIER, SVEN ET AL.: ""CroCPS: Addressing Photometric Challenges in Self-Supervised Category-Level 6D Object Poses with Cross-Modal Learning"", PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE, 2022;;HE, KAIMINGZHANG, XIANGYUREN, SHAOQING ET AL.: ""Deep residual learning for image recognition"", PROCEEDINGS OF THE IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, 2016, pages 770 - 778;;BA, YUNHAOGILBERT, ALEXWANG, FRANKLIN ET AL.: ""16th European Conference, Glasgow, UK, August 23-28, 2020, Proceedings, Part XXIV"", vol. 16, 23 August 2020, SPRINGER INTERNATIONAL PUBLISHING, article ""Deep shape from polarization. In : Computer Vision-ECCV 2020"", pages: 554 - 571;;ZHANG, CHAONINGZHENG, SHENGLI, CHENGHAO ET AL.: ""A Survey on Segment Anything Model (SAM): Vision Foundation Model Meets Prompt Engineering"", ARXIV PREPRINT ARXIV:2306.06211, 2023;;LI, ZHENYUCHEN, ZEHUILIU, XIANMING ET AL.: ""Depthformer: Exploiting long-range correlation and local information for accurate monocular depth estimation"", ARXIV PREPRINT ARXIV:2203.14211, 2022;;KINGMA, DIEDERIK PBA, JIMMY. ADAM: ""A method for stochastic optimization"", ARXIV PREPRINT ARXIV: 1412.6980, 2014;;DENNINGER, MAXIMILIANSUNDERMEYER, MARTINWINKELBAUER, DOMINIK ET AL., BLENDERPROC. ARXIV PREPRINT ARXIV:1911.01911, 2019;;JAKOB, WENZELSPEIERER, SEBASTIENROUSSEL, NICOLAS ET AL.: ""DR. JIT: a just-in-time compiler for differentiable rendering"", ACM TRANSACTIONS ON GRAPHICS (TOG, vol. 41, no. 4, 2022, pages 1 - 19;;JUNG, HYUNJUNWU, SHUN-CHENGRUHKAMP, PATRICK ET AL.: ""HouseCat6D--A Large-Scale Multi-Modal Category Level 6D Object Pose Dataset with Household Objects in Realistic Scenarios"", ARXIV PREPRINT ARXIV:2212.10428, 2022;;RANFTL, RENEBOCHKOVSKIY, ALEXEYKOLTUN, VLADLEN: ""Vision transformers for dense prediction"", PROCEEDINGS OF THE IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION, 2021, pages 12179 - 12188;;FUJI TSANG, CLEMENT ET AL., KAOLIN: A PYTORCH LIBRARY FOR ACCELERATING 3D DEEP LEARNING RESEARCH, 2022, Retrieved from the Internet <URL:https://github.com/NVIDIAGameWorks/kaolin>;;GROUEIX, THIBAULTFISHER, MATTHEWKIM, VLADIMIR G ET AL.: ""A papier-mache approach to learning 3d surface generation"", PROCEEDINGS OF THE IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, 2018, pages 216 - 224, XP033475981, DOI: 10.1109/CVPR.2018.00030",PENDING
572,US,A1,US 2025/0239169 A1,039-278-947-334-022,7/24/2025,2025,US 202418427410 A,1/30/2024,KR 20240010235 A,1/23/2024,EXPLAINABLE ENGINEERING EDUCATION METAVERSE TO SUPPORT 3D MATRIX CURRICULUM,"A method of providing education may be provided. The method of providing education may include: constructing a matrix-type curriculum database consisting of subject information corresponding to each curriculum for each technology; obtaining a language model corresponding to a student based on learning data of the student, and spawning a virtual NPC that provides an education service to the student in a metaverse space based on the language model; determining curriculum corresponding to the student based on the learning data; determining content corresponding to the student based on the curriculum and the learning data; and evaluating an achievement level of the student based on the learning data.",KOREA UNIV OF TECHNOLOGY AND EDUCATION INDUSTRY UNIV COOPERATION FOUNDATION,KIM WON TAE;;YUN SEONG JIN;;KWON JIN WOO,,https://lens.org/039-278-947-334-022,Patent Application,yes,0,0,1,039-278-947-334-022,US,1,039-278-947-334-022,US,0,G09B5/065,G09B5/06,,0,0,,,,PENDING
573,US,B1,US 12360791 B1,051-185-946-759-020,7/15/2025,2025,US 202418787750 A,7/29/2024,US 202418787750 A;;US 202463644188 P,5/8/2024,Generating new software code from legacy software code using large language models,"Computer-implemented systems and methods use a Large Language Model (LLM) for converting a legacy computer program in a first language to a human-language description of the legacy computer program, which description can be validated as being an accurate description of the legacy computer program. Once validated, the human-language description can be converted, again using an LLM, to a computer program in a target programming language. An LLM can also be used to generate test scripts for the new target-language program to test the performance of the target-language program in a production environment. An LLM can also be used to reconcile outputs from the legacy program to the new target program, such as on a function-by-function basis. If the differences between the outputs (if any) are sufficiently negligible, the legacy computer program can be decommissioned, and the new, target language program can be used in production.",MORGAN STANLEY SERVICES GROUP INC,VADAPARTY KUMAR;;DUTTAGUPTA KALLOL;;MATHEW THOMAS;;SEN KUNDAN;;NAGAR SHWETANK,,https://lens.org/051-185-946-759-020,Granted Patent,yes,18,0,1,051-185-946-759-020,US,1,051-185-946-759-020,US,0,G06F9/45516;;G06F8/447;;G06F8/31;;G06F8/35,G06F9/455;;G06F8/30;;G06F8/35;;G06F8/41,,8,0,,,"Duc et al., “Generative Artificial Intelligence for Software Engineering—A Research Agenda,” arXiv, 2023. (Year: 2023).;;Fan et al., “Large Language Models for Software Engineering: Survey and Open Problems,” arXiv, 2023. (Year: 2023).;;Patil et al., “A Review of Current Trends, Techniques, and Challenges in Large Language Models (LLMs),” PrePrints.org, 2024. (Year: 2024).;;Wong et al,. “Natural Language Generation and Understanding of Big Code for AI-Assisted Programming: A Review,” Entropy, 2023. (Year: 2023).;;Sahil Bhatia et al., Verified Code Transpilation with LLMs, Jun. 2024, 19 pages.;;Hasan Ferit Eniser et al., Towards Translating Real-World Code with LLMs: A Study of Translating to Rust, May 2024, 11 pages.;;Rangeet Pan et al., Lost in Translation: A Study of Bugs Introduced by Large Language Models while Translating Code, Jan. 2024, 13 pages.;;IBM News, COBOL programmers are getting harder to find. IBM's code-writing AI can help, Oct. 2023, 7 pages.",ACTIVE
574,US,A1,US 2025/0119396 A1,085-631-852-729-200,4/10/2025,2025,US 202318481920 A,10/5/2023,US 202318481920 A,10/5/2023,CHARGE CARD KNOWLEDGE CHATBOT,"An example operation may include one or more of storing a database of payment card data, conversing with a user via a chatbot within a chat window of a software application, wherein the conversing comprises receiving a query from the user about a payment card during a chat session between the user and the chatbot, executing a large language model (LLM) on the query about the payment card and the database of payment card data to generate a chatbot response, and displaying the generated chatbot response via the chatbot within the chat window of the software application during the chat session.",TORONTO DOMINION BANK,TAHERI SHAHRIAR,,https://lens.org/085-631-852-729-200,Patent Application,yes,0,0,1,085-631-852-729-200,US,1,085-631-852-729-200,US,0,H04L51/02;;G06F40/20;;G06F40/20;;H04L51/02,H04L51/02;;G06F40/20,,0,0,,,,PENDING
575,US,A1,US 2025/0111229 A1,122-963-811-934-76X,4/3/2025,2025,US 202418902107 A,9/30/2024,US 202418902107 A;;US 202363586139 P;;US 202363586185 P,9/28/2023,SYSTEMS AND METHODS FOR UNCERTAINTY-AWARE INPUT OPTIMIZATION IN GENERATIVE NEURAL NETWORKS,"Methods of modifying an input, such as a prompt, for a machine learning model are disclosed. In at least some instances, the method includes transforming a received user model into a risk-aware model, applying that risk-aware model to a received input, and receiving, based on the application of the risk-aware model, output and corresponding risk values. In turn, the method includes determining whether the corresponding risk values, or an aggregate of such values, are less than a predetermined threshold level. If the values or aggregate are greater than the predetermined threshold level, then a process is performed to modify the input to minimize the corresponding risk values. The risk-aware model is iteratively applied to the modified input and the modification process continues to be performed until the corresponding risk values are less than the predetermined threshold level. Other methods, and systems for performing any methods disclosed, are also provided.",THEMIS AI INC,RUS DANIELA;;ELISTRATOV IAROSLAV;;SCHMITT-ULMS FYNN;;DEMIR EGE;;PEREZ ALEJANDRO;;AHMADI ELAHEH,THEMIS AI INC (2024-10-23),https://lens.org/122-963-811-934-76X,Patent Application,yes,0,0,1,122-963-811-934-76X,US,1,122-963-811-934-76X,US,0,G06N3/08;;G06N3/0475;;G06N3/047;;G06N3/0475;;G06N3/08,G06N3/08;;G06N3/0475,,0,0,,,,PENDING
576,US,B1,US 12254873 B1,007-343-792-077-080,3/18/2025,2025,US 202418934453 A,11/1/2024,US 202418934453 A;;US 202418766833 A,7/9/2024,Natural language survey system,"Systems and methods for a natural language survey system are provided. The natural language survey system may harness generative artificial intelligence (“AI”) and machine learning to enhance survey question generation, survey participance and completed survey analysis and research. The natural language survey system may include a dynamic interactive platform. The dynamic interactive platform may enable a researcher to create a survey using natural language. The dynamic interactive platform may enable a researcher to directly identify survey goals instead of creating a plurality of goal-oriented specific questions. The dynamic interactive platform may enable a plurality of participants to participate in the survey. The dynamic interactive platform may provide reports and insights to the researcher upon completion of the survey by the participants.",PRIME RES SOLUTIONS LLC,ROBINSON JONATHAN;;LITMAN LEONID;;PARIS REUBEN,PRIME RESEARCH SOLUTIONS LLC (2024-11-01),https://lens.org/007-343-792-077-080,Granted Patent,yes,11,0,1,007-343-792-077-080,US,3,140-546-249-663-178;;007-343-792-077-080;;026-986-586-975-486,US,0,G06F40/166;;G06F40/279;;G06F40/30;;G06F40/40;;G06Q30/0203;;G10L15/26;;G06Q10/105;;G06Q30/0245;;G06Q50/22;;G06Q50/20;;G10L15/183;;G10L15/30;;G10L15/22;;G10L15/16;;G10L25/30;;G10L15/26,G10L15/00;;G10L15/16;;G10L15/183;;G10L15/22;;G10L15/26;;G10L15/30;;G10L25/30,,1,1,092-181-670-623-323,10.1145/3652988.3673929,"Yun et al., “Keeping Users Engaged During Repeated Administration of the Same Questionnaire: Using Large Language Models to Reliably Diversify Questions,” arXiv, Nov. 21, 2023.",ACTIVE
577,US,A1,US 2024/0428016 A1,086-983-434-015-171,12/26/2024,2024,US 202418749064 A,6/20/2024,KR 20230080428 A,6/22/2023,METHOD FOR GENERATING STORYBOARD BASED ON SCRIPT TEXT,"Disclosed is a method for generating a storyboard based on a script text, which is performed by a computing device. The method may include obtaining the script text. The method may include performing clustering for text parts included in script text based on location information. The method may include determining a prompt information for each cluster generated by clustering based on the location information. The method may include generating the storyboard for each cluster based on the determined prompt information.",ACTIONPOWER CORP,SONG JAEYUP;;LEE JINGU;;KWAK SEUNGHO,ACTIONPOWER CORP (2024-06-20),https://lens.org/086-983-434-015-171,Patent Application,yes,1,0,2,086-983-434-015-171;;003-941-494-989-06X,US;;KR,2,086-983-434-015-171;;003-941-494-989-06X,US;;KR,0,G06F40/295;;G06T11/00;;G06F40/40;;G06F40/166;;G06F40/30;;G06F40/40;;G06F40/166;;G06T11/00;;G06F40/295,G06F40/40;;G06F40/166;;G06F40/295;;G06T11/00,,0,0,,,,PENDING
578,WO,A1,WO 2024/073098 A1,161-563-961-646-837,4/4/2024,2024,US 2023/0034209 W,9/29/2023,US 202263411898 P,9/30/2022,METHODS AND SYSTEMS FOR AUTOMATICALLY GENERATING AND EXECUTING COMPUTER CODE USING A NATURAL LANGUAGE DESCRIPTION OF A DATA MANIPULATION TO BE PERFORMED ON A DATA SET,"A method for automatically generating and executing computer code includes receiving, by a machine learning engine, a user-specified data set and a user-specified task. The machine learning engine analyzes at least one characteristic of the user-specified data set and at least one characteristic of the user-specified task and generates at least one machine learning model for processing the user-specified data set. The machine learning model generates a first output by processing the user-specified data set. The machine learning engine receives a natural language description of a user-requested data transformation task for execution with a subset of the first output and directs a large language model to identify an archetype of the user-requested data transformation task. The large language model applies the user-requested data transformation task to the subset of the first output using the archetype to generate a second output.",AKKIO INC,GILLMAN NATE;;LAHLAF NADIA;;PARANGI APERAHAMA;;REILLY JONATHON;;WIES NATHAN,,https://lens.org/161-563-961-646-837,Patent Application,yes,2,1,1,161-563-961-646-837,WO,2,161-563-961-646-837;;125-306-585-630-942,US;;WO,0,G06F8/33;;G06F8/30;;G06F40/16;;G06F40/216;;G06F40/30;;G06N3/0464;;G06N3/045;;G06N3/08,G06F8/33;;G06F8/30;;G06F8/41;;G06F40/151;;G06N20/00,,3,2,129-909-783-436-882;;003-176-784-453-268,10.1145/3501385.3543957;;10.1145/3520312.3534862,"SARSA SAMI; DENNY PAUL; HELLAS ARTO; LEINONEN JUHO: ""Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models"", PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, ACMPUB27, NEW YORK, NY, USA, 3 August 2022 (2022-08-03) - 21 June 2023 (2023-06-21), New York, NY, USA, pages 27 - 43, XP059145157, ISBN: 979-8-4007-0095-8, DOI: 10.1145/3501385.3543957;;VAITHILINGAM PRIYAN PVAITHILINGAM@G.HARVARD.EDU; ZHANG TIANYI TIANYI@PURDUE.EDU; GLASSMAN ELENA L. GLASSMAN@SEAS.HARVARD.EDU: ""Expectation vs. Experience: Evaluating the Usability of Code Generation Tools Powered by Large Language Models"", PROCEEDINGS OF THE 2022 ACM WORKSHOP ON SOFTWARE SUPPLY CHAIN OFFENSIVE RESEARCH AND ECOSYSTEM DEFENSES, ACMPUB27, NEW YORK, NY, USA, 27 April 2022 (2022-04-27) - 1 December 2022 (2022-12-01), New York, NY, USA, pages 1 - 7, XP058969347, ISBN: 978-1-4503-9889-3, DOI: 10.1145/3491101.3519665;;SWARAT CHAUDHURI: ""A systematic evaluation of large language models of code"", PROCEEDINGS OF THE 6TH ACM SIGPLAN INTERNATIONAL SYMPOSIUM ON MACHINE PROGRAMMING, ACM, NEW YORK, NY, USA, 13 June 2022 (2022-06-13), New York, NY, USA, pages 1 - 10, XP093153402, ISBN: 978-1-4503-9273-0",PENDING
579,US,A1,US 2024/0281663 A1,181-258-782-077-899,8/22/2024,2024,US 202418427400 A,1/30/2024,US 202418427400 A;;US 202363446740 P,2/17/2023,PROMPT GENERATION FOR LARGE LANGUAGE MODEL USING TEXTUAL CONTENT,"A method includes obtaining, using at least one processing device of an electronic device, information associated with a webpage presented to a user. The method also includes providing, using the at least one processing device, the information to an on-device machine learning model of the electronic device. The method further includes generating, using the on-device machine learning model, a prompt for a large language model based on the information. The prompt includes an action from a set of candidate actions that the large language model is able to perform and at least some of the information. The method also includes providing, using the at least one processing device, the prompt as input to the large language model and receiving, using the at least one processing device, a response from the large language model. In addition, the method includes presenting, using the at least one processing device, the response to the user.",SAMSUNG ELECTRONICS CO LTD,CHEN WINSTON;;GOMBOS LASZLO,SAMSUNG ELECTRONICS CO. LTD (2024-01-29),https://lens.org/181-258-782-077-899,Patent Application,yes,0,4,1,181-258-782-077-899,US,1,181-258-782-077-899,US,0,G06N3/0895;;G06N3/0895,G06N3/0895,,0,0,,,,PENDING
580,WO,A2,WO 2025/024317 A2,054-577-984-830-467,1/30/2025,2025,US 2024/0038851 W,7/19/2024,US 202363515026 P;;US 202363587319 P;;US 202463624921 P,7/21/2023,INTERACTIVE PHYSIOLOGICAL MONITORING SYSTEMS,"A user question can be classified into topics and mapped to appropriate static and/or dynamic content related to the user and/or question. This data can then be collectively provided to a large language model in order to generate a suitable response, which may include, for example, summarization, rephrasing, analysis, and the like, as well as executable code for dynamically presenting content of the response to the user and/or functionally adapting a user platform according to the response.",WHOOP INC,CANTU VIVIANO;;CIPOLLO NICHOLAS;;COON JUSTIN;;WHITE ALEXANDER;;DUCHARME RIVARD LAURENT;;WAYDO JAIME,,https://lens.org/054-577-984-830-467,Patent Application,yes,1,0,2,070-497-561-697-764;;054-577-984-830-467,WO,3,070-497-561-697-764;;013-044-070-438-881;;054-577-984-830-467,US;;WO,0,G06F16/3329;;G06F16/316;;G06F16/3347;;G06F16/353;;G16H20/30;;G16H10/20,,,0,0,,,,PENDING
581,US,A1,US 2025/0028746 A1,013-044-070-438-881,1/23/2025,2025,US 202418779546 A,7/22/2024,US 202418779546 A;;US 2024/0038851 W;;US 202363515026 P;;US 202363587319 P;;US 202463624921 P,7/21/2023,INTERACTIVE PHYSIOLOGICAL MONITORING SYSTEMS,"A user question can be classified into topics and mapped to appropriate static and/or dynamic content related to the user and/or question. This data can then be collectively provided to a large language model in order to generate a suitable response, which may include, for example, summarization, rephrasing, analysis, and the like, as well as executable code for dynamically presenting content of the response to the user and/or functionally adapting a user platform according to the response.",WHOOP INC,CANTU VIVIANO;;CIPOLLO NICHOLAS JOHN;;COON JUSTIN TYLER;;WHITE ALEXANDER KEYSER;;DUCHARME RIVARD LAURENT;;WAYDO JAIME,WHOOP INC (2024-07-23),https://lens.org/013-044-070-438-881,Patent Application,yes,0,2,1,013-044-070-438-881,US,3,070-497-561-697-764;;013-044-070-438-881;;054-577-984-830-467,US;;WO,0,A61B2560/0462;;A61B2560/045;;G06F16/3329;;G06F16/3328;;G06F16/3329;;G06F16/3328;;A61B5/6831;;A61B2560/0462;;A61B2560/045,G06F16/332;;A61B5/00,,0,0,,,,PENDING
582,US,B2,US 12282565 B2,192-529-172-020-159,4/22/2025,2025,US 202418792523 A,8/1/2024,US 202418792523 A;;US 202418607141 A;;US 202318399422 A;;US 202318327040 A;;US 202318114194 A;;US 202318098895 A,1/19/2023,Generative cybersecurity exploit synthesis and mitigation,"Described herein are systems and methods for identifying security vulnerabilities. The systems and methods herein can utilize security vulnerability information to identify potential security threats and can utilize this information to generate an attack using a machine learning model, such as a large language model. Generated attacks can be carried out to assess impact of a security vulnerability. An output can be provided that represents the assessed impact. In some implementations, the systems and methods herein generate patches or other mitigations for security vulnerabilities, which can be tested and deployed to address security vulnerabilities.",CITIBANK NA,CAMERON WILLIAM FRANKLIN;;GOYAL PRAMOD;;RAO PRITHVI NARAYANA;;RAJARETNAM MANJIT;;SILVER MIRIAM,CITIBANK N.A (2024-10-28),https://lens.org/192-529-172-020-159,Granted Patent,yes,102,0,2,192-529-172-020-159;;081-164-654-051-886,US,36,166-860-055-274-237;;192-529-172-020-159;;117-165-481-521-817;;062-084-390-952-648;;009-332-012-767-769;;130-711-467-813-772;;150-084-174-776-205;;134-859-487-724-028;;136-076-696-451-742;;174-498-778-674-614;;135-411-020-650-37X;;082-042-370-293-809;;081-164-654-051-886;;126-999-415-386-749;;101-393-155-626-043;;028-517-317-595-400;;183-393-311-078-435;;120-491-497-842-713;;071-444-314-653-665;;151-710-271-944-022;;169-310-367-816-659;;114-332-483-825-36X;;176-222-606-932-299;;109-693-731-347-460;;187-959-165-043-749;;165-235-788-605-427;;184-797-936-150-334;;129-627-428-962-735;;132-864-126-338-301;;147-316-129-152-657;;087-574-341-939-358;;052-233-397-211-176;;154-552-332-382-958;;158-104-528-887-831;;122-629-432-281-208;;053-045-267-490-224,US;;WO;;EP,0,G06F21/552;;G06F21/577;;G06F21/577;;G06F21/552,G06F21/57;;G06F21/55,,5,2,023-805-754-895-182;;057-188-654-598-132,10.1145/3196884;;10.1109/milcom52596.2021.9653139,"International Search Report and Written Opinion Received received in Application No. PCT/US23/85942, dated Feb. 15, 2024, 6 pages.;;Cranium, Adopt & Accelerate AI Safely, retrieved on Nov. 7, 2024, from https://cranium.ai/.;;Farris, K., A., et al., “VULCON: A System for Vulnerability Prioritization, Mitigation, and Management,” ACM Transactions on Privacy and Security, vol. 21, No. 4, Article 16. Publication date: Jun. 2018, 28 pages.;;Coalition for Content Provenance and Authenticity, Contents Credentials C2PA Technological Specification, v2.1,Sep. 20, 2024. (Year: 2024).;;Stokes, et al. “Preventing Machine Learning Poisoning Attacks Using Authentication and Provenance”, MILCOM 2021-2021 IEEE Military Communications Conference (MILCOM), 2021, pp. 181-188. (Year: 2021).",ACTIVE
583,US,A1,US 2025/0094688 A1,193-696-850-238-865,3/20/2025,2025,US 202418780384 A,7/22/2024,IN 202341062232 A,9/15/2023,SUMMARY GENERATION SYSTEM,"A summary generation system is disclosed that is configured to generate a summary for content to be summarized by identifying relevant chunks of information from the content to be summarized using a large language model (LLM) and a set of questions. The set of questions enable the system to identify and retrieve relevant chunks of information. Each question undergoes a translation or transformation process to generate multiple question variants for each question. The multiple question variants are used by the system to optimize the search to obtain relevant chunks of information. Then, using the multiple question variants and an LLM, the system extracts information (i.e., answers) from the relevant chunks of information. The summary generation system then collates the answers to create an accurate and comprehensive summary for the content to be summarized.",ORACLE INT CORP,AGGARWAL ANKIT KUMAR;;XING JIE;;KAHN HAAD,ORACLE INTERNATIONAL CORPORATION (2024-07-03),https://lens.org/193-696-850-238-865,Patent Application,yes,0,0,1,193-696-850-238-865,US,1,193-696-850-238-865,US,0,G06F40/289;;G06F40/166;;G16H50/70;;G06F40/30;;G06F40/166;;G16H50/70;;G06F40/289,G06F40/166;;G06F40/289;;G16H50/70,,0,0,,,,PENDING
584,US,A1,US 2024/0220735 A1,127-364-159-537-76X,7/4/2024,2024,US 202318232144 A,8/9/2023,US 202318232144 A;;US 202318123861 A;;US 202263436416 P,12/30/2022,GENERATIVE SUMMARIES FOR SEARCH RESULTS,"At least selectively utilizing a large language model (LLM) in generating a natural language (NL) based summary to be rendered in response to a query. In some implementations, in generating the NL based summary additional content is processed using the LLM. The additional content is in addition to query content of the query itself and, in generating the NL based summary, can be processed using the LLM and along with the query content—or even independent of the query content. Processing the additional content can, for example, mitigate occurrences of the NL based summary including inaccuracies and/or can mitigate occurrences of the NL based summary being over-specified and/or under-specified.",GOOGLE LLC,GRAY MATTHEW K;;BLITZER JOHN;;HERRICK CORINN;;VENKATACHARY SRINIVASAN;;MADHAVAN JAYANT;;OATES SAM;;PARAKH PHIROZE;;SHAH ADITYA;;ROFOUEI MAHSAN;;BADR IBRAHIM,GOOGLE LLC (2023-03-10),https://lens.org/127-364-159-537-76X,Patent Application,yes,3,6,5,155-624-241-440-32X;;088-412-588-671-386;;051-418-787-798-034;;127-364-159-537-76X;;146-835-607-835-558,US,7,180-662-477-753-801;;127-364-159-537-76X;;155-624-241-440-32X;;088-412-588-671-386;;051-418-787-798-034;;097-989-857-353-566;;146-835-607-835-558,US;;WO,0,G06F16/345;;G06F40/56;;G06F16/3344;;G06N20/00;;G06N3/0455;;G06N3/0475;;G06F16/3328;;G06F40/40,G06F40/40;;G06F16/332,,0,0,,,,ACTIVE
585,US,A1,US 2025/0005303 A1,097-989-857-353-566,1/2/2025,2025,US 202418829990 A,9/10/2024,US 202418829990 A;;US 202318232144 A;;US 202318123861 A;;US 202263436416 P,12/30/2022,GENERATIVE SUMMARIES FOR SEARCH RESULTS,"At least selectively utilizing a large language model (LLM) in generating a natural language (NL) based summary to be rendered in response to a query. In some implementations, in generating the NL based summary additional content is processed using the LLM. The additional content is in addition to query content of the query itself and, in generating the NL based summary, can be processed using the LLM and along with the query content—or even independent of the query content. Processing the additional content can, for example, mitigate occurrences of the NL based summary including inaccuracies and/or can mitigate occurrences of the NL based summary being over-specified and/or under-specified.",GOOGLE LLC,GRAY MATTHEW K;;BLITZER JOHN;;HERRICK CORINN;;VENKATACHARY SRINIVASAN;;MADHAVAN JAYANT;;OATES SAM;;PARAKH PHIROZE;;SHAH ADITYA;;ROFOUEI MAHSAN;;BADR IBRAHIM,GOOGLE LLC (2023-03-10),https://lens.org/097-989-857-353-566,Patent Application,yes,0,3,1,097-989-857-353-566,US,7,180-662-477-753-801;;127-364-159-537-76X;;155-624-241-440-32X;;088-412-588-671-386;;051-418-787-798-034;;097-989-857-353-566;;146-835-607-835-558,US;;WO,0,G06F40/40;;G06F16/3328;;G06F16/3328;;G06F40/40,G06F40/40;;G06F16/332,,0,0,,,,PENDING
586,WO,A1,WO 2024/192509 A1,019-182-862-709-815,9/26/2024,2024,CA 2024050321 W,3/15/2024,US 202363453060 P,3/17/2023,SYSTEM AND METHOD FOR GENERATION OF SIMULATED COMPUTER VISION TRAINING DATA USING A VIRTUAL REALITY ENGINE,"A computer-implemented method is provided herein for generation of at least one synthetic image for use as training data to train a machine learning model to identify or detect at least one dynamic object in the at least one synthetic image. In one embodiment, the method comprises: receiving a model for the dynamic object and an animation asset specifying a motion of the dynamic object in an animation sequence; attaching one or more static meshes to the dynamic object, the one or more static meshes moving with the dynamic object during the animation sequence; playing the animation sequence for the dynamic object, including the attached one or more static meshes, to generate one or more images; processing the generated one or more images; and generating one of the synthetic images based on the processed images. Other embodiments include using diffusion models to generate variant synthetic training images.",ONE CUP PRODUCTIONS LTD;;MALHOTRA ANMOL,MALHOTRA ANMOL;;SHMIGELSKY JEFFREY;;CHAN HON WING ERIC;;AMALANATHAN JESWIN PRINCE JAMES;;ZHOU JIATANG,,https://lens.org/019-182-862-709-815,Patent Application,yes,2,0,1,019-182-862-709-815,WO,1,019-182-862-709-815,WO,0,G06T13/40;;G06N20/00;;G06V10/774;;G06T17/00;;G06V10/82;;G06V10/764;;G06V10/776;;G06T11/001;;G06N3/045;;G06N3/047;;G06N3/08;;G06N3/088;;G06N3/084,G06V10/774;;G06N20/00;;G06T7/10;;G06T13/40,,1,0,,,"NICHOL ALEX, DHARIWAL PRAFULLA, RAMESH ADITYA, SHYAM PRANAV, MISHKIN PAMELA, MCGREW BOB, SUTSKEVER ILYA, CHEN MARK: ""GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models"", INTERNATIONAL CONFERENCE ON MACHINE LEAMING, 8 March 2022 (2022-03-08), XP093215956",PENDING
587,WO,A1,WO 2025/094082 A1,096-330-088-618-248,5/8/2025,2025,IB 2024060715 W,10/30/2024,US 202363594341 P,10/30/2023,DOCUMENT GENERATION SYSTEM,"User-input unstructured text data describing one or more entities is received, at least one of which is associated with the figure. The unstructured text data is processed to generate corresponding structured text data, and the structured text data is processed to generate a set of parts. A subset of the set of parts identifying parts that are present in the figure is determined and prompt data is formulated for a neural network large language model to generate description text corresponding to the figure. The formulating of the prompt data includes deriving description data associated with the figure from the user-input unstructured text data, deriving part data corresponding to the subset of the set of parts for the figure. The prompt data is sent to the large language model, and in return description text data is received for the figure from the large language model.",PATENTLY LTD;;SPAARGAREN JEROME,SPAARGAREN JEROME;;HOLYE BENJAMIN JAMES,,https://lens.org/096-330-088-618-248,Patent Application,yes,5,0,2,142-313-021-399-150;;096-330-088-618-248,US;;WO,2,142-313-021-399-150;;096-330-088-618-248,US;;WO,0,G06F16/2455;;G06F40/284;;G06F16/242;;G06F40/56;;G06F40/30;;G06F16/2455;;G06F40/284;;G06F16/242,G06F40/169;;G06F40/106;;G06F40/284;;G06F40/289;;G10L15/26,,0,0,,,,PENDING
588,US,A1,US 2025/0086234 A1,090-178-412-353-236,3/13/2025,2025,US 202318465042 A,9/11/2023,US 202318465042 A,9/11/2023,Surgical System Leveraging Large Language Models,"A natural language request is received for surgical event information associated with one or more network-connected medical devices. Based on the natural language request, a generative artificial intelligence model is prompted to generate a database query. This database query is used to query a graph database which returns, data responsive to the database query. Such responsive information can be conveyed to a user initiating the request in a user interface (e.g., GUI, audio, etc.). In some variations, the results from the graph database are used to poll one or more other models to obtain further contextual information or to provide curation of the results in a more user-friendly and intuitive manner.",ORBSURGICAL LTD,RIVA-CAMBRIN HOMER A;;LAMA SANJU;;SINGH RAHUL;;SUTHERLAND GARNETTE R,ORBSURGICAL LTD (2023-09-08),https://lens.org/090-178-412-353-236,Patent Application,yes,4,2,1,090-178-412-353-236,US,1,090-178-412-353-236,US,0,A61B18/12;;G06F16/9024;;G06F16/9038;;G06F16/90335;;G06F16/90332;;A61B34/30;;G10L2015/223;;G10L15/1822;;G10L25/54;;G06F16/90332;;G06F16/9024;;G06F16/90335;;G06F16/9038;;A61B34/30;;G10L15/22;;G10L15/30;;A61B18/12;;G10L15/183,G06F16/9032;;G06F16/901;;G06F16/903;;G06F16/9038;;G10L15/183;;G10L15/22;;G10L15/30,,0,0,,,,PENDING
589,US,A1,US 2025/0028904 A1,054-580-487-596-531,1/23/2025,2025,US 202318353705 A,7/17/2023,US 202318353705 A,7/17/2023,MASKED LANGUAGE MODEL AS A DEFENSE AGAINST TEXTUAL ADVERSARIAL ATTACKS,"One example method includes receiving a text string that includes multiple words, tokenizing the text string to create a tokenized text string, substituting each token in the tokenized text string with a mask token to create a masked text string, performing an inference process on the masked text string to obtain a respective probability for each token, determining a respective suspicion level for each probability, modulating the suspicion levels to obtain a respective weighted suspicion score for each token, and comparing each of the weighted suspicion scores with a threshold to determine whether any one or more of the words indicate that the text string includes an attack prompt.",DELL PRODUCTS LP,PALATNIK DE SOUSA IAM;;BRAGA ENES KAREN;;MARTINS KAREN STÉFANY;;NASCIMENTO DA SILVA PABLO,DELL PRODUCTS L.P (2023-07-13),https://lens.org/054-580-487-596-531,Patent Application,yes,3,0,1,054-580-487-596-531,US,1,054-580-487-596-531,US,0,G06F40/284;;G06F40/30;;G06F40/30;;G06F40/284,G06F40/284;;G06F40/30,,1,1,075-568-835-855-174,10.1145/3579856.3590339,"Zhang, X., Zhang, Z., Zhong, Q., Zheng, X., Zhang, Y., Hu, S., & Zhang, L. Y. (2023, July). Masked Language Model Based Textual Adversarial Example Detection. In Proceedings of the 2023 ACM Asia Conference on Computer and Communications Security (pp. 925-937).",PENDING
590,EP,A1,EP 4550171 A1,032-142-979-702-574,5/7/2025,2025,EP 24208791 A,10/24/2024,IT 202300022941 A,10/31/2023,METHOD AND SYSTEM FOR ACCESS TO AND FRUITION OF DIGITAL CONTENTS BASED ON INTEGRATION OF EXTENDED REALITY AND ARTIFICIAL INTELLIGENCE,"There is described a method, carried out by electronic processing, for access to and fruition of digital contents comprising extended reality, XR, contents.The method firstly involves providing at least one 3D three-dimensional database of three-dimensional digital data representative of the aforesaid extended reality, XR, contents. Such a 3D three-dimensional database comprises 3D database elements associated with the representation of extended reality, XR. Such elements belong to at least one of the following types: ""environment"", ""object"", ""interactive point"", ""animation"".The method then comprises the step of providing a user interface, accessible through electronic processing means; such a user interface is adapted to receive user indications from a user regarding extended reality contents that the user wishes to use and/or user indications regarding modes of fruition of extended reality contents.The method further comprises the step of generating a database of textual documentation based on at least part of the aforesaid user indications.The method then includes, by means of a trained artificial intelligence, Al, model, identifying the aforesaid 3D database elements and semantically correlating them to information generated by the aforesaid textual documentation database; and carrying out, on the basis of the aforesaid semantic correlation, by the aforesaid artificial intelligence, Al, model, one or more of the following steps:- activating actions for fruition of extended reality corresponding to the aforesaid user indications regarding extended reality contents, and/or- providing the user with extended reality contents through modes and/or expressive registers corresponding to the aforesaid user indications regarding modes of fruition.There is also described a corresponding electronic processing system for access to and fruition of digital contents comprising extended reality, XR, contents.",CARRARO LAB S R L,CARRARO GUALTIERO;;CARRARO ROBERTO,,https://lens.org/032-142-979-702-574,Patent Application,yes,0,0,1,032-142-979-702-574,EP,1,032-142-979-702-574,EP,0,G06T19/006;;G06F16/444,G06F16/44;;G06T13/00;;G06T19/00,,4,4,025-621-519-955-620;;178-006-716-951-462;;020-617-509-184-101;;073-408-645-076-908,10.1109/vsmm.2014.7136656;;10.3389/frvir.2022.798032;;10.1007/s11042-022-13362-5;;pmc9206100;;35755621;;10.1109/aici.2009.482,"WALCZAK KRZYSZTOF ET AL: ""Building Contextual Augmented Reality Environments with semantics"", 2014 INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS & MULTIMEDIA (VSMM), IEEE, 9 December 2014 (2014-12-09), pages 353 - 361, XP032790269, DOI: 10.1109/VSMM.2014.7136656;;ANDREAS DENGEL: ""A Review on Augmented Reality Authoring Toolkits for Education"", FRONTIERS IN VIRTUAL REALITY, vol. 3, 27 April 2022 (2022-04-27), pages 1 - 15, XP093160130, ISSN: 2673-4192, DOI: 10.3389/frvir.2022.798032;;ROBIN HORST: ""Virtual reality content creation based on self-contained components in the e-learning domain: Re-using pattern-based vr content in different authoring toolkits"", vol. 83, no. 15, 18 June 2022 (2022-06-18), Bo, pages 46557 - 46594, XP093160256, ISSN: 1573-7721, Retrieved from the Internet <URL:https://link.springer.com/article/10.1007/s11042-022-13362-5/fulltext.html> DOI: 10.1007/s11042-022-13362-5;;BOYONG GAO ET AL: ""An Overview of Semantics Processing in Content-Based 3D Model Retrieval"", ARTIFICIAL INTELLIGENCE AND COMPUTATIONAL INTELLIGENCE, 2009. AICI '09. INTERNATIONAL CONFERENCE ON, IEEE, PISCATAWAY, NJ, USA, 7 November 2009 (2009-11-07), pages 54 - 59, XP031598152, ISBN: 978-1-4244-3835-8",PENDING
591,US,A1,US 2024/0028949 A1,081-267-355-530-74X,1/25/2024,2024,US 202217869528 A,7/20/2022,US 202217869528 A,7/20/2022,REWARD FEEDBACK FOR LEARNING CONTROL POLICIES USING NATURAL LANGUAGE AND VISION DATA,"Example implementations described herein involve systems and methods for providing a reward to a machine learning algorithm, which can include receiving an image, and a task description defined in text; slicing the image into a plurality of sub-images; executing an embedding model to embed the text of the task description and the sub-images to generate a distribution for the sub-images based on relevance to the task description; and generating the reward from the distribution for the sub-images.",HITACHI LTD,WALKER ANDREW JAMES;;ACHARYA JOYDEEP,HITACHI LTD (2022-07-21),https://lens.org/081-267-355-530-74X,Patent Application,yes,5,0,3,196-973-442-617-411;;081-267-355-530-74X;;033-208-951-232-254,US;;JP,3,196-973-442-617-411;;033-208-951-232-254;;081-267-355-530-74X,US;;JP,0,G06N3/008;;G06N20/00;;G06N3/092,G06N20/00,,0,0,,,,PENDING
592,US,B2,US 12282502 B2,189-506-195-933-268,4/22/2025,2025,US 202217659138 A,4/13/2022,US 202217659138 A,4/13/2022,Generating synthesized user data,"Disclosed are examples of systems, apparatuses, methods, and computer program products for generating synthesized user data. A method may involve receiving a data specification schema. A method may involve determining a number of test data objects to be generated. A method may involve defining the test data objects, the defining of each test data object including: determining, from the data specification schema, a number of fields of the test data object to be populated, the fields representing categories of simulated user data; and determining values for the fields, the values simulating user data. The method may involve storing the test data objects in a database. The method may involve generating a tabular data file including or identifying the test data objects, the tabular data file configured to be processed by one or more processors of a computing system during a user data testing procedure of the computing system.",SAUCE LABS INC,WHITEHEAD JR EMMET JAMES;;REED LENA;;KANO AFSHIN MOBRAMAEIN,SAUCE LABS INC (2022-03-30),https://lens.org/189-506-195-933-268,Granted Patent,yes,29,1,3,089-590-819-043-722;;065-916-624-253-136;;189-506-195-933-268,US,3,089-590-819-043-722;;065-916-624-253-136;;189-506-195-933-268,US,0,G06F16/3329;;G06N20/00;;G06F16/3329;;G06N20/00;;G06F40/20;;G06F16/338;;G06F16/252;;G06F16/22;;G06N3/006;;G06F16/285;;G06F16/2477;;G06F16/367;;G06F16/2228;;G06N7/01;;G06F16/316,G06F16/00;;G06F16/22;;G06F16/2458;;G06F16/25;;G06F16/28;;G06F16/31;;G06F16/3329;;G06F16/338;;G06F16/36;;G06F40/20;;G06N3/006;;G06N7/01;;G06N20/00,,14,5,148-819-237-107-061;;105-899-998-168-187;;008-619-667-741-828;;123-372-306-763-631;;112-523-003-721-844,10.14257/ijseia.2014.8.1.18;;10.5220/0005500602770284;;10.1109/iccs54944.2021.00010;;10.1109/hcc.2001.995260;;10.1016/0898-1221(92)90026-e,"Iyad Alazzam et al., “Test Cases Selection Based on Source Code Features Extraction”, International Journal of Software Engineering and Its Applications, vol. 8, No. 1 (2014), pp. 203-214.;;Dessislava Petrova-Antonova et al.,Automatic generation of test data for XML schema-based testing of web services , 2015 10th International Joint Conference on Software Technologies (ICSOFT), 2015, pp. 1-8.;;Chennamsetty Madhusudhana Rao et al., “A Comparative Study of NLP based Semantic Web Standard model using SPARQL database”, 2021 International Conference on Computing Sciences (ICCS) (pp. 1-6).;;J. Leopold et al., “A visual query system for the specification and scientific analysis of continual queries”, Proceedings IEEE Symposia on Human-Centric Computing Languages and Environments (Cat. No.01TH8587) (2001, pp. 203-211).;;Eliza Kuttner et al., “Processing natural language with schema constraint networks”, Computers & Mathematics with Applications, vol. 24, Issue 11, Dec. 1992, pp. 3-10.;;“Announcing AI21 Studio and Jurassic-1 Language Models,” AI21 labs, 5 pages, URL: https://www.ai21.com/blog/announcing-ai21-studio-and-jurassic-1.;;Cellat S., “Fine-Tuning Transformer-Based Language Models,” Y Meadows, 2021, 8 pages.;;Garbade M. J., “Understanding few-shot learning in machine learning,” Medium, 2018, 5 pages.;;“GPT-Neo,” EleutherAI, 2 pages, URL: https://www.eleuther.ai/projects/gpt-neo/.;;Kulshrestha R., “Transformers,” Transformers in NLP: A beginner friendly explanation, Towards Data Science, 2020, 14 pages.;;Lieber, et al., “Jurassic-1: Technical Details and Evaluation,” White Paper, 9 pages.;;Osborne S., “Learning NLP Languages Models with Real Data,” Towards Data Science, 2019, 24 pages, URL: https://towardsdatascience.com/learning-nlp-language-models-with-real-data-cdff04c51c25.;;“Prompt Engineering Tips and Tricks with GPT-3,” andrew makes things, Apr. 21, 2021, 6 pages.;;“Zero-Shot Learning in Modern NLP,” State-of-the-art NLP models for text classification without annotated data, Joe Davison Blog, May 29, 2020, 14 pages.",ACTIVE
593,US,A1,US 2024/0370479 A1,120-932-291-917-151,11/7/2024,2024,US 202318204419 A,6/1/2023,US 202318204419 A;;US 202363463647 P,5/3/2023,SEMANTIC SEARCH AND SUMMARIZATION FOR ELECTRONIC DOCUMENTS,Techniques for an artificial intelligence (AI) platform to search a document collection are described. Embodiments may use AI and machine learning techniques within a framework of an electronic document management system to perform semantic searching of an electronic document or a collection of electronic documents for certain types of information. The AI platform may summarize the information in a natural language representation of a human language. Other embodiments are described and claimed.,DOCUSIGN INC,HUDETZ CASEY;;WELLS KEENAN;;HE YAN;;ZAKHVATOV ALEXEY;;LAM YAN PUI;;SRIVASTAVA SOUMYA;;GREBELSKI MARIO M;;HASAN SOULEIMAN;;SHARMA ABHINAV U;;ALBERT NAVIN,,https://lens.org/120-932-291-917-151,Patent Application,yes,7,5,1,120-932-291-917-151,US,3,105-637-329-268-21X;;120-932-291-917-151;;192-538-743-066-367,US;;WO,0,G06V30/416;;G06F40/30;;G06F16/316;;G06F16/3347;;G06F16/3347;;G06V30/416;;G06F40/30;;G06F16/316,G06F16/33;;G06F16/31;;G06F40/30;;G06V30/416,,0,0,,,,PENDING
594,US,A1,US 2025/0094734 A1,134-031-581-433-542,3/20/2025,2025,US 202418885501 A,9/13/2024,US 202418885501 A;;US 202363583159 P;;US 202363583162 P;;US 202363583164 P,9/15/2023,LARGE LANGUAGE MODEL HANDLING OUT-OF-SCOPE AND OUT-OF-DOMAIN DETECTION FOR DIGITAL ASSISTANT,"Techniques for using a LLM to detect OOS and OOD utterances. In one aspect, a method includes routing an utterance to a skill bot. The skill bot is configured to execute an action for completing a task associated with the utterance, and a workflow associated with the action includes a GenAI component state configured to facilitate completion of at least part of the task. The method further includes inputting a prompt into a GenAI model for processing. The prompt includes the utterance and scope-related elements that teach the GenAI model to output an invalid input variable when the utterance is OOS or OOD. When the GenAI model determines the utterance is OOS or OOD as part of the processing, the response is generated to include the invalid input variable, and the GenAI component state is caused to transition to a different state or workflow based on the response.",ORACLE INT CORP,SRIDHARAN VANSHIKA;;ZHANG XINWEI;;DAVELAAR STEVEN MARTIJN;;BHATT NEERJA;;XU XIN,ORACLE INTERNATIONAL CORPORATION (2024-10-03),https://lens.org/134-031-581-433-542,Patent Application,yes,0,0,1,134-031-581-433-542,US,2,134-031-581-433-542;;038-820-171-081-558,US,0,G06N3/0475;;G06F40/40;;G06F9/453;;G06F40/30;;G06F40/40;;G06N3/0475;;G06F9/453,G06F40/40;;G06F9/451;;G06N3/0475,,0,0,,,,PENDING
595,WO,A1,WO 2025/059502 A1,051-207-728-313-113,3/20/2025,2025,US 2024/0046672 W,9/13/2024,US 202363582506 P;;US 202318507010 A;;US 202318507011 A,9/13/2023,CONFIGURING AND MANAGING RADIO-BASED NETWORKS VIA AN ARTIFICIAL INTELLIGENCE ASSISTANT,"Disclosed are various embodiments for an artificial intelligence (AI) assistant to configure and manage radio-based networks such as cellular networks. In one embodiment, an AI language model is taught to recognize a deployment configuration grammar for deploying radio-based networks. A prompt is received from a customer to generate at least a portion of a deployment configuration for a network function in a radio-based network. The deployment configuration, or portion thereof, is generated by the AI language model according to an intent expressed in the prompt.",AMAZON TECH INC,GRIDA BEN YAHYA IMEN;;SAWHNEY SALIL;;KHAWAJA KHURRAM AJAZ;;NA ZHENYE,,https://lens.org/051-207-728-313-113,Patent Application,yes,5,0,1,051-207-728-313-113,WO,3,051-207-728-313-113;;021-762-318-010-253;;036-253-562-359-333,US;;WO,0,H04L41/0803;;H04L41/16;;H04L41/22;;H04W24/02,H04L41/0803;;H04L41/16;;H04L41/22;;H04W24/02,,0,0,,,,PENDING
596,US,A1,US 2025/0088946 A1,021-762-318-010-253,3/13/2025,2025,US 202318507011 A,11/10/2023,US 202318507011 A;;US 202363582506 P,9/13/2023,USING ARTIFICIAL INTELLIGENCE TO PROVIDE OBSERVABILITY INTO RADIO-BASED NETWORKS,"Disclosed are various embodiments for using artificial intelligence (AI) to provide observability to radio-based networks such as cellular networks. In one embodiment, an AI language model is taught to recognize status information for radio-based networks. A prompt is received from a customer to provide a type of status information for at least a portion of the radio-based network. The status information is obtained. A response to the prompt is generated by the AI language model that includes or summarizes the type of status information using the obtained status information according to an intent expressed in the prompt.",AMAZON TECH INC,GRIDA BEN YAHYA IMEN;;SAWHNEY SALIL;;KHAWAJA KHURRAM AJAZ;;NA ZHENYE,AMAZON TECHNOLOGIES INC (2023-11-09),https://lens.org/021-762-318-010-253,Patent Application,yes,0,0,2,021-762-318-010-253;;036-253-562-359-333,US,3,051-207-728-313-113;;021-762-318-010-253;;036-253-562-359-333,US;;WO,0,G06F16/9032;;H04W16/20;;H04L41/16;;H04W48/16;;H04W24/02;;G06F16/9032;;H04W48/16;;H04L41/16;;H04W16/20,H04W48/16;;G06F16/9032,,0,0,,,,PENDING
597,US,A1,US 2025/0054322 A1,098-762-587-483-052,2/13/2025,2025,US 202418787616 A,7/29/2024,US 202418787616 A;;US 202363518407 P,8/9/2023,Attribute Recognition with Image-Conditioned Prefix Language Modeling,Systems and methods for attribute recognition can include obtaining an image and a text string. The text string can be processed with a language model to generate a set of candidate attributes based on sequence based prediction. The image and the candidate attributes can be processed with an image-text model to determine a likelihood that the respective candidate attribute is depicted in the image. The likelihood determination can then be utilized to determine a predicted attribute for the object of interest.,GOOGLE LLC,YE KEREN;;ZHU YICHENG;;KE JUNJIE;;YU JIAHUI;;GUIBAS LEONIDAS JOHN;;MILANFAR PEYMAN;;YANG FENG,GOOGLE LLC (2023-08-07),https://lens.org/098-762-587-483-052,Patent Application,yes,0,1,1,098-762-587-483-052,US,1,098-762-587-483-052,US,0,G06F40/279;;G06V20/70;;G06F40/279;;G06V20/70,G06V20/70;;G06F40/279,,0,0,,,,PENDING
598,US,A1,US 2025/0157289 A1,165-835-636-067-841,5/15/2025,2025,US 202418907925 A,10/7/2024,US 202418907925 A;;US 202418794858 A;;US 202363597851 P,11/10/2023,PREDICTIVE GAMING INSIGHT PLATFORM,"A system and method(s) for aggregating gaming data generated by casino devices connected to a casino network. The system accesses a machine learning model trained through exploratory data analysis of the aggregated gaming data, mapping input features to model parameters used for predicting a target output value. The system further predicts, using the machine learning model, user-specific output value that identifies a player behavior by analyzing a portion of the aggregated gaming data associated with a specific user account logged into one of the casino devices. Based on the identified player behavior, the system automatically adjusts a configuration of the casino devices to optimize its operation for the specific user account.",LNW GAMING INC,WOLFE JON CHRISTIAN;;NALL WESLEY;;VENKATARAMAN MURALI;;SHIN JONG-WOOK,LNW GAMING INC (2024-10-07),https://lens.org/165-835-636-067-841,Patent Application,yes,0,1,2,121-132-275-891-255;;165-835-636-067-841,US;;AU,3,121-132-275-891-255;;007-982-852-093-033;;165-835-636-067-841,US;;AU,0,G07F17/3239;;G07F17/3239,G07F17/32,,0,0,,,,PENDING
599,US,B1,US 12039263 B1,065-327-474-419-632,7/16/2024,2024,US 202318493715 A,10/24/2023,US 202318493715 A,10/24/2023,Systems and methods for orchestration of parallel generative artificial intelligence pipelines,"The systems and methods described herein relate to improvements to generative artificial intelligence systems through the use of generative artificial intelligence pipelines to supply external information to pre-trained large language models for use in answering queries. To improve the efficiency and accuracy of large language models in responding to user queries, according to various aspects described herein, such queries may be modified and augmented with additional relevant information and may be divided into multiple queries for parallel handling, the results of which may then be combined into a response. The additional relevant information may include portions of documents or other data sets to be used in generating the response. Additional aspects may further improve resilience and flexibility by managing the generation or implementation of such modified and augmented queries.",MCKINSEY & COMPANY INC,MONDLOCK PETER;;ALEIXO CATARINA;;LOBUNETS OLEKSANDR,MCKINSEY & COMPANY INC (2023-10-31),https://lens.org/065-327-474-419-632,Granted Patent,yes,10,5,1,065-327-474-419-632,US,1,065-327-474-419-632,US,0,G06F40/30;;G06F40/20;;G06F40/30;;G06F40/20,G06F40/20;;G06F40/30,,4,0,,,"Microsoft, Learn, “What is Semantic Kernel?” Web page downloaded at <https://learn.microsoft.com/en-us/semantic-kernel/overview/>. Retrieved from the Internet on Dec. 15, 2023.;;Llamaindex, “Welcome to LlamaIndex” Web page downloaded at <https://docs.llamaindex.ai/en/stable/#why-llamaindex>. Retrieved from the Internet on Dec. 15, 2023.;;Python, Langchain, “Introduction” Web Page downloaded at <https://python.langchain.com/docs/get_started/introduction>. Retrieved from the Internet on Dec. 15, 2023.;;Microsoft Learn, “Build language model pipelines with memory.” https://learn.microsoft.com/en-us/azure/architecture/ai-ml/openai/guide/language-model-pipelines>. Retrieved from the Internet on Sep. 15, 2023.",ACTIVE
600,WO,A1,WO 2025/117001 A1,185-975-719-878-594,6/5/2025,2025,US 2024/0044626 W,8/30/2024,US 202363604217 P,11/30/2023,DRILLING PERFORMANCE ASSISTED WITH AN ARTIFICIAL INTELLIGENCE ENGINE,"A method for extracting data from a database for use in a well construction process includes receiving a question from a user. The question is in a well construction language. The method also includes determining context based upon the question. Determining the context includes retrieving key performance indicators (KPIs) based upon the question, and retrieving a plurality of tables from the database. The tables are retrieved based upon the question. The method also includes generating a prompt based upon the question and the context. The method also includes generating a structured query language (SQL) query based upon the prompt using a large language model (LLM). The method also includes running the SQL query against the tables in the database in an attempt to produce a new table. The method also includes performing a wellsite action in response to the new table.",SCHLUMBERGER TECHNOLOGY CORP;;SCHLUMBERGER CA LTD;;SERVICES PETROLIERS SCHLUMBERGER;;GEOQUEST SYSTEMS BV,AMOUR MYRIAM;;SORIANO REMENTERIA AGUSTIN;;GUILLOT VALERIAN;;RACHMAT BENEDICTUS KENT,,https://lens.org/185-975-719-878-594,Patent Application,yes,1,0,2,010-162-702-989-947;;185-975-719-878-594,US;;WO,2,010-162-702-989-947;;185-975-719-878-594,US;;WO,0,G06F16/243;;G06F16/2458;;G06F16/2455;;G06F16/211,G06F16/242,,2,0,,,"ANONYMOUS: ""How do i create a custom model for text to sql queries?"", 25 November 2023 (2023-11-25), XP093225304, Retrieved from the Internet <URL:https://web.archive.org/web/20231125003812/https://community.openai.com/t/how-do-i-create-a-custom-model-for-text-to-sql-queries/205539> [retrieved on 20241118];;ANONYMOUS: ""Ria GPT natural language interface to Postgres"", 23 November 2023 (2023-11-23), XP093225307, Retrieved from the Internet <URL:https://web.archive.org/web/20231123085502/https://github.com/drorm/ria> [retrieved on 20241118]",PENDING
601,US,A1,US 2025/0225430 A1,027-391-685-458-293,7/10/2025,2025,US 202418406739 A,1/8/2024,US 202418406739 A,1/8/2024,AI-BASED VISUAL STYLE TRANSFER,"A data processing system implements receiving a first prompt including a style visual content item and a topic content item and requesting generating an output visual content item; constructing a second prompt as an input to a first generative model, by appending the style visual content item and the topic content item to a first instruction string that comprises instructions to the first generative model to generate a textual description combining a topic in the topic content item with a style in the style visual content item as a third prompt; inputting the third prompt into a second generative model to generate the output visual content item by including the topic in the output visual content item and replacing visual element(s) of the style visual content item based on the topic while preserving the style; and providing the output visual content item to be presented on a user interface.",MICROSOFT TECHNOLOGY LICENSING LLC,CHENG MINGXI;;LI JI,,https://lens.org/027-391-685-458-293,Patent Application,yes,0,0,1,027-391-685-458-293,US,1,027-391-685-458-293,US,0,G06F9/451;;G06N20/00,G06N20/00;;G06F9/451,,0,0,,,,PENDING
602,WO,A1,WO 2025/042852 A1,104-727-923-039-199,2/27/2025,2025,US 2024/0042959 W,8/19/2024,US 202363533537 P,8/18/2023,METHODS AND APPARATUSES INVOLVING AUTOMATED WEBSITE CONTENT GENERATION AND STRUCTURE USING LARGE DATA TRAINED MODELS,"In certain examples, computer-implemented methods include assembling automatically generated content into a website structure that is optimal to a particular user and tailored to user goals and consistent with attributes of media assets of the user. The method further includes: analyzing, for the particular user (e.g., individual or entity), inputs and media assets; constructing a set of context-aware prompts, wherein each of the context-aware prompts is associated with one or more contexts discerned in response to user inputs and media assets being analyzed; and generating, via large language modeling and based on the constructed context-aware prompts, the website content inclusive of text, code, and media elements. In photography examples, such methods customize content based on responses to constructed context-aware prompts, and use a library of predefined website content (e.g., images) with configurable parameters and customized content created dynamically.",ZENFOLIO INC,BARRACLOUGH KEITH;;NELSON JEROME;;FERRIER MICHAEL,,https://lens.org/104-727-923-039-199,Patent Application,yes,3,2,1,104-727-923-039-199,WO,1,104-727-923-039-199,WO,0,G06F40/103;;G06F40/279;;G06F8/38;;G06F40/166;;G06F40/56;;G06F40/58;;G06F40/186;;G06F40/30,G06F16/957;;G06F8/33;;G06F8/38;;G06F16/958;;G06F40/103;;G06F40/166;;G06F40/279,,0,0,,,,PENDING
603,US,B1,US 12079570 B1,174-196-993-327-996,9/3/2024,2024,US 202318493697 A,10/24/2023,US 202318493697 A,10/24/2023,Systems and methods for packaging reusable generative artificial intelligence pipelines,"The systems and methods described herein relate to improvements to generative artificial intelligence systems through the use of generative artificial intelligence pipelines to supply external information to pre-trained large language models for use in answering queries. To improve the efficiency and accuracy of large language models in responding to user queries, according to various aspects described herein, such queries may be modified and augmented with additional relevant information and may be divided into multiple queries for parallel handling, the results of which may then be combined into a response. The additional relevant information may include portions of documents or other data sets to be used in generating the response. Additional aspects may further improve resilience and flexibility by managing the generation or implementation of such modified and augmented queries.",MCKINSEY & COMPANY INC,MONDLOCK PETER;;ALEIXO CATARINA;;LOBUNETS OLEKSANDR,MCKINSEY & COMPANY INC (2023-10-31),https://lens.org/174-196-993-327-996,Granted Patent,yes,17,5,1,174-196-993-327-996,US,1,174-196-993-327-996,US,0,G06F40/30;;G06F40/20;;G06F40/30;;G06F40/20,G10L15/22;;G06F40/20;;G06F40/30;;G10L15/28,,4,0,,,"Microsoft, Learn, “What is Semantic Kernel?” Web page downloaded at <https://learn.microsoft.com/en-us/semantic-kernel/overview/>. Retrieved from the Internet on Dec. 15, 2023.;;Llamaindex, “Welcome to LlamaIndex” Web page downloaded at <https://docs.llamaindex.ai/en/stable/#why-llamaindex>. Retrieved from the Internet on Dec. 15, 2023.;;Python, Langchain, “Introduction” Web page downloaded at <https://python.langchain.com/docs/get_started/introduction>. Retrieved from the Internet on Dec. 15, 2023.;;Microsoft Learn, “Build language model pipelines with memory.” https://learn.microsoft.com/en-us/azure/architecture/ai-ml/openai/guide/language-model-pipelines>. Retrieved from the Internet on Sep. 15, 2023.",ACTIVE
604,US,A1,US 2024/0086493 A1,084-693-337-883-016,3/14/2024,2024,US 202318511600 A,11/16/2023,US 202318511600 A;;KR 20220079508 A;;KR 20220079509 A;;KR 20220079510 A;;KR 20230084884 A;;KR 20230084886 A;;KR 20230084888 A;;KR 20230084889 A;;US 202318129711 A;;US 202217898109 A,6/29/2022,"METHOD FOR DIAGNOSING A DATASET TO GENERATE SYNTHETIC DATA, AND A COMPUTING DEVICE AND SYSTEM FOR PERFORMING SUCH A METHOD","According to an embodiments of the present disclosure, a computer-implemented method comprising: obtaining, by one or more processors, a first data set; identifying, by one or more processors, a first data point set by determining at least one feature of the first data set from at least one layer of a first trained model, wherein the first data point set corresponding to the first data set is associated with a first embedding space of a first dimension; obtaining, by one or more processors, a first diagnostic data corresponding to the first data set based on the first data point set by analyzing at least one property of the first data set; and generating, by one or more processors, a first set of synthetic data, wherein the generating the first set of synthetic data comprises: inputting a prompt data associated with the at least one property of the first data set into a second trained model; and obtaining the first set of synthetic data from at least one layer of the second trained model may be provided.",PEBBLOUS INC,LEE JOO HAENG;;LEE JEONG WON,PEBBLOUS INC (2022-08-24),https://lens.org/084-693-337-883-016,Patent Application,yes,0,1,1,084-693-337-883-016,US,18,140-027-127-730-403;;180-618-575-225-238;;066-030-584-201-254;;192-178-295-105-433;;056-084-065-699-725;;022-076-960-911-856;;177-827-913-307-58X;;078-407-944-533-678;;191-213-333-848-970;;147-501-834-694-149;;128-586-572-072-927;;092-480-890-598-561;;100-629-628-977-233;;053-200-261-642-474;;163-491-632-833-239;;025-278-168-324-783;;010-168-536-567-251;;084-693-337-883-016,US;;WO;;EP;;KR;;JP,0,G06F18/22;;G06F18/214;;G06N3/088;;G06N3/0475;;G06N3/0455;;G06N3/0464;;G06N3/0499;;G06F18/214;;G06F18/22;;G06F18/213;;G06N20/00,G06F18/214;;G06F18/213;;G06F18/22;;G06N20/00,,0,0,,,,PENDING
605,US,A1,US 2025/0131034 A1,164-710-942-513-234,4/24/2025,2025,US 202318491037 A,10/20/2023,US 202318491037 A,10/20/2023,SYSTEMS AND METHODS FOR GENERATING A QUERYABLE IMAGE FROM TEXT,"In some implementations, the techniques described herein relate to a method including (i) receiving, by a processor, user input describing at least one parameter for a query image, (ii) generating, via a generative machine learning model executed by the processor, the query image based at least in part on the user input describing the at least one parameter for the query image, (iii) providing, by the processor, the query image as input to an image-based search algorithm, and (iv) returning a result received by the processor from the image-based search algorithm.",YAHOO ASSETS LLC,DE JUAN PALOMA;;SOARES JOAO VITOR BALDINI,YAHOO ASSETS LLC (2023-10-19),https://lens.org/164-710-942-513-234,Patent Application,yes,4,0,1,164-710-942-513-234,US,1,164-710-942-513-234,US,0,G06T2200/24;;G06F16/532;;G06F16/538;;G06T11/00;;G06F40/40;;G06F16/532;;G06F16/538;;G06T2200/24;;G06T11/00;;G06F40/40,G06F16/532;;G06F16/538;;G06F40/40;;G06T11/00,,0,0,,,,PENDING
606,US,A1,US 2025/0173606 A1,122-831-722-317-191,5/29/2025,2025,US 202318523612 A,11/29/2023,US 202318523612 A,11/29/2023,AUTOMATED MACHINE-LEARNED LANGUAGE MODEL PROMPT RECOMMENDATIONS,An online system may receive a registration of an application for a language model gateway configured as an intermediary between users and a first machine-learned language model. The online system may monitor a conversation associated with the application using the language model gateway. The conversation is between a user of the application and the first machine-learned language model and includes a prompt from the user directed toward the first machine-learned language model. The online system may extract the prompt and compile an input for a second machine-learned language model that is fine-tuned to improve prompts. The input may be the prompt and one or more criteria to improve the prompt. The online system may provide the input to the second machine-learned language model. The online system may determine a suggested improvement to the prompt using the second machine-learned language model and provide the suggested improvement to the user.,MAPLEBEAR INC,DEARING RYAN;;JENSEN JACOB;;PARROTT MICHAEL,MAPLEBEAR INC (2023-11-30),https://lens.org/122-831-722-317-191,Patent Application,yes,0,1,1,122-831-722-317-191,US,1,122-831-722-317-191,US,0,G06N20/00;;G06F40/279;;G06F40/205;;G06N3/084;;G06N20/00;;G06F40/205;;G06F40/279,G06N20/00;;G06F40/205;;G06F40/279,,0,0,,,,PENDING
607,US,A1,US 2025/0131247 A1,186-016-162-938-838,4/24/2025,2025,US 202318493741 A,10/24/2023,US 202318493741 A,10/24/2023,Systems and Methods for Managing Decentralized Data Sources in Generative Artificial Intelligence Pipelines,"The systems and methods described herein relate to improvements to generative artificial intelligence systems through the use of generative artificial intelligence pipelines to supply external information to pre-trained large language models for use in answering queries. To improve the efficiency and accuracy of large language models in responding to user queries, according to various aspects described herein, such queries may be modified and augmented with additional relevant information from decentralized data sources. The retrieval-augmented generation pipeline may interface with one or more decentralized data sources and retrieve the external information, including unstructured text and/or structured data.",MCKINSEY & COMPANY INC,MONDLOCK PETER;;HUDELSON WILLIAM M P;;LAKNER KITTI,MCKINSEY & COMPANY INC (2023-11-09),https://lens.org/186-016-162-938-838,Patent Application,yes,0,0,1,186-016-162-938-838,US,1,186-016-162-938-838,US,0,G06N3/0475;;G06F16/2471;;G06N3/0455;;G06F16/284;;G06N5/022;;G06N3/0455;;G06F16/284;;G06F16/2471;;G06N3/0475,G06N3/0455;;G06F16/2458;;G06F16/28;;G06N3/0475,,0,0,,,,PENDING
608,US,A1,US 2025/0239066 A1,028-707-637-223-419,7/24/2025,2025,US 202519020630 A,1/14/2025,US 202519020630 A;;US 202463624632 P,1/24/2024,Hierarchical Machine-Learned Agents For Performing Mixed Sequence Processing Tasks,"A computing device can obtain a first machine-learned sequence processing model configured to use a plurality of first tools, wherein at least one first tool of the plurality of first tools is a second machine-learned sequence processing model configured to use one or more second tools. The computing device can obtain an input context. The computing device can select, using the first machine-learned sequence processing model based at least in part on the input context, a first tool of the plurality of first tools, wherein the first tool selected is the second machine-learned sequence processing model. The computing device can select, using the second machine-learned sequence processing model, at least one second tool of the one or more second tools. The computing device can generate, using the at least one second tool of the one or more second tools, a first output.",GOOGLE LLC,CASTREJON SUBIRA LLUIS ENRIC;;MENSINK THOMAS EDGAR JOSEF;;ZHOU ZHEN HAO;;FERRARI VITTORIO;;FILGUEIRAS DE ARAUJO ANDRE;;UIJLINGS JASPER REINOUT ROBERTUS,,https://lens.org/028-707-637-223-419,Patent Application,yes,0,0,1,028-707-637-223-419,US,1,028-707-637-223-419,US,0,G06F40/295;;G06V10/87,G06V10/70;;G06F40/295,,0,0,,,,PENDING
609,US,A1,US 2024/0242040 A1,062-667-185-734-072,7/18/2024,2024,US 202318541035 A,12/15/2023,US 202318541035 A;;US 202363439813 P,1/18/2023,METHOD AND SYSTEM FOR DETERMINING A MEASURE OF CONCEPTUAL CONSISTENCY IN LARGE LANGUAGE MODELS,"Embodiments of the present principles generally relate to methods, apparatuses and systems for determining a measure of conceptual consistency in large language models for understanding of relevant concepts. In some embodiments, a method for measuring conceptual consistency may include prompting an LLM in order to extract answers to background queries and anchor tasks. The method also includes comparing background knowledge facts for a given anchor task associated with known answers with facts extracted from the LLM to determine an LLM performance. The method also includes determining a background knowledge score and an anchor task score based on the LLM's performance. The method also includes determining a conceptual may include score for the LLM by predicting the anchor task score from the background knowledge score. The method also includes outputting an indication of the conceptual may include score.",STANFORD RES INST INT,COGSWELL MICHAEL;;DIVAKARAN AJAY;;GONG YUNYE;;SAHU PRITISH,SRI INTERNATIONAL (2023-12-12),https://lens.org/062-667-185-734-072,Patent Application,yes,0,3,1,062-667-185-734-072,US,1,062-667-185-734-072,US,0,G06F40/40;;G06F40/40,G06F40/40,,0,0,,,,PENDING
610,WO,A2,WO 2024/259235 A2,139-719-591-881-557,12/19/2024,2024,US 2024/0034009 W,6/14/2024,US 202363508314 P,6/15/2023,SYSTEMS AND METHODS FOR CONTINUOUS TESTING OF LARGE NATURAL LANGUAGE CONVERSATIONAL MODELS,"Described are platforms, methods, systems, and media configured for testing generative AI models, including LLMs, utilizing operations comprising: deploying plurality of bots, wherein each bot comprises a persona, and wherein at least a subset of the bots are configured to interact with the model; harvesting an output resulting from the interactions; and analyzing the output, wherein the analysis comprises screening for one or more breakdowns.",MILLION DOORS INC,TRIM CRAIG M;;KAO JOHN JIEN,,https://lens.org/139-719-591-881-557,Patent Application,yes,0,1,2,121-253-025-666-638;;139-719-591-881-557,WO,2,121-253-025-666-638;;139-719-591-881-557,WO,0,G06F11/3684;;G06F40/30,,,0,0,,,,PENDING
611,US,A1,US 2025/0118066 A1,073-943-540-447-631,4/10/2025,2025,US 202318484351 A,10/10/2023,US 202318484351 A,10/10/2023,ENHANCING ANOMALY DETECTION PIPELINE WITH A POST-HOC GENERATIVE AI MODEL TO SUPPORT HUMAN UNDERSTANDING AND POLICY AUTOMATION,"One example method includes receiving an input vector that includes time series data indicative of an anomaly, generating, based on the input vector, a visual image that corresponds to the time series data, using a first vision-language model (VLM) to transform the visual image into output text that explains the anomaly, building a prompt that comprises the visual image and the explanation text, using a second VLM to generate a recommendation based on the prompt, and resolving a cause of the anomaly by implementing the recommendation.",DELL PRODUCTS LP,HATTORI LEANDRO TAKESHI;;SOMMAGGIO COLETTA LUIZ FERNANDO;;DA CRUZ FERREIRA VICTOR;;FACCO RODRIGUES VINICIUS,DELL PRODUCTS L.P (2023-10-05),https://lens.org/073-943-540-447-631,Patent Application,yes,0,0,1,073-943-540-447-631,US,1,073-943-540-447-631,US,0,G06F40/289;;G06V10/86;;G06V10/98;;G06F40/40;;G06V10/86;;G06V10/98;;G06F40/40;;G06F40/289,G06V10/86;;G06F40/289;;G06F40/40;;G06V10/98,,0,0,,,,PENDING
612,US,A1,US 2025/0174152 A1,188-126-137-896-736,5/29/2025,2025,US 202418960700 A,11/26/2024,US 202418960700 A;;US 202363604066 P,11/29/2023,ADAPTIVE PHONICS INSTRUCTION USING PHONEME-GRAPHEME MAPPING AND DYNAMIC CONTENT GENERATION,"An individualized decodable text system and non-transitory computer-readable medium, among other materials, are disclosed for generating customized reading materials tailored to students. The system includes processors configured to prompt a user to select subsets of phonemes and corresponding graphemes. Based on these selections, the system identifies or constructs a set of words containing only the selected phonemes and graphemes, excluding unselected ones, and generates phrases or sentences for student practice. Real-time feedback on pronunciation may be provided through word and phoneme-level scoring. The system may leverage a pre-indexed phoneme-grapheme database or rule-based word construction, using dynamic filtering and efficient querying techniques for adaptability and scalability. This approach facilitates individualized instruction by aligning reading materials with each student's developmental needs to improve decoding accuracy and promote reading fluency.",ILLUMINATIONS LLC,PALMITER LETA,ILLUMINATIONS LLC (2024-11-23),https://lens.org/188-126-137-896-736,Patent Application,yes,0,0,1,188-126-137-896-736,US,1,188-126-137-896-736,US,0,G09B5/06;;G09B19/04;;G09B5/06;;G09B19/04,G09B19/04;;G09B5/06,,0,0,,,,PENDING
613,US,A1,US 2025/0190861 A1,149-492-845-587-817,6/12/2025,2025,US 202418821351 A,8/30/2024,US 202418821351 A;;US 202363608579 P;;US 202363607269 P,12/7/2023,ARTIFICIAL INTELLIGENCE ASSISTANT FOR NETWORK SERVICES AND MANAGEMENT,An artificial intelligence assistant analyzes network observations to generate regular expressions using an artificial intelligence model for network automation management pipelines that identify and resolve network issues. A method includes obtaining at least one instruction and information about a plurality of enterprise network assets and configuration of an enterprise network that includes the plurality of enterprise network assets and generating at least one regular expression using an artificial intelligence model based on context description of the at least one instruction and the information about the plurality of enterprise network assets and the configuration of the enterprise network. The method further includes generating at least one solution for configuring at least one network asset of the plurality of enterprise network assets based on the at least one regular expression and providing the at least one solution to cause a configuration change in the at least one network asset.,CISCO TECH INC,SUN PENGFEI;;SHAO QIHONG;;MURPHY ELISSA E;;TUROVSKY BARAK,CISCO TECHNOLOGY INC (2024-08-16),https://lens.org/149-492-845-587-817,Patent Application,yes,0,0,1,149-492-845-587-817,US,1,149-492-845-587-817,US,0,G06N20/00;;G06N20/00,G06N20/00,,0,0,,,,PENDING
614,US,A1,US 2025/0184361 A1,015-415-146-787-141,6/5/2025,2025,US 202318526507 A,12/1/2023,US 202318526507 A,12/1/2023,REAL TIME COACHING AND PREVENTION OF HUMAN-CENTRIC SECURITY VULNERABILITIES,"The disclosed system generates “real-time” notifications to prevent cybersecurity violations while also effectively training users. The system captures text from a user interface and selects a set of task instructions based on whether the text corresponds to an outgoing or incoming communication. If the captured text is incoming, the system selects task instructions related to phishing. If the captured text is (intended) outgoing, then the system selects task instructions related to data leakage. The system forms a prompt with the selected task instructions and the captured text and then inputs the prompt to a generative language model. If the response from the generative language model indicates a cybersecurity violation, such as either phishing or potential data leakage, then the system generates a notification accordingly. The system also records generation of notifications per user to facilitate risk assessment.",PALO ALTO NETWORKS INC,DALLA MOHAMMED MOHSIN;;BHATTACHARYA AVISHEK;;SINGHAL ANURAG,PALO ALTO NETWORKS INC (2023-11-30),https://lens.org/015-415-146-787-141,Patent Application,yes,5,0,1,015-415-146-787-141,US,1,015-415-146-787-141,US,0,H04L63/20;;H04L63/1441;;G06V30/262;;H04L63/1483;;H04L63/20;;G06V30/262;;H04L63/1441,H04L9/40;;G06V30/262,,0,0,,,,PENDING
615,US,A1,US 2025/0202760 A1,164-349-679-151-314,6/19/2025,2025,US 202318537968 A,12/13/2023,US 202318537968 A,12/13/2023,OBSERVABILITY PLATFORM SERVICE FOR OPERATIONAL ENVIRONMENT,"Provided are systems and methods that facilitates cross-correlation among alerts within different systems in a complex operating environment. In one example, a method may include receiving a plurality of alert messages generated by a plurality of systems within a distributed and shared operating environment and storing the plurality of alert messages, identifying a subset of alert messages among the plurality of alert messages that are correlated based on relationships identified from the subset of alert messages, generating a description of a root cause of the subset of alert messages based on execution of an artificial intelligence (AI) model on the identified subset of alert messages, and displaying the description of the root cause via a user interface.",SAP SE,SANCHEZ ANTHONY;;KASZONYI GABOR;;ROMERO MARIO EDUARDO;;MELASECCA GREGORY;;CHEN YU;;MARTENS SHEA;;KERTESZ JOZSEF;;ADIGE VITTALRAYA SHENOY;;HIU YEN ONN;;PETROV PETAR;;TOTH BALINT JANOS;;RUIZ ISMAEL,SAP SE (2023-12-02),https://lens.org/164-349-679-151-314,Patent Application,yes,15,0,1,164-349-679-151-314,US,1,164-349-679-151-314,US,0,H04L41/0654;;H04L41/0631;;H04L41/22;;H04L41/0686;;H04L41/16;;H04L41/0631;;H04L41/0654;;H04L41/22;;H04L41/0686,H04L41/0631;;H04L41/0654;;H04L41/0686;;H04L41/22,,0,0,,,,PENDING
616,US,A1,US 2024/0403560 A1,016-424-541-600-819,12/5/2024,2024,US 202318446314 A,8/8/2023,US 202318446314 A;;US 202363505802 P,6/2/2023,PREVENTION OF PROMPT INJECTION ATTACKS ON LARGE LANGUAGE MODELS BY TOKENIZATION OF STRUCTURED DATA ELEMENTS,Systems and methods for implementing prevention of prompt injection attacks on large language models by tokenization of structured data elements is presented. The systems and methods replace one or more data elements in a database response with one or more tokens to produce a tokenized database response. The systems and methods provide the tokenized database response to a large language model (LLM). The systems and methods receive a tokenized LLM output that includes at least one of the one or more tokens. The systems and methods produce a detokenized LLM output by replacing the one or more tokens in the tokenized LLM output with the one or more data elements.,CROWDSTRIKE INC,RADU DANIEL;;RADU MARIAN;;KRASSER SVEN,CROWDSTRIKE INC (2023-08-08),https://lens.org/016-424-541-600-819,Patent Application,yes,0,7,2,016-424-541-600-819;;012-059-017-962-487,US;;EP,2,016-424-541-600-819;;012-059-017-962-487,US;;EP,0,G06F21/6227;;G06F21/6254;;G06F21/604;;G06F21/6245;;G06F40/284;;G06F16/908;;G06F40/284,G06F40/284;;G06F16/908,,0,0,,,,PENDING
617,WO,A1,WO 2025/054881 A1,081-885-094-907-657,3/20/2025,2025,CN 2023118736 W,9/14/2023,CN 2023118736 W,9/14/2023,OPTIMIZATION-BASED IMAGE EDITING,"Described is an image processing apparatus (800), the apparatus comprising one or more processors (804) configured to: receive (701) image editing instructions (207, 208) indicating a desired modification to an input image (201); and input (702) the input image to an encoding-decoding process to form an edited image (213), wherein the encoding-decoding process comprises inputting (i) an intermediate image (205) derived from the input image and (ii) the image editing instructions (207, 208) to a pre-trained generative diffusion model to form the edited image (213) in dependence on respective outputs of a first loss function and a second loss function, the first loss function configured to preserve detail in one or more parts of the input image and the second loss function configured to guide the input image to be modified according to the image editing instructions. This can give pre-trained generative models highly controllable editing capability and allow to faithfully preserve image regions that are not to be edited (such as in background regions), and to achieve controllability using multiple instructions such as text, scribble and pose.",HUAWEI TECH CO LTD,LI BOWEN;;PARISOT SARAH;;YANG YONGXIN;;MCDONAGH STEVEN GEORGE;;TUDOSIU PETRU-DANIEL;;ZHANG SHIFENG,,https://lens.org/081-885-094-907-657,Patent Application,yes,4,0,1,081-885-094-907-657,WO,1,081-885-094-907-657,WO,0,G06T11/60,G06T11/60,,0,0,,,,PENDING
618,US,A1,US 2023/0124288 A1,169-162-632-161-461,4/20/2023,2023,US 202217968391 A,10/18/2022,US 202217968391 A;;US 202163257064 P,10/18/2021,Responsible Artificial Intelligence Controller,"Generally, the present disclosure is directed to systems and methods that include and/or leverage a responsible artificial intelligence controller to provide context-specific responsible artificial intelligence control. The responsible AI controller (RAI Controller) is a solution to the problem of a single model that cannot be simultaneously responsible to all its users. The controller embraces the notion of demographic and societal diversity, and it gives the user control over their interaction with the AI system.",GOOGLE LLC,MEIER-HELLSTERN KATHLEEN SUSAN;;CROAK MARIAN R,GOOGLE LLC (2022-03-08),https://lens.org/169-162-632-161-461,Patent Application,yes,0,8,1,169-162-632-161-461,US,1,169-162-632-161-461,US,0,G06F40/35;;G06F40/216;;G06N3/0455;;G06N3/063;;G06N3/084;;G06F9/44536;;G06F40/40,G06F9/445;;G06F40/40,,0,0,,,,PENDING
619,US,A1,US 2024/0403337 A1,095-167-244-230-074,12/5/2024,2024,US 202418586639 A,2/26/2024,JP 2023089841 A,5/31/2023,"INFORMATION PROCESSING DEVICE, COMPUTER PROGRAM PRODUCT, AND INFORMATION PROCESSING METHOD","According to one embodiment, an information processing device includes a memory and one or more processors coupled to the memory. The one or more processors are configured to: receive input of a prompt including a first text and an expected value of an answer related to the first text; predict, upon input of the first text and at least one image, the answer for each of the at least one image by using an AI model that outputs the answer; compute accuracy of the answer from the expected value and the answer; and display, on a display device, display information including at least the prompt, the answer, and the accuracy.",TOSHIBA KK,MISHIMA NAO;;NODA REIKO;;KOZAKAYA TATSUO,KABUSHIKI KAISHA TOSHIBA (2024-03-26),https://lens.org/095-167-244-230-074,Patent Application,yes,0,0,2,095-167-244-230-074;;135-799-255-123-383,US;;JP,2,095-167-244-230-074;;135-799-255-123-383,US;;JP,0,G06F16/5846;;G06V10/25;;G06F16/3329;;G06F16/3329;;G06V10/25;;G06F16/5846,G06F16/332;;G06F16/583;;G06V10/25,,0,0,,,,PENDING
620,US,A1,US 2025/0110454 A1,105-871-139-824-129,4/3/2025,2025,US 202418899676 A,9/27/2024,US 202418899676 A;;US 202363541155 P,9/28/2023,DIGITAL TWIN SYSTEMS MANAGEMENT,At least one processor may receive data descriptive of operation of equipment and store the data in a data store. the at least one processor may build a digital twin of the equipment using the data by training at least one machine learning model on at least a portion of the data in the data store and building a model accessible by a user interface and comprising at least one parameter determined by the trained machine learning model. The at least one processor may simulate operation of the equipment using the digital twin in response to receiving an entry in at least one user-variable input included in the model.,CBRE INC,SCHOLTEN ANNO J;;HICKEY DAMIAN PATRICK;;TULI YASH;;CRINER TRAVIS JEREMY,,https://lens.org/105-871-139-824-129,Patent Application,yes,0,0,1,105-871-139-824-129,US,1,105-871-139-824-129,US,0,G05B13/041;;G05B13/0265;;G05B13/0265;;G05B13/041,G05B13/04;;G05B13/02,,0,0,,,,PENDING
621,US,A1,US 2025/0165721 A1,004-336-405-263-947,5/22/2025,2025,US 202318515246 A,11/20/2023,US 202318515246 A,11/20/2023,GUIDED DYNAMIC CONSTRUCTION OF LARGE LANGUAGE MODEL (LLM) PROMPTS,"Example solutions for reducing the likelihood of hallucinations by large language models (LLMs) and improving the relevance of generated text are disclosed. A set of multiple of machine learning (ML) models, each custom-trained to identify a different specific topic within text, dynamically generate multiple topic-specific prompts from a received email in an email thread. A user, responding to the prompts, produces material that is used in conjunction with customer relations management (CRM) data and enterprise suite data (e.g., calendar/schedule information) to dynamically generate an LLM prompt. An LLM, using the prompt, generates output text suitable for a business correspondence, such as a reply email, to the sender of the email. The combination of the responses to the multiple topic-specific prompts and the CRM and enterprise suite data in the LLM prompt both ensures relevance of the reply correspondence and minimizes the risk of hallucinations.",MICROSOFT TECHNOLOGY LICENSING LLC,EISENSTADT ROY;;ASI ABED EL KADER;;SEGAL BAR;;ZACH EYAL;;RONEN ROYI,MICROSOFT TECHNOLOGY LICENSING LLC (2023-11-14),https://lens.org/004-336-405-263-947,Patent Application,yes,5,0,1,004-336-405-263-947,US,1,004-336-405-263-947,US,0,G06F40/103;;G06F40/40;;G06F40/30;;G06F40/103;;G06F40/40,G06F40/40;;G06F40/103,,0,0,,,,PENDING
622,US,A1,US 2025/0190853 A1,188-186-967-408-652,6/12/2025,2025,US 202318536177 A,12/11/2023,US 202318536177 A,12/11/2023,ENHANCING IN-CONTEXT LEARNING WITH FOUNDATION MODELS VIA FEW-SHOT LINEAR PROBE CALIBRATION,Aspects provide in-context learning with calibration for a foundation model. A validation prompt including one or more demonstration samples and an evaluation example is received and an output probability generated using the foundation model and the validation prompt. A calibration loss is computed based on the output probability and a set of calibration parameters. The set of calibration parameters is updated based on the calibration loss using an optimization algorithm. An inferencing operation is performed using the updated calibration parameters.,IBM;;RENSSELAER POLYTECH INST,ABBAS MOMIN;;ZHOU YI;;RAM PARIKSHIT;;BARACALDO ANGEL NATHALIE;;SAMULOWITZ HORST CORNELIUS;;SALONIDIS THEODOROS;;CHEN TIANYI,INTERNATIONAL BUSINESS MACHINES CORPORATION (2012-07-16);;RENSSELAER POLYTECHNIC INSTITUTE (2024-06-06),https://lens.org/188-186-967-408-652,Patent Application,yes,0,0,1,188-186-967-408-652,US,1,188-186-967-408-652,US,0,G06N20/00;;G06N7/01;;G06N7/01;;G06N20/00,G06N20/00;;G06N7/01,,0,0,,,,PENDING
623,WO,A1,WO 2024/226360 A1,105-637-329-268-21X,10/31/2024,2024,US 2024/0024882 W,4/17/2024,US 202318141194 A;;US 202363463647 P;;US 202318204419 A,4/28/2023,SEMANTIC SEARCH AND SUMMARIZATION FOR ELECTRONIC DOCUMENTS,Techniques for an artificial intelligence (AI) platform to search a document collection are described. Embodiments may use AI and machine learning techniques within a framework of an electronic document management system to perform semantic searching of an electronic document or a collection of electronic documents for certain types of information. The AI platform may summarize the information in a natural language representation of a human language. Other embodiments are described and claimed.,DOCUSIGN INC,HUDETZ CASEY;;WELLS KEENAN;;HE YAN;;ZAKHVATOV ALEXEY;;LAM YAN PUI;;SRIVASTAVA SOUMYA;;GREBELSKI MARIO M;;HASAN SOULEIMAN;;SHARMA ABHINAV U;;ALBERT NAVIN,,https://lens.org/105-637-329-268-21X,Patent Application,yes,1,1,1,105-637-329-268-21X,WO,3,105-637-329-268-21X;;120-932-291-917-151;;192-538-743-066-367,US;;WO,0,G06F16/345;;G06F16/93,G06F16/34;;G06F16/93,,0,0,,,,PENDING
624,WO,A1,WO 2024/191430 A1,045-613-859-440-610,9/19/2024,2024,US 2023/0027391 W,7/11/2023,US 202363451868 P;;US 202318123141 A,3/13/2023,DIALOG MANAGEMENT FOR LARGE LANGUAGE MODEL-BASED (LLM-BASED) DIALOGS,"Implementations relate to dialog management of a large language model (LLM) utilized in generating natural language (NL) output during an ongoing dialog. Processor(s) of a system can: receive NL based input as part of the ongoing dialog, generate NL based output utilizing the LLM, and cause the NL based output to be rendered. Further, the processor(s) can receive subsequent NL based input as part of the ongoing dialog. In some implementations, the processor(s) can determine whether to modify a corresponding dialog context in generating subsequent NL based output, and modify the corresponding dialog context accordingly. For example, the processor(s) can restrict the corresponding dialog context, or supplant the corresponding dialog context with a corresponding curated dialog context. In additional or alternative implementations, the processor(s) can modify a corresponding NL based output threshold utilized in generating the subsequent NL based response to ensure the resulting NL based output is desirable.",GOOGLE LLC,BAEUML MARTIN;;BAILEY ALEXANDER;;BRAGAGNOLO JONAS;;D'HALLUIN FLORENT;;STROHMAN TREVOR,,https://lens.org/045-613-859-440-610,Patent Application,yes,4,0,1,045-613-859-440-610,WO,2,184-577-098-029-169;;045-613-859-440-610,US;;WO,0,G06F40/35;;G06F40/216;;G06F40/30,G06F40/35;;G06F40/216;;G06F40/30,,0,0,,,,PENDING
625,US,A1,US 2025/0184340 A1,183-006-274-014-05X,6/5/2025,2025,US 202418959021 A,11/25/2024,US 202418959021 A;;US 202418769872 A;;US 202318524468 A,11/30/2023,SYSTEM AND METHOD FOR IMPROVING CYBERSECURITY BY GENERATING ACTIVITY REPORTS USING MACHINE-LEARNING MODELS,"Presented herein are systems and methods for generating suspicious activity reports using large language models. A system may include one or more processors that obtain event data associated with an event from a client device and from one or more databases, apply a prompt generator on the event data to generate a large language model (LLM) prompt, and generate a machine-readable suspicious activity (SAR) report in accordance with an LLM prompt. The one or more processors may also apply the prompt generator on the event data based on determining that a fraud risk score associated with the event satisfies a reporting threshold score. Computer program products are also presented.",CITIBANK NA,WALI GIRISH;;TUTEJA DEEPALI;;RAMAKRISHNA PRASANTH BABU MADAKASIRA;;PICKARD BRETT;;GURUMURTHI SAKETH RAM;;SILVER MIRIAM,CITIBANK N.A (2024-07-03),https://lens.org/183-006-274-014-05X,Patent Application,yes,0,0,4,047-329-997-062-114;;152-323-702-865-649;;183-006-274-014-05X;;116-777-333-918-610,US;;WO,4,047-329-997-062-114;;152-323-702-865-649;;183-006-274-014-05X;;116-777-333-918-610,US;;WO,0,H04L67/10;;H04L63/1425;;H04L67/10;;H04L63/1425;;G06F40/20;;G06Q20/4016,H04L9/40;;H04L67/10,,0,0,,,,PENDING
626,US,A1,US 2025/0238874 A1,003-002-805-922-626,7/24/2025,2025,US 202519033310 A,1/21/2025,US 202519033310 A;;US 202463623670 P,1/22/2024,MACHINE LEARNING USER INTERFACE BASED FORM QUERY RESPONSE,"The technical solutions of the present disclosure are directed to providing validated responses to form specific user queries using machine learning. A system can include a processor to receive, via a user interface, a query corresponding to an entry of a form and identify a data structure. The processor can generate, using the data structure, a prompt to validate the entries and identify, based on the prompt and the data structure input a ML model, an error in an entry of the plurality of entries of the form. The processor can generate, based on the error and the data structure input into the ML model, a response to the query comprising a proposed correction to the error in the form, and provide, for display via the user interface, the response to the query indicating the error and the proposed correction.",ADP INC,JIA YONGMEI;;HOUSTON PHILIP ANDREW,,https://lens.org/003-002-805-922-626,Patent Application,yes,0,0,1,003-002-805-922-626,US,1,003-002-805-922-626,US,0,G06F16/248;;G06Q40/123,G06Q40/12;;G06F16/248,,0,0,,,,PENDING
627,WO,A1,WO 2025/093772 A1,097-056-729-197-55X,5/8/2025,2025,EP 2024081072 W,11/4/2024,US 202363596229 P,11/3/2023,SEARCHING THROUGH CANDIDATE COMPUTER PROGRAMS FOR PERFORMING A TASK USING A LANGUAGE MODEL NEURAL NETWORK,"Methods, systems, and apparatuses, including computer programs encoded on computer storage media, for determining a final computer program for performing a task by searching through a space of candidate computer programs That is, by starting with an initial computer program and using an evolutionary search procedure that uses a pre-trained language model to generate new candidate computer programs in conjunction with an evaluation function to verify the quality of the new candidate computer programs, the resulting final computer program can be determined in an automatic fashion and can perform the task (often using novel steps and processes) more effectively than the initial computer program for the task.",DEEPMIND TECH LTD,ROMERA-PAREDES BERNARDINO;;NOVIKOV ALEXANDER;;BAREKATAIN MOHAMMADAMIN;;BALOG MATEJ;;MUDIGONDA PAWAN KUMAR;;DUPONT EMILIEN;;RODRIGUEZ RUIZ FRANCISCO JESUS;;FAWZI ALHUSSEIN,,https://lens.org/097-056-729-197-55X,Patent Application,yes,5,0,2,097-056-729-197-55X;;000-159-491-082-404,US;;WO,2,097-056-729-197-55X;;000-159-491-082-404,US;;WO,0,G06N3/045;;G06F8/30;;G06F8/35;;G06N3/08;;G06F9/5016;;G06F9/5038;;G06F9/5077,G06F8/30;;G06F8/35;;G06N3/045,,0,0,,,,PENDING
628,US,A1,US 2025/0061282 A1,071-761-143-396-156,2/20/2025,2025,US 202418784900 A,7/25/2024,CN 202311030154 A,8/15/2023,"METHOD OF GENERATING TRAINING DATA, READABLE MEDIUM, AND ELECTRONIC DEVICE","A method of generating training data, a readable medium and an electronic device are provided. The method includes: acquiring sample data; determining a data generation template according to the sample data; generating question data according to the first data in the sample data and the data generation template, and determining answer data according to the second data other than the first data in the sample data; and combining the question data and the answer data into the training data.",BEIJING YOUZHUJU NETWORK TECH CO LTD,MA YUKUN,,https://lens.org/071-761-143-396-156,Patent Application,yes,0,0,2,112-451-371-349-679;;071-761-143-396-156,US;;CN,2,112-451-371-349-679;;071-761-143-396-156,US;;CN,0,G06F18/214;;G06F16/3329;;G06F40/30;;G06F40/295;;G06F40/30,G06F40/30,,0,0,,,,PENDING
629,WO,A1,WO 2025/019136 A1,086-427-450-215-475,1/23/2025,2025,US 2024/0035836 W,6/27/2024,US 202318221997 A,7/14/2023,GEOMECHANICAL DATA INTERPRETATION AND RECOMMENDATION SYSTEM USING LARGE LANGUAGE MODELS,"A method may include providing one or more inputs to a hybrid data generator, wherein one of the one or more inputs is based at least in part on a wellsite location, wherein the hybrid data generator comprises a large language model, and wherein the large language model is based at least in part on a machine learning algorithm. The method may further include utilizing an information handling system to generate a drilling program based at least in part on the one or more inputs and the hybrid data generator. The method may further include performing at least a portion of a drilling operation based at least in part on the drilling program and collecting at least one measurement from at least one sensor during the drilling operation.",HALLIBURTON ENERGY SERVICES INC,DYNGOSZ MATEUSZ MICHAL;;DE OLIVEIRA CLAUDIA LUCIA BONIN;;JAMISON DALE E,,https://lens.org/086-427-450-215-475,Patent Application,yes,5,0,2,086-427-450-215-475;;048-979-207-539-215,US;;WO,2,086-427-450-215-475;;048-979-207-539-215,US;;WO,0,E21B44/00;;E21B44/00;;E21B2200/22;;E21B2200/20,G06N3/10,,0,0,,,,PENDING
630,US,A1,US 2025/0095860 A1,126-973-654-023-712,3/20/2025,2025,US 202418888437 A,9/18/2024,US 202418888437 A;;US 202363539149 P,9/19/2023,COMPUTING SYSTEM FOR MEDICAL DATA PROCESSING,"Disclosed within are methods and systems for method for personalized medical data processing. One method includes receiving, by a health assistant computing entity, member-specific health data from a plurality of member computing entities via a network and processing the received health data using machine learning and artificial intelligence algorithms executed by the health assistant computing entity to generate personalized health insights. The processed health data and generated insights are stored in a private database associated with the automated health assistant computing entity and the processed data and insights are used to generate a dynamic wellness plan for each member. Communication between the member computing entities and professional computing entities are facilitated to implement the wellness plan and the member's health data is continuously monitored and the wellness plan is dynamically updated based on new data inputs. Real-time feedback and recommendations are provided to the member through the member computing entities.",BIONIC HEALTH INC,ALLEN ROBERT C;;PELO JARED W,BIONIC HEALTH INC (2024-09-11),https://lens.org/126-973-654-023-712,Patent Application,yes,0,0,1,126-973-654-023-712,US,1,126-973-654-023-712,US,0,G16H20/30;;G16H20/70;;G16H10/60;;G16H20/60;;G16H20/10;;G16H50/30;;G16H50/20;;G16H40/67;;G16H50/70;;G16H50/30;;G16H10/60;;G16H20/70;;G16H20/30;;G16H20/60;;G16H20/10,G16H50/30;;G16H10/60;;G16H20/10;;G16H20/30;;G16H20/60;;G16H20/70,,0,0,,,,PENDING
631,US,A1,US 2024/0311575 A1,184-577-098-029-169,9/19/2024,2024,US 202318123141 A,3/17/2023,US 202318123141 A;;US 202363451868 P,3/13/2023,DIALOG MANAGEMENT FOR LARGE LANGUAGE MODEL-BASED (LLM-BASED) DIALOGS,"Implementations relate to dialog management of a large language model (LLM) utilized in generating natural language (NL) output during an ongoing dialog. Processor(s) of a system can: receive NL based input as part of the ongoing dialog, generate NL based output utilizing the LLM, and cause the NL based output to be rendered. Further, the processor(s) can receive subsequent NL based input as part of the ongoing dialog. In some implementations, the processor(s) can determine whether to modify a corresponding dialog context in generating subsequent NL based output, and modify the corresponding dialog context accordingly. For example, the processor(s) can restrict the corresponding dialog context, or supplant the corresponding dialog context with a corresponding curated dialog context. In additional or alternative implementations, the processor(s) can modify a corresponding NL based output threshold utilized in generating the subsequent NL based response to ensure the resulting NL based output is desirable.",GOOGLE LLC,BAEUML MARTIN;;BAILEY ALEXANDER;;BRAGAGNOLO JONAS;;D'HALLUIN FLORENT;;STROHMAN TREVOR,GOOGLE LLC (2023-03-15),https://lens.org/184-577-098-029-169,Patent Application,yes,10,3,1,184-577-098-029-169,US,2,184-577-098-029-169;;045-613-859-440-610,US;;WO,0,G06N20/00;;G06F40/35;;G06F40/56;;G06N20/00;;G06F40/35,G06F40/35;;G06N20/00,,0,0,,,,PENDING
632,US,A1,US 2024/0169974 A1,074-065-706-269-880,5/23/2024,2024,US 202318132356 A,4/7/2023,US 202318132356 A;;US 202263427079 P,11/21/2022,REAL-TIME SYSTEM FOR SPOKEN NATURAL STYLISTIC CONVERSATIONS WITH LARGE LANGUAGE MODELS,"The techniques disclosed herein enable systems for spoken natural stylistic conversations with large language models. In contrast to many existing modalities for interacting with large language models that are limited to text, the techniques presented herein enable users to carry a fully spoken conversation with a large language model. This is accomplished by converting a user speech audio input to text and utilizing a prompt engine to analyze a sentiment expressed by the user. A large language model, having been trained on example conversations, by generating a text response as well as a style cue to express emotion in response to the sentiment expressed by speech audio input. A text-to-speech engine can subsequently interpret the text response and style cue to generate an audio output which emulates the sensation of human conversation.",MICROSOFT TECHNOLOGY LICENSING LLC,BONAR ADRIAN WYATT;;FOX JENNIFER;;BERDY NICOLE E;;MUNOZ MOLLIE;;CALLEGARI SHAWN;;LUCATO DEVIS;;VOLUM RYAN H,MICROSOFT TECHNOLOGY LICENSING LLC (2014-10-14),https://lens.org/074-065-706-269-880,Patent Application,yes,5,8,1,074-065-706-269-880,US,2,074-065-706-269-880;;009-970-878-101-315,US;;WO,0,G10L15/26;;G06F40/30;;G10L13/033;;G06F40/58;;G10L13/10;;G10L2013/083;;G10L25/63;;G10L15/26;;G10L2015/225;;G10L13/02;;G10L15/1815;;G10L13/08,G10L13/10;;G10L15/26,,0,0,,,,PENDING
633,WO,A1,WO 2025/117380 A1,125-663-707-516-36X,6/5/2025,2025,US 2024/0057117 W,11/22/2024,US 202363605066 P,12/1/2023,LEVERAGING LARGE LANGUAGE MODELS FOR STANDARDIZING CLINICAL DATA,Disclosed are various embodiments for leveraging large language models (LLMs) and retrieval-augmented generation (RAG) for data standardization of clinical AI data. A query comprising a target dataset that needs to be standardized and a dataset dictionary can be obtained. Augmented data can be extracted from an external source. A prompt including the query and the augmented data can be generated and applied to a large language model configured to output a response to the query. The response can include the target dataset standardized according to a standard format.,GENENTECH INC;;HOFFMANN LA ROCHE;;HOFFMANN LA ROCHE,PANDIT YOGESH P;;SETT ARINDAM;;HASHEMIFAR SOMAYE SADAT;;HEJRATI SEYED MOHAMMADMOHSEN;;YADAV MRUNAL SHRIRAM,,https://lens.org/125-663-707-516-36X,Patent Application,yes,0,0,1,125-663-707-516-36X,WO,1,125-663-707-516-36X,WO,0,G06F16/84;;G06F16/90332,G06F16/84;;G06F16/9032,,1,0,,,"STOLLNITZ BEA: ""Add your own data to an LLM using Retrieval-Augmented Generation (RAG)"", 9 October 2023 (2023-10-09), XP093247538, Retrieved from the Internet <URL:https://web.archive.org/web/20231009115142/https://bea.stollnitz.com/blog/rag/> [retrieved on 20250206]",PENDING
634,US,A1,US 2025/0209416 A1,164-761-434-132-929,6/26/2025,2025,US 202318391639 A,12/20/2023,US 202318391639 A,12/20/2023,"INTEGRATED REVIEW, INVENTORY, AND COMMUNICATION AUTOMATION SYSTEMS AND METHODS","At least one processor may receive a plurality of review comments, identify at least a subset of the plurality of review comments representing at least one positive review, and identify at least one product indicated by the at least one positive review. The at least one processor may determine, from data produced by an inventory system, that the at least one product has a low inventory level. In response to the determining, the at least one processor may generate a message configured to automatically order the at least one product from a supplier system and send the message to the supplier system, thereby automatically ordering the at least one product.",INTUIT INC,MUTHU MALATHY;;FINEGAN CORINNE L;;TYMOFIEV ALEXIS KIM,INTUIT INC (2023-12-15),https://lens.org/164-761-434-132-929,Patent Application,yes,7,0,1,164-761-434-132-929,US,1,164-761-434-132-929,US,0,G06Q10/087;;G06Q50/01;;G06Q30/0282;;G06Q10/087;;G06Q50/01;;G06Q30/0282,G06Q10/087;;G06Q30/0282;;G06Q50/00,,0,0,,,,PENDING
635,WO,A1,WO 2025/076231 A1,148-074-909-094-31X,4/10/2025,2025,US 2024/0049809 W,10/3/2024,US 202363542393 P;;US 202363595405 P;;US 202363599163 P;;US 202418904571 A;;US 202418904639 A,10/4/2023,LANGUAGE-BASED OBJECT DETECTION AND DATA AUGMENTATION,"Methods and systems for object detection include generating (802) a negative description for an input image based on a positive description of the input image using a language model. A negative image is generated (804) based on the input image and the negative description by replacing a portion of the input image that is described by the positive description with content that is described by the negative description using a generative image model. An object detection model is trained (806) with the input image, the positive description, the negative description, and the negative image.",NEC LAB AMERICA INC,SCHULTER SAMUEL;;AICH ABHISHEK;;GOPALKRISHNA VIJAY KUMAR BAIKAMPADY,,https://lens.org/148-074-909-094-31X,Patent Application,yes,0,0,4,111-427-963-354-328;;148-074-909-094-31X;;108-643-504-691-26X;;197-641-041-110-033,US;;WO,4,111-427-963-354-328;;148-074-909-094-31X;;108-643-504-691-26X;;197-641-041-110-033,US;;WO,0,G06T2210/12;;G06F40/40;;G06V20/50;;G06V10/774;;G06V10/82;;G06V20/58;;G06V20/70;;G06V10/86;;G06T11/60;;G06V20/56;;G06T5/77;;B60W60/001;;G06V20/70;;G06V10/86;;G06V10/774;;G06V10/82;;G06V20/50;;G06F40/40;;G06T2210/12;;G06T11/60;;B60W60/001;;G06V20/58;;G06T5/77,G06V20/56;;B60W40/02;;G06F40/126;;G06N3/0455;;G06V10/774;;G06V20/70,,0,0,,,,PENDING
636,WO,A1,WO 2025/027383 A1,103-558-371-892-501,2/6/2025,2025,IB 2024000392 W,8/1/2024,US 202363530472 P,8/2/2023,TRANSACTIONAL PLATFORM UTILIZING ARTIFICIAL INTELLIGENCE,"A system implements an online marketplace through digital communications sessions with users and providers to match providers with available provider time to a consumer user requiring services of the provider with payment exchanged between the consumer user and the provider user. Market pricing for services are calculated based on a metric of demand. Digital communications sessions are delivered for a duration corresponding to the payment made. Fictional personas may be utilized, including those associated with an artificial intelligence.",MINE ZERO GMBH,HERKEN ROLF,,https://lens.org/103-558-371-892-501,Patent Application,yes,13,0,1,103-558-371-892-501,WO,13,015-080-264-570-072;;135-942-474-500-520;;024-669-185-368-923;;004-563-321-240-473;;028-182-074-262-377;;044-816-109-990-027;;084-160-913-731-175;;173-712-615-812-216;;150-774-851-332-598;;184-991-776-183-135;;047-848-837-842-159;;113-789-892-008-567;;103-558-371-892-501,US;;WO;;EP,0,G06Q30/0641;;G06Q30/0613;;G06Q30/0611;;G06Q10/10;;G06Q10/109;;G06Q20/085;;G06Q20/145;;G06Q20/065;;G06Q20/02;;G06Q20/127;;G06Q20/383;;G06Q20/3829;;G06Q20/3823;;G06Q30/0241;;G06Q50/01;;G06Q50/10;;G06Q30/02,G06Q10/10;;G06Q10/109;;G06Q20/02;;G06Q20/06;;G06Q20/08;;G06Q20/12;;G06Q20/14;;G06Q20/38;;G06Q30/02;;G06Q30/0241;;G06Q30/0601;;G06Q50/00;;G06Q50/10,,0,0,,,,PENDING
637,WO,A1,WO 2025/136503 A1,099-834-780-671-414,6/26/2025,2025,US 2024/0053134 W,10/25/2024,US 202318390675 A,12/20/2023,PROACTIVE ASSISTANCE VIA A CASCADE OF LLMS,"A method (500) for providing proactive assistance includes obtaining a contextual event (202) associated with a user of a user device (110). The method includes determining, using a local LLM (152) executing on the user device, a remote LLM prompt confidence. Based on determining that the remote LLM prompt confidence satisfies a threshold, the method includes generating a remote LLM prompt (156) for a remote LLM (160). The method includes transmitting, to the remote LLM (160), the remote LLM prompt. The method includes receiving, response content (162) providing the proactive assistance associated with the contextual event. The method includes providing, for output from the user device, presentation content based on the response content received from the remote LLM.",GOOGLE LLC,CARBUNE VICTOR;;SHARIFI MATTHEW,,https://lens.org/099-834-780-671-414,Patent Application,yes,1,0,2,127-371-426-703-001;;099-834-780-671-414,US;;WO,2,127-371-426-703-001;;099-834-780-671-414,US;;WO,0,G06F16/33295;;G06F16/90332;;G06N3/006;;G06N3/0475;;G06N3/045;;G06N3/098;;G06F40/20,G06F16/3329;;G06F16/9032,,1,0,,,"YUN ZHU ET AL: ""Towards an On-device Agent for Text Rewriting"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 22 August 2023 (2023-08-22), XP091598325",PENDING
638,US,A1,US 2025/0139350 A1,065-997-802-199-257,5/1/2025,2025,US 202318497344 A,10/30/2023,US 202318497344 A,10/30/2023,GENERATIVE PAGE BASED ON SCREENSHOTS,"Aspects of the disclosure provide for mechanisms for dynamically generating at least one page using one or more screenshots. A method of the disclosure includes receiving a screenshot, identifying a plurality of fragments of the screenshot, wherein each fragment corresponds to one of: structural user interface (UI) elements or content of the screenshot, generating, for each fragment of the plurality of fragments, an entity, wherein the entity is a pre-defined structure representation of the fragment, and generating, based on the entities associated with the plurality of fragments, at least one page associated with the screenshot.",PAGER TECH INC,MAHEDY ALEXANDER;;BUCK DUNCAN;;ARMSTRONG AUSTIN CHRISTIAN-DURUP,PAGER TECHNOLOGIES INC (2023-10-30),https://lens.org/065-997-802-199-257,Patent Application,yes,0,0,1,065-997-802-199-257,US,1,065-997-802-199-257,US,0,G06F40/106;;G06F40/166;;G06F40/166;;G06F40/106,G06F40/106;;G06F40/166,,0,0,,,,PENDING
639,US,A1,US 2024/0370517 A1,163-036-056-183-48X,11/7/2024,2024,US 202418655024 A,5/3/2024,US 202418655024 A;;US 202363499945 P,5/3/2023,DELIVERING RESPONSES TO QUERIES EXPRESSED IN NATURAL LANGUAGE BASED ON A DYNAMIC DOCUMENT CORPUS,"A system and method generate answers to user queries by providing natural language responses containing direct citations to primary sources. The system comprises a data collection pipeline that ingests, processes, and organizes data from multiple sources, and a retrieval mechanism that processes user queries, identifies relevant data, and employs a machine learning model, such as a Large Language Model (LLM), to generate natural language responses based on the retrieved data. The generated responses are augmented with direct references to the primary sources, ensuring accurate attribution and up-to-date information. This system combines the natural language capabilities of LLMs with the direct connections to primary sources provided by traditional search engines, delivering real-time, dynamic processing of resources without incurring high re-training costs.",QDECK INC,DEVOS LUKE THOMAS;;IRELAND II TIMOTHY JAMES;;IRELAND ABIGAIL LYNN;;LEUNG SIU TANG;;MODORAN ANDREI;;OSTERCAMP BRAD STEVEN;;PRAKASAM JAGDEESH,,https://lens.org/163-036-056-183-48X,Patent Application,yes,1,3,3,132-608-599-869-281;;168-222-330-193-383;;163-036-056-183-48X,US;;WO,3,132-608-599-869-281;;168-222-330-193-383;;163-036-056-183-48X,US;;WO,0,G06F16/957;;G06F16/9558;;G06F40/295;;G06F40/30;;G06F16/9558;;G06F40/295;;G06F16/957,G06F16/955;;G06F16/957;;G06F40/295,,0,0,,,,ACTIVE
640,US,A1,US 2024/0330649 A1,170-421-835-144-070,10/3/2024,2024,US 202418610804 A,3/20/2024,KR 20230041865 A,3/30/2023,INFERENCE METHOD EMPLOYING PROMPT-BASED META-LEARNING NETWORK AND COMPUTER SYSTEM,"Provided is an inference method employing a prompt-based meta-learning network and a computer system. The inference method includes selecting a task, generating a prompt key for the selected task using a prompt-embedding network (PEN), calculating similarities between the prompt key for the selected task and prompt keys included in a prompt key pool (PKP), acquiring a prompt value for the selected task using a memory network (MN), and generating an inference result for the selected task using a model-agnostic meta-learning (MAML)-based pre-trained model (MPM).",ELECTRONICS & TELECOMMUNICATIONS RES INST,YANG JEONGMIN;;KIM HYUN WOO;;SONG HWAJEON;;YOO BYUNGHYUN;;CHUNG EUISOK;;HAN RAN,ELECTRONICS AND TELECOMMUNICATIONS RESEARCH INSTITUTE (2024-03-05),https://lens.org/170-421-835-144-070,Patent Application,yes,0,0,2,188-643-227-200-814;;170-421-835-144-070,US;;KR,2,188-643-227-200-814;;170-421-835-144-070,US;;KR,0,G06N3/043;;G06N3/045;;G06N3/08;;G06N3/0985;;G06N3/096;;G06N3/09;;G06N3/045;;G06N3/043,G06N3/043,,0,0,,,,PENDING
641,US,A1,US 2025/0156390 A1,078-755-711-026-318,5/15/2025,2025,US 202318508532 A,11/14/2023,US 202318508532 A,11/14/2023,MERKLE-ENHANCED TRAINING DATA AUDIT PROCESS,"The present inventive concept provides for a method of verifying data using Merkle proof and root. The method includes organizing a dataset into a Merkle tree, the dataset including a plurality of data elements. A Merkle root is generated that represents the dataset organized into the Merkle tree. A generated Merkle proof is provided for a data element of the plurality of data elements, and it is determined whether the data element is included in the dataset using the Merkle root and the Merkle proof.",IBM,CUOMO GENNARO ANTHONY;;DOLPH BLANE H,INTERNATIONAL BUSINESS MACHINES CORPORATION (2023-11-08),https://lens.org/078-755-711-026-318,Patent Application,yes,7,0,1,078-755-711-026-318,US,1,078-755-711-026-318,US,0,G06F16/2246;;G06F16/2246,G06F16/22,,0,0,,,,PENDING
642,US,A1,US 2025/0217170 A1,011-940-334-379-903,7/3/2025,2025,US 202419002441 A,12/26/2024,US 202419002441 A;;US 202363615607 P,12/28/2023,Machine-Learned User Interface Command Generator Using Pretrained Image Processing Model,"An example method can include providing a natural language instruction and user interface image data to a machine-learned sequence processing model that is configured to process image data and generate commands for controlling the target computing device, wherein the machine-learned sequence processing model has parameters learned using an interface recognition objective based on an evaluation of an interface recognition output generated based on processing a rendered training interface from a pre-training dataset and an interface navigation objective based on an evaluation of a user interface command generated based on processing a rendered training interface from a fine-tuning dataset; receiving, from the machine-learned sequence processing model, a command indicating an interaction with the user interface to implement the natural language instruction; and generating, based on the command, a control signal configured to initiate the interaction.",GOOGLE LLC,SHAW PETER THOMAS;;JOSHI MANDAR;;TOUTANOVA KRISTINA NIKOLOVA;;COHAN JAMES FISCHL;;BERANT JONATHAN HAIM;;LEE KENTON CHIU TSUN;;PASUPAT PANUPONG;;HU HEXIANG;;KHANDELWAL URVASHI,,https://lens.org/011-940-334-379-903,Patent Application,yes,0,0,1,011-940-334-379-903,US,1,011-940-334-379-903,US,0,G06V30/19;;G06F9/451;;G06F9/451;;G06F9/54;;G06V30/19,G06F9/451;;G06F9/54;;G06V30/19,,0,0,,,,PENDING
643,US,A1,US 2025/0190641 A1,114-024-852-509-043,6/12/2025,2025,US 202318391718 A,12/21/2023,US 202318391718 A;;US 202363606603 P,12/6/2023,SYSTEM AND METHOD FOR AI-POWERED LOT SUBDIVISION OPTIMIZATION AND VISUALIZATION OF A REAL PROPERTY BASED ON GOVERNMENTAL REGULATORY FRAMEWORK,"A land-use planning system includes a data collection module configured to extract a shape file associated with a property address of a plot of real property in a jurisdiction. The shape file includes a location, a geometry, and attribution of a point, a line, and/or a polygon features of the plot of real property. An artificial intelligence (AI) model is adapted to analyze the shape file. The AI model is fine-tuned based on a regulation governing lot subdivision in the jurisdiction. A recommendation engine is integrated with the AI model to generate an optimal plot boundary suggestion to adhere to the governmental regulation while maximizing financial viability of split lots from the property address. A visualization component creates a visual representation of the split lots in the jurisdiction displaying the optimal plot boundary suggestion on a rendering of the shape file.",ABHYANKER RAJ,ABHYANKER RAJ,ATHERTON STUDIOS INC (2024-02-13),https://lens.org/114-024-852-509-043,Patent Application,yes,0,0,1,114-024-852-509-043,US,1,114-024-852-509-043,US,0,G06F30/27;;G06Q50/165;;G06F30/13;;G06Q50/16;;G06F30/13;;G06T19/003;;G06F30/27;;G06Q50/165,G06F30/13;;G06F30/27;;G06Q50/16;;G06T19/00,,0,0,,,,PENDING
644,US,A1,US 2025/0181895 A1,188-821-282-992-630,6/5/2025,2025,US 202318525665 A,11/30/2023,US 202318525665 A,11/30/2023,RANKING DATA RECORDS FOR AUTOMATIC MESSAGE GENERATION,"Solutions for ranking data records, in order to automatically generate message (e.g., email), extract features from an incoming message and identify data records (e.g., opportunities) associated with the message source within a data source. Features within each data record (e.g., opportunity title, names, products, and times) are matched against the incoming message features to rank the data records (e.g., rank opportunities against an incoming message). The ranking is presented to a user in a user interface (UI), and a language model dynamically generates outgoing message. The user may endorse the selection of the top-ranked data record, or select another data record for the language model to dynamically generate outgoing message.",MICROSOFT TECHNOLOGY LICENSING LLC,BEREZIN YEHIEL;;OSTRIKOV ALEXANDER;;RONEN ROYI;;LEVIN ROY,MICROSOFT TECHNOLOGY LICENSING LLC (2024-01-22),https://lens.org/188-821-282-992-630,Patent Application,yes,0,0,1,188-821-282-992-630,US,1,188-821-282-992-630,US,0,G06N3/0455;;G06N20/00;;G06N3/0455,G06N3/0455,,0,0,,,,PENDING
645,US,A1,US 2025/0245082 A1,137-756-286-255-007,7/31/2025,2025,US 18424528,1/26/2024,,,AUTOMATIC ENDPOINT DISCOVERY SYSTEMS AND METHODS,At least one processor may receive a plurality of uniform resource locator (URL) paths each comprising a respective one or more hierarchical path segments and divide each of the plurality of URL paths into tokens. The at least one processor may determine that at least one first hierarchical level of the plurality of URL paths represents at least one resource by performing a first statistical analysis and may determine that at least one second hierarchical level of the plurality of URL paths represents at least one variable by performing a second statistical analysis. The at least one processor may determine a standard format of the plurality of URL paths comprising the at least one resource and the at least one variable and perform processing utilizing the standard format for an application programming interface (API) associated with the plurality of URL paths.,INTUIT INC.,Kiril LASHVICHER;;Yossi BARSHISHAT;;Shirley AVISHOUR,,https://lens.org/137-756-286-255-007,Patent Application,yes,0,0,1,137-756-286-255-007,US,1,137-756-286-255-007,US,0,G06F9/547,G06F9/54,,0,0,,,,UNKNOWN
646,US,B1,US 12259913 B1,112-589-516-725-631,3/25/2025,2025,US 202418441863 A,2/14/2024,US 202418441863 A,2/14/2024,Caching large language model (LLM) responses using hybrid retrieval and reciprocal rank fusion,A system and method for improving computer functionality by retrieving answers/responses to questions/input from a cache such as those used with chatbots and generative AI systems. Disclosed is a multi-layered caching strategy that focuses on the relevance of a cache hit by improving the quality of the answer. The approach demonstrates that response latency is significantly reduced when using caching and how a caching strategy could be applied in various layers of increasing relevance for a simple Question-and-Answer system with the possibility of extending to more complex generative AI interactions.,INVENTUS HOLDINGS LLC,MUSCHETT BRIEN H;;ODOM JUSTIN G,INVENTUS HOLDINGS LLLC (2024-02-14),https://lens.org/112-589-516-725-631,Granted Patent,yes,30,0,1,112-589-516-725-631,US,1,112-589-516-725-631,US,0,G06F16/3329;;G06F16/38;;G06F16/3347;;G06F16/335;;G06F16/3326;;G06F16/3326;;G06F16/38;;G06F16/335;;G06F16/3347;;G06F16/3329,G06F16/332;;G06F16/33;;G06F16/3329;;G06F16/334;;G06F16/335;;G06F16/38,,15,4,040-238-483-085-265;;029-824-428-917-210;;089-940-491-109-202;;185-706-254-292-036,10.18653/v1/2023.nlposs-1.24;;10.1145/1151087.1151091;;10.3115/1073012.1073049;;10.18653/v1/2024.findings-acl.704,"Bang, F. (2023, December). GPTCache: An Open-Source Semantic Cache for LLM Applications Enabling Faster Answers and Cost Savings. In Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) (pp. 212-218).;;Jónsson, B. P., Arinbjarnar, M., Pórsson, B., Franklin, M. J., & Srivastava, D. (2006). Performance and overhead of semantic cache management. ACM Transactions on Internet Technology (TOIT), 6(3), 302-331.;;Harabagiu, S., Moldovan, D., Pasca, M., Mihalcea, R., Surdeanu, M., Bunsecu, R., . . . & Morarescu, P. (Jul. 2001). The role of lexico-semantic feedback in open-domain textual question-answering. In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics (pp. 282-289).;;Ramírez, G., Lindemann, M., Birch, A., & Titov, I. (2023). Cache & Distil: Optimising API Calls to Large Language Models. arXiv preprint arXiv:2310.13561.;;Sahar Mor “12 Techniques to reduce your LLM API bill and launch blazingly fast products”, Deep Dives, Ai Tidbits, Jan. 13, 2024.;;Zhu, Banghua, et al. “On Optimal Caching and Model Multiplexing for Large Model Inference.” arXiv preprint arXiv:2306.02003 (2023).;;https://python.langchain.com/docs/integrations/Ilms/Ilm_caching.;;https://github.com/zilliztech/GPTCache.;;https://plg.uwaterloo.ca/˜gvcormac/cormacksigir09-rrf.pdf.;;https://www.elastic.co/guide/en/elasticsearch/reference/current/rrf.html.;;https://towardsdatascience.com/forget-rag-the-future-is-rag-fusion-1147298d8ad1.;;https://www.elastic.co/blog/improving-information-retrieval-elastic-stack-hybrid.;;https://arxiv.org/abs/2210.11934.;;https://medium.com/@sowmiyajaganathan/hybrid-search-with-re-ranking-ff120c8a426d.;;https://github.com/rochacon/es-janitor.",ACTIVE
647,US,A1,US 2023/0297887 A1,009-932-318-435-731,9/21/2023,2023,US 202218082394 A,12/15/2022,US 202218082394 A;;US 202263320041 P,3/15/2022,SYSTEMS AND METHODS FOR GENERATING AUTOMATIC TRAINING SUGGESTIONS,Systems and methods for generating training questions are disclosed. The method includes identifying a structure for generating an input; formulating the input according to the structure; providing the input to a first machine learning model; receiving an output from the first machine learning model based on the input; and training a second machine learning model based on the output. The first machine learning model may be a pre-trained generative language model.,ADA SUPPORT INC,GURGU ARMAND SILVIU;;MELIDIS CHRISTOS;;GIBSON GORDON;;SILS ADAM;;GEORGE ASHLEY;;TABATABAEI NIMA;;BHATIA AMAN,,https://lens.org/009-932-318-435-731,Patent Application,yes,0,12,1,009-932-318-435-731,US,1,009-932-318-435-731,US,0,G06N3/096;;G06N3/0455;;G06N3/0475;;G06N5/02;;G06N5/04;;G06N20/00,G06N20/00,,0,0,,,,PENDING
648,WO,A1,WO 2025/088566 A1,152-897-554-505-248,5/1/2025,2025,IB 2024060525 W,10/25/2024,US 202318494631 A,10/25/2023,OBJECT SECURITY CONTROL,"A system for managing access to objects in a computing system. The system includes processes to allow users to request access to objects, and the automated review of such requests. The system is configured to consider a wide range of factors, including the content of the request and the object requested, information relating to the user, and metadata relating to the document, as well as user behaviours. Natural language analysis is utilised to analyse a user's request for access and the object to which access is requested.",VARONIS SYSTEMS,SNE RON;;BELGI AMIR;;NEYSTADT JOHN EUGENE;;KADEC ORR,,https://lens.org/152-897-554-505-248,Patent Application,yes,5,0,2,147-272-012-949-396;;152-897-554-505-248,US;;WO,2,147-272-012-949-396;;152-897-554-505-248,US;;WO,0,G06F21/6218;;G06F21/604;;G06F2221/2141;;H04L63/102;;H04L63/105;;G06F21/6209;;G06F40/216;;G06F21/604,G06F21/60;;G06F21/62;;H04L9/40,,0,0,,,,PENDING
649,US,A1,US 2025/0071074 A1,033-720-595-096-219,2/27/2025,2025,US 202318497055 A,10/30/2023,US 202318497055 A;;US 202363578929 P,8/25/2023,SYSTEMS AND METHODS FOR LLM-ASSISTED EMAIL AUTOMATION,"In some implementations, the techniques described herein relate to a method including: (i) identifying, by a processor, an electronic message addressed to an inbox of a user that comprises a confirmation of a transaction involving a platform, (ii) searching, by the processor, for an additional electronic message addressed to the inbox indicating an alteration applicable to the transaction, (iii) causing display, by the processor, of a prompt informing the user of the alteration applicable to the transaction, (iv) composing, by a large language model (LLM) executed by the processor, a potential electronic message to an operator of the platform requesting the alteration be retroactively applied to the transaction, and (v) in response to receiving user input regarding the potential electronic message, sending, by the processor, a subsequent electronic message to the operator of the platform requesting the alteration be retroactively applied to the transaction.",YAHOO ASSETS LLC,SEBASTIAN KENNETH;;WANG CAROL;;ANTONOVSKY GREGORY;;DHANAGOPAL RENGANATHAN;;UPRETI SURAJ;;YANG EDWARD;;SHIRWADKAR SANIKA;;RANE CHINMAY;;MAREEDU PRAVEEN;;OOSTERHOF LIPPE;;GANDHI KAIVALYA NIRANJAN;;PIVA MARIA,YAHOO ASSETS LLC (2023-08-28),https://lens.org/033-720-595-096-219,Patent Application,yes,0,0,1,033-720-595-096-219,US,1,033-720-595-096-219,US,0,G06F40/205;;G06Q30/0207;;H04L51/21;;H04L51/063;;G06Q10/107;;G06Q30/06;;H04L51/063;;G06Q10/107;;G06F40/205;;G06Q30/06;;G06Q30/0207;;H04L51/21,H04L51/063;;G06F40/205;;G06Q10/107;;G06Q30/0207;;G06Q30/06;;H04L51/21,,0,0,,,,PENDING
650,WO,A1,WO 2024/112393 A1,009-970-878-101-315,5/30/2024,2024,US 2023/0035462 W,10/19/2023,US 202263427079 P;;US 202318132356 A,11/21/2022,REAL-TIME SYSTEM FOR SPOKEN NATURAL STYLISTIC CONVERSATIONS WITH LARGE LANGUAGE MODELS,"The techniques disclosed herein enable systems for spoken natural stylistic conversations with large language models. In contrast to many existing modalities for interacting with large language models that are limited to text, the techniques presented herein enable users to carry a fully spoken conversation with a large language model. This is accomplished by converting a user speech audio input to text and utilizing a prompt engine to analyze a sentiment expressed by the user. A large language model, having been trained on example conversations, by generating a text response as well as a style cue to express emotion in response to the sentiment expressed by speech audio input. A text-to-speech engine can subsequently interpret the text response and style cue to generate an audio output which emulates the sensation of human conversation.",MICROSOFT TECHNOLOGY LICENSING LLC,BONAR ADRIAN WYATT;;FOX JENNIFER;;BERDY NICOLE E;;MUNOZ MOLLIE;;CALLEGARI SHAWN;;LUCATO DEVIS;;VOLUM RYAN,,https://lens.org/009-970-878-101-315,Patent Application,yes,2,2,1,009-970-878-101-315,WO,2,074-065-706-269-880;;009-970-878-101-315,US;;WO,0,G06F40/30,G06F40/30,,0,0,,,,PENDING
651,US,A1,US 2024/0062016 A1,134-595-674-172-71X,2/22/2024,2024,US 202318496794 A,10/27/2023,US 202318496794 A;;US 202318190867 A;;US 202117234666 A;;US 202063011857 P;;US 202263381248 P,4/17/2020,Systems and Methods for Textual Classification Using Natural Language Understanding Machine Learning Models for Automating Business Processes,"In one embodiment, a method for detecting intent of a textual message for a business records process includes receiving a request message, extracting text and metadata from the request message, executing semantic queries to determine an intent of the request message, by, for each semantic query, where the semantic query specifies a machine learning language model to be used, what text and metadata from the message and textual prompt to provide to each machine learning language model, and a formatting template specifying how an expected answer from each machine learning language model should be formatted, providing some of the extracted text and metadata and a textual prompt to each machine learning language model as specified in the semantic query, receiving an answer from each machine learning language model that includes an indication of an intent classification, and performing a corresponding business action in response to the indicated intent classification.",AUDITORIA AI INC,TONG TAO;;REDDY LATTUPALLY CHANDRATEJA;;AU HAI;;JOSHI ANUVRATH RAVINDRANATH;;CLIFTON AARON RICHARD,AUDITORIA.AI INC (2024-01-24),https://lens.org/134-595-674-172-71X,Patent Application,yes,3,17,1,134-595-674-172-71X,US,6,006-202-512-164-177;;075-729-887-135-878;;134-595-674-172-71X;;196-429-752-583-158;;134-921-531-014-600;;127-629-560-408-607,US;;WO,0,G06F40/30;;G06F40/20;;G06F40/30,G06F40/30;;G06F40/20,,1,0,,,"Provost, Data Science for Business, pp. 1-69, Aug (Year: 2019)",PENDING
652,US,B1,US 12222898 B1,086-012-013-913-959,2/11/2025,2025,US 202418886129 A,9/16/2024,US 202418886129 A,9/16/2024,AI platform for processing and querying specified objects,"An AI based system and method for processing and querying files. A method of processing files for an artificial intelligence (AI) querying service includes: hierarchically parsing the files into a set of hierarchically connected data chunks; generating metadata for each of the hierarchically connected data chunks, wherein the metadata includes hierarchical information; processing the hierarchically connected data chunks and metadata with an embedding model to generate vector embeddings that include the hierarchical information; generating textual summaries from the hierarchically connected data chunks; and storing the vector embeddings, textual summaries, and hierarchically connected data chunks for the AI querying service.",UTECH PRODUCTS INC,MADAN RAKESH K;;JAFFRI ZOHAIR HUSSAIN;;ALAGURAJAH JEEVITHAN;;MADAN MANISH K,UTECH PRODUCTS INC (2024-09-13),https://lens.org/086-012-013-913-959,Granted Patent,yes,1,0,1,086-012-013-913-959,US,1,086-012-013-913-959,US,0,G06F16/148;;G06F16/9024;;G06F16/90332;;G06F16/148;;G06F16/156;;G06F16/144;;G06F16/185,G06F16/00;;G06F16/14;;G06F16/185,,0,0,,,,ACTIVE
653,US,B1,US 12370947 B1,085-822-267-867-057,7/29/2025,2025,US 19004814,12/30/2024,,,"Train crossing warning system, apparatuses and methods therefor","A disclosed method implements: determining, by a cloud server, a geofence surrounding a section of a roadway at a crossing of train tracks, the geofence comprising geofence coordinates; monitoring, by the cloud server, railway sensor and telematics data related to trains running on the train tracks at the crossing; predicting that a train will approach the crossing at a predicted time; generating a warning message in response to predicting that a train will approach the crossing at a predicted time; and sending the warning message to a vehicle located within the geofence.","RAPIDSOS, INC.",Daniel Richard Seidberg,,https://lens.org/085-822-267-867-057,Granted Patent,yes,28,0,1,085-822-267-867-057,US,1,085-822-267-867-057,US,0,B60Q9/008;;B61L25/025;;H04W4/021;;H04W4/40,B60Q9/00;;B61L25/02;;H04W4/021;;H04W4/40,,0,0,,,,UNKNOWN
654,US,A1,US 2024/0095463 A1,036-068-428-967-421,3/21/2024,2024,US 202217947946 A,9/19/2022,US 202217947946 A,9/19/2022,NATURAL LANGUAGE PROCESSING APPLICATIONS USING LARGE LANGUAGE MODELS,"Approaches presented herein can provide for the performance of specific types of tasks using a large model, without a need to retrain the model. Custom endpoints can be trained for specific types of tasks, as may be indicated by the specification of one or more guidance mechanisms. A guidance mechanism can be added to or used along with a request to guide the model in performing a type of task with respect to a string of text. An endpoint receiving such a request can perform any marshalling needed to get the request in a format required by the model, and can add the guidance mechanisms to the request by, for example, prepending one or more text strings (or text prefixes) to a text-formatted request. A model receiving this string can process the text according to the guidance mechanisms. Such an approach can allow for a variety of tasks to be performed by a single model.",NVIDIA CORP,LEARY RYAN;;COHEN JONATHAN,NVIDIA CORPORATION (2022-09-23),https://lens.org/036-068-428-967-421,Patent Application,yes,6,14,4,001-424-088-300-265;;004-123-249-544-229;;036-068-428-967-421;;161-581-106-725-293,US;;DE;;CN;;JP,4,001-424-088-300-265;;004-123-249-544-229;;036-068-428-967-421;;161-581-106-725-293,US;;DE;;CN;;JP,0,G06F40/30;;G06F40/20;;G06F40/284;;G06F40/40;;G06F40/284;;G06F40/40,G06F40/40;;G06F40/284,,2,2,046-318-837-994-078;;141-050-737-093-773,10.1109/icufn.2016.7536948;;10.1109/dexa.2004.1333441,"Ly Pichponreay, Jin-Hyuk Kim, Chi-Hwan Choi, Kyung-Hee Lee and Wan-Sup Cho, ""Smart answering Chatbot based on OCR and Overgenerating Transformations and Ranking,"" 2016 Eighth International Conference on Ubiquitous and Future Networks (ICUFN), Vienna, 2016, pp. 1002-1005, doi: 10.1109/ICUFN.2016.75369 (Year: 2016);;M. Palmirani, R. Brighi and M. Massini, ""Processing normative references on the basis of natural language questions,"" Proceedings. 15th International Workshop on Database and Expert Systems Applications, 2004., Zaragoza, Spain, 2004, pp. 9-12, doi: 10.1109/DEXA.2004.1333441. keywords: {Natural langua (Year: 2004)",PENDING
655,US,A1,US 2024/0340302 A1,169-952-280-547-008,10/10/2024,2024,US 202418628625 A,4/5/2024,US 202418628625 A;;US 202363457557 P,4/6/2023,AMPLIFICATION OF FORMAL METHOD AND FUZZ TESTING TO ENABLE SCALABLE ASSURANCE FOR COMMUNICATION SYSTEM,"Methods for more secure mobile network communications are disclosed. Specifically, details involving natural language processing (NLP) based auto formal modeling of protocols and specifications with large language models (NLP) are provided. Methods for formal and fuzzing amplification for fuzz testing to detect vulnerabilities are also disclosed. Furthermore, solutions are provided to identified vulnerabilities in existing 5G infrastructures. Also disclosed is a digital twin fuzzing framework.",STEVENS INSTITUTE OF TECHNOLOGY,WANG YING;;YANG JINGDA,,https://lens.org/169-952-280-547-008,Patent Application,yes,0,6,2,072-920-095-848-112;;169-952-280-547-008,US,2,072-920-095-848-112;;169-952-280-547-008,US,0,G06F40/20;;H04L63/1433;;G06N5/048;;G06F2221/033;;G06F21/577;;G06N20/00;;G06F40/20;;H04L63/1433;;G06F21/577;;G06F2221/033;;G06N5/048,H04L9/40;;G06F40/20,,0,0,,,,PENDING
656,US,A1,US 2025/0165618 A1,147-316-129-152-657,5/22/2025,2025,US 202418900430 A,9/27/2024,US 202418900430 A;;US 202418792523 A;;US 202418607141 A;;US 202318399422 A;;US 202318327040 A;;US 202318114194 A;;US 202318098895 A,1/19/2023,GENERATIVE CYBERSECURITY EXPLOIT DISCOVERY AND EVALUATION,"Described herein are systems and methods for discovering and proactively mitigating previously unknown security vulnerabilities. The systems and methods herein can utilize security vulnerability information to discover potential security threats and can utilize this information to generate an attack using a machine learning model, such as a large language model. Generated attacks can be carried out to assess impact of a security vulnerability. An output can be provided that represents the assessed impact. In some implementations, the systems and methods herein generate patches or other mitigations for security vulnerabilities, which can be tested and deployed to address security vulnerabilities.",CITIBANK NA,CAMERON WILLIAM FRANKLIN;;GOYAL PRAMOD;;RAO PRITHVI NARAYANA;;RAJARETNAM MANJIT;;SILVER MIRIAM;;MYERS JAMES,CITIBANK N.A (2024-10-28),https://lens.org/147-316-129-152-657,Patent Application,yes,12,0,2,120-491-497-842-713;;147-316-129-152-657,US,36,166-860-055-274-237;;192-529-172-020-159;;117-165-481-521-817;;062-084-390-952-648;;009-332-012-767-769;;130-711-467-813-772;;150-084-174-776-205;;134-859-487-724-028;;136-076-696-451-742;;174-498-778-674-614;;135-411-020-650-37X;;082-042-370-293-809;;081-164-654-051-886;;126-999-415-386-749;;101-393-155-626-043;;028-517-317-595-400;;183-393-311-078-435;;120-491-497-842-713;;071-444-314-653-665;;151-710-271-944-022;;169-310-367-816-659;;114-332-483-825-36X;;176-222-606-932-299;;109-693-731-347-460;;187-959-165-043-749;;165-235-788-605-427;;184-797-936-150-334;;129-627-428-962-735;;132-864-126-338-301;;147-316-129-152-657;;087-574-341-939-358;;052-233-397-211-176;;154-552-332-382-958;;158-104-528-887-831;;122-629-432-281-208;;053-045-267-490-224,US;;WO;;EP,0,G06F21/552;;G06F21/577;;G06F2221/034;;G06F21/577;;G06F21/552,G06F21/57;;G06F21/55,,0,0,,,,ACTIVE
657,US,A1,US 2025/0165617 A1,176-222-606-932-299,5/22/2025,2025,US 202418900216 A,9/27/2024,US 202418900216 A;;US 202418792523 A;;US 202418607141 A;;US 202318399422 A;;US 202318327040 A;;US 202318114194 A;;US 202318098895 A,1/19/2023,GENERATIVE CYBERSECURITY EXPLOIT DISCOVERY AND EVALUATION,"Described herein are systems and methods for discovering and proactively mitigating previously unknown security vulnerabilities. The systems and methods herein can utilize security vulnerability information to discover potential security threats and can utilize this information to generate an attack using a machine learning model, such as a large language model. Generated attacks can be carried out to assess impact of a security vulnerability. An output can be provided that represents the assessed impact. In some implementations, the systems and methods herein generate patches or other mitigations for security vulnerabilities, which can be tested and deployed to address security vulnerabilities.",CITIBANK NA,CAMERON WILLIAM FRANKLIN;;GOYAL PRAMOD;;RAO PRITHVI NARAYANA;;RAJARETNAM MANJIT;;SILVER MIRIAM,CITIBANK N.A (2024-10-28),https://lens.org/176-222-606-932-299,Patent Application,yes,12,0,1,176-222-606-932-299,US,36,166-860-055-274-237;;192-529-172-020-159;;117-165-481-521-817;;062-084-390-952-648;;009-332-012-767-769;;130-711-467-813-772;;150-084-174-776-205;;134-859-487-724-028;;136-076-696-451-742;;174-498-778-674-614;;135-411-020-650-37X;;082-042-370-293-809;;081-164-654-051-886;;126-999-415-386-749;;101-393-155-626-043;;028-517-317-595-400;;183-393-311-078-435;;120-491-497-842-713;;071-444-314-653-665;;151-710-271-944-022;;169-310-367-816-659;;114-332-483-825-36X;;176-222-606-932-299;;109-693-731-347-460;;187-959-165-043-749;;165-235-788-605-427;;184-797-936-150-334;;129-627-428-962-735;;132-864-126-338-301;;147-316-129-152-657;;087-574-341-939-358;;052-233-397-211-176;;154-552-332-382-958;;158-104-528-887-831;;122-629-432-281-208;;053-045-267-490-224,US;;WO;;EP,0,G06F21/552;;G06F21/577;;G06F2221/034;;G06F21/577;;G06F21/552,G06F21/57;;G06F21/55,,0,0,,,,PENDING
658,US,A1,US 2025/0190693 A1,068-461-810-399-252,6/12/2025,2025,US 202519054800 A,2/15/2025,US 202519054800 A;;US 2024/0050403 W;;US 202463719137 P;;US 202463715666 P;;US 202463712475 P;;US 202463711078 P;;US 202463708233 P;;US 202363588835 P,10/9/2023,Computer-Implemented Methods and Systems for Generative Text Painting,"A system and method for transforming text within documents using, such as by using large language models (LLMs). Users can select source text from a source document, in response to which a painting configuration is identified or generated based on the source text, such as by providing the source text and a source prompt to a large language model to produce source output, and selecting or generating the painting configuration based on the source output. The user can select destination text, in response to which the painting configuration is applied to the destination text, such as by selecting or generating a destination action definition based on the painting configuration and the destination text, and providing the destination action definition to a large language model to produce destination output. The destination text may be replaced with the destination output, or output derived therefrom. In this way, the system can extract a variety of sophisticated properties, such as style or tone, from user-selected text source text, and apply those properties to user-selected destination text, with minimal user input.",QUABBIN PATENT HOLDINGS INC,PLOTKIN ROBERT,QUABBIN PATENT HOLDINGS INC (2024-10-08),https://lens.org/068-461-810-399-252,Patent Application,yes,8,0,1,068-461-810-399-252,US,2,068-461-810-399-252;;173-703-443-920-733,US;;WO,0,G06F40/186;;G06F40/30;;G06F40/166;;G06F3/04842;;G06F40/186;;G06F3/04842;;G06F40/30,G06F40/186;;G06F3/04842;;G06F40/30,,0,0,,,,PENDING
659,US,A1,US 2025/0117854 A1,084-406-654-710-43X,4/10/2025,2025,US 202318481145 A,10/4/2023,US 202318481145 A,10/4/2023,GENERATING PORTFOLIO CHANGES BASED ON UPCOMING LIFE EVENT,"An example operation may include one or more of storing a portfolio of assets of a user in memory, receiving text from a conversation between the user on a first device and a second user on a second device, identifying an upcoming life event of the user based on execution of a generative artificial intelligence (GenAI) model on the received text from the conversation, determining a change to the portfolio of assets of the user based on the upcoming life event and existing assets within the portfolio of assets, and displaying the change to the portfolio of assets of the user via a user interface.",TORONTO DOMINION BANK,PANDEY ANAND;;TRIVEDI PRERAK;;TAO LINDA LING;;LEE JOHN JONG-SUK,,https://lens.org/084-406-654-710-43X,Patent Application,yes,0,0,1,084-406-654-710-43X,US,1,084-406-654-710-43X,US,0,G06N3/0475;;G06N3/0455;;G06Q40/06;;G06Q40/06;;G06N3/0455;;G06N3/0475,G06Q40/06;;G06N3/0455;;G06N3/0475,,0,0,,,,PENDING
660,US,A1,US 2025/0047968 A1,064-235-373-883-693,2/6/2025,2025,US 202418899732 A,9/27/2024,KR 20230088242 A;;KR 20230113506 A;;KR 2024009708 W,7/7/2023,METHOD FOR SUPPORTING IMAGE CAPTURING AND ELECTRONIC DEVICE SUPPORTING SAME,"Embodiments of the disclosure provide a method for supporting image capturing and an electronic device for supporting the same. The electronic device may include a first camera, a second camera disposed on an opposite surface to the first camera, a display, a memory, and at least one processor. The at least one processor may obtain a first image from at least one camera of the first camera and the second camera, based on executing an application. The at least one processor may analyze the first image. The at least one processor may determine a designated shooting mode, based on analyzing the first image. The at least one processor may display a graphic element on the display, based on determining the designated shooting mode. The at least one processor may determine a designated camera to operate in the designated shooting mode, based on a user input to capture an image. The at least one processor may capture a second image by using the designated camera.",SAMSUNG ELECTRONICS CO LTD,CHUNG MIYEOUNG;;KIM SANGGEON;;KIM SOORYUH;;KIM HEEWOONG;;PARK JEONGMIN,SAMSUNG ELECTRONICS CO. LTD (2024-09-12),https://lens.org/064-235-373-883-693,Patent Application,yes,0,1,2,064-235-373-883-693;;046-053-132-161-251,US;;WO,5,064-235-373-883-693;;085-295-012-019-302;;046-053-132-161-251;;098-596-568-417-550;;158-516-879-900-429,US;;WO;;EP;;KR,0,H04N23/61;;H04N23/90;;H04N23/57;;H04N23/667;;H04N23/62;;H04N23/63;;H04N23/611;;H04N23/632;;H04N23/667;;H04N23/632;;H04N23/611,H04N23/611;;H04N23/63;;H04N23/667,,0,0,,,,PENDING
661,EP,A1,EP 4521764 A1,158-516-879-900-429,3/12/2025,2025,EP 24745612 A,7/8/2024,KR 20230088242 A;;KR 20230113506 U;;KR 2024009708 W,7/7/2023,"METHOD FOR SUPPORTING IMAGE CAPTURING, AND ELECTRONIC DEVICE FOR SUPPORTING SAME","Embodiments of the disclosure provide a method for supporting image capturing and an electronic device for supporting the same. The electronic device may include a first camera, a second camera disposed on an opposite surface to the first camera, a first display, a memory, and at least one processor. The at least one processor may obtain at least one first image from at least one of the first camera and the second camera. The at least one processor may analyze the at least one first image. The at least one processor may determine a designated shooting mode, based on analyzing the at least one first image. The at least one processor may display a graphic element on the first display, based on determining the designated shooting mode. The at least one processor may capture a second image by using a designated camera, the designated camera being one of the first camera or the second camera.",SAMSUNG ELECTRONICS CO LTD,CHUNG MIYEOUNG;;KIM SANGGEON;;KIM SOORYUH;;KIM HEEWOONG;;PARK JEONGMIN,,https://lens.org/158-516-879-900-429,Patent Application,yes,0,0,2,098-596-568-417-550;;158-516-879-900-429,EP,5,064-235-373-883-693;;085-295-012-019-302;;046-053-132-161-251;;098-596-568-417-550;;158-516-879-900-429,US;;WO;;EP;;KR,0,H04N23/57;;H04N23/61;;H04N23/62;;H04N23/63;;H04N23/667;;H04N23/90;;H04N23/631,H04N23/667;;H04N23/57;;H04N23/61;;H04N23/62;;H04N23/63;;H04N23/90,,0,0,,,,PENDING
662,US,A1,US 2025/0217428 A1,157-004-234-054-952,7/3/2025,2025,US 202418982645 A,12/16/2024,US 202418982645 A;;US 202363616468 P,12/29/2023,Web Browser with Integrated Vector Database,A web browsing application can implement a vector database to store session data. A web browsing application can automatically embed loaded web content into an embedded data store that maintains session data for a number of web sessions. A user can query the web browser using simple instructions. The web browser can interpret the instructions and use the embedded data store to quickly search across multiple modalities of embedded data to retrieve relevant results. The web browser can use machine-learned models to answer queries or perform other tasks by performing vector-based queries over the content of visited web data.,GOOGLE LLC,PEDERSEN ZEBEDEE;;RUBINOVITZ YASMINE,,https://lens.org/157-004-234-054-952,Patent Application,yes,0,0,1,157-004-234-054-952,US,1,157-004-234-054-952,US,0,G06F16/9535;;G06F16/9538;;G06F16/2237;;G06F16/9538;;G06F16/2237;;G06F16/9535,G06F16/9538;;G06F16/22;;G06F16/9535,,0,0,,,,PENDING
663,US,A1,US 2025/0119495 A1,098-066-111-458-178,4/10/2025,2025,US 202318481125 A,10/4/2023,US 202318481125 A,10/4/2023,REAL-TIME DYNAMIC VISUALIZATION OF CONTENT,"An example operation may include one or more of displaying a report on a user interface of a software application on a user device, listening to a call between a user on the user device and a different user on a second user device that is connected to the user device via a network, executing a generative artificial intelligence (GenAI) model based on content that is heard during the call and content within the report displayed on the user interface to identify content within the displayed report that is discussed during the call, and modifying the displayed report to emphasize the identified content within the displayed report on the user interface.",TORONTO DOMINION BANK,PANDEY ANAND;;TRIVEDI PRERAK;;TAO LINDA LING;;LEE JOHN JONG-SUK,,https://lens.org/098-066-111-458-178,Patent Application,yes,0,0,1,098-066-111-458-178,US,1,098-066-111-458-178,US,0,G06N3/0475;;H04M3/42221;;G06N3/0475;;H04M3/42221,H04M3/42;;G06N3/0475,,0,0,,,,PENDING
664,US,B2,US 11245448 B2,077-481-368-507-525,2/8/2022,2022,US 202117144775 A,1/8/2021,CN 201810744524 A;;CN 2019086714 W,7/9/2018,Antenna connection detection method and apparatus,"An antenna connection detection method and apparatus are provided, to detect whether a connection sequence between communications interfaces of a network side device and antenna elements is incorrect. The method includes that a network side device receives, by using antenna elements connected to a plurality of communications interfaces, reference signals sent by N terminal devices, where N is an integer greater than 0. Then, the network side device determines N channel correlation matrices based on the reference signals sent by the N terminal devices, and then determines, based on the N channel correlation matrices and a preset channel correlation matrix, whether a connection sequence between the plurality of communications interfaces and the antenna elements is incorrect, where one channel correlation matrix is used to represent correlation between transmission channels between the network side device and one terminal device.",HUAWEI TECH CO LTD,ZHANG PENGCHENG,HUAWEI TECHNOLOGIES CO. LTD (2021-01-07),https://lens.org/077-481-368-507-525,Granted Patent,yes,19,0,8,078-145-784-625-153;;077-481-368-507-525;;175-167-722-423-330;;118-204-782-361-04X;;139-226-781-203-866;;142-253-893-974-632;;000-996-121-957-494;;196-093-730-396-97X,US;;WO;;EP;;CN,8,078-145-784-625-153;;077-481-368-507-525;;175-167-722-423-330;;118-204-782-361-04X;;139-226-781-203-866;;142-253-893-974-632;;000-996-121-957-494;;196-093-730-396-97X,US;;WO;;EP;;CN,0,H04B7/0413;;H04B7/0456;;H04B17/10;;H04B17/20;;H04B17/18;;H04B7/0413;;H04B7/10;;H04B7/0469;;H01Q1/246;;H04L5/0048,H01Q1/24;;H04B7/0456;;H04L5/00,,4,0,,,"Extended European Search Report issued in European Application No. 19834227.1 dated Jun. 25, 2021, 9 pages.;;Office Action issued in Chinese Application No. 201810744524.X dated Nov. 18, 2020, 4 pages.;;Office Action issued in Chinese Application No. 201810744524.X dated May 25, 2020, 10 pages (with English translation).;;PCT International Search Report and Written Opinion issued in International Application No. PCT/CN2019/086714 dated Jul. 17, 2019, 15 pages (with English translation).",ACTIVE
665,US,A1,US 2025/0111282 A1,107-467-364-908-554,4/3/2025,2025,US 202418899844 A,9/27/2024,US 202418899844 A;;US 202363541158 P,9/28/2023,ALARM MONITORING AND EVALUATION SYSTEMS AND METHODS,At least one processor may receive vent data describing a plurality of events related to equipment managed by a building management system. The at least one processor may process the event data using at least one machine learning model. Outputs of the at least one machine learning model may include at least a priority label and a probability score for each respective event in the event data. The at least one processor may generate a user interface within the building management system. The user interface may indicate at least the priority label and the probability score for at least one of the events.,CBRE INC,SCHOLTEN ANNO;;NESBITT BRETT;;KAITELL VICTOR;;GREY JOSEPH;;SCHOLTEN MAXX;;EVANS STEVE;;LAHOTI KAPIL RAM,,https://lens.org/107-467-364-908-554,Patent Application,yes,0,0,1,107-467-364-908-554,US,1,107-467-364-908-554,US,0,G06F18/23;;G06F9/451;;G06N20/00;;G06N20/00;;G06F18/23;;G06F9/451,G06N20/00;;G06F9/451;;G06F18/23,,0,0,,,,PENDING
666,US,A1,US 2024/0143161 A1,130-320-460-187-23X,5/2/2024,2024,US 202318384118 A,10/26/2023,US 202318384118 A;;US 202263419390 P,10/26/2022,SYSTEM AND METHOD FOR DIGITIZING AND MINING HANDWRITTEN NOTES TO ENABLE REAL-TIME COLLABORATION,"The invention relates to computer-implemented systems and methods for automatically discerning creation of handwritten verbiage (or typed) on a digital display; converting it to digital text objects that have been repaired (e.g., spelling, punctuation, etc.); and then inserting it as Scalable Vector Graphics onto the display.",KPMG LLP,SISSELMAN MICHAEL;;BERISHA-CORNEJO ANDREW;;DURNO W EVAN;;YU XIAOYU,KPMG LLP (2023-10-06),https://lens.org/130-320-460-187-23X,Patent Application,yes,0,0,1,130-320-460-187-23X,US,1,130-320-460-187-23X,US,0,G06F40/30;;G06F40/171;;G06F3/04845;;G06F3/0481;;G06F3/0482;;G06V30/226;;G06F40/40;;G06F3/04883,G06F3/04883;;G06F40/40,,0,0,,,,PENDING
667,WO,A1,WO 2025/155705 A1,146-282-484-808-818,7/24/2025,2025,US 2025/0011848 W,1/16/2025,US 202463622963 P,1/19/2024,ROBUST TRAINING OF NEURAL NETWORKS AT ARBITRARY PRECISION AND SPARSITY,"For each of a plurality of training iterations, a computing system can generate, using a machine-learned model, one or more training outputs based on one or more training inputs; and update one or more parameters of the machine-learned model based at least in part on the one or more training outputs. In some instances, generating a training output can include scaling a plurality of respective first values, such as activation values or parameters of the machine-learned model, to generate a plurality of scaled values. Generating the training output can include perturbing the plurality of scaled values based on a second precision that is lower than a first precision associated with the respective first values. Generating the training output can include performing a denoising transformation and a first matrix multiplication to generate a denoised approximation of a second matrix multiplication comprising the plurality of respective first values.",GOOGLE LLC,YE CHENGXI;;CHU GRACE;;LIU YANFENG;;LEW LUKASZ;;HOWARD ANDREW GERALD,,https://lens.org/146-282-484-808-818,Patent Application,yes,0,0,1,146-282-484-808-818,WO,1,146-282-484-808-818,WO,0,G06N3/084;;G06N3/0495,G06N3/0495;;G06N3/084,,0,0,,,,PENDING
668,WO,A1,WO 2025/090062 A1,036-501-007-497-083,5/1/2025,2025,US 2023/0035868 W,10/25/2023,US 2023/0035868 W,10/25/2023,GENERATIVE AI APPLIANCE,"In example implementations described herein, there are systems and methods for generating output associated with an industrial application including extracting content and context information associated with the industrial application, producing one or more context- specific large language models (LLMs) by adjusting one or more LLMs based on the content and context information, identifying a triggering event associated with a particular context; and generating a response to the triggering event using a context-specific LLM corresponding to the particular context.",HITACHI VANTARA LLC,LIN WEI;;DAMO MAURO;;KOMMEPALLI HAREESH;;WANG MOHAN;;PATEL BHARTI,,https://lens.org/036-501-007-497-083,Patent Application,yes,6,1,1,036-501-007-497-083,WO,1,036-501-007-497-083,WO,0,G06F16/21;;G06F16/9032;;G06N5/01;;G06N3/0455;;G06N5/022;;G06N3/045,G06F16/9032;;G06F9/451;;G06F16/21;;G06N3/0455;;G06N5/01,,0,0,,,,PENDING
669,US,A1,US 2025/0119494 A1,173-022-017-311-376,4/10/2025,2025,US 202318481102 A,10/4/2023,US 202318481102 A,10/4/2023,AUTOMATED CALL LIST BASED ON SIMILAR DISCUSSIONS,"An example operation may include one or more of receiving content from a conversation between a user on a user device and a second user on a second user device that is connected to the user device via a network, identifying a topic of the conversation based on execution of a generative artificial intelligence (GenAI) model on the received content from the conversation, identifying a call list that is previously stored in memory that is associated with the topic of the conversation based on keywords included in the identified topic of the conversation, and adding an identifier of the user to the call list stored in memory.",TORONTO DOMINION BANK,PANDEY ANAND;;TRIVEDI PRERAK;;TAO LINDA LING;;LEE JOHN JONG-SUK,,https://lens.org/173-022-017-311-376,Patent Application,yes,0,1,1,173-022-017-311-376,US,1,173-022-017-311-376,US,0,H04M3/2218;;G10L15/26;;H04L12/1822;;H04L51/02;;H04L12/1827;;G06Q50/16;;G06Q50/186;;G06Q2220/00;;G06Q40/06;;G06Q30/0241;;G06Q30/015;;G06Q10/109;;G06F40/30;;G06F40/284;;G06F40/216;;H04M3/2218;;G10L2015/088;;G10L15/26;;G10L15/1822,H04M3/22;;G10L15/08;;G10L15/18;;G10L15/26,,0,0,,,,PENDING
670,WO,A2,WO 2025/147287 A2,192-654-562-249-840,7/10/2025,2025,US 2024/0033624 W,6/12/2024,US 202363507908 P,6/13/2023,SYSTEMS AND METHODS FOR ELASTIC BOT CLUSTER DEPLOYMENTS IN CONTINUOUS MODEL TESTING,"Described are platforms, methods, systems, and media configured for testing a model, utilizing operations comprising: identifying a plurality of AI-driven bots, wherein each bot comprises a persona; generating a bot priority score for each bot; determining a number of testing phases; computing the number of bots deployed in each testing phase; determining a resource scaling approach; generating an intelligent scheduling score for each bot; and deploying the plurality of bots, over a network, to test the model according to the priority scores, the testing phases, the resource scaling approach, and the intelligent scheduling scores.",MILLION DOORS INC,TRIM CRAIG M;;KAO JOHN JIEN,,https://lens.org/192-654-562-249-840,Patent Application,yes,0,0,1,192-654-562-249-840,WO,1,192-654-562-249-840,WO,0,,G06F11/3668,,0,0,,,,PENDING
671,US,A1,US 2024/0273584 A1,097-344-953-175-175,8/15/2024,2024,US 202418440051 A,2/13/2024,US 202418440051 A;;US 202363445115 P,2/13/2023,ARTIFICIAL INTELLIGENCE COACH FOR PROVIDING CUSTOMER SERVICE FEEDBACK TO EMPLOYEES,"An artificial intelligence coach is provided that can automatically generate customer service feedback for employees of a company. In one example, a computer system can generate an input for the artificial intelligence coach, the input including custom input data that is associated with an employee. The computer system can provide the input to the artificial intelligence coach. The artificial intelligence coach can be configured to generate an output based on the custom input data. The output can include customer service feedback for the employee. The computer system can then transmit the customer service feedback to a client device of the employee via a network.",THE DGC GROUP,GONIER DEVIN,THE DGC GROUP (2024-03-26),https://lens.org/097-344-953-175-175,Patent Application,yes,16,1,1,097-344-953-175-175,US,1,097-344-953-175-175,US,0,G06Q30/0282;;G06Q30/0282,G06Q30/0282,,0,0,,,,PENDING
672,US,A1,US 2024/0428005 A1,098-744-285-355-304,12/26/2024,2024,US 202318211808 A,6/20/2023,US 202318211808 A,6/20/2023,GENERATING GROUNDED DOCUMENTS USING LARGE LANGUAGE MODELS,"The present disclosure relates to methods and systems for automatically generating documents for a specific topic using large language models. The methods and systems receive an input query that identifies a topic for the document. The methods and systems automatically generate, using the large language models, a framework for the document with sections and subsections for the document. The methods and systems write the document, using the large language models, and provide references for the data sources used to obtain the data that the large language model used to write the document.",MICROSOFT TECHNOLOGY LICENSING LLC,ABRAHAM ROBIN;;XU MINGYANG;;CHEN JULIA;;XIANG YIJIAN;;MAO MANQING;;LIN JIANZHE;;TING PAISHUN;;DU LIANG,MICROSOFT TECHNOLOGY LICENSING LLC (2024-03-21),https://lens.org/098-744-285-355-304,Patent Application,yes,10,0,2,098-744-285-355-304;;005-861-785-120-447,US;;WO,2,098-744-285-355-304;;005-861-785-120-447,US;;WO,0,G06F16/3344;;G06F16/38;;G06F16/3344;;G06F40/40;;G06F40/177,G06F40/40;;G06F16/33;;G06F40/177,,2,1,066-527-887-472-872,10.18653/v1/2023.findings-emnlp.467,"Nakano et al., ""Webgpt: Browser-assisted question-answering with human feedback."" arXiv preprint arXiv:2112.09332 (Year: 2021);;Liu et al., ""Evaluating verifiability in generative search engines."" arXiv preprint arXiv:2304.09848 (Year: 2023)",PENDING
673,US,A1,US 2025/0232766 A1,148-791-491-957-350,7/17/2025,2025,US 202519016435 A,1/10/2025,US 202519016435 A;;US 202463620530 P,1/12/2024,NEXT-GEN AI INTERACTIVE VOICE RESPONSE SYSTEMS AND METHODS FOR ROADSIDE ASSISTANCE,"An interaction voice response apparatus and method includes obtaining, from a chat bot, interaction data from an interaction with a user and based on a prompt, generating, with a large language model communicatively coupled to the chat bot and directed by the prompt, content based on the interaction data from the interaction with the user corresponding to data fields in a format defined by the prompt, wherein the content comprises direct extractions directly extracted from the interaction data, inferences deduced from the interaction data, or combinations thereof, generating, with the large language model, deduction flag indications, wherein a positive deduction flag indication of the deduction flag indications is generated when the content comprises an inference of the inferences, and outputting a data set comprising at least one next intent recommendation as a deduction based on the content and the indications in the format.",ALLSTATE INSURANCE CO,WALTERS KYLE;;TARVIN BRANDON;;BUCCO TODD;;COULTER MICHAEL,,https://lens.org/148-791-491-957-350,Patent Application,yes,0,0,1,148-791-491-957-350,US,1,148-791-491-957-350,US,0,G10L15/183;;G06F40/103;;G06Q30/015;;G10L15/1815;;G06F9/453;;G10L15/22,G10L15/183;;G06F9/451;;G06F40/103;;G06Q30/015;;G10L15/18;;G10L15/22,,0,0,,,,PENDING
674,US,B1,US 12182539 B1,088-458-232-557-850,12/31/2024,2024,US 202418669421 A,5/20/2024,US 202418669421 A;;US 202318535001 A,12/11/2023,Systems and methods for modifying decision engines during software development using variable deployment criteria,"Systems and methods provide a first deployment criterion for deploying modified decision engines. A first existing decision engine is accessed, as well as a first modified decision engine that includes rule data generated by an artificial intelligence model based on the first existing decision engine. A first difference between a first output and a first modified output is determined, where the first output is generated by the first existing decision engine and the first modified output is generated by the first modified decision engine. A first selected decision engine is deployed to process subsequent data items to produce subsequent outputs, based on whether the first difference satisfies first deployment criterion. When metric generated based on the subsequent outputs satisfies a criterion modification condition, the artificial intelligence model is used to generate a second deployment criterion, wherein a second selected rule-based decision engine is deployed based on the second deployment criterion.",CITIBANK NA,MYERS JAMES;;SILVER MIRIAM,CITIBANK N.A (2023-12-07),https://lens.org/088-458-232-557-850,Granted Patent,yes,26,0,1,088-458-232-557-850,US,9,029-896-635-687-836;;153-832-473-000-677;;193-633-581-788-608;;008-197-963-435-473;;095-237-791-646-678;;075-469-762-619-491;;088-458-232-557-850;;064-693-030-404-249;;037-391-572-754-742,US;;WO;;EP,0,G06F8/60;;G06F8/77;;G06N5/025;;G06N20/00;;G06F8/20;;G06F40/20;;G06F8/71;;G06F40/20;;G06F8/20,G06F8/20;;G06F40/20,,6,5,050-586-324-044-478;;024-946-819-320-693;;187-225-234-054-554;;005-798-776-780-92X;;101-425-910-725-787,10.1109/icsec.2013.6694743;;10.1109/icicict.2014.6781260;;10.1145/3613904.3642018;;10.1109/tse.2011.24;;10.1109/access.2024.3436902,"Rattanasawad et al, “A Review and Comparison of Rule Languages and Rule-based Inference Engines for the Semantic Web”, IEEE, pp. 1-6 (Year: 2013).;;Verma et al, “Integration of Rule based and Case based Reasoning System to Support Decision Making”, IEEE, pp. 106-108 (Year: 2014).;;Vereschak et al, “Trust in AI-assisted Decision Making: Perspectives from Those Behind the System and Those for Whom the Decision is Made”, ACM, pp. 1-14 (Year: 2024).;;Cuadrado et al, “An Autonomous Engine for Services Configuration and Deployment”, IEEE, pp. 520-536 (Year: 2012).;;Halvoník et al, “Large Language Models and Rule-Based Approaches in Domain-Specific Communication”, IEEE, pp. 107046-107058 (Year: 2024).;;Vartak et al “Modeldb: A System for Machine Learning Model Management”, ACM, pp. 1-3 (Year: 2016).",ACTIVE
675,US,A1,US 2025/0094722 A1,035-824-132-768-487,3/20/2025,2025,US 202418968920 A,12/4/2024,CN 202410168741 A,2/5/2024,ANNOTATION METHOD FOR LARGE LANGUAGE MODEL,"An annotation method for a large language model, an electronic device, and a medium are provided. The method may include: obtaining a plurality of response texts that are generated by a large language model for a request text and that meet a difference requirement; obtaining a plurality of scores corresponding to the plurality of response texts, where each of the plurality of scores indicates a degree to which a corresponding response text in the plurality of response texts matches the request text; and obtaining an annotated text for at least one of the plurality of response texts based on the plurality of scores, where the annotated text is used to adjust a parameter of the large language model.",BEIJING BAIDU NETCOM SCI & TECH CO LTD,DAI DAI;;WU HUA;;HU GANGQIANG,BEIJING BAIDU NETCOM SCIENCE TECHNOLOGY CO. LTD (2024-11-27),https://lens.org/035-824-132-768-487,Patent Application,yes,0,0,3,035-824-132-768-487;;027-410-573-378-927;;110-437-124-451-859,US;;CN;;JP,3,035-824-132-768-487;;027-410-573-378-927;;110-437-124-451-859,US;;CN;;JP,0,G06N5/041;;G06N20/00;;G06F40/30;;G06F40/169;;G06F40/30,G06F40/30,,0,0,,,,PENDING
676,US,A1,US 2025/0068398 A1,071-690-497-473-74X,2/27/2025,2025,US 202318237681 A,8/24/2023,US 202318237681 A,8/24/2023,METHOD AND SYSTEM FOR AUTOMATIC WORKFLOW GENERATION BY LARGE LANGUAGE MODELS,"A method for using a large language model to generate executable code for workflow execution in a manner that integrates user feedback and adjusts the workflow as needed while preserving data privacy is provided. The method includes: receiving first information that relates to a workflow context, second information that relates to at least one application programming interface (API), and third information that relates to a code generation request; using the received information to generate a lecture, and transmitting the lecture to a language model; receiving a user query that relates to performing a task, and transmitting the query to the language model; receiving a workflow that is automatically generated by the language model based on the lecture and the query; and executing the workflow in order to generate an output that is responsive to the query.",JPMORGAN CHASE BANK NA,ZENG ZHEN;;WATSON WILLIAM;;CHO NAAN;;RAHIMI SABA;;BALCH TUCKER RICHARD;;VELOSO MANUELA,JPMORGAN CHASE BANK N.A (2023-10-17),https://lens.org/071-690-497-473-74X,Patent Application,yes,3,3,1,071-690-497-473-74X,US,1,071-690-497-473-74X,US,0,G06F8/35;;G06Q40/06;;G06F9/5038;;G06N3/0475;;G06F8/35;;G06Q40/06;;G06F9/54,G06F8/35;;G06F9/54,,0,0,,,,PENDING
677,US,A1,US 2025/0117856 A1,017-253-976-468-40X,4/10/2025,2025,US 202318481154 A,10/4/2023,US 202318481154 A,10/4/2023,GOAL TRACKING AND GOAL-BASED ADVICE GENERATION,"An example operation may include one or more of receiving a current status of a portfolio of a user and previous actions taken on the portfolio of the user over a predetermined period of time, determining a goal for the user based on execution of a generative artificial intelligence (GenAI) model on the current status of the portfolio of the user and the previous actions taken, receiving a request for the portfolio of the user via a user device, and in response to the request, generating a text-based description of the goal and displaying the text-based description of the goal with portfolio content from the portfolio of the user on a user interface of the user device.",TORONTO DOMINION BANK,PANDEY ANAND;;TRIVEDI PRERAK;;TAO LINDA LING;;LEE JOHN JONG-SUK,,https://lens.org/017-253-976-468-40X,Patent Application,yes,2,1,1,017-253-976-468-40X,US,1,017-253-976-468-40X,US,0,G06F40/40;;G06Q40/06;;G06F40/40;;G06Q40/06,G06Q40/06;;G06F40/40,,0,0,,,,PENDING
678,US,A1,US 2025/0117855 A1,107-995-658-693-041,4/10/2025,2025,US 202318481149 A,10/4/2023,US 202318481149 A,10/4/2023,PREDICTING PERFORMANCE OF A PORTFOLIO WITH ASSET OF INTEREST,"An example operation may include one or more of storing a current portfolio of a user in memory, receiving contextual data of the user from a user device of the user, identifying an asset of interest of the user based on execution of a generative artificial intelligence (GenAI) model based on the received contextual data of the user and the current portfolio of the user stored in memory, predicting a performance of the current portfolio with the identified asset of interest included therein at a future point in time, and displaying the predicted performance of the current portfolio with the identified asset of interest included therein on a user interface.",TORONTO DOMINION BANK,PANDEY ANAND;;TRIVEDI PRERAK;;TAO LINDA LING;;LEE JOHN JONG-SUK,,https://lens.org/107-995-658-693-041,Patent Application,yes,3,0,1,107-995-658-693-041,US,1,107-995-658-693-041,US,0,G06Q40/06;;G06Q40/06,G06Q40/06,,0,0,,,,PENDING
679,US,A1,US 2025/0232130 A1,126-205-006-469-212,7/17/2025,2025,US 202418412392 A,1/12/2024,US 202418412392 A,1/12/2024,DYNAMIC RECONFIGURATION OF DASHBOARD CONTENT BASED ON CALL PROGRESS,"An example operation may include one or more of identifying a first topic from a call actively in progress, displaying a dashboard on a user device on the call, wherein the dashboard comprises content related to the first topic, receiving discussion data from the call, determining that a focus of the call has shifted from the first topic to a second topic, executing an artificial intelligence (AI) model on the second topic, dynamically generating dashboard content based on the execution, and displaying the dynamically generated dashboard content to the dashboard on the user device.",TORONTO DOMINION BANK,TAO LINDA LING;;PANDEY ANAND;;TRIVEDI PRERAK,,https://lens.org/126-205-006-469-212,Patent Application,yes,0,0,1,126-205-006-469-212,US,1,126-205-006-469-212,US,0,G06F40/40;;G06F3/0482;;G06Q40/06,G06F40/40;;G06F3/0482;;G06Q40/06,,0,0,,,,PENDING
680,US,A1,US 2025/0077895 A1,132-155-448-101-76X,3/6/2025,2025,US 202418826005 A,9/5/2024,US 202418826005 A;;US 202363580699 P,9/5/2023,FUSING IN-CONTEXT LEARNING AND FINE-TUNING FOR LANGUAGE MODEL NEURAL NETWORKS,"Methods, systems, and apparatuses, including computer programs encoded on computer storage media, for configuring a set of language model neural networks, e.g., a first large language model and a second smaller-sized language model, and performing a machine learning task on new inputs using the set of language model neural networks. Configuring the language model neural networks and performing a machine learning task can include leveraging the ability of a first large language model to follow prompt-engineered instructions and perform chain-of-thought reasoning, while also fine-tuning a second, smaller language model neural network to optimize the machine learning task performance.",GOOGLE LLC,WANG XINYI;;WIETING JOHN FREDERICK;;CLARK JONATHAN HUDSON,GOOGLE LLC (2024-10-05),https://lens.org/132-155-448-101-76X,Patent Application,yes,0,0,1,132-155-448-101-76X,US,1,132-155-448-101-76X,US,0,G06N3/045;;G06N3/0985;;G06N3/08;;G06N3/045;;G06N3/0985,G06N3/0985;;G06N3/045,,0,0,,,,PENDING
681,US,B2,US 12327421 B2,171-634-122-915-889,6/10/2025,2025,US 202318160860 A,1/27/2023,US 202318160860 A;;US 202263303958 P,1/27/2022,Using automatically uncovered failure cases to improve the performance of neural networks,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for adjusting a target neural network using automatically generated test cases before deployment of the target neural network in a deployment environment. One of the methods may include generating a plurality of test inputs by using a test case generation neural network; processing the plurality of test inputs using a target neural network to generate one or more test outputs for each test input; and identifying, from the one or more test outputs generated by the target neural network for each test input, failing test inputs that result in generation of test outputs by the target neural network that fail one or more criteria.",DEEPMIND TECH LTD,PEREZ ETHAN JOSEAN;;HUANG SAFFRON SHAN;;MCALEESE-PARK NATHANIEL JOHN;;IRVING GEOFFREY,GDM HOLDING LLC (2025-06-03);;DEEPMIND TECHNOLOGIES LIMITED (2023-11-06),https://lens.org/171-634-122-915-889,Granted Patent,yes,7,0,7,090-110-837-110-327;;065-907-416-627-100;;171-634-122-915-889;;195-464-271-670-637;;140-153-490-280-491;;194-616-785-996-726;;049-501-452-758-722,US;;CN;;KR;;JP,7,090-110-837-110-327;;171-634-122-915-889;;065-907-416-627-100;;195-464-271-670-637;;140-153-490-280-491;;194-616-785-996-726;;049-501-452-758-722,US;;CN;;KR;;JP,0,G06F11/3684;;G06F11/3688;;G06N3/04;;G06N3/08;;G06N3/045;;G06V30/1916;;G06V10/82;;G06F11/3684;;G06N3/0442;;G06N3/0475;;G06N3/088;;G06N3/09;;G06N3/092;;G06N20/10;;G06N5/01;;G06N3/006;;H04L51/02;;H04L12/1895;;G06F16/35;;G06N3/10;;G06N3/0475;;G06N3/045;;G06F40/284;;G06F40/40;;G06N3/092;;G06V30/1916,G06V30/19;;G06N3/092,,4,1,057-352-466-674-566,10.18653/v1/2021.naacl-main.235,"Xu, “Bot adversarial dialogue for safe conversational agents”, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 2950-2968. Jun. 11, 2021. (Year: 2021).;;Rae, “Scaling Language Models: Methods, Analysis & Insights from Training Gopher,” arXiv:2112.11446, Jan. 21, 2022. (Year: 2022).;;Office Action in Japanese Appln. No. 202310303, dated Mar. 11, 2024, 7 pages (with English translation).;;Decision to Grant Patent in Japanese Appln. No. 202310303, dated Sep. 9, 2024, 5 pages (with English translation).",ACTIVE
682,US,A1,US 2025/0117853 A1,015-412-167-062-832,4/10/2025,2025,US 202318481138 A,10/4/2023,US 202318481138 A,10/4/2023,PORTFOLIO GENERATION BASED ON MISSING ASSET,"An example operation may include one or more of storing a portfolio of assets of a user in memory, receiving contextual data of the user from a user device of the user, identifying an asset of interest that is not included in the portfolio of assets of the user based on execution of a generative artificial intelligence (GenAI) model on the portfolio of assets of the user and the received contextual data of the user, generating a different portfolio of assets based on the asset of interest that is not included in the portfolio of assets of the user, and displaying the different portfolio of assets via a user interface.",TORONTO DOMINION BANK,PANDEY ANAND;;TRIVEDI PRERAK;;TAO LINDA LING;;LEE JOHN JONG-SUK,,https://lens.org/015-412-167-062-832,Patent Application,yes,0,0,1,015-412-167-062-832,US,1,015-412-167-062-832,US,0,G06N3/0475;;G06Q40/06;;G06N3/0475;;G06Q40/06,G06Q40/06;;G06N3/0475,,0,0,,,,PENDING
683,WO,A1,WO 2025/155805 A1,083-198-732-126-782,7/24/2025,2025,US 2025/0012006 W,1/17/2025,US 202463622127 P;;US 202418617211 A,1/18/2024,TECHNIQUES FOR COMPUTER-BASED SYSTEMATIC LITERATURE REVIEW,"Computer-based techniques for performing systematic literature reviews are provided. Some embodiments include an SLR system including various components that interoperate to generate regulation-compliant SLR reports regarding an issue based on user-defined parameters. In several embodiments, the SLR system may integrate various artificial intelligence techniques to facilitate generation of SLR reports. For example, various SLR systems disclosed hereby may utilize generative pre-trained transformers to assist in aspects of systematic literature reviews, such as literature database queries, literature screening, data question generation, level of evidence classification, qualitative assessments, data extraction, and report generation.",ECNE RES LLC,WEATHERS ELIZABETH;;HOPKINS THOMAS;;ATEIA SAMY,,https://lens.org/083-198-732-126-782,Patent Application,yes,0,0,2,083-198-732-126-782;;179-029-777-408-111,US;;WO,2,083-198-732-126-782;;179-029-777-408-111,US;;WO,0,G06F40/20;;G06F16/35;;G06F16/383,G06F40/279;;G06F16/33;;G06F16/35;;G06F40/44,,0,0,,,,PENDING
684,US,A1,US 2025/0053835 A1,122-994-738-162-733,2/13/2025,2025,US 202418796141 A,8/6/2024,US 202418796141 A;;US 202463660871 P;;US 202363517948 P,8/7/2023,METHODS AND SYSTEMS FOR GENERATIVE QUESTION ANSWERING FOR CONSTRUCTION PROJECT DATA,"The present disclosure provides methods and systems for generative question answering for construction project document. The method comprises: receiving a question from a user via a message interface, wherein the question is related to information from a plurality of construction project documents; identifying, using one or more large language models, one or more relevant documents from the plurality of construction project documents and one or more chunks relevant to the question, and generating an answer based at least in part on the one or more relevant documents and one or more chunks; and providing the answer and one or more links to the one or more relevant documents in a text message in the message interface.",TRUNK TOOLS INC,STEPHAN MORITZ PASCAL;;BALOUSEK ROBERT MICHAEL;;BUCHNER SARAH;;BELSOLE CHRISTOPHER JAMES,,https://lens.org/122-994-738-162-733,Patent Application,yes,0,0,4,021-245-456-977-328;;066-318-276-550-228;;180-621-207-237-435;;122-994-738-162-733,US;;WO,4,021-245-456-977-328;;066-318-276-550-228;;180-621-207-237-435;;122-994-738-162-733,US;;WO,0,G06N5/04;;G06N5/04,G06N5/04,,0,0,,,,PENDING
685,US,A1,US 2025/0217209 A1,045-844-182-683-888,7/3/2025,2025,US 202418982609 A,12/16/2024,US 202418982609 A;;US 202363616464 P,12/29/2023,Hardware-Accelerated Interaction Assistance System,"An interaction assistance system for a user computing device can operate as an intermediate layer in a human-machine interface to receive user action data that describes user actions with a user computing device, interpret the actions in context, and intelligently instruct or command the host system to perform tasks associated with the user action data. An example interaction assistance system can enable faster and more efficient human-machine interfaces by simplifying a number or complexity of inputs to perform a given task.",GOOGLE LLC,PEDERSEN ZEBEDEE;;RUBINOVITZ YASMINE,,https://lens.org/045-844-182-683-888,Patent Application,yes,0,0,2,045-844-182-683-888;;108-105-262-522-982,US;;WO,2,045-844-182-683-888;;108-105-262-522-982,US;;WO,0,H04L67/14;;G06N20/00;;G06N3/08;;G06N3/044;;G06F9/451;;G06F9/541,G06F9/54;;G06F9/451,,0,0,,,,PENDING
686,US,A1,US 2025/0124408 A1,017-184-507-140-755,4/17/2025,2025,US 202418893741 A,9/23/2024,US 202418893741 A;;US 202318486498 A,10/13/2023,SYSTEM FOR ANALYZING LEARNERS,Embodiments are directed to managing skill proficiencies. Declared skills may be determined based on a job description and natural language processing (NLP) actions declared in one or more extraction models. An inference prompt for a large language model (LLM) may be generated based on the job description such that the job description and the declared skills may be included in the inference prompt. The LLM may be trained with the inference prompt to generate a response such that the inference prompt may be iteratively updated based on validations of the response. The LLM may be retrained with the updated inference prompt to generate an updated response that includes the inferred skills that may be separate from the declared skills. A job profile that corresponds to the job description may be updated to include the declared skills and the separate inferred skills.,ASTRUMU INC,CAI XIAO;;PATEL UJASH SURESH;;SKITSKO FEDIR,ASTRUMU INC (2023-10-12),https://lens.org/017-184-507-140-755,Patent Application,yes,5,1,2,184-011-939-094-481;;017-184-507-140-755,US,2,184-011-939-094-481;;017-184-507-140-755,US,0,G06F40/289;;G06Q50/2057;;G06Q10/1053;;G06F40/40;;G06Q10/1053;;G06Q50/2057;;G06F40/40;;G06F40/289,G06Q10/1053;;G06F40/289;;G06F40/40;;G06Q50/20,,1,1,114-885-175-201-459,36474618;;10.1007/s40593-022-00317-y;;pmc9715283,"José-García, A., Sneyd, A., Melro, A. et al. C3-IoC: A Career Guidance System for Assessing Student Skills using Machine Learning and Network Visualisation. Int J Artif Intell Educ 33, 1092–1119 (2023). https://doi.org/10.1007/s40593-022-00317-y. (Year: 2023)",PENDING
687,WO,A1,WO 2024/164723 A1,123-334-784-243-262,8/15/2024,2024,CN 2023140237 W,12/20/2023,CN 2023140237 W,12/20/2023,DATA MIRROR,"At least one processor may receive a sample data set, determine at least one feature of data in the sample data set, and determine at least one structural characteristic of the sample data set. The at least one processor may determine that at least a portion of the data is categorical data from the at least one feature and the at least one structural characteristic. By operating a machine learning (ML) model, the at least one processor may generate synthetic data having the same at least one feature as the categorical data. The at least one processor may package the synthetic data into a synthetic data set having the same at least one feature and at least one structural characteristic as the sample data set.",HSBC SOFTWARE DEVELOPMENT GUANGDONG LTD,ZHONG GALEN;;LI JOHN;;WANG KEVIN;;WU LOOSON,,https://lens.org/123-334-784-243-262,Patent Application,yes,3,0,1,123-334-784-243-262,WO,1,123-334-784-243-262,WO,0,G06N20/00,G06F11/14,,0,0,,,,PENDING
688,US,A1,US 2025/0117629 A1,138-771-995-403-81X,4/10/2025,2025,US 202318481132 A,10/4/2023,US 202318481132 A,10/4/2023,GENERATING A CALL SCRIPT BASED ON CONVERSATION,"An example operation may include one or more of receiving a conversation of a user, identifying a goal of the user from the conversation, identifying a different user that is associated with the identified goal of the conversation, generating a call script comprising a description of content therein to be discussed with a different user based on execution of a generative artificial intelligence (GenAI) model on the identified goal, and integrating the call script into a digital calendar of the different user.",TORONTO DOMINION BANK,PANDEY ANAND;;TRIVEDI PRERAK;;TAO LINDA LING;;LEE JOHN JONG-SUK,,https://lens.org/138-771-995-403-81X,Patent Application,yes,0,0,1,138-771-995-403-81X,US,1,138-771-995-403-81X,US,0,G06N3/08;;G06N3/0475;;G06N3/045;;G06N20/00;;G06N3/08;;G06N3/0475,G06N3/0475;;G06N3/08,,0,0,,,,PENDING
689,US,A1,US 2025/0232377 A1,034-819-279-775-195,7/17/2025,2025,US 202418412343 A,1/12/2024,US 202418412343 A,1/12/2024,DYNAMIC DASHBOARD GENERATION BASED ON FOCUS OF CONVERSATION,"An example operation may include one or more of training an artificial intelligence (AI) model based on a plurality of dashboards related to a software application that corresponds to a plurality of topics, ingesting a call transcript from a previous call with a user, generating a new topic from the call transcript, determining that the new topic is distinct from the existing plurality of topics, executing the AI model based on the new topic, generating a dashboard with content based on the execution of the AI model, and displaying the dashboard via the software application.",TORONTO DOMINION BANK,TAO LINDA LING;;PANDEY ANAND;;TRIVEDI PRERAK,,https://lens.org/034-819-279-775-195,Patent Application,yes,0,0,1,034-819-279-775-195,US,1,034-819-279-775-195,US,0,G06F40/40;;G06Q40/06,G06Q40/06;;G06F40/40,,0,0,,,,PENDING
690,US,A1,US 2025/0217706 A1,084-113-473-428-081,7/3/2025,2025,US 202418982571 A,12/16/2024,US 202418982571 A;;US 202363616459 P,12/29/2023,Real-Time Input Conditioning for Sequence Processing Models,An example system provides real-time input conditioning for processing queries with machine-learned systems and models. Input conditioning can include processing an initial or raw user input and intelligently curating context data and instructions for input to a machine-learned model to perform a task associated with the user action. Input conditioning can significantly improve the performance of a machine-learned model compared to simply passing raw user inputs.,GOOGLE LLC,PEDERSEN ZEBEDEE;;RUBINOVITZ YASMINE,,https://lens.org/084-113-473-428-081,Patent Application,yes,0,0,1,084-113-473-428-081,US,1,084-113-473-428-081,US,0,G06N20/00;;G06N20/00,G06N20/00,,0,0,,,,PENDING
691,US,A1,US 2025/0148400 A1,180-839-298-982-642,5/8/2025,2025,US 202318502276 A,11/6/2023,US 202318502276 A,11/6/2023,ADMINISTRATIVE MANAGEMENT OF USER ACTIVITY DATA USING GENERATIVE ARTIFICIAL INTELLIGENCE,"A device includes: a processor, and a memory storing executable instructions which, when executed by the processor, causes the processor, alone or in combination with other processors, to provide the following: a user interface comprising administrator access to a collaboration system, the user interface comprising a control to invoke an artificial intelligence (AI) assistant function; and an Application Programming Interface (API) to, in response to activation of the control, download user activity data for the collaboration system, generate a prompt for a Large Language Model (LLM) comprising the user activity data and instructing the LLM to generate a report based on the user activity data, and submit the prompt to the LLM and receive the report generated by the LLM. The user interface provides the report and controls for administrative actions suggested by the report.",MICROSOFT TECHNOLOGY LICENSING LLC,MENGKE LI;;ZHENG QIWEN;;HEINTZ JASON ALLEN;;MANGINO JOHN MATTHEW;;MINASYAN DAVID,MICROSOFT TECHNOLOGY LICENSING LLC (2023-11-06),https://lens.org/180-839-298-982-642,Patent Application,yes,0,0,1,180-839-298-982-642,US,1,180-839-298-982-642,US,0,G06Q10/06398;;G06Q10/103;;G06F40/40;;G06Q10/06398;;G06Q10/103;;G06F40/40,G06Q10/0639;;G06F40/40;;G06Q10/10,,0,0,,,,PENDING
692,US,B1,US 12293272 B1,053-361-459-194-969,5/6/2025,2025,US 202519008444 A,1/2/2025,US 202519008444 A;;US 202419004001 A;;US 202418646104 A;;US 202418599955 A,3/8/2024,Agentic workflow system and method for generating synthetic data for training or post training artificial intelligence models to be aligned with domain-specific principles,An agentic workflow system and method generate question and answer pairs and prompts that may be used to aligns generative artificial intelligence (a large language model (LLM) or a large multimodal model (LMM)) with the principles of a specific domain so that the generative artificial intelligence is better able to respond to a user query in the specific domain. The system and method may also generate aligning processes that may be used to post-train an already trained generative artificial intelligence system or fine tune the training of the generative artificial intelligence system to align that generative artificial intelligence system with the principles of the specific domain. The system and method may be used to align the generative artificial intelligence system to a plurality of different domains.,SEEKR TECH INC,POULIS STEFANOS;;BAUER ANDREW J;;MESA DIEGO A;;CLARK ROBIN J;;CONDO PATRICK C,SEEKR TECHNOLOGIES INC (2025-03-05),https://lens.org/053-361-459-194-969,Granted Patent,yes,76,0,1,053-361-459-194-969,US,3,176-778-748-892-548;;077-869-383-900-326;;053-361-459-194-969,US,0,G06N3/045;;G06N3/08;;G06N20/00;;G06N20/00,G06N20/00,,29,9,061-422-655-369-830;;061-422-655-369-830;;063-468-461-979-362;;112-553-588-148-808;;015-680-451-864-665;;064-663-537-978-850;;013-102-577-704-82X;;085-418-168-065-388;;149-515-723-705-706,10.1162/tacl_a_00530;;10.1162/tacl_a_00530;;10.2139/ssrn.5202236;;10.1145/3630106.3658979;;10.18653/v1/2024.emnlp-main.444;;10.18653/v1/2024.findings-emnlp.273;;10.18653/v1/2024.emnlp-main.15;;10.18653/v1/2024.acl-short.2;;10.1145/3673791.3698415,"Sun, “Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision”, 37th Conference on Neural Information Processing Systems, 2023. (Previously supplied). (Year: 2023).;;Siriwardhana, “Improving the Domain Adaptation of Retrieval Augmented Generation (RAG) Models for Open Domain Question Answering”, Transactions of the Association for Computational Linguistics, vol. 11, pp. 1-17, 2023. (Previously supplied). (Year: 2023).;;Shen, “Large Language Model Alignment: A Survey”, 2023. (Previously supplied). (Year: 2023).;;Durante, “Agent AI: Surveying the Horizons of Multimodal Interaction”, Jan. 25, 2024. (Year: 2024).;;Baulepur, “Aligning Language Models with Factuality and Truthfulness” Thesis submitted in partial fulfillment of Bachelor of Science in Computer Science, University of Illinois At Urbana-Champaign, 2023, 50 pages.;;Azaria, et al., “The Internal State of an LLM Knows When its Lying”, School of Computer Science, Ariel University, Israel and Machine Learning Dept., Carnegie Mellon University, Pittsburgh, PA, Apr. 2023, 10 pages.;;Lee, et al., “Linguistic Properties of Truthful Response,” University of Pennsylvania, PA, USA., Jun. 2023, 6 pages.;;Poulis, “Algorithms for Interactive Machine Learning”, Dissertation submitted in partial fulfillment of degree of Doctor of Philosophy in Computer Science, University of California, San Diego, 2019, 148 pages.;;Yang, et al., “RefGPT: Reference—Truthful & Customized Dialogues Generation by GPTs and for GPTs”, Shanghai Jiao Tong University, Hong Kong Polytechnical University, Beijing University of Posts and Telecommunications, May 2023, 20 pages.;;Pan, et al., “On the Risk of Misinformation Pollution with Large Language Models”, National University of Singapore, University of California, Santa Barbara, University of Waterloo, MBZUAI, Zhejiang University, May 2023, 14 pages.;;McKenna, et al., “Sources of Hallucination by Large Language Models on Inference Tasks”, University of Edinburgh, Google Research, Macquarie University, May 2023, 17 pages.;;Sun, “Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision”, 37th Conference on Neural Information Processing Systems, 2023. (Year: 2023).;;Siriwardhana, “Improving the Domain Adaptation of Retrieval Augmented Generation (RAG) Models for Open Domain Question Answering”, Transactions of the Association for Computational Linguistics, vol. 11, pp. 1-17, 2023. (Year: (2023).;;Shen, “Large Language Model Alignment: A Survey”, 2023. (Year: 2023), 76 pgs.;;Dawson, “Algorithmic Adjudication and Constitutional AI—The Promise of A Better AI Decision Making Future?”, Year 2024, 29 pgs.;;Huang, “Collective Constitutional AI: Aligning a Language Model with Public Input”, Year 2024, 23 pgs.;;Bai, “Constitutional AI: Harmlessness from AI Feedback”, Year 2022, 24 pgs.;;Xu, “A Survey on Knowledge Distillation of Large Language Models” Oct. 2024, 43 pgs, https://arxiv.org/pdf/2402.13116.;;Mitra, “AgentInstruct: Toward Generative Teaching with Agentic Flows” Jul. 2024, 32 pgs, https://arxiv.org/pdf/2407.03502.;;Ghosh, “A Closer Look at the Limitations of Instruction Tuning” Jul. 2024, 31 pgs, https://arxiv.org/abs/2402.05119.;;Gekhmann, “Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?” Oct. 2024, 20 pgs, https://arxiv.org/abs/2405.05904.;;Mecklenburg, “Injecting New Knowledge into Large Language Models via Supervised Fine-Tuning” Apr. 2024, 16 pgs, https://arxiv.org/abs/2404.00213.;;Zhang, “Self-Tuning: Instructing LLMs to Effectively Acquire New Knowledge through Self-Teaching” Jun. 2024, 30 pgs, https://arxiv.org/abs/2406.06326.;;Rozner, “Knowledge Editing in Language Models via Adapted Direct Preference Optimization” Sep. 2024, 13 pgs, https://arxiv.org/abs/2406.09920.;;Ye, “Qilin Med: Multi-stage Knowledge Injection Advanced Medical Large Language Model”, 13 pgs, Apr. 2024.;;Ovadia, “Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs”, Jan. 2024, 14 pgs, https://arxiv.org/abs/2312.05934.;;Zhu, “FanOutQA: A Multi-Hop, Multi-Document Question Answering Benchmark for Large Language Models” Jun. 2024, 20 pgs, https://arxiv.org/abs/2402.14116.;;Soudani, “Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge” Dec. 2024, 11 pgs, https://arxiv.org/abs/2403.01432.;;Zhang, “RAFT: Adapting Language Model to Domain Specific RAG” 12 pgs, Jun. 2024, https://arxiv.org/abs/2403.10131.",ACTIVE
693,US,A1,US 2025/0245215 A1,013-331-753-153-633,7/31/2025,2025,US 18429150,1/31/2024,,,LARGE LANGUAGE MODEL INTERFACE FOR COMPLEX DATABASES,"This disclosure introduces a novel method and system for using a large language model (LLM) to create a convenient interface for a complex database. The system includes a custom prompt generator that creates custom prompts from natural language queries. The custom prompts are used to control how the LLM interacts with a database look-up tool. The database look-up tool provides queries to the database in a format understandable by the database and receives responses from the database. This system is useful for obtaining information that is not in a natural language, and thus, is poorly suited for being processed as an embedding by the LLM. Information obtained from the database is included in an answer produced by the LLM.","MICROSOFT TECHNOLOGY LICENSING, LLC",Maria Angels DE LUIS BALAGUER;;Sara Malvar MAUA;;Swati SHARMA;;Ranveer CHANDRA,,https://lens.org/013-331-753-153-633,Patent Application,yes,0,0,1,013-331-753-153-633,US,1,013-331-753-153-633,US,0,G06F16/243;;G06F16/2425;;G16B50/00,G06F16/242;;G16B50/00,,0,0,,,,UNKNOWN
694,US,A1,US 2025/0103052 A1,095-618-049-938-050,3/27/2025,2025,US 202418613943 A,3/22/2024,US 202418613943 A;;US 202363585368 P,9/26/2023,DYNAMIC PERFORMANCE OF ACTIONS BY A MOBILE ROBOT BASED ON SENSOR DATA AND A SITE MODEL,"Systems and methods are described for instructing performance of an action by a mobile robot based on transformed data. A system may obtain a site model in a first data format and sensor data in a second data format. The site model and/or the sensor data may be annotated. The system may transform the site model and the sensor data to generate transformed data in a third data format. The system may provide the transformed data to a computing system. For example, the system may provide the transformed data to a machine learning model. Based on the output of the computing system, the system may identify an action and instruct performance of the action by a mobile robot.",BOSTON DYNAMICS INC,KLINGENSMITH MATTHEW JACOB;;MCDONALD MICHAEL JAMES;;AGRAWAL RADHIKA;;ALLUM CHRISTOPHER PETER;;SHINKLE ROSALIND FISH BLAIS,BOSTON DYNAMICS INC (2024-11-05),https://lens.org/095-618-049-938-050,Patent Application,yes,0,1,2,045-680-015-184-709;;095-618-049-938-050,US;;WO,2,045-680-015-184-709;;095-618-049-938-050,US;;WO,0,B25J9/161;;G06F40/30;;G05D2109/12;;G05D1/246;;G10L15/22;;G10L2015/223,G05D1/246;;G05D109/12;;G06F40/30;;G10L15/22,,0,0,,,,PENDING
695,WO,A1,WO 2025/090955 A1,113-892-487-166-903,5/1/2025,2025,US 2024/0053102 W,10/25/2024,US 202363593413 P,10/26/2023,EFFICIENTLY SERVING MACHINE-LEARNED MODEL COMPUTATIONS WITH HIGH THROUGHPUT AND LOW LATENCY,"An example method includes receiving input requests to process a plurality of input sequences using the machine-learned sequence processing model to generate a plurality of output sequences respectively corresponding to the plurality of input sequences; generating a plurality of initial attention tensors respectively for the plurality of input sequences, wherein: one or more respective initial attention tensors are generated for each respective input sequence in parallel over input elements of the respective input sequence; and the one or more respective initial attention tensors are generated in one or more batches having a first batch size using a prefill system that comprises one or more prefill computing devices and executes one or more layers of the machine-learned sequence processing model; and autoregressively generating, using the plurality of initial attention tensors, a plurality of output elements for each of the plurality of output sequences in one or more batches having a second batch size, wherein: the plurality of output elements are generated using a generation system that comprises one or more generation computing devices.",GOOGLE LLC,PIQUERAS ENRIQUE;;BRADBURY JAMES EDWARD KAHN;;SAETA BRENNAN;;DOUGLAS SHOLTO FRANCIS ALEXANDRE;;LEVSKAYA ANSELM;;SCHUH PARKER EDWARD;;POPE REINER,,https://lens.org/113-892-487-166-903,Patent Application,yes,2,0,1,113-892-487-166-903,WO,1,113-892-487-166-903,WO,0,G06F2209/509;;G06F9/5044;;G06N3/063;;G06N3/045;;G06F9/5027,G06F9/50;;G06F3/045;;G06N3/063,,11,3,103-212-983-826-945;;120-047-640-592-980;;084-641-049-769-580,pmc8371605;;34265844;;10.1038/s41586-021-03819-2;;10.18653/v1/d18-2012;;10.18653/v1/2020.emnlp-main.83,"POPE REINER ET AL: ""Efficiently Scaling Transformer Inference"", ARXIV.ORG, 1 November 2022 (2022-11-01), pages 1 - 18, XP093263089, Retrieved from the Internet <URL:https://arxiv.org/pdf/2211.05102>;;AMEY AGRAWAL ET AL: ""SARATHI: Efficient LLM Inference by Piggybacking Decodes with Chunked Prefills"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 31 August 2023 (2023-08-31), XP091601783;;POPE ET AL.: ""Efficiently Scaling Transformer Inference"", ARXIV:2211.05102V1, 9 November 2022 (2022-11-09);;RINK ET AL.: ""Memory-Efficient Array Redistribution Through Portable Collective Communication"", ARXIV:2112.01075V2, 28 November 2022 (2022-11-28);;ZHOU ET AL.: ""Mixture-of Experts with Expert Choice Routing"", ARXIV:2202.09368V2, 14 October 2022 (2022-10-14);;DOSOVITSKIY ET AL.: ""An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"", ARXIV:2010.11929V2, 3 June 2021 (2021-06-03);;AGOSTINELLI ET AL.: ""MusicLM.- Generating Music From Text"", ARX1V:2301.11325V1, 26 January 2023 (2023-01-26);;JUMPER ET AL.: ""Highly accurate protein structure prediction with AlphaFold"", NATURE, vol. 596, 26 August 2021 (2021-08-26), pages 583, XP055888904, DOI: 10.1038/s41586-021-03819-2;;KUDO ET AL.: ""SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"", PROCEEDINGS OF THE 2018, 31 October 2018 (2018-10-31), pages 66 - 71;;VASWANI ET AL.: ""Attention Is All You Need"", ARY.IV: 1706.03762V7, 2 August 2023 (2023-08-02);;SAHARIA ET AL.: ""Non-Autoregressive Machine Translation with Latent Alignments"", ARXIV:2004.07437V3, 16 November 2020 (2020-11-16)",PENDING
696,US,A1,US 2025/0077487 A1,195-866-008-402-661,3/6/2025,2025,US 202318242464 A,9/5/2023,US 202318242464 A,9/5/2023,SOFTWARE QUALITY TICKET ENRICHMENT,"Searches based on an incoming ticket identify quality ticket enrichment data using a vector database. Language model prompts target particular kinds of quality ticket data. The incoming quality ticket, or a search result ticket, or both, are enriched using enrichment data, such as a user intent identification, a workaround suggestion, a resolution description, a target audience description, a relevance description, an impact description, a description of missing resolution facilitation information, an association between the incoming quality ticket and the search result ticket, a user sentiment identification, a tag suggestion, or a feedback utility estimate. The enrichment reduces engineering and support burdens, and facilitates faster more effective resolution of the problem or the request that is stated or implied in the incoming quality ticket. Duplicate tickets are merged or removed. Tickets are prioritized. Missing problem resolution information is identified and requested sooner.",MICROSOFT TECHNOLOGY LICENSING LLC,GROENEWEGEN PETER;;MIHAYLOV NIKOLA MINKOV;;COX LARISSA MARIE;;MULLEN NICHOLAS TAYLOR;;WILSON-THOMAS MARK ALISTAIR;;CHAPMAN PAUL;;BAFNA KSHAMA GAJRAJ;;KUMAR ABHISHEK;;CHLUS JASON;;MITCHELL HOLLY,MICROSOFT TECHNOLOGY LICENSING LLC (2023-08-29),https://lens.org/195-866-008-402-661,Patent Application,yes,0,0,1,195-866-008-402-661,US,1,195-866-008-402-661,US,0,G06F16/951;;G06F16/215;;G06F16/24578;;G06F16/215;;G06F16/951;;G06F16/24578,G06F16/215;;G06F16/2457;;G06F16/951,,0,0,,,,PENDING
697,US,A1,US 2025/0224861 A1,032-658-289-290-012,7/10/2025,2025,US 202418404783 A,1/4/2024,US 202418404783 A,1/4/2024,AUTOMATED MOODBOARD AUGMENTATION VIA CROSS-MODAL GENERATIVE ASSOCIATION MAKING,"A method for automated moodboard augmentation via cross-modal generative association making is described. The method includes specifying, by a user, a region to augment in their digital workspace, including at least one selected image. The method also includes inferring a representative text, label, or description for the at least one selected image. The method further includes creating a basis for concept blending based on the representative text, label, or description inferred for the at least one selected image. The method also includes generating images in response to an adjustable slider, as adjusted by the user, to adjust how much the generated images should resemble directly adjacent images, including the at least one selected image.",TOYOTA RES INST INC;;TOYOTA MOTOR CO LTD,HONG MATTHEW KYUNG-SOO;;HAKIMI SHABNAM;;CHEN YIN-YING,,https://lens.org/032-658-289-290-012,Patent Application,yes,0,0,1,032-658-289-290-012,US,1,032-658-289-290-012,US,0,G06F3/04845;;G06F3/0482;;G06F3/04847,G06F3/04845;;G06F3/0482;;G06F3/04847,,0,0,,,,PENDING
698,US,A1,US 2024/0412866 A1,104-241-196-003-746,12/12/2024,2024,US 202318333404 A,6/12/2023,US 202318333404 A,6/12/2023,OMNI-CHANNEL ARTIFICIAL INTELLIGENCE (AI) CHATBOT FOR MEDICAL DIAGNOSIS AND MEDICAL TREATMENT,"Provided are techniques for an omni-channel Artificial Intelligence (AI) chatbot module collecting data and performing analysis. Survey questions for a participant are received. A first channel of a plurality of channels of communication and a period of time for contact are identified. A conversation is initiated by attempting to contact the participant using the first channel and during the period of time. in response to the participant accepting the contact, each of the survey questions are converted to natural language. There is interaction with the participant using the first channel to receive survey answers to the survey questions in the natural language. The survey answers are analyzed, and an analysis result is output.",IBM,WEN BO;;SIU VINCE;;WANG CHEN;;TIAN HONGFEI,INTERNATIONAL BUSINESS MACHINES CORPORATION (2023-06-12),https://lens.org/104-241-196-003-746,Patent Application,yes,4,1,1,104-241-196-003-746,US,1,104-241-196-003-746,US,0,H04L51/02;;G16H50/20;;G16H10/20;;G16H80/00;;G16H40/67;;H04L51/02;;G16H50/20,G16H50/20;;H04L51/02,,2,2,197-425-156-530-832;;030-378-454-438-094,10.1109/icdsca56264.2022.9987931;;pmc6888408;;10.3390/ijerph16224360;;31717300,"Dey, Aniket. An Integrated Approach to Non-Invasive Diagnosis of Dementia Using Natural Language Processing and Machine Learning. 2022 IEEE 2nd International Conference on Data Science and Computer Application (ICDSCA). (Year: 2022);;Dudchenko A, Kopanitsa G. Comparison of Word Embeddings for Extraction from Medical Records. Int J Environ Res Public Health. 2019 Nov 8;16(22):4360. doi: 10.3390/ijerph16224360. PMID: 31717300; PMCID: PMC6888408 (Year: 2019)",PENDING
699,WO,A1,WO 2024/236515 A1,119-412-685-953-038,11/21/2024,2024,IB 2024054744 W,5/15/2024,US 202363502306 P,5/15/2023,SYSTEM AND METHOD FOR ENHANCED MODEL INTERACTION INTEGRATION WITHIN A WEBSITE BUILDING SYSTEM,Embodiments provide for integrating enhanced model interaction within a website building system. Models leveraged according to embodiments may include trained generative artificial intelligence models that are leveraged to customize structure and content within a website building system. Improved generation of composite prompts leads to improved generation of customized structure and content within the website building system.,WIX COM LTD,PEREZ MEIR;;ASAF YAARA;;NISSAN YUVAL;;GOLAN OZ;;BROSH ELIAHU;;NACHSHON ODED HAIM;;ANTEBI BATYA,,https://lens.org/119-412-685-953-038,Patent Application,yes,9,0,2,143-814-315-792-830;;119-412-685-953-038,US;;WO,2,143-814-315-792-830;;119-412-685-953-038,US;;WO,0,G06F16/958;;G06F40/186;;G06F3/0482;;G06F3/0484;;G06F9/547,G06F16/958,,0,0,,,,PENDING
700,US,A1,US 2024/0242427 A1,186-947-475-173-982,7/18/2024,2024,US 202418412317 A,1/12/2024,US 202418412317 A;;US 202363438998 P,1/13/2023,SYSTEMS AND METHODS FOR MEDIA CONTENT GENERATION,"The present disclosure provides a system that supports generation of media content based on textual inputs. The system is designed to receive text and other forms of content as input. The text input may be amplified using one or more artificial intelligence techniques to produce modified text content. The text content is then processed using an artificial intelligence algorithm configured to perform text-to-image processing to produce image content. The amplification of the text content and the generation of image content based on the text content may be performed iteratively, with changes to the text content in each iteration resulting in a new image that potentially comes closer to the user's desired result for the image content. 3D data may be extracted from the final image and used to generate a 3D model that may be integrated with or used by external systems, platforms, or devices.",ACCENTURE GLOBAL SOLUTIONS LTD,ACKERMAN JORDAN ALEXANDER;;KUNIAVSKY MICHAEL,,https://lens.org/186-947-475-173-982,Patent Application,yes,0,1,2,186-947-475-173-982;;016-609-646-415-338,US,2,186-947-475-173-982;;016-609-646-415-338,US,0,G06F40/40;;G06F40/166;;G06F40/56;;G06T17/00;;G06T19/20;;G06T17/00;;G06F40/40;;G06T2219/2024;;G06T2200/24;;G06T19/20;;G06F40/166,G06T17/00;;G06F40/166,,0,0,,,,PENDING
701,US,A1,US 2025/0182028 A1,111-037-524-301-028,6/5/2025,2025,US 202318528569 A,12/4/2023,US 202318528569 A,12/4/2023,GOAL-BASED INTELLIGENT ENGINE,"An example operation may include one or more of ingesting profile data from one or more websites via one or more application programming interfaces (APIs) and storing the profile data within a data store, displaying one or more prompts on a user interface of a user profile page within a software application hosted by a host platform, receiving one or more responses to the one or more prompts, determining a goal for a user of the user profile page based on execution of an artificial intelligence (AI) model on the profile data, the one or more prompts, and the one or more responses to the one or more prompts, and displaying an identifier of the goal via the user interface of the user profile page of the software application.",TORONTO DOMINION BANK,GORMLEY BREENA PATRICIA,,https://lens.org/111-037-524-301-028,Patent Application,yes,0,0,1,111-037-524-301-028,US,1,111-037-524-301-028,US,0,G06N20/00;;G06Q10/0637;;G06N20/00;;G06Q10/0637,G06Q10/0637;;G06N20/00,,0,0,,,,PENDING
702,US,B1,US 12020140 B1,123-140-695-826-84X,6/25/2024,2024,US 202318383447 A,10/24/2023,US 202318383447 A,10/24/2023,Systems and methods for ensuring resilience in generative artificial intelligence pipelines,"The systems and methods described herein relate to generative artificial intelligence systems using retrieval-augmented generation pipelines to supply information to large language models (LLMs). The potential for failures by such LLMs to return responses to prompts significantly increases with system complexity. To improve the resilience of the pipelines in handling such failures, various aspects described herein provide mechanisms for early detection and remediation of such prompt failure events. Thus, prompt failure events may be identified based upon (i) an elapsed time between sending a prompt and receiving a first token from the LLM exceeding a first threshold or (ii) an elapsed time between receiving such first token and receiving a last token exceeding a second threshold. Remediation may be achieved by causing a copy of the failed prompt to be sent to the LLM, without waiting for an error from the LLM provider or a standard network request timeout.",MCKINSEY & COMPANY INC,MONDLOCK PETER,MCKINSEY & COMPANY INC (2023-11-09),https://lens.org/123-140-695-826-84X,Granted Patent,yes,35,2,1,123-140-695-826-84X,US,1,123-140-695-826-84X,US,0,G06F16/25;;G06F40/00;;G06N3/0455;;G06N3/0475;;H04L69/324;;G06N3/006;;G06N3/0455;;G06N3/0475;;G06F16/25;;G06F40/00;;H04L69/324,H04L69/324;;G06F16/25;;G06F40/00;;G06N3/0455;;G06N3/0475,,7,0,,,"Microsoft, Learn, “What is Semantic Kernel?” Web page downloaded at <https://learn.microsoft.com/en-us/semantic-kernel/overview/>. Retrieved from the Internet on Dec. 15, 2023.;;LlamaIndex, “Welcome to LlamaIndex” Web page downloaded at <https://docs.llamaindex.ai/en/stable/#why-llamaindex>. Retrieved from the Internet on Dec. 15, 2023.;;Python, Langchain, “Introduction” Web page downloaded at <https://python.langchain.com/docs/get_started/introduction>. Retrieved from the Internet on Dec. 15, 2023.;;Non-final Office Action, U.S. Appl. No. 18/493,697, dated Dec. 13, 2023.;;Non-final Office Action, U.S. Appl. No. 18/493,715, dated Dec. 1, 2023.;;Non-final Office Action, U.S. Appl. No. 18/493,741, dated Dec. 29, 2023.;;Microsoft Learn, “Build language model pipelines with memory.” https://learn.microsoft.com/en-us/azure/architecture/ai-ml/openai/guide/language-model-pipelines>. Retrieved from the Internet on Sep. 15, 2023.",ACTIVE
703,US,A1,US 2025/0225158 A1,166-737-960-318-515,7/10/2025,2025,US 202418408204 A,1/9/2024,US 202418408204 A,1/9/2024,PROMPT REGISTRATION AND REUSE,"An embodiment registers, in a ledger, a plurality of prompt-output pairs, each prompt-output pair in the plurality of prompt-output pairs comprising a prompt to a model and an output from the model, wherein the prompt comprises a text description of a content to be generated by the model, wherein the output comprises the content. An embodiment receives a first prompt, the first prompt comprising a first text description of a first content to be generated by the model. An embodiment selects a selected prompt-output pair from the plurality of prompt-output pairs registered in the ledger, the selected prompt-output pair having a similarity above a threshold similarity to the first prompt. An embodiment causes, using a prompt portion of the selected prompt-output pair, the model to produce a second content, wherein the second content is an improvement over the first content.",IBM,FIGUEREDO DE SANTANA VAGNER;;VASCONCELOS MARISA AFFONSO;;GUERRA MELINA DE VASCONCELOS ALBERIO;;FEFFER MICHAEL ANTHONY;;BERGER SARA E,,https://lens.org/166-737-960-318-515,Patent Application,yes,0,0,1,166-737-960-318-515,US,1,166-737-960-318-515,US,0,G06F16/38;;G06F16/3325,G06F16/332;;G06F16/38,,0,0,,,,PENDING
704,WO,A1,WO 2024/226267 A1,015-698-718-577-59X,10/31/2024,2024,US 2024/0023481 W,4/6/2024,US 202318139046 A,4/25/2023,SELF-TEACHING LARGE LANGUAGE MODELS,"The present disclosure relates to methods and systems for self-teaching a large language model (LLM). The methods and systems use a self-learning framework with a plurality of phases. In each phase of the self-learning framework, the LLM generates a diverse set of outputs for a question and an aggregation is performed on the diverse set of outputs generate a phase output. The phase output from a previous phase is used as an input to the LLM in a next phase.",MICROSOFT TECHNOLOGY LICENSING LLC,IMANI SHIMA;;SHRIVASTAVA HARSH,,https://lens.org/015-698-718-577-59X,Patent Application,yes,0,0,2,042-649-344-763-23X;;015-698-718-577-59X,US;;WO,2,042-649-344-763-23X;;015-698-718-577-59X,US;;WO,0,G06F40/30;;G06N20/00;;G06N5/04;;G06F16/3329;;G06F40/40;;G06F40/205,G06N20/00;;G06F40/30,,5,0,,,"WANG XUEZHI ET AL: ""Self-Consistency Improves Chain of Thought Reasoning in Language Models"", ARXIV (CORNELL UNIVERSITY), 7 March 2023 (2023-03-07), XP093176980, Retrieved from the Internet <URL:https://arxiv.org/pdf/2203.11171> DOI: 10.48550/arxiv.2203.11171;;WAYNE XIN ZHAO ET AL: ""A Survey of Large Language Models"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 31 March 2023 (2023-03-31), XP091472869;;XAVIER DAULL ET AL: ""Complex QA and language models hybrid architectures, Survey"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 7 April 2023 (2023-04-07), XP091479047;;SHIMA IMANI ET AL: ""DiversiGATE: A Comprehensive Framework for Reliable Large Language Models"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 22 June 2023 (2023-06-22), XP091545660;;""Electronics Engineers"", IEEE",PENDING
705,US,B1,US 12306834 B1,063-496-745-436-35X,5/20/2025,2025,US 202418941826 A,11/8/2024,US 202418941826 A;;US 202463684775 P,8/19/2024,Artificial intelligence platform and method for AI-enabled search and dynamic knowledge base management,"An intelligent search agent that can accept search request input in various ways to initiate a search of databases, websites, documents, PDF files, photos, and other digital data. Search requests can be initiated manually, through automated scheduling, and other ways and can be initiated in multiple ways including voice input, text input, form filling, large language model (LLM) processes, AI agents, selecting from dashboard menus, computer instructions and other methods. Applications of machine learning (ML) and natural language processing (NLP) and others are used to enhance the search agent's capabilities while minimizing user effort requirements. The Search Agent works in conjunction with a knowledge base function to dynamically form and manage one or more knowledge bases using search results and to automatically integrate search results into workflow processes.",ARTI ANALYTICS INC,FERCHAU JOERG;;HUBANA TARIK;;HODZIC MIGDAT,ARTI ANALYTICS INC. A DELAWARE CORPORATION (2024-11-07),https://lens.org/063-496-745-436-35X,Granted Patent,yes,15,1,1,063-496-745-436-35X,US,1,063-496-745-436-35X,US,0,G06F16/24542;;G06F16/2237;;G06F16/2237;;G06F16/24542,G06F16/24;;G06F16/22;;G06F16/2453,,6,2,077-057-271-016-786;;135-807-736-410-962,10.18653/v1/2024.acl-long.108;;10.18653/v1/2022.emnlp-main.375,"Clustered Retrieved Augmented Generation, Kesson et al (Year: 2024).;;M-RAG: Reinforcing Large Language Model Performance through Retrieval-Augmented Generation with Multiple Partitions, Wang et al (Year: 2024).;;Retrieval-Augmented Generation with One-Time Vector Database Built from Search Results, (Year: 2023).;;Surla et al, An Easy Introduction to Multimodal Retrieval-Augmented Generation, Mar. 20, 2024, Nvidia; downloaded from https://developer.nvidia.com/blog/an-easy-introduction-to-multimodal-retrieval-augmented-generation/ on Oct. 20, 2024.;;Zhu et al., REALM: RAG-Driven Enhancement of Multimodal Electronic Health Records Analysis via Large Language Models (2024) arXiv:2402.07016v1 [cs.AI] Feb. 10, 2024; downloaded from https://arxiv.org/abs/2402.07016 on Oct. 20, 2024.;;Chen et al., “MuRAG: Multimodal Retrieval-Augmented Generator for Open Question Answering over Images and Text”, arXiv:2210.02928v2 [cs.CL], downloaded from https://arxiv.org/abs/2210.02928 on Oct. 20, 2022.",ACTIVE
706,US,A1,US 2025/0181321 A1,070-323-835-174-398,6/5/2025,2025,US 202318528542 A,12/4/2023,US 202318528542 A,12/4/2023,DESIGN-BASED INTELLIGENT ENGINE,"An example operation may include one or more of ingesting data from one or more websites via one or more application programming interfaces (APIs) and storing the data within a data store of a host platform, generating one or more prompts and displaying the one or more prompts on a user interface of a user profile page within a software application hosted by the host platform, receiving one or more responses to the one or more prompts, generating a design of a structure based on execution of an artificial intelligence (AI) model on the data from the one or more websites, the one or more prompts, and the one or more responses, and displaying the design of the structure via the user interface of the user profile page of the software application.",TORONTO DOMINION BANK,GORMLEY BREENA PATRICIA,THE TORONTO-DOMINION BANK (2023-12-19),https://lens.org/070-323-835-174-398,Patent Application,yes,0,0,1,070-323-835-174-398,US,1,070-323-835-174-398,US,0,G06F8/34;;G06F8/36;;G06F8/35;;G06F8/34;;G06F8/36;;G06F8/35,G06F8/34;;G06F8/35;;G06F8/36,,0,0,,,,PENDING
707,WO,A1,WO 2025/136458 A1,174-727-384-312-094,6/26/2025,2025,US 2024/0039385 W,7/24/2024,US 202318544772 A,12/19/2023,LARGE LANGUAGE MODEL INTERFACE FOR WELLBORE CEMENT JOB DESIGN,"A method may include: providing one or more inputs to a hybrid data generator, wherein one of the one or more inputs is based at least in part on a wellsite location, wherein the hybrid data generator comprises a large language model, and wherein the large language model is based at least in part on a machine learning algorithm; utilizing an information handling system to generate a cement job design based at least in part on the one or more inputs and the hybrid data generator; performing at least a portion of a cementing operation based at least in part on the cement job design; and collecting at least one measurement from at least one sensor during the cementing operation.",HALLIBURTON ENERGY SERVICES INC,YERUBANDI K V V N KRISHNA BABU;;JIMENEZ WALMY CUELLO;;JOGDAND ANOOP SHESHRAO,,https://lens.org/174-727-384-312-094,Patent Application,yes,0,0,2,174-727-384-312-094;;186-705-153-062-639,US;;WO,2,174-727-384-312-094;;186-705-153-062-639,US;;WO,0,E21B2200/20;;E21B47/005;;E21B2200/22;;E21B2200/20;;E21B47/005,G06N3/092;;E21B33/14;;G06N3/04,,0,0,,,,PENDING
708,US,A1,US 2025/0077765 A1,015-472-342-247-493,3/6/2025,2025,US 202318240054 A,8/30/2023,US 202318240054 A,8/30/2023,SYSTEM AND METHODS TO FACILITATE CONTENT GENERATION USING GENERATIVE ARTIFICIAL INTELLIGENCE MODELS,"The present disclosure is directed to systems and methods to enhance the process of creating an artificial intelligence (AI) generated content or content items, such as images, text, video, sounds, etc., using a text or other suitable prompt, such as via voice input. The systems and methods disclosed provide streamlined content generation with, e.g., reduced processing power and computing time. In an embodiment the systems and methods receive a prompt for generating a first content item using a generative artificial intelligence (AI) model and retrieve, based on the prompt, a collection of matching content items. The systems and methods may then receive input selecting one of the content items from the collection and identify a prompt used to generate the selected content item. The systems and methods may then merge using a trained natural language processing model, the received prompt with the prompt of the selected content item to create a third prompt. In an embodiment the systems and methods may modify the third prompt based on additional input and, based on the modified third prompt, generate a second content item.",ADEIA IMAGING LLC,XU NING;;COULEAUD JEAN-YVES;;YANG CATO,ADEIA IMAGING LLC (2023-09-29),https://lens.org/015-472-342-247-493,Patent Application,yes,0,3,1,015-472-342-247-493,US,1,015-472-342-247-493,US,0,G06F16/24578;;G06N3/0475;;G06F40/174;;G06F40/56;;G06F40/30;;G06F3/0482;;G06F3/04847;;G06F3/04845;;G06F40/174;;G06F3/0482;;G06F16/24578;;G06N3/0475;;G06F3/04847,G06F40/174;;G06F3/0482;;G06F3/04847;;G06F16/2457;;G06N3/0475,,0,0,,,,PENDING
709,US,A1,US 2025/0182196 A1,108-658-687-414-354,6/5/2025,2025,US 202318528589 A,12/4/2023,US 202318528589 A,12/4/2023,INTELLIGENT ENGINE FOR GUIDING ESTIMATION,"An example operation may include one or more of training an artificial intelligence (AI) model to recommend numerical goals based on execution of the AI model on historical profile data and contextual data that is associated with the historical profile data, storing profile data of a user profile within a data store of a software application, receiving a request via a user interface of a user profile page of the software application, wherein the request comprises context of a user of the user profile, determining a numerical goal for the user profile based on execution of the AI model on the profile data of the user profile and the context, and displaying the numerical goal via the user interface of the user profile page within the software application.",TORONTO DOMINION BANK,GORMLEY BREENA PATRICIA,THE TORONTO-DOMINION BANK (2023-12-19),https://lens.org/108-658-687-414-354,Patent Application,yes,3,0,1,108-658-687-414-354,US,1,108-658-687-414-354,US,0,H04L67/306;;G06Q40/02;;H04L67/306;;G06Q40/02,G06Q40/02;;H04L67/306,,0,0,,,,PENDING
710,US,A1,US 2025/0139636 A1,084-201-193-115-347,5/1/2025,2025,US 202318384242 A,10/26/2023,US 202318384242 A,10/26/2023,Mobile Assistant Enhanced by Artificial intelligence,"Disclosed herein are system, method, and device embodiments for providing a mobile interface powered by artificial intelligence. A user remains on a single user-interface page, conducting interactions with a customer relationship management tool using natural language. The technique leverages a large language model as an intermediary middle-layer, allowing a user to engage core functions. The technique builds an appropriate prompt including the natural language and uses the large language model to build an execution plan that references tools and tasks performable in the customer relationship management tool. By chaining prompts, the technique incorporates prior interactions into subsequent prompts. Mobile-specific information such as location, images, and scanned barcodes may be included in a prompts. Running the large language model on the client device allows the user to perform CRM functions while operating in an offline mode, a mode that secures user data and enhances privacy.",SALESFORCE INC,MANGANO ANDREW;;AGARWAL SAKET;;GOLDBERG STEPHEN;;BOVET JEAN ELIE;;SIGLER ABIGAIL;;KLEIN DAVID,,https://lens.org/084-201-193-115-347,Patent Application,yes,0,0,1,084-201-193-115-347,US,1,084-201-193-115-347,US,0,G06F40/20;;G06Q30/01;;G06F40/20;;G06Q30/01,G06Q30/01;;G06F40/20,,0,0,,,,PENDING
711,US,A1,US 2025/0068764 A1,083-869-527-775-702,2/27/2025,2025,US 202318454997 A,8/24/2023,US 202318454997 A,8/24/2023,PROTECTING SENSITIVE USER INFORMATION IN DEVELOPING ARTIFICIAL INTELLIGENCE MODELS,"A system for development of an Artificial Intelligence (AI) model while protecting sensitive user information includes: a confidential computing environment in which original prompts to the AI model written by users are collected; a trained synthetic prompt generator to generate synthetic prompts based on the original prompts, wherein the synthetic prompt generator generates anonymized synthetic prompts without sensitive user information identifiable from the original prompts; and a developer computing environment in which the synthetic prompts are submitted to the AI model under development to generate a dataset that includes the synthetic prompts and corresponding AI model output for analysis to determine updates for the AI model while protecting the sensitive user information of actual users.",MICROSOFT TECHNOLOGY LICENSING LLC,JOSHI DHRUV;;SIM ROBERT;;MANOEL ANTONIO ANDRE MONTEIRO;;BHAKTHAVATSALAM SUMITHRA;;LI JI;;LEONE JOHN CHRISTIAN;;SOBHANI DOLLY,MICROSOFT TECHNOLOGY LICENSING LLC (2023-08-07),https://lens.org/083-869-527-775-702,Patent Application,yes,7,2,1,083-869-527-775-702,US,1,083-869-527-775-702,US,0,G06F21/6245;;G06F40/20;;G06F40/20;;G06F21/6245,G06F21/62;;G06F40/20,,0,0,,,,PENDING
712,US,A1,US 2025/0182222 A1,161-292-968-783-47X,6/5/2025,2025,US 202318528473 A,12/4/2023,US 202318528473 A,12/4/2023,BUILDING TRAVEL ITINERARIES USING A GENERATIVE INTELLIGENT ENGINE,"An example operation may include one or more of ingesting data from one or more websites via one or more application programming interfaces (APIs) and storing the data within a data store of a host platform, displaying one or more prompts on a user interface of a user profile page within a software application hosted by the host platform, receiving one or more responses to the one or more prompts, generating a travel itinerary based on execution of an artificial intelligence (AI) model on the data from the one or more websites, the one or more prompts, and the one or more responses, and displaying the travel itinerary via the user interface of the user profile page of the software application.",TORONTO DOMINION BANK,GORMLEY BREENA PATRICIA,THE TORONTO-DOMINION BANK (2023-12-19),https://lens.org/161-292-968-783-47X,Patent Application,yes,2,0,1,161-292-968-783-47X,US,1,161-292-968-783-47X,US,0,H04L67/306;;G06Q50/14;;G06Q10/025;;G06Q50/14;;H04L67/306;;G06Q10/025,G06Q50/14;;G06Q10/02;;H04L67/306,,0,0,,,,PENDING
713,US,A1,US 2025/0238612 A1,089-137-483-466-143,7/24/2025,2025,US 202418421283 A,1/24/2024,US 202418421283 A,1/24/2024,Systems and Methods for Domain-Agnostic Context Extraction in Natural Language Processing,"In one embodiment, a method includes determining speech tags for multiple words associated with a body of text by a language model, processing the words by determining whether each word is a noun, proper noun, or adposition by a domain-agnostic context extraction (DCE) model to generate a set of n-grams corresponding to a domain-agnostic context of the body of text, and generating a contextual summary of the body of text based on the set of n-grams.",SAMSUNG ELECTRONICS COMPANY LTD,HOPE PAUL S;;LEE JEREMY W K,,https://lens.org/089-137-483-466-143,Patent Application,yes,0,0,1,089-137-483-466-143,US,1,089-137-483-466-143,US,0,G06F40/279;;G06F40/30;;G06F40/166,G06F40/279;;G06F40/166;;G06F40/30,,0,0,,,,PENDING
714,US,A1,US 2025/0173965 A1,093-426-979-581-845,5/29/2025,2025,US 202318522197 A,11/28/2023,US 202318522197 A,11/28/2023,AUTOMATIC RETOPOLOGIZATION OF TEXTURED 3D MESHES,"Methods and apparatuses for automating the retopologization of 3D meshes including the automated selection and adjustment of correspondence points are described. The automated selection of correspondence points may be performed to refine locations of correspondence points using a matching score that is computed based on surface normal similarity between surfaces corresponding with a candidate correspondence point on an input scan mesh and a point on a morphable model of 3D surfaces. The matching score may also take into account a distance between a candidate correspondence point on the input scan mesh and a corresponding point on the morphable model of 3D surfaces and similarities in surface features, such as similarities in surface curvature at the candidate correspondence point on the input scan mesh and the corresponding point on the morphable model of 3D surfaces.",MICROSOFT TECHNOLOGY LICENSING LLC,PETIKAM LOHIT DEV;;HEWITT CHARLES THOMAS;;BALTRUSAITIS TADAS;;GARBIN STEPHAN JOACHIM,MICROSOFT TECHNOLOGY LICENSING LLC (2023-11-28),https://lens.org/093-426-979-581-845,Patent Application,yes,0,0,2,093-426-979-581-845;;056-782-148-806-192,US;;WO,2,093-426-979-581-845;;056-782-148-806-192,US;;WO,0,G06V20/653;;G06V40/169;;G06V10/755;;G06T17/20;;G06T7/30;;G06V40/169;;G06T17/20,G06T17/20;;G06V40/16,,0,0,,,,PENDING
715,WO,A1,WO 2025/151563 A1,018-481-026-496-475,7/17/2025,2025,US 2025/0010824 W,1/8/2025,US 202463619257 P;;US 202418909242 A,1/9/2024,"GENERATIVE AI WITH SPECIFIC, AUDITABLE CITATION REFERENCES","According to aspects of the disclosed subject matter, systems and methods for providing a generated response to an input prompt are presented, where the generated response includes auditable, specific citations to one or more content sources. Moreover, and in various embodiments, the generated responses may utilize, in whole or in part, user-supplied content and/or user-identified content as content sources for responding to an input prompt.",2ND CHAIR LLC,BRITTENHAM AUSTIN MICHAEL;;KIRSTENSEN ANDREW DANIEL,,https://lens.org/018-481-026-496-475,Patent Application,yes,0,0,2,018-481-026-496-475;;188-332-180-229-901,US;;WO,2,018-481-026-496-475;;188-332-180-229-901,US;;WO,0,G06F40/35;;G06F40/166,G06N3/0475;;G06F9/44;;G06F16/2457;;G06F18/21;;G06F40/205;;G06F40/258;;G06N5/04;;G06N20/00;;G06V30/418,,0,0,,,,PENDING
716,WO,A1,WO 2025/159330 A1,099-925-960-371-842,7/31/2025,2025,KR KR2024/019868,12/5/2024,"US 18/4/021,283",1/24/2024,METHOD AND ELECTRONIC DEVICE FOR PROCESSING NATURAL LANGUAGE,"In an embodiment, a method for processing natural language by an electronic device is provided. The method may comprise determining a plurality of speech tags for a plurality of words associated with a body of text by using a language model; determining whether each word of the plurality of words is a noun, proper noun, or adposition based on a corresponding speech tag by processing the plurality of words using a domain-agnostic context extraction, DCE, model to generate a set of n-grams corresponding to a domain-agnostic context of the body of text; and generating a contextual summary of the body of text based on the set of n-grams.","SAMSUNG ELECTRONICS CO., LTD.","HOPE, Paul S.;;LEE, Jeremy W.K.",,https://lens.org/099-925-960-371-842,Patent Application,yes,0,0,1,099-925-960-371-842,WO,1,099-925-960-371-842,WO,0,,G06F40/205;;G06F40/30;;G06F40/279;;G06F40/268;;G06F40/117;;G06F16/34;;G06N20/00,,0,0,,,,UNKNOWN
717,WO,A1,WO 2025/147460 A1,104-083-712-253-493,7/10/2025,2025,US 2024/0062390 W,12/31/2024,US 202463617898 P;;US 202463653702 P;;US 202463728892 P,1/5/2024,SYSTEMS AND METHODS FOR IMPROVING PERFORMANCE OF A LARGE LANGUAGE MODEL BY CONTROLLING TRAINING CONTENT,"Systems and methods for providing enhanced generative models are disclosed. A prompt from a user device provided to a generative model, such as a large language model, is detect. A response to the prompt, output by the generative model is detected. A contribution of a first item of content, used to train the generative model, to the generative model output is estimate. Feedback is generated based at least in part on the estimated contribution of the first item of content, used to train the generative model, to the generative model output. The feedback generated based at least in part on the estimated contribution of the first item of content, used to train the generative model, to the generative model output is transmitted to one or more networked destinations.",PRORATAAI INC,GROSS WILLIAM TOD;;PEDRETTI ANDREA,,https://lens.org/104-083-712-253-493,Patent Application,yes,5,0,4,104-083-712-253-493;;016-430-523-160-160;;088-924-182-571-085;;177-809-290-525-943,US;;WO,4,104-083-712-253-493;;016-430-523-160-160;;088-924-182-571-085;;177-809-290-525-943,US;;WO,0,G06N3/0475;;G06N3/09;;G06N3/0895,G06N3/0475;;G06N3/08;;G06Q50/10;;H04N21/854,,0,0,,,,PENDING
718,US,B1,US 12106205 B1,062-084-390-952-648,10/1/2024,2024,US 202418661519 A,5/10/2024,US 202418661519 A;;US 202418633293 A,4/11/2024,"Dynamic, resource-sensitive model selection and output generation and methods and systems of the same","The disclosed data generation platform enables selection of particular machine learning models on the basis of a predicted resource allocation requirement associated with a given prompt. For example, the model validation platform can evaluate the resource use (e.g., cost) associated with processing a user's prompt with a given type of model. Based on this estimated resource use, the model validation platform can route the prompt to a suitable model to optimize a performance metric value, thereby improving the efficiency of the system. In some implementations, the data generation platform trains a model to accurately estimate resource usage based on ground-truth model-related costs, thereby improving the effectiveness of model selection for efficiency improvements.",CITIBANK NA,JAIN PAYAL;;MAONAH TARIQ HUSAYN;;SATERNUS MARIUSZ;;LEWANDOWSKI DANIEL;;RATH BIRAJ KRUSHNA;;MURRAY STUART;;DAVIES PHILIP,CITIBANK N.A (2024-05-14),https://lens.org/062-084-390-952-648,Granted Patent,yes,21,1,1,062-084-390-952-648,US,36,166-860-055-274-237;;192-529-172-020-159;;117-165-481-521-817;;062-084-390-952-648;;009-332-012-767-769;;130-711-467-813-772;;150-084-174-776-205;;134-859-487-724-028;;136-076-696-451-742;;174-498-778-674-614;;135-411-020-650-37X;;082-042-370-293-809;;081-164-654-051-886;;126-999-415-386-749;;101-393-155-626-043;;028-517-317-595-400;;183-393-311-078-435;;120-491-497-842-713;;071-444-314-653-665;;151-710-271-944-022;;169-310-367-816-659;;114-332-483-825-36X;;176-222-606-932-299;;109-693-731-347-460;;187-959-165-043-749;;165-235-788-605-427;;184-797-936-150-334;;129-627-428-962-735;;132-864-126-338-301;;147-316-129-152-657;;087-574-341-939-358;;052-233-397-211-176;;154-552-332-382-958;;158-104-528-887-831;;122-629-432-281-208;;053-045-267-490-224,US;;WO;;EP,0,G06N3/0455;;G06N3/084;;G06N3/084;;G06N3/0455,G06N3/0455;;G06N3/084,,0,0,,,,ACTIVE
719,US,A1,US 2024/0273796 A1,086-382-131-096-863,8/15/2024,2024,US 202418439585 A,2/12/2024,US 202418439585 A;;US 202363484482 P,2/11/2023,Animated Image File Generation,"Techniques are provided for generating animated image files. In one embodiment, the techniques involve receiving a request for an animated image file, receiving an image selection and text instructions, generating a storyboard based on the text instructions, generating a multi-modal prompt based on the image selection and the storyboard, generating multiple images based on the multi-modal prompt, and generating the animated image file based on the multiple images.",EBRANDS INNOVATIONS LLC,EDSON ALEX,EBRANDS INNOVATIONS LLC (2024-02-14),https://lens.org/086-382-131-096-863,Patent Application,yes,0,1,1,086-382-131-096-863,US,1,086-382-131-096-863,US,0,G06T13/00;;G06F40/56;;G06T13/00,G06T13/00,,0,0,,,,PENDING
720,US,A1,US 2025/0232325 A1,092-330-774-940-784,7/17/2025,2025,US 202519027488 A,1/17/2025,US 202519027488 A;;US 202463621826 P,1/17/2024,"MULTI TENNANT SYSTEM AND METHOD FOR IDENTIFYING SOCIAL, CULTURAL, AND CONTEXTUAL BIAS FOR PERSONAL AND ORGANIZATIONAL USERS","A system for identifying social, cultural, and contextual bias (i.e., friction illumination) for personal and organizational users is disclosed, including at least one user computing device in operable connection with a user network. An application server is in operable communication with the user network to host an application program for identifying social, cultural, and contextual bias for personal and organizational users. The application program having a user interface module for providing access to the application program via the at least one user computing device. An AI engine provides qualitative analysis in a user interface for identifying social, cultural and contextual bias and provide analysis related to the social, cultural and contextual bias.",CORMIER DWAYNE RAY,CORMIER DWAYNE RAY,,https://lens.org/092-330-774-940-784,Patent Application,yes,0,0,1,092-330-774-940-784,US,1,092-330-774-940-784,US,0,G06Q30/0203,G06Q30/0203,,0,0,,,,PENDING
721,US,B1,US 12243638 B1,003-045-701-085-368,3/4/2025,2025,US 202418615623 A,3/25/2024,US 202418615623 A,3/25/2024,Generating service offerings based on associated content and historical data,Embodiments are directed to generating service offerings based on associated content and historical data. Content from a content panel may be provided. Subjects associated with the content may be determined based on information included in the content. A service category associated with the subjects may be determined based on services provided by a healthcare organization. An offering model may be employed to generate an offering panel based on the service category. The offering model may be evaluated based on monitoring interactions between users and the offering panel. Results of the evaluation may be employed to perform further actions including: designating the offering model for retraining based on the performance metrics; retraining the designated offering model; employing the retrained offering model to generate other offering panels for display to the users; or the like.,DEXCARE INC,MINER MADISON COLE;;KOLVE ERIC ANDREW;;MANION JONATHAN PETER;;GARA JR ROBERT IMRE,DEXCARE INC (2024-03-22),https://lens.org/003-045-701-085-368,Granted Patent,yes,40,0,1,003-045-701-085-368,US,1,003-045-701-085-368,US,0,G16H40/20;;G16H50/70;;G16H10/60;;G16H40/20;;G16H50/70;;G16H10/60,G06Q10/0639;;G06F40/40;;G06Q30/018;;G16H10/60;;G16H40/20;;G16H50/70,,24,1,163-058-331-541-497,10.1080/08874417.2002.11647605,"Tan et al., “From Telemedicine Toe-health: Uncovering New Frontiers of Biomedical Research, Clinical Applications & Public Health Services Delivery” The Journal of Computer Information Systems, vol. 42 No. 5, pp. 7-18,Year: 2002.;;International Search Report and Written Opinion for International Patent Application No. PCT/US2023/013531 mailed Jun. 6, 2023, pp. 1-7.;;Office Communication for U.S. Appl. No. 17/551,084 mailed Nov. 1, 2023, pp. 1-22.;;Office Communication for U.S. Appl. No. 17/837,218 mailed Mar. 9, 2023, pp. 1-7.;;Office Communication for U.S. Appl. No. 17/837,218 mailed Mar. 15, 2023, pp. 1-2.;;Office Communication for U.S. Appl. No. 18/114,916 mailed May 23, 2023, pp. 1-9.;;Office Communication for U.S. Appl. No. 17/837,218 mailed Nov. 17, 2022, pp. 1-20.;;Office Communication for U.S. Appl. No. 17/692,738 mailed Jan. 5, 2023, pp. 1-8.;;Office Communication for U.S. Appl. No. 17/837,218 mailed Feb. 9, 2023, pp. 1-5.;;Office Communication for U.S. Appl. No. 17/837,218 mailed Aug. 12, 2022, pp. 1-17.;;Office Communication for U.S. Appl. No. 17/692,738 mailed Oct. 4, 2022, pp. 1-10.;;Office Communication for U.S. Appl. No. 17/692,738 mailed Jun. 13, 2022, pp. 1-9.;;Office Communication for U.S. Appl. No. 17/551,084 mailed May 23, 2023, pp. 1-6.;;Office Communication for U.S. Appl. No. 17/551,084 mailed Sep. 16, 2022, pp. 1-4.;;Office Communication for U.S. Appl. No. 17/551,084 mailed Jul. 1, 2022, pp. 1-59.;;Office Communication for U.S. Appl. No. 18/114,916 mailed Sep. 19, 2023, pp. 1-7.;;Office Communication for U.S. Appl. No. 17/551,084 mailed Jul. 13, 2023, pp. 1-28.;;Office Communication for U.S. Appl. No. 17/551,084 mailed Nov. 15, 2022, pp. 1-61.;;Office Communication for U.S. Appl. No. 17/551,084 mailed Mar. 6, 2023, pp. 1-26.;;Office Communication for U.S. Appl. No. 18/130,660 mailed Sep. 28, 2023, pp. 1-19.;;Office Communication for U.S. Appl. No. 18/130,660 mailed Dec. 14, 2023, pp. 1-4.;;Office Communication for U.S. Appl. No. 18/130,660 mailed Jan. 11, 2024, pp. 1-7.;;Office Communication for U.S. Appl. No. 18/130,660 mailed Jun. 14, 2023, pp. 1-16.;;Office Communication for U.S. Appl. No. 17/551,084 mailed Mar. 14, 2022, pp. 1-52.",ACTIVE
722,US,A1,US 2024/0346811 A1,032-432-855-734-254,10/17/2024,2024,US 202418609182 A,3/19/2024,CN 202310396909 A,4/13/2023,"METHOD, APPARATUS, DEVICE AND STORAGE MEDIUM FOR FEATURE AGGREGATION","Embodiments of the disclosure provide a method, apparatus, device and storage medium for feature aggregation. The method comprises: extracting, with an image encoder, an image feature representation of an input image; for each image feature element set of a plurality of image feature element sets divided along a predetermined dimension of the plurality of dimensions in the image feature representation, selecting a first number of image feature elements from the image feature element set based on a ranking of corresponding image feature elements in the image feature element set, and determining an aggregated image feature element by aggregating the selected first number of image feature elements; and determining an aggregated image feature representation of the input image based on a plurality of aggregated image feature elements determined for the plurality of image feature element sets, respectively.",BEIJING YOUZHUJU NETWORK TECH CO LTD,CUI QUAN;;YI MUYANG;;WU HAO;;YANG CHENG,,https://lens.org/032-432-855-734-254,Patent Application,yes,0,0,2,032-432-855-734-254;;051-310-012-845-46X,US;;CN,2,032-432-855-734-254;;051-310-012-845-46X,US;;CN,0,G06V10/806;;G06V10/82;;G06N3/045;;G06V10/7715;;G06V10/26;;G06V10/764;;G06V10/806;;G06V10/82;;G06V10/806;;G06V10/7715;;G06V10/26;;G06V10/764,G06V10/80;;G06V10/26;;G06V10/764;;G06V10/77,,0,0,,,,PENDING
723,US,A1,US 2025/0133042 A1,063-478-841-534-92X,4/24/2025,2025,US 202318492061 A,10/23/2023,US 202318492061 A,10/23/2023,IN-CONTEXT LEARNING WITH TEMPLATES FOR LARGE LANGUAGE MODEL GENERATION OF CUSTOMIZED EMAILS,A disclosed method facilitates AI-generation of a customized email per a methodology that significantly reduces the risk of the customized email including hallucinated facts or undesirable personal identity information (PII). The method includes identifying an email template and a recipient identifier that identifies a recipient of the customized email based on user inputs to an email application; mining contextual data stored in association with the recipient identifier; generating a large language model (LLM) prompt based on the email template and the contextual data; providing the LLM prompt as input to a trained large language model (LLM); receiving the customized email as an output from the LLM; and returning the customized email to the email application for display within a user interface.,MICROSOFT TECHNOLOGY LICENSING LLC,TSVETKOV ALEXANDER;;ASI ABEDELKADER;;EISENSTADT ROY;;RONEN ROYI,MICROSOFT TECHNOLOGY LICENSING LLC (2023-10-20),https://lens.org/063-478-841-534-92X,Patent Application,yes,0,0,2,063-478-841-534-92X;;116-595-296-606-150,US;;WO,2,063-478-841-534-92X;;116-595-296-606-150,US;;WO,0,G06Q10/107;;G06F40/56;;G06F9/451;;G06F40/174;;G06F40/20;;H04L51/063,H04L51/063;;G06F40/20,,0,0,,,,PENDING
724,US,A1,US 2025/0225325 A1,165-373-390-442-061,7/10/2025,2025,US 202418408254 A,1/9/2024,US 202418408254 A,1/9/2024,RESPONSIBLE PROMPT RECOMMENDATION,"An embodiment generates, by analyzing prompts, a prompt template. Each prompt includes a text description of a content to be generated by a model. An embodiment classifies, using a first trained classification model, a variant portion of a prompt into a category in a set of categories. An embodiment selects, from a repository of prompt templates including the prompt template, a selected prompt template having a similarity above a threshold similarity to a first prompt. An embodiment classifies, using the selected prompt template, a variant portion of the first prompt into a first category in the set of categories. An embodiment adjusts, responsive to determining that the first category is designated as a harmful category, the variant portion of the first prompt. An embodiment causes, using the adjusted first prompt, the model to produce a first content.",IBM,FIGUEREDO DE SANTANA VAGNER;;VASCONCELOS MARISA AFFONSO;;GUERRA MELINA DE VASCONCELOS ALBERIO;;FEFFER MICHAEL ANTHONY;;BERGER SARA E;;SU TIANYU,,https://lens.org/165-373-390-442-061,Patent Application,yes,0,0,1,165-373-390-442-061,US,1,165-373-390-442-061,US,0,G06F40/289;;G06F40/30;;G06F18/2415,G06F40/289;;G06F18/2415;;G06F40/30,,0,0,,,,PENDING
725,US,B1,US 12299557 B1,089-085-983-111-574,5/13/2025,2025,US 202418437200 A,2/8/2024,US 202418437200 A;;US 202363614022 P;;US 202463616817 P;;US 202463626075 P,12/22/2023,Response plan modification through artificial intelligence applied to ambient data communicated to an incident commander,"Disclosed are a method, system, and apparatus of response plan modification through artificial intelligence applied to ambient data communicated to an incident commander. According to one embodiment, the method includes analyzing a description of a fire in progress, automatically generating an incident action plan through an Incident Action Artificial-Intelligence Model (“IAAIM”) based on the description of the fire in progress, and modifying the incident action plan based on a trusted radio communication to an incident commander.",ELLIS TODD;;STAHL MICHAEL;;DUMAN GOKTUG;;ABHYANKER RAJ;;GOVERNMENTGPT INC,ELLIS TODD;;STAHL MICHAEL;;DUMAN GOKTUG;;ABHYANKER RAJ,GOVERNMENTGPT INC (2024-02-08),https://lens.org/089-085-983-111-574,Granted Patent,yes,511,0,1,089-085-983-111-574,US,4,076-838-759-550-152;;000-039-866-900-076;;089-085-983-111-574;;020-902-893-320-691,US,0,G06N3/0475;;G06N3/0475,G06N3/0475,,107,46,029-869-348-014-58X;;009-410-718-662-302;;030-782-192-848-089;;021-112-407-658-938;;179-642-526-200-266;;012-901-758-164-599;;084-571-544-039-488;;144-964-918-331-945;;055-905-600-957-087;;154-128-376-055-868;;121-189-863-158-241;;117-311-220-092-957;;065-892-364-599-072;;056-472-042-512-029;;023-590-607-914-288;;024-935-188-406-074;;059-008-438-892-89X;;067-413-304-844-330;;075-256-997-744-52X;;137-759-700-332-172;;115-833-458-965-135;;035-583-542-812-191;;164-104-766-932-738;;044-104-847-700-209;;062-053-030-520-719;;095-266-199-156-584;;122-163-213-157-950;;030-909-808-377-795;;156-949-464-097-727;;047-127-214-209-138;;006-959-658-463-270;;054-900-176-584-189;;092-153-314-296-057;;025-207-553-863-523;;085-897-427-533-256;;015-786-119-889-065;;065-003-321-174-397;;008-829-481-791-689;;043-888-313-868-666;;067-413-304-844-330;;067-413-304-844-330;;112-006-294-701-601;;087-123-952-000-056;;012-920-028-413-702;;076-492-332-259-790;;093-861-167-252-938,10.1007/978-94-024-2142-2_3;;10.3390/drones3030059;;10.1109/mwc.2019.1900025;;10.3390/drones5010015;;10.3390/drones5010017;;10.1145/3290605.3300502;;10.24251/hicss.2018.009;;10.21428/03d8ffbd.b0ec5747;;10.7249/rr2012;;10.1109/iccict50803.2021.9510067;;38855024;;10.1177/14613557231214383;;pmc11159584;;10.70127/irjedt.vol.7.issue03.894;;pmc8356344;;10.1002/cl2.1112;;37131919;;10.1007/s12103-015-9316-4;;10.1109/cne.2007.369676;;10.1109/iembs.2009.5334555;;pmc4467691;;19964938;;pmc4279550;;25405513;;10.3390/s141121565;;10.1057/s41284-023-00380-7;;10.1109/jstsp.2014.2364559;;10.7717/peerj-cs.1973;;pmc11041969;;38660177;;10.21437/interspeech.2013-615;;10.1145/2652524.2652537;;10.18653/v1/2023.ijcnlp-demo.3;;10.48175/ijarsct-18843;;10.1109/crmico.2014.6959791;;10.1109/crmico.2014.6959803;;10.1109/crmico.2007.4369005;;17869159;;10.1016/j.medengphy.2007.05.014;;10.1093/police/paad083;;10.6028/nist.ir.8196;;10.1109/iwbf50991.2021.9465079;;10.21428/cb6ab371.117a102e;;10.2139/ssrn.3426427;;10.1109/jsen.2014.2357257;;10.3138/jmvfh-2021-0095;;28314707;;pmc5375974;;10.2196/resprot.7499;;10.1007/s10916-018-1104-5;;30327939;;10.3390/s18082414;;30044415;;pmc6111409;;10.1016/j.jsams.2021.04.008;;34148796;;10.1057/s41284-023-00380-7;;10.1057/s41284-023-00380-7;;10.1080/10439463.2024.2315583;;10.1080/13600834.2021.1994220;;10.1109/icatt.2017.7972662;;10.1109/icatt.2015.7136781;;10.1109/msmw.2013.6622052,"“IAP Software”, by The Response Group, Published in [2003] https://www.responsegroupinc.com/iap.;;“Next-Generation Incident Command System (NICS)”, by Kontur, Found Online On [Mar. 12, 2024] https://www.kontur.io/portfolio/nics/.;;“Next-Generation Incident Command System”, by MIT Lincoln Laboratory, Found Online On [Mar. 12, 2024] https://www.Il.mit.edu/r-d/projects/next-generation-incident-command-system.;;“Next-Generation Incident Command System Fact Sheet”, by U.S. Department of Homeland Security, Published Online On [Jun. 5, 2024] https://www.dhs.gov/sites/default/files/publications/Next%20Generation%20Incident%20Command%20System-NICS_0.pdf.;;“Response Tools”, by NJ Resources, Found Online On [Mar. 12, 2024] https://njr.net/response-tools/.;;“Axon Body 4”, by Patrick W. Smith et al., Published In [1993] https://www.axon.com/products/axon-body-4.;;“Digital Evidence Management, In-Car Video, and Advanced Body Cameras.”, by Utility, Found Online On [Mar. 12, 2024] https://www.utility.com/.;;“DisasterTech”, by Roger Coleman et al., Published in [2019] https://www.disastertech.com/.;;“Using Unmanned Aerial Vehicles (UAVs) as Mobile Sensing Platforms (MSPs) for Disaster Response, Civil Security and Public Safety”, Published at Fundamental and Applied Research in Unmanned Aircraft Systems Technology, by Hanno Hildmann et al, Published Online On [Jul. 29, 2019] https://www.mdpi.com/2504-446X/3/3/59.;;“Toward UAV-Based Airborne Computing”, Published at IEEE Wireless Communications, by Kejie Lu et al., Published Online on [Aug. 5, 2019] https://par.nsf.gov/servlets/purl/10110848.;;“Unmanned Aerial Vehicles for Wildland Fires: Sensing, Perception, Cooperation and Assistance”, Published at Feature Papers of Drones, by Moulay A. Akhloufi et al., Published Online On [Feb. 22, 2021] https://www.mdpi.com/2504-446X/5/1/15.;;“UAV-Enabled Disaster Management: Applications, Open Issues, And Challenges”, Published at Journal of Field Robotics, by Amina Khan et al., Published Online On [Nov. 15, 2022] https://gmsarnjournal.com/home/wp-content/uploads/2023/06/vol18no1-6.pdf.;;“Drone Swarms in Fire Suppression Activities: A Conceptual Framework”, Published at UAV Application for Wildfire Detection, Prevention and Management, by Elena Ausonio et al., Published Online On [Mar. 7, 2021] https://www.mdpi.com/2504-446X/5/1/17.;;“An Exploratory Study of the Use of Drones for Assisting Firefighters During Emergency Situations”, Published at Conference on Human Factors in Computing Systems Proceedings, by Md. Nafiz Hasan Khan et al., Published Online On [May 2, 2019] http://clab.iat.sfu.ca/pubs/Khan-DronesFirefighters-CHI2019.pdf.;;“The Good, the Bad and the Indispensable—Insights into the Practical Potential of Emergency Response Information Systems and Drones for Firefighters”, Published at Hawaii International Conference on System Sciences, by Julian Weidinger, Published Online In [2018] https://core.ac.uk/download/pdf/143480849.pdf.;;“Autonomous First Response Drone-Based Smart Rescue System for Critical Situation Management in Future Wireless Networks”, Published at Journal on Innovative Communication Technologies, by Joel P. Lemayian et al., Published Online On [May 23, 2020] https://assets.pubpub.org/ybmy2nbl/71604609477880.pdf.;;“Tactile Feedback in Defence & Security: The Next Frontier”, by Haptic, Published Online on [May 13, 2023] https://www.haptic.ro/tactile-feedback-in-defence-security-the-next-frontier/.;;“Wearable Technologies for Law Enforcement”, Published at National Istitute of Justice, by Richard Silberglitt et al., Published Online on [Sep. 8, 2017] https://www.rand.org/content/dam/rand/pubs/research_reports/RR2000/RR2012/RAND_RR2012.pdf.;;“IoT based Smart Vest and Helmet for Defence Sector”, Published at IEEE International Conference on Communication Information and Computing Technology, by Ninad V. Joshi, Published Online On [Jun. 25, 2021] https://shorturl.at/inKQ8.;;Utilizing Glove-Based Gestures and a Tactile Vest Display for Covert Communications and Robot Control, Published at Army Research Laboratory, by Linda R. Elliott et al., Published Online in [2014] https://apps.dtic.mil/sti/pdfs/ADA607637.pdf.;;“Wearable Technologies Can Help Soldiers Survive in Adverse Environment”, Published at Chakraview, by Dr. Jayakrishnan N. Nair, Published Online On [Dec. 18, 2020] https://defence.capital/2020/12/18/wearable-technologies-can-help-soldiers-survive-in-adverse-environment/.;;“IOT Based Soldier E-Jacket Using GPS”, Published at Journal of Interdisciplinary Cycle Research, by Prof.Swapnil Chaudhari et al., Published Online In [Mar. 2020] https://shorturl.at/euRZ7.;;“Police Body-Worn Cameras and Privacy: Views and Concerns of Officers and Citizens”, Published at International Journal of Police Science & Management, by Brigitte Poirier et al., Published Online On [Nov. 21, 2023] https://journals.sagepub.com/doi/pdf/10.1177/14613557231214383.;;“LORA Based Soldier Tracking and Health Monitoring Device”, Published at International Research Journal of Engineering and Technology, by Kruthikaran et al., Published Online in [Mar. 2023] https://www.irjet.net/archives/V10/i3/IRJET-V10I367.pdf.;;“A Literature Review on IOT-Based Soldier Health Monitoring E-Jacket”, Published at International Research Journal of Modernization in Engineering Technology and Science, by Ms. Dnyanada Meshram et al., Published Online in [Feb. 2023] https://www.irjmets.com/uploadedfiles/paper/issue_2_february_2023/33517/final/fin_irjmets1676464912.pdf.;;“Body-Worn Cameras' Effects On Police Officers and Citizen Behavior: A Systematic Review”, Published at Campbell Systematic Reviews, by Cynthia Lum et al., Published Online On [Sep. 9, 2020] https://onlinelibrary.wiley.com/doi/epdf/10.1002/cl2.1112.;;“Enhancing Response Capabilities with Smartwatches in Public Safety”, Published at The Public Safety Network, Found Online On [Mar. 12, 2024] https://www.publicsafety.network/wp-content/uploads/2021/01/Smartwatches-in-Public-Safety-White-Paper_FINAL.pdf.;;“Police Tactical Vest: IoT and AI to Enhance Safety on Operations”, Published at Mechatronics Canada, Published Online On [Mar. 1, 2024] https://www.mechatronicscanada.ca/product-news/police-tactical-vest-iot-ai/.;;“Body-Worn Video Cameras for Law Enforcement Market Survey Report”, Published at Homeland Security, Published Online In [Jun. 2015] https://www.dhs.gov/sites/default/files/publications/Body-Worn-Cams-MSR_0615-508_1.pdf.;;“Police Body-Worn Cameras: Perceptions of Law Enforcement Leadership”, Published at Springerlink, by John Ortiz Smykla, Oublished Online on [Dec. 4, 2015] https://link.springer.com/content/pdf/10.1007/s12103-015-9316-4.pdf.;;“Geolocation Wearables for Enhanced Law Enforcement”, Published at Utilities One, Published Online On [Nov. 15, 2023] https://utilitiesone.com/geolocation-wearables-for-enhanced-law-enforcement#anchor-0.;;“Want to control your electronics with your tongue?”, Published at ZDNET, by Jada Jones, Published Online On [May 13, 2023] https://www.zdnet.com/article/want-to-control-your-electronics-with-your-tongue-this-company-is-making-that-happen/.;;“A Magnetic Wireless Tongue-Computer Interface”, Published at IEEE Xplore, by Xueliang Huo et al., Published Online On [Jun. 11, 2007] https://www.researchgate.net/publication/4252014_A_Magnetic_Wireless_Tongue-Computer_Interface.;;“A Hands-Free, Mouth Operated Joystick Computer Mouse Designed Specifically for Individuals With Disabled Hand Movement”, by Quadlife, Published Online On [Sep. 17, 2020] https://quad.life/product.;;“MouthPad Turns Your Tongue into a Mouse For Your Phone”, Published at Engadget, by Cherlynn Low, Published Online On [Jan. 12, 2024] https://www.engadget.com/the-mouthpad-turns-your-tongue-into-a-mouse-for-your-phone-184541021.html?_fsig=dqmn468RiJE_pgKZXmIOHw--%7EA.;;“Evaluation of the Tongue Drive System by Individuals with High-Level Spinal Cord Injury”, Published at Conf Proc IEEE Eng Med Biol Soc, by Xueliang Huo et al., Published Online On [Mar. 12, 2024] https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4467691/pdf/nihms698831.pdf.;;“An Arch-Shaped Intraoral Tongue Drive System with Built-in Tongue-Computer Interfacing SoC”, Published at Miniaturized Wireless Biosensors, by Hangue Park et al., Published Online On [Nov. 14, 2014] https://www.mdpi.com/1424-8220/14/11/21565.;;“Body-Worn Camera Activation In Prisons: Understanding Correctional Officers' Decision-Making and Use of Discretion”, Published at Security Journal, Published by Shannon Dodd et al., Published Online On [May 26, 2023] https://link.springer.com/article/10.1057/s41284-023-00380-7.;;“Airfence”, by Sensofusion, Found Online On [Jul. 19, 2024] https://sensofusion.com/airfence/.;;“A Real-Time End-to-End Multilingual Speech Recognition Architecture”, Published at IEEE Journal of Selected Topics in Signal Processing, Published by Javier Gonzalez-Dominguez et al., Published Online On [Oct. 23, 2014] https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6935076.;;“Real-Time Multilingual Speech Recognition and Speaker Diarization System Based On Whisper Segmentation”; Published at PeerJ Computer Science, Published by Ke-Ming Lyu et al., Published Online On [Mar. 29, 2024] https://peerj.com/articles/cs-1973.pdf.;;“Simultaneous Speech-To-Speech Translation System With Neural Incremental ASR, MT, And TTS”, Published at Nara Institute of Science and Technology, Published by Katsuhito Sudoh et al., Published Online On [Nov. 10, 2020] https://arxiv.org/pdf/2011.04845.;;“Simple, Lexicalized Choice of Translation Timing for Simultaneous Speech Translation”, Published at Nara Institute of Science and Technology, Published by Tomoki Fujita, Published Online in [Jan. 2013] https://www.isca-archive.org/interspeech_2013/fujita13_interspeech.pdf.;;“Real Time Speech Translator”, Published at Czech Technical University (CTU), Published by Xavier Garcia Cabrera, Published Online On [Jun. 25, 2008] https://upcommons.upc.edu/bitstream/handle/2099.1/6128/memoria.pdf?sequence=1&isAllowed=y.;;“An Empirical Simulation-based Study of Real-Time Speech Translation for Multilingual Global Project Teams”, Published at International Symposium on Empirical Software Engineering and Measurement, Published by Fabio Calefato et al., Published Online On [Sep. 18, 2014] https://collab.di.uniba.it/fabio/wp-content/uploads/sites/5/2014/05/ESEM2014_camera-ready.pdf.;;“Turning Whisper into Real-Time Transcription System”, Published at International Joint Conference on Natural Language Processing (IJCNLP) and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics (AACL), Published by Dominik Macháček et al., Published Online in [Nov. 2023] https://aclanthology.org/2023.ijcnlp-demo.3.pdf.;;“Precision Payload Delivery System”, by Corvo, Found Online On [Jul. 19, 2024] https://corvouas.com.au/wp-content/uploads/CORVO-PPDS-web-version-23082023-compressed.pdf.;;“RQ-20 Puma”, by AeroVironment, Inc., Published Online On [Aug. 4, 2020] https://english.iswnews.com/14555/military-knowledge-rq-20-puma-drone/.;;“Counter Drone Systems”, by Adani Defence and Aerospace, Found Online On [Jul. 19, 2024] https://www.adanidefence.com/en/counter-drone-systems.;;“Dragon Eye Miniature UAV”, by Defence Update, Published Online On [Aug. 23, 2005] https://defense-update.com/20050823_dragon-eye.html#google_vignette.;;“Countering the UAS Threat”, by Defence Update, Published by Tamir Eshel, Published Online On [Jun. 27, 2024] https://defense-update.com/20240627_c-uas-2.html#google_vignette.;;“Multilingual Speech Transcription and Translation System”, Published at International Journal of Advanced Research in Science, Communication and Technology (IJARSCT), Published by Dheeraj K N et al., Published Online in [Jun. 2024] https://ijarsct.co.in/Paper18843.pdf.;;“Real Time Direct Speech-to-Speech Translation”, Published at International Research Journal of Engineering and Technology (IRJET), Published by Sanchit Chaudhari et al., Published Online in [Jan. 2022] https://www.irjet.net/archives/V9/i1/IRJET-V9I1104.pdf.;;“Methods and algorithms of correction of propagation factor influence on errors of measurement coordinates receivers GNSS”, Published at International Crimean Conference Microwave & Telecommunication Technology, Published by V. I. Lutsenko et al., Published Online On [Oct. 22, 2012] https://ieeexplore.ieee.org/document/6335995/authors#authors.;;“Elimination of abnormally high errors of determining the coordinates of global navigation satellite system receivers”, Published at International Crimean Conference Microwave & Telecommunication Technology, Published by V.I. Lutsenko et al., Published Online On [Nov. 4, 2013] https://ieeexplore.ieee.org/document/6652840/authors#authors.;;“Interpolation method of introducing differential corrections into measurements of coordinate and pseudoranges in global navigation systems”, Published at International Crimean Conference Microwave & Telecommunication Technology, Published by V.I. Lutsenko et al., Published Online On [Nov. 4, 2013] https://ieeexplore.ieee.org/document/6652837/authors#authors.;;“Fixed-Wing UAV Systems: Modular VTOL, Long-Range Maritime UAV, Tactical ISR UAS”, by Tekever, Found Online On [Jul. 19, 2024] https://www.unmannedsystemstechnology.com/company/tekever/.;;“Introducing Generative AI for Law Enforcement”, by C3 AI, Published at Youtube, Published Online On [Aug. 10, 2023] https://www.youtube.com/watch?v=eO4cQjnwqgo.;;“Vanderbilt Engineering Students Create “Smart Vest” to Save Police Officers”, by Vanderbilt University, Published at Youtube, Published Online On [Apr. 27, 2017] https://www.youtube.com/watch?v=jq5DO3717E8.;;“Smart Vest”, by Harley-Davidson, Published at Youtube, Published Online On [Apr. 9, 2024] https://www.youtube.com/watch?v=C42bk5h4y-E.;;“This Vest Can Save Lives”, by Virginia Tech, Published at Youtube, Published online on [Sep. 1, 2015] https://www.youtube.com/watch?v=79x7_N6mTYo&t=6s.;;“Vanderbilt Students Create Smart Police Vest”, by Sarah McCarthy, Published at Newschannel 5, Published online On [Apr. 27, 2017] https://www.newschannel5.com/news/vanderbilt-students-create-smart-police-vest.;;“Vanderbilt Students Develop Smart Police Vest That Calls For Backup”, by Ariana Maia Sawyer, Published at The Tennessee, Published Online On [Apr. 25, 2017] https://www.tennessean.com/story/news/crime/2017/04/24/vanderbilt-students-develop-smart-police-vest-calls-backup/100854078/.;;“Prototype “Smart Vest” Could Greatly Reduce Highway Worker Deaths and Injuries ByTalking to Traffic”, by Tom Jackson, Published at EquipmentWorld, Published Online on [Sep. 22, 2015] https://www.equipmentworld.com/roadbuilding/video/14963694/prototype-smart-vest-could-greatly-reduce-highway-worker-deaths-and-injuries-by-talking-to-traffic.;;“Smart Vest: Wearable Multi-Parameter Remote Physiological Monitoring System”, by P.S. Pandian, Published at Medical Engineering & Physics, Published Online On [Sep. 14, 2007] https://www.sciencedirect.com/science/article/abs/pii/S1350453307000975?via%3Dihub.;;“Robust Speech Recognition via Large-Scale Weak Supervision”, by Alec Radford et al., Published at Cornell University, Published Online On [Dec. 6, 2022] https://arxiv.org/pdf/2212.04356.;;“Faster-whisper”, Published at Github, Found Online On [May 1, 2024] https://github.com/SYSTRAN/faster-whisper.;;“Insanely Fast Whisper”, Published at Github, Found Online On [May 1, 2024] https://github.com/Vaibhavs10/insanely-fast-whisper.;;“WhisperLive”, Published at Github, Found Online On [May 1, 2024] https://github.com/collabora/WhisperLive.;;“Whisper.cpp”, Published at Github, Found Online On [May 1, 2024] https://github.com/ggerganov/whisper.cpp/tree/master.;;“Exploration of Alerting Methods on Vest-Worn System”, by Kristen P. Hines, Published at Virginia Polytechnic Institute and State University, Published online On [May 4, 2016] https://vtechworks.lib.vt.edu/server/api/core/bitstreams/af47ee5d-2b50-462d-9da7-bd7982a1ecf3/content.;;“Artificial Intelligence and Face Recognition for Body Cams”, by Hernan Cafiel, Published at Ebenezer Technologies, Published Online on [Dec. 9, 2022] https://ebenezertechs.com/face-recognition-body-cams/.;;“Integrating Body-Worn Cameras, Drones, And AI: A Framework Or Enhancing Police Readiness And Response”, by Amanda Davies et al., Published at Oxford University Press, Published Online On [Dec. 13, 2023] https://academic.oup.com/policing/article/doi/10.1093/police/paad083/7471863.;;“Security Analysis of First Responder Mobile and Wearable Devices”, by Joshua M. Franklin, Published at National Institute of Standards and Technology Interagency, Published Online In [May 2020] https://nvlpubs.nist.gov/nistpubs/ir/2020/NIST.IR.8196.pdf.;;“Body Worn Cameras With Facial Recognition Technology: When It Constitutes a Search”, by Kelly Blount, Published at American University Washington College of Law, Published Online In [2017] https://core.ac.uk/download/pdf/327253044.pdf.;;“Towards On-Device Face Recognition in Body-worn Cameras”, by Ali Almadan, Published at IEEE International Workshop on Biometrics and Forensics, Published Online On [Apr. 7, 2021] https://arxiv.org/pdf/2104.03419.;;“Law Enforcement's Pairing of Facial Recognition Technology with Body-Worn Cameras Escalates Privacy Concerns”, by Katelyn Ringrose, Published at Virginia Law Review, Published Online On [Feb. 18, 2019] https://virginialawreview.org/wp-content/uploads/2020/12/04.%20Final%20Ringrose.pdf.;;“Police use of facial recognition technology: The potential for engaging the public through co-constructed policy-making”, by Dallas Hill, Published at International Journal of Police Science & Management, Published Online On [Apr. 4, 2022] https://journals.sagepub.com/doi/epub/10.1177/14613557221089558.;;“Information Technology on the Beat: The Impacts of Body-Worn Camera and Facial Recognition Technology on Public Safety”, by Jiyong Park, Published at University of North Carolina, Published Online On [Jul. 24, 2019] https://shorturl.at/bfqL.4.;;“Chilling: The Constitutional Implications of Body-Worn Cameras and Facial Recognition Technology at Public Protests”, by Julian R. Murphy, Published at Washington and Lee University, Published Online on [Aug. 30, 2018] https://scholarlycommons.law.wlu.edu/cgi/viewcontent.cgi?article=1104&context=wlulr-online.;;“Recent Advances in Wearable Sensors for Health Monitoring”, by Mary M. Rodgers, Published at IEEE Sensors Journal, Published online On [Sep. 16, 2014] https://shorturl.at/nwxY2.;;“Dress for Success: Embedded Health Sensors In The Future Soldier”, by Paul Dhillon, Published at Journal of Military, Veteran and Family Health, Published Online In [2022] https://jmvfh.utpjournals.press/doi/pdf/10.3138/jmvfh-2021-0095.;;“How Biometric Monitoring Will Save Law Enforcement Lives”, by Lt. Grant Bedford, Published at Police1, Published Online On [Dec. 18, 2019] https://www.police1.com/health-fitness/articles/how-biometric-monitoring-will-save-law-enforcement-lives-91PHTP83yHZNAOdw/#:˜:text=These%20devices%20could%20be%20placed,monitoring%20program%20to%20other%20departments.;;“Biometrics and Policing: A Protocol for Multichannel Sensor Data Collection and Exploratory Analysis of Contextualized Psychophysiological Response During Law Enforcement Operations”, by Robert D Furberg et al., Published at JMIR Research Protocols, Published Online on [Mar. 17, 2017] https://pdfs.semanticscholar.org/e725/3d89aa98ffc8036163acdea18137db13464d.pdf.;;“Real-Time Remote Health Monitoring Systems Using Body Sensor Information and Finger Vein Biometric Verification: A Multi-Layer Systematic Review”, by A. H. Mohsin et al., Published at Journal of Medical Systems, Published Online On [Oct. 16, 2018] https://shorturl.at/IJPQ5.;;“Warfighter Physiological and Environmental Monitoring”, by G.A. Shaw et al., Published at Massachusetts Institute of Technology, Published Online On [Nov. 1, 2024] https://apps.dtic.mil/sti/tr/pdf/ADA428022.pdf.;;“Wearable Health Devices—Vital Sign Monitoring, Systems and Technologies”, by Duarte Diaset al., Published at Wearable Smart Devices, Published Online On [Jul. 25, 2018] https://www.mdpi.com/1424-8220/18/8/2414.;;“On The Real-Time Prevention and Monitoring of Exertional Heat Illness in Military Personnel”, by M.J. Buller, Published at Journal of Science and Medicine in Sport, Published Online On [Apr. 26, 2021] https://www.jsams.org/action/showPdf?pii=S1440-2440%2821%2900104-3.;;“The Power of Biometrics: A Game-Changer for Officer Wellness”, by Deputy Chief Aaron Johnson, Published at Police1, Published online on [Mar. 2, 2024] https://www.police1.com/wellness-week/the-power-of-biometrics-a-game-changer-for-officer-wellness.;;“Wearable Tech for Law Enforcement”, Published at inTime, Found Online on [May 3, 2024] https://intime.com/industries/police/wearable-tech-for-law-enforcement/.;;“Can Body Cameras Reduce Altercations in a Correctional Facility?”, by Dawn Lenzmeier, published at NEWCOM, Published Online On [Nov. 30, 2022] https://newcomglobal.com/wp-content/uploads/2022/11/NEWCOM-Body-Cameras-Reduce-Altercations-in-a-Correctional-Facility.pdf.;;“Body Cameras in Corrections? Get ready For Game-Changing Benefits”, Published at Utility, Published online on [Feb. 29, 2024] https://www.utility.com/blog/body-cameras-in-corrections-get-ready-for-game-changing-benefits/.;;“Body-Worn Camera Activation in Prisons: Understanding Correctional Officers' Decision-Making and Use of Discretion”, by Dodd, Published at Security Journal, Published Online on [May 26, 2023] https://research-repository.griffith.edu.au/server/api/core/bitstreams/b534906f-5064-4e5e-94a7-e0f8cf1c99a8/content.;;“A Randomized Controlled Trial of the Impact of Body-Worn Cameras in the Loudoun County, VA, Adult Detention Center”, by Brittany C. Cunningham et al., Published at CNA, Published Online In [Jun. 2023] https://www.ojp.gov/pdffiles1/nij/grants/307338.pdf.;;“Body-Worn Camera Activation In Prisons: Understanding Correctional Officers' Decision-Making And Use Of Discretion”, by Shanon Dodd et al., Published at Security Journal, Published On [May 26 2023] https://hizligecisodemesi.net/body-worn-camera-scholarly-articles-7cf3.;;“Policing Universities: Exploring the use of body-worn cameras (BWCs) by private campus security officers”, by Francesca Menichelli, Published at Policing and Society, Published Online on [Feb. 17, 2024] https://www.tandfonline.com/doi/epdf/10.1080/10439463.2024.2315583?needAccess=true.;;“Transition of Body-Worn Cameras from Policing to Corrections”, by Jasmine Kaur, Published at EBP Society, Published online On [Mar. 24, 2023] https://www.ebpsociety.org/blog/education/547-transition-of-body-worn-cameras-from-policing-to-corrections.;;“Life-Saving Suits for Law Enforcement: Looking Ahead at Wearable Technology”, by Thomas B. Cashion et al., Published at International Association of Chiefs of Police, Published Online on [Jun. 27, 2018] https://www.policechiefmagazine.org/life-saving-wearable-technology/.;;“Policing Faces: The Present And Future of Intelligent Facial Surveillance”, by Lachlan Urquhart et al., Published at Information & Communication Technology Law, Published online On [Oct. 28, 2021] https://www.pure.ed.ac.uk/ws/portalfiles/portal/239314767/UrquhartLMirandaD2021ICTLPolicingFaces.pdf.;;“Hardware to Protect Against Drones”, by Dedrone, Found Online On [May 3, 2024] https://www.dedrone.com/products/counter-drone-technology.;;“Counter-Drone Solutions”, ARDRONIS, Found Online On [May 3, 2024] https://www.rohde-schwarz.com/hk/products/aerospace-defense-security/counter-drone-systems_250881.html.;;“Protectors of Critical Infrastructure are Enabled by Spotter Radars to Prevent Harm”, by Spotter Global, Found Online On [May 3, 2024] https://www.spotterglobal.com/.;;“Development of Equipment for Satellite Navigation Systems GLONASS, GPS, GALILEO”, by KB Center, Found Online On [May 3, 2024] http://www.kbcentr.com.ua/.;;“Design Smart Antenna for GPS/GLONASS Using Adaptive Beamforming”, Herasymenko K.V. et al., Lviv Polytechnic National University Institutional Repository, Published Online In [Jan. 2012] https://shorturl.at/osIS5.;;“Equipment Optimization For Weather Balloon and Ground-Based Weather Stations Using GNSS”, by A. G. Laush, Published at International Conference on Antenna Theory and Techniques (ICATT), Published Online In [2017] https://sci-hub.yncjkj.com/10.1109/icatt.2017.7972662.;;“A Novel Dual Band Microstrip Antenna Array for Receiving of Satellite Navigational Signals GPS/GLONASS/GALILEO”, by Sergiy Y. Martynyuk et al., Published at International Conference on Antenna Theory and Techniques Published Online In [2015] https://sci-hub.yncjkj.com/10.1109/icatt.2015.7136781.;;“Model of Mapping Function for The Calculation of Zenith Tropospheric Delay”, by V.I. Lutsenko et al., Published at International Kharkov Symposium on Physics and Engineering of Microwaves, Millimeter and Submillimeter Waves, Published Online In [2013] https://sci-hub.53yu.com/10.1109/msmw.2013.6622052.",ACTIVE
726,WO,A1,WO 2025/012292 A1,134-836-569-745-189,1/16/2025,2025,EP 2024069410 W,7/9/2024,GB 202310582 A,7/10/2023,METHOD AND SYSTEM,The disclosure relates to generating and obtaining content for a user profile associated with a building in a way which is more accurate and specific to a building.,PLANNA LTD,HANASH ALAIN,,https://lens.org/134-836-569-745-189,Patent Application,yes,0,0,3,134-836-569-745-189;;027-739-327-094-500;;116-252-763-099-430,GB;;WO;;EP,3,134-836-569-745-189;;027-739-327-094-500;;116-252-763-099-430,GB;;WO;;EP,0,G06Q10/20;;G06Q50/08;;G06F16/90332;;G06F16/9035;;G06F16/9535,G06Q10/20;;G06Q50/08;;G06T7/00,,1,1,161-349-545-432-808,10.1007/978-981-99-0835-6_52,"MAHEYSH V ET AL: ""CNN-Based Detection of Cracks and Moulds in Buildings"", 4TH INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND SUSTAINABLE INFORMATICS (ICMCSI 2023); 11-12 JAN. 2023; KIRTIPUR, NEPAL; LECTURE NOTES ON DATA ENGINEERING AND COMMUNICATIONS TECHNOLOGIES ; ISSN 2367-4520,, vol. 166, 11 June 2023 (2023-06-11), pages 729 - 744, XP009557326, ISBN: 978-981-99-0835-6, [retrieved on 20230527], DOI: 10.1007/978-981-99-0835-6_52",PENDING
727,US,A1,US 2025/0209269 A1,026-315-955-681-065,6/26/2025,2025,US 202418991618 A,12/22/2024,US 202418991618 A;;US 202363614485 P,12/22/2023,Stateful Text Generation Using Large Language Models,"Systems and methods for stateful text generation using large language models are described. For example, a method may include inputting a first prompt to a large language model to cause the large language model to output a list of keywords based on a context window; inputting a second prompt to the large language model to cause the large language model to output an adjacency matrix for keywords in the list of keywords that indicates which of the keywords in the list of keywords are related in the context window; and determining a graph including nodes corresponding to respective keywords in the list of keywords and edges corresponding to relationships between keywords indicated by the adjacency matrix.",STUDY GENIE INC,BHARDWAJ SARVESH,STUDY GENIE INC (2024-12-24),https://lens.org/026-315-955-681-065,Patent Application,yes,0,0,1,026-315-955-681-065,US,1,026-315-955-681-065,US,0,G06F40/279;;G06F40/40;;G09B7/00;;G06F40/30;;G06F40/284;;G06F40/279;;G09B7/00;;G06F40/40,G06F40/279;;G06F40/40;;G09B7/00,,0,0,,,,PENDING
728,WO,A1,WO 2025/068600 A1,008-341-433-692-759,4/3/2025,2025,EP 2024077489 W,9/30/2024,US 202363541287 P,9/28/2023,TRAINING DIFFUSION NEURAL NETWORKS BY BACKPROPAGATING DIFFERENTIABLE REWARDS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training a diffusion neural network using a differentiable reward function.",DEEPMIND TECH LTD,SWERSKY KEVIN JORDAN;;VICOL PAUL ADRIAN;;FLEET DAVID JAMES;;CLARK KEVIN STEFAN,,https://lens.org/008-341-433-692-759,Patent Application,yes,1,0,1,008-341-433-692-759,WO,1,008-341-433-692-759,WO,0,G06N3/084;;G06N3/047;;G06N3/0475;;G06N3/092;;G06N3/0455;;G06N3/0464,G06N3/0475;;G06N3/0455;;G06N3/0464;;G06N3/047;;G06N3/084;;G06N3/092,,7,0,,,"JIAZHENG XU ET AL: ""ImageReward: Learning and Evaluating Human Preferences for Text-to-Image Generation"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 6 June 2023 (2023-06-06), XP091530230;;YING FAN ET AL: ""DPOK: Reinforcement Learning for Fine-tuning Text-to-Image Diffusion Models"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 25 May 2023 (2023-05-25), XP091519510;;KEVIN CLARK ET AL: ""Directly Fine-Tuning Diffusion Models on Differentiable Rewards"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 29 September 2023 (2023-09-29), XP091626950;;LING YANG ET AL: ""Diffusion Models: A Comprehensive Survey of Methods and Applications"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 24 October 2022 (2022-10-24), XP091796280;;KEVIN BLACK ET AL: ""Training Diffusion Models with Reinforcement Learning"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 22 May 2023 (2023-05-22), XP091515984;;HU ET AL., ARXIV:2106.09685, 2021;;HO ET AL., ARXIV:2006:11239",PENDING
729,US,A1,US 2025/0086310 A1,129-145-288-689-789,3/13/2025,2025,US 202318466049 A,9/13/2023,US 202318466049 A,9/13/2023,LARGE LANGUAGE MODEL PRIVACY PRESERVATION SYSTEM,Computer-implemented methods for a large language model privacy preservation system. Aspects include receiving prompt data from a user device. Aspects further include generating pre-processed prompt data using the prompt data from the user device. Aspects also include identifying a category for the pre-processed prompt data using topic modeling. Aspects include generating normalized prompt data using the pre-processed prompt data. Aspects further include storing the category and the normalized prompt data.,IBM,CUOMO GENNARO ANTHONY;;DOLPH BLAINE H;;HAY CHRISTOPHER,INTERNATIONAL BUSINESS MACHINES CORPORATION (2023-09-12),https://lens.org/129-145-288-689-789,Patent Application,yes,5,0,1,129-145-288-689-789,US,1,129-145-288-689-789,US,0,G06F21/6245;;G06F16/3335;;G06F16/3335;;G06F21/6245,G06F21/62;;G06F16/33,,1,0,,,"US 63/499,489 to Burton, published as US 12,210,839 (listed above) (Year: 2023)",PENDING
730,US,A1,US 2025/0209543 A1,081-688-703-867-230,6/26/2025,2025,US 202318392137 A,12/21/2023,US 202318392137 A,12/21/2023,ARTIFICIAL INTELLIGENCE DRIVEN SYSTEM FOR ACCELERATED SOFTWARE APPLICATION CONTENT GENERATION,"Aspects of the present disclosure relate to generating software application content related to forms. Embodiments include generating a first prompt comprising instructions to extract a first type of information from a form and providing the first prompt to a first machine learning model. Embodiments further include receiving, from the first machine learning model, first extracted information. Embodiments further include generating a second prompt comprising instructions to extract a second type of information from the form and providing the second prompt to the first machine learning model. Embodiments further include receiving, from the first machine learning model, second extracted information. Embodiments further include generating a third prompt comprising instructions to generate software application content based on the first and second extracted information and providing the third prompt to a second machine learning model. Embodiments further include receiving, from the second machine learning model, generated software application content.",INTUIT INC,MUTHU MALATHY;;FINEGAN CORINNE L;;BECKER RICHARD J;;KALLEPALLI GOUTHAM;;IDOWU OLABODE;;PENA-PENA KARELIA DEL CARMEN;;SINHA ANKITA,INTUIT INC (2023-12-11),https://lens.org/081-688-703-867-230,Patent Application,yes,9,0,1,081-688-703-867-230,US,1,081-688-703-867-230,US,0,G06N20/00;;G06Q40/123;;G06N3/045;;G06N3/0455;;G06N3/044;;G06N20/00;;G06Q40/123,G06Q40/12;;G06N20/00,,0,0,,,,PENDING
731,US,A1,US 2025/0238597 A1,142-839-263-325-601,7/24/2025,2025,US 202418416690 A,1/18/2024,US 202418416690 A,1/18/2024,GENERATIVE NEURAL NETWORK MODEL DOCUMENT MODIFICATION,A method of modifying a document is described. A first user input is received from a user via an editing window of a graphical user interface. The first user input represents a request to a generative neural network model for drafting assistance with the document. The editing window displays content of the document during an editing session of the document for the user. An output generated by the generative neural network model based on the first user input and the content of the document is asynchronously obtained while maintaining the editing session. The content of the document is modified during the editing session to include the output generated by the generative neural network model. The modified content is caused to be displayed within the editing window during the editing session.,MICROSOFT TECH LICENSING LLC,RAMOS GONZALO A;;SUH JIN A;;AMORES FERNANDEZ JUDITH;;CZERWINSKI MARY P;;PALANI SRISHTI,,https://lens.org/142-839-263-325-601,Patent Application,yes,0,0,2,142-839-263-325-601;;002-150-864-751-562,US;;EP,2,142-839-263-325-601;;002-150-864-751-562,US;;EP,0,G06F40/166;;G06F40/56;;G06F40/253;;G06F40/103;;G06F40/166;;G06F40/106,G06F40/166;;G06F40/106,,0,0,,,,PENDING
732,US,A1,US 2025/0158958 A1,077-584-555-321-832,5/15/2025,2025,US 202418589137 A,2/27/2024,US 202418589137 A;;US 202363598001 P,11/10/2023,HANDLING RAW DNS QUERIES IN DNS CLIENT,"Methods and apparatuses for handling raw DNS queries or DNS queries that generate responsive DNS records from a DNS server that are not recognized or decodable by a DNS client are described. The DNS client may receive a DNS query from an application and provide a numerical IP address and one or more DNS records for a given domain name to the application. In some cases, a DNS client provides an interface that enables the application to send and receive DNS queries and responses to DNS queries that use DNS functionalities and customizations that are not recognized by the DNS client. This capability allows the application to craft its own DNS queries to send and receive resulting response bytes or packets through the DNS client, while allowing the DNS queries to pass through the DNS client to make use of host system cache, policies, and settings.",MICROSOFT TECHNOLOGY LICENSING LLC,PATANGE ADITI PRAVIN;;JUSTEL MILAN CROWLEY;;JERCAIANU ALEXANDRU;;COX MATTHEW RAYMOND;;PASHOV IVAN DIMITROV,MICROSOFT TECHNOLOGY LICENSING LLC (2024-02-22),https://lens.org/077-584-555-321-832,Patent Application,yes,4,0,1,077-584-555-321-832,US,1,077-584-555-321-832,US,0,H04L61/58;;H04L61/4511;;H04L61/58;;H04L61/4511,H04L61/4511;;H04L61/58,,0,0,,,,PENDING
733,US,A1,US 2025/0245249 A1,104-460-669-005-718,7/31/2025,2025,US 18428790,1/31/2024,,,AUGMENTING SEMANTIC SEARCH SCORES BASED ON RELEVANCY AND POPULARITY,"Systems and methods for generating augmented search results are disclosed. An example method is performed by one or more processors of a search results ranking system and includes receiving a transmission over a communications network from a computing device associated with a user of the search results ranking system, the transmission including a search query, submitting, to a vector database, a token query matching a tokenized version of the search query against a plurality of data assets, submitting, to the vector database, one or more vector queries matching a vectorized version of the search query against the plurality of data assets, identifying, based on results of the token query and the one or more vector queries, contextually relevant results among the plurality of data assets, and generating augmented search results for the search query based on the contextually relevant results.",Intuit Inc.,Saikiran Sri THUNUGUNTLA;;Vignesh RADHAKRISHNAN;;Anishkumar SS;;Chaitra RAO,,https://lens.org/104-460-669-005-718,Patent Application,yes,0,0,1,104-460-669-005-718,US,1,104-460-669-005-718,US,0,G06F16/3329;;G06F16/3347;;G06F16/383;;G06F40/284,G06F16/332;;G06F16/33;;G06F16/383;;G06F40/284,,0,0,,,,UNKNOWN
734,WO,A2,WO 2025/024326 A2,063-698-268-034-790,1/30/2025,2025,US 2024/0038878 W,7/19/2024,US 202363515071 P,7/21/2023,GENERATIVE ARTIFICIAL INTELLIGENCE (AI) FOR DIGITAL WORKFLOWS,"An artificial intelligence (Al) assisted generative digital task fulfillment process within digital model platforms is provided. Disclosed are methods and systems for carrying out digital tasks through generative Al, including tasks related to the streamlined design, validation, verification, certification, assembly, operations, and maintenance processes of complex systems. Hie method includes receiving access to a context Al model trained on Internet-scale data, receiving a user prompt indicating the digital task, and generating contextual data based on the user prompt using the context Al model, where the contextual data identifies a syntax Al model. The method includes training the syntax Al model to generate a template script having a placeholder variable for a parameter related to the digital task. The method also includes using a parameter substitution process to generate the orchestration script by substituting the variable with a parameter value.",ISTARI DIGITAL INC,ROPER WILLIAM JR;;BENSON CHRISTOPHER LEE;;KRISHNAN SRIRAM;;ABUNOJAIM BAHA ALDEEN E A;;GALVIN PETER;;MARKS JOSHUA ADAM;;JUNG MARSHALL ADAM,,https://lens.org/063-698-268-034-790,Patent Application,yes,0,1,2,063-698-268-034-790;;135-567-352-592-461,WO,2,063-698-268-034-790;;135-567-352-592-461,WO,0,G06N3/0475;;G06N20/00,G06N3/0475,,0,0,,,,PENDING
735,WO,A1,WO 2024/207023 A1,130-858-976-850-842,10/3/2024,2024,US 2024/0022559 W,4/1/2024,US 202363493712 P;;US 202363493722 P,3/31/2023,SYSTEMS AND METHODS FOR IMAGE LABELING UTILIZING MULTI-MODEL LARGE LANGUAGE MODELS,"An example method includes receiving a set of first images. For each first image in a subset of the set of first images, multiple inputs to multiple artificial intelligence model systems are generated, the multiple inputs and the first image are provided to the multiple artificial intelligence model systems, multiple responses from the multiple artificial intelligence model systems are received, based on the multiple responses, a label for the first image is determined, and the first image and the label are added to a model training data set. A computer vision model is trained based on the model training data set. A second image is received, the computer vision model is applied to the second image, and an output from the computer vision model is received.",PLAINSIGHT TECH INC,SPEARS LOGAN;;ODOM III FRANK;;BAUMGARTNER CONSTANTIN,,https://lens.org/130-858-976-850-842,Patent Application,yes,5,0,2,130-858-976-850-842;;120-887-089-502-964,US;;WO,2,130-858-976-850-842;;120-887-089-502-964,US;;WO,0,G06V10/764;;G06V10/774;;G06V20/70;;G06V10/945;;G06V10/82;;G06V20/70;;G06V10/774;;G06V10/764;;G06V10/945;;G06T2207/20081;;G06V10/82;;G06T7/70,G06V10/764;;G06T7/11;;G06V10/776,,0,0,,,,PENDING
736,US,B1,US 12056003 B1,018-453-493-471-949,8/6/2024,2024,US 202418440976 A,2/14/2024,US 202418440976 A,2/14/2024,Methods and systems of incident management employing preemptive incident prevention and self healing processing,A method and system of managing incidents in a system by employing preemptive incident prevention and self-healing processing. The method detects potential incidents and actual incidents in the system and performs self-healing prevention actions for any detected potential incidents and performs self-healing actions for any detected or notified incidents. The system performs an automated root cause analysis for event notifications related to an incident.,MORGAN STANLEY SERVICES GROUP INC,RAMOS ALBERTO;;MHATRE VILAS HARESHWAR;;VADAPARTY KUMAR;;SANSBURY DARRYL ALAN;;KARUPPUSAMY VELLIANGIRI;;PRADHAN BIJAYA KUMAR;;TESTA DAVID;;REYES FREDDY;;SONI ABHISHEK;;AGGARWAL PIYUSH;;LEIFERT MARCELO;;JOY JUDITH CHRISTI,MORGAN STANLEY SERVICES GROUP INC (2024-02-05),https://lens.org/018-453-493-471-949,Granted Patent,yes,18,2,1,018-453-493-471-949,US,1,018-453-493-471-949,US,0,G06F11/079;;G06F11/0793;;G06F11/004;;G06F2201/805;;G06F11/079;;G06F11/0793;;G06F2201/805;;G06F11/0709;;G06F11/004,G06F11/00;;G06F11/07,,0,0,,,,ACTIVE
737,US,A1,US 2025/0140258 A1,169-589-711-393-191,5/1/2025,2025,US 202418767882 A,7/9/2024,US 202418767882 A;;US 202363594367 P;;US 202363611031 P;;US 202463640814 P,10/30/2023,SPEAKER VERIFICATION USING CO-LOCATION INFORMATION,"Provided herein is a method for non-audible speech detection and output. The method comprises providing a radio frequency (RF) sensing device configured to be coupled to a head of a user. The method further comprises using the RF sensing device to collect RF signal data associated with movement of one or more speech articulators of the user. The method further comprises outputting or facilitating an output comprising a non-audible speech translation using at least in part processed RF signal data, wherein the non-audible speech of the user comprises continuous speech by the user.",REFLEX TECH INC,BENSTER TYLER STEPHEN;;ELISHA RESHEF HAIM;;WILSON GUY HALLECK;;MOUSSAKHANI KAVEH,REFLEX TECHNOLOGIES INC (2024-07-10),https://lens.org/169-589-711-393-191,Patent Application,yes,2,0,3,159-702-398-715-72X;;022-155-065-833-965;;169-589-711-393-191,US,4,022-155-065-833-965;;159-702-398-715-72X;;169-589-711-393-191;;091-888-683-854-449,US;;WO,0,G06F3/012;;G10L21/02;;G01S2013/0245;;G01S13/02;;G01S13/426;;G01S7/412;;G01S7/417;;G10L15/16;;G10L15/22;;G10L15/1815;;G06F3/013;;G10L15/25;;G10L25/75;;G10L2015/227;;G06F3/012;;G01S13/89;;G06F40/58;;G01S13/50,G10L15/25;;G01S13/50;;G06F40/58,,4,2,105-083-683-691-131;;009-315-341-570-612,10.21203/rs.3.rs-1092137/v1;;35273225;;pmc8913675;;10.1038/s41598-022-07842-9;;27801867;;10.3390/s16111812;;pmc5134471,"Wagner, C., Schaffer, P., Amini Digehsara, P. et al. Silent speech command word recognition using stepped frequency continuous wave radar. Sci Rep 12, 4192 (2022). https://doi.org/10.1038/s41598-022-07842-9 (Year: 2022);;Shin, Y. H. & Seo, J. Towards contactless silent speech recognition based on detection of active and visible articulators using IRUWB radar. Sensors 16, 1812. https://doi.org/10.3390/s16111812 (2016) (Year: 2016);;Laabs translation (Year: 2023);;Laabs in German (Year: 2023)",PENDING
738,US,A1,US 2025/0138914 A1,188-535-915-876-801,5/1/2025,2025,US 202418407852 A,1/9/2024,US 202418407852 A;;US 202318498284 A,10/31/2023,Using Generative Artificial Intelligence to Improve User Interactions,"The present disclosure generally relates to systems, software, and computer-implemented methods for using generative artificial intelligence to improve user interactions. One example method includes receiving a notification from a contact center application that user interaction events have been generated during an interaction session. Event descriptions for events generated in the session are located in a contact center application use case definition. Event descriptions are enhanced with event information for to generate contextualized event information. The contextualized event information to is added to a generative large language model artificial intelligence context that is provided to a generative large language model artificial intelligence engine. A query is provided to the generative large language model artificial intelligence engine. A query response is received from the generative large language model artificial intelligence engine and the query response is used in the interaction session.",TORONTO DOMINION BANK,MOHAMMED SHAHZAD;;D'AGOSTINO DINO PAUL,THE TORONTO-DOMINION BANK (2024-07-23),https://lens.org/188-535-915-876-801,Patent Application,yes,3,0,4,050-063-526-925-860;;001-588-021-925-86X;;188-535-915-876-801;;024-198-002-912-503,US,4,001-588-021-925-86X;;024-198-002-912-503;;050-063-526-925-860;;188-535-915-876-801,US,0,G06F16/243;;G06F16/243;;G06F9/542,G06F9/54;;G06F16/242,,2,0,,,"Petr Gazarov, What is an API? In English, please., 19 December 2019, <URL: https://www.freecodecamp.org/news/what-is-an-api-in-english-please-b880a3214a82/> (Year: 2019);;Difference between AI, ML, LLM, and Generative AI, 27 August 2023, <URL: https://toloka.ai/blog/difference-between-ai-ml-llm-and-generative-ai/> (Year: 2023)",ACTIVE
739,US,A1,US 2024/0420208 A1,047-355-712-403-800,12/19/2024,2024,US 202418744524 A,6/14/2024,US 202418744524 A;;US 202363472981 P,6/14/2023,SYSTEMS AND METHODS FOR ENHANCING ACCURACY OF CONVERSATIONAL INFORMATION RETRIEVAL FOR COMMERCE,"Systems, methods, and apparatuses for customer engagement that receive a product catalog including information associated with a plurality of products; encode product data by at least one of generating a reverse text index associated with a plurality of products in the product catalog or vectorizing embeddings of the information associated with the plurality of products in the product catalog; store the encoded product data in a product catalog database; receive input from an end user; at least one of convert the end user input to a text query or create input vectors by vectorizing embeddings associated with the input; retrieve a list of products from the product catalog database based on at least one of the text query or the input vectors associated with the input; and output a response to the end user, wherein the response includes a link to information of products in the list of products.",BLOOMREACH INC,POLIAK SEBASTIÁN;;NOVÁCEK JAN;;EDWARDS PAUL;;ALLANA IRSHAD;;PAUL SAMIT;;WANG XUN;;JHA VIKAS;;QAMRA ARUN,BLOOMREACH INC (2024-06-17),https://lens.org/047-355-712-403-800,Patent Application,yes,0,0,2,047-355-712-403-800;;174-009-752-509-119,US;;WO,2,047-355-712-403-800;;174-009-752-509-119,US;;WO,0,G06Q30/0627;;G06Q30/0603;;G06F16/3329;;G06F40/134;;G06Q30/0627;;G06F40/134;;G06F16/3329;;G06Q30/0603,G06F16/332;;G06Q30/0601;;G06F40/134,,0,0,,,,PENDING
740,US,B2,US 12271498 B2,027-899-464-270-884,4/8/2025,2025,US 202318452768 A,8/21/2023,US 202318452768 A,8/21/2023,Graph-based data compliance using natural language text,"Various embodiments of the present disclosure provide automated data compliance techniques for complex access controlled datasets subject to a plurality of data access constraints. Some of the techniques may include generating, using one or more natural language models, entity-relationship data for an access controlled dataset and generating a knowledge graph based on the entity-relationship data. The knowledge graph includes a plurality of vertices connected by a plurality of edges that may be traversed to identify a data access condition indicative of a data access violation or a data coverage violation. Some of the techniques may include generating, using the knowledge graph, a natural language condition description based on the data access condition and providing a condition alert indicative of the natural language condition description.",OPTUM INC,JOHNSON JR DONALD E;;PASALA SOMADEV;;KONDADADI RAVI;;HALIM HADI D;;ANUSHIRAVANI RAMIN;;TOMAR AYUSH;;RUSSELL ADAM;;ROSSMILLER ROBERT K,OPTUM INC (2023-07-19),https://lens.org/027-899-464-270-884,Granted Patent,yes,33,0,2,027-899-464-270-884;;116-270-697-462-789,US,2,027-899-464-270-884;;116-270-697-462-789,US,0,G06F16/288;;G06F21/6218;;G06F16/9024;;G06F16/288;;G06F21/6218,G06F21/62;;G06F16/28,,5,2,158-326-485-072-459;;014-697-935-610-252,10.1109/tse.2021.3124332;;10.1109/cec-eee.2006.13,"“3 Contract Metadata Extraction Best Practices”, Ironclad, (7 pages), Apr. 6, 2023, https://ironcladapp.com/journal/contract-data/contract-metadata-extraction.;;Amaral, Orlando et al., “Al-Enabled Automation for Completeness Checking of Privacy Policies”, IEEE Transactions on Software Engineering, vol. 48, No. 11, (28 pages), Nov. 11, 2022.;;Extended European Search Report for European Patent Application No. 17842048.5, Mar. 23, 2020, (8 pages), European Patent Office, Munich, Germany.;;International Search Report and Written Opinion for PCT Application No. PCT/US2017/047120, dated Nov. 7, 2017, 10 pages, United States Patent and Trademark Office, US.;;Kwok, Thomas et al., “An Automatic Method to Extract Data from an Electronic Contract Composed of a Noumber of Documents in PDF Format”, Proceedings of the 8th IEEE International Conference on E-Commerce Technology and the 3rd IEEE International Conference on Enterprise Computing, E-Commerce, and E-Services, (5 pages), 2006, https://dominoweb.draco.res.ibm.com/reports/rc24083.pdf.",ACTIVE
741,US,A1,US 2025/0238312 A1,029-223-237-705-422,7/24/2025,2025,US 202519033270 A,1/21/2025,US 202519033270 A;;US 202463623658 P,1/22/2024,MACHINE LEARNING BASED FORM ANALYSIS AND ERROR DETECTION,"The technical solutions of the present disclosure receive, via a graphical user interface (GUI), a selection of a GUI element to view data of entity accounts generated using network operations and execute, responsive to the selection, an anomaly detection. The system can identify, responsive to the execution, from the data of the entity accounts, parameters associated with network operations execution. The system can determine, based on the data, ranges of values for the parameters, each range of values corresponding to a respective parameter. The system can detect, based on the parameters and the ranges of values input into one or more machine learning (ML) models, an anomaly corresponding to a parameter that is out of a range of values. The system can select, responsive to the detection, an action to address the anomaly and perform, responsive to the selected action, a network operation to address the anomaly.",ADP INC,JIA YONGMEI;;HOUSTON PHILIP ANDREW;;ZHANG SHENG,,https://lens.org/029-223-237-705-422,Patent Application,yes,0,0,1,029-223-237-705-422,US,1,029-223-237-705-422,US,0,G06F11/0793;;G06F11/0766;;G06F11/079;;G06F11/0709,G06F11/07,,0,0,,,,PENDING
742,WO,A1,WO 2025/024298 A1,025-763-488-706-78X,1/30/2025,2025,US 2024/0038801 W,7/19/2024,US 202318224889 A,7/21/2023,TRAINING AND APPLICATION OF BOTTLENECK MODELS AND EMBEDDINGS,"Disclosed implementations relate to adding ""bottleneck"" models to machine learning pipelines that already apply domain models to translate and/or transfer representations of high-level semantic concepts between domains. In various implementations, an initial representation in a first domain of a transition from an initial state of an environment to a goal state of the environment may be processed based on a pre-trained first domain encoder to generate a first embedding that semantically represents the transition. The first embedding may be processed based on one or more bottleneck models to generate a second embedding with fewer dimensions than the first embedding. In various implementations, the second embedding may be processed in various ways to train one or more of the bottleneck model(s) based on various different auxiliary loss functions.",X DEV LLC,SINGH RISHABH;;ANDRE DAVID;;HONKE GARRETT RAYMOND;;SHAH FALAK;;VYAS NISARG;;PARMAR JAYENDRA;;ROSEN BRIAN M;;TRIVEDI SHAILI,,https://lens.org/025-763-488-706-78X,Patent Application,yes,2,0,2,025-763-488-706-78X;;093-810-680-468-975,US;;WO,2,025-763-488-706-78X;;093-810-680-468-975,US;;WO,0,G06F40/30;;G06N20/00,G06F40/30,,2,2,147-188-977-474-698;;098-666-070-270-556,10.1109/access.2021.3077350;;10.1109/icce-tw46550.2019.8991988,"SUSHANT SINGH ET AL: ""The NLP Cookbook: Modern Recipes for Transformer based Deep Learning Architectures"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 23 March 2021 (2021-03-23), XP081942137;;CHANG HONG-YI ET AL: ""English learning tool for elders- design of instant fruit identification system with TensorFlow"", 2019 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS - TAIWAN (ICCE-TW), IEEE, 20 May 2019 (2019-05-20), pages 1 - 2, XP033712847, DOI: 10.1109/ICCE-TW46550.2019.8991988",PENDING
743,EP,A1,EP 4546160 A1,093-093-271-462-100,4/30/2025,2025,EP 24210146 A,10/31/2024,CN 202410468539 A,4/18/2024,"METHOD AND APPARATUS OF DETERMINING INTERACTION INFORMATION, ELECTRONIC DEVICE AND STORAGE MEDIUM","The present disclosure provides a method and an apparatus of determining interaction information, an electronic device and a storage medium, which relates to a field of artificial intelligence technology, in particular to a large model, a generative model, an NLP, an intelligent search and other fields. The specific implementation plan is to determine a plurality of questioning dimensions according to query information of a subject and historical query information, where each questioning dimension includes a dimension name and a plurality of options; determine a target questioning dimension from the plurality of questioning dimensions according to evaluation values of the plurality of questioning dimensions and whether semantic information of the plurality of questioning dimensions are consistent with semantic information of a query result associated with the query information; and determine the interaction information according to the dimension name and the plurality of options in the target questioning dimension.",BEIJING BAIDU NETCOM SCI & TECH CO LTD,LI XIAO;;JIA XIN;;GU SIMIU;;WANG JUNFENG;;SHI HAIBO;;LU YU;;XU SHENG;;ZHANG LIANG;;ZHOU WENJIE;;LIU YIJUN;;LU MEI;;WU ZICHEN;;YANG MIN;;WANG HUANJIE;;TANG QIAO;;CUI MENGMENG,,https://lens.org/093-093-271-462-100,Patent Application,yes,1,0,5,199-868-680-270-227;;093-093-271-462-100;;116-270-099-211-576;;114-040-148-159-748;;088-087-156-351-593,US;;EP;;CN;;JP,5,199-868-680-270-227;;093-093-271-462-100;;116-270-099-211-576;;114-040-148-159-748;;088-087-156-351-593,US;;EP;;CN;;JP,0,G06F16/2457;;G06F16/283;;G06F16/2453;;G06F16/24569;;G06N5/01;;G06F16/3329;;G06F16/3322;;G06F16/3338;;G06F16/2455;;G06N5/01,G06F16/332;;G06F16/3329;;G06F16/3332,,0,0,,,,PENDING
744,US,A1,US 2024/0070585 A1,199-867-242-984-84X,2/29/2024,2024,US 202318236816 A,8/22/2023,US 202318236816 A;;US 202263400125 P,8/23/2022,"Medical Liability Prevention, Mitigation, and Risk Quantification","In an illustrative embodiment, systems and methods are provided for combining disparate data sets gathered from a variety of external resources to produce safety metrics related to healthcare facilities, correlating data elements derived from the data sets to identify variables that impact safety incident risk in a medical facility environment, and normalizing patient outcomes with underlying population wellness data to allow for benchmarking across facilities and/or geographic regions.",AON RISK CONSULTANTS INC,GALUSHA LARRY JOE;;GILBERT JASMINE;;BLACK KELLY M;;DAVIDSON TIM;;BERARDINUCCI PETER,,https://lens.org/199-867-242-984-84X,Patent Application,yes,2,0,1,199-867-242-984-84X,US,1,199-867-242-984-84X,US,0,G06Q10/0635;;G06Q10/06393;;G16H50/30;;G16H10/60;;G16H40/20;;G06N20/00;;G06N3/045;;G06N3/0475;;G06Q10/0635;;G06N20/00;;G06Q10/06393;;G16H40/20,G06Q10/0635;;G06N20/00;;G06Q10/0639;;G16H40/20,,1,1,010-950-308-107-712,10.1007/978-3-540-30133-2_107,"Abe, A; Kogure, K; Hagita, N. “Nursing risk prediction as chance discovery.” SPRINGER-VERLAG BERLIN, 2004.) (Year: 2004)",PENDING
745,US,A1,US 2023/0342392 A1,057-596-683-832-509,10/26/2023,2023,US 202318342461 A,6/27/2023,US 202318342461 A;;US 202217840390 A;;US 202016797640 A,2/21/2020,GENERATIVE AI SYSTEMS AND METHODS FOR ECONOMIC ANALYTICS AND FORECASTING,"Generative AI systems and methods are provided to produce leading indicators of economic activity based on, for example, agricultural, fishing, mining, lumber harvesting, environmental, or ecological attributes and other factors determined from a range of available data sources. A consistent, semantic metadata structure is described as well as a hypothesis generating and testing system capable of generating predictive analytics models in a non-supervised or partially supervised mode. Users may then subscribe to the date for the use in economic forecasting.",MCCARSON BRIAN,MCCARSON BRIAN,AIECONOMY LLC (2024-11-19),https://lens.org/057-596-683-832-509,Patent Application,yes,4,12,2,057-596-683-832-509;;104-276-531-633-519,US,14,047-561-968-866-355;;195-152-679-664-772;;060-821-074-818-847;;106-650-584-011-393;;016-101-423-428-10X;;057-596-683-832-509;;198-724-866-588-373;;104-276-531-633-519;;004-535-549-272-828;;042-466-929-911-734;;193-145-554-233-76X;;130-365-423-350-594;;139-867-629-060-653;;126-237-643-161-188,US;;WO,0,G08G3/00;;G06N3/0675;;G06N3/0464;;G06N3/044;;G06N3/092;;G06F16/587;;G08G1/0133;;G06V20/13;;G06V2201/10;;G06V10/70;;G06F18/217;;G06V20/52;;G08G5/20;;G08G3/00;;G06F16/907;;G08G1/0133;;G06N3/08;;G06V20/13;;G06F18/29;;G06F18/2133;;G06F18/24155;;G06N7/01;;G06F16/587;;G06V10/764;;G06V10/84;;G06V20/188;;G06F18/217;;G06V2201/10;;G06N3/092;;G06V10/70;;G06V20/52;;G06N3/044;;G06N3/0464;;G06N3/0675;;G08G5/20,G06F16/587;;G06F16/907;;G06F18/20;;G06F18/2133;;G06F18/2415;;G06N3/08;;G06N7/01;;G06V10/764;;G06V10/84;;G06V20/10;;G06V20/13;;G08G1/01;;G08G3/00;;G08G5/00,,5,2,119-304-887-662-281;;047-543-432-840-756,10.1016/j.agsy.2018.04.002;;10.1080/01431161.2017.1323282,"Lopez-Lozano et al. (“An evaluation framework to build a cost-efficient crop monitoring system. Experiences from the extension of the European crop monitoring system,” Agricultural Systems 168, 2019, pp. 231-246) (Year: 2019);;Kolanovic et al. (“Big Data and AI Strategies: Machine Learning and Alternative Data Approach to Investing”, J.P. Morgan, Global Quantitative and Derivatives Strategy, 18 May 2017, pp. 1-280) (Year: 2017);;Radford et al. (“Language Models are Unsupervised Multitask Learners”, OpenAI blog, 1(8), 2019, pp.1-24) (Year: 2019);;Cong et al. (“Alternative Data for FinTech and Business Intelligence”, Available at SSRN: https://ssrn.com/abstract=3521349 or http://dx.doi.org/10.2139/ssrn.3521349, October 10, 2019, p. 1-31) (Year: 2019);;2. Saeed et al. (“Forecasting wheat yield from weather data and MODIS NDVI using Random Forests for Punjab province, Pakistan”, International Journal of Remote Sensing, 38:17, 2017, pp. 4831-4854) (Year: 2017)",ACTIVE
746,US,A1,US 2025/0147984 A1,035-998-727-117-595,5/8/2025,2025,US 202418936825 A,11/4/2024,US 202418936825 A;;US 202363547120 P,11/2/2023,CLOUD-BASED MULTI-USER MINDMAP GENERATION ENGINE AND INTEGRATED CUSTOMER RELATIONS MANAGEMENT DATABASE PLATFORM,"A generative artificial-intelligence augmented mindmap chart engine and customer relations management database platform includes an customer relations management database module, and a mindmap generation engine including a discovery module, a generative artificial intelligence interface module configured to communicate with one or more generative artificial-intelligence models using one or more application programming interfaces, a retrieval-augmented generation database module, a mindmap database configured to store one or more mindmap charts and one or more metadata tags associated with the one or more mindmap charts, and an updater module configured to initiate a mindmap chart update sequence.",HULICK THOMAS,HULICK THOMAS,,https://lens.org/035-998-727-117-595,Patent Application,yes,0,0,1,035-998-727-117-595,US,1,035-998-727-117-595,US,0,G06F16/285;;G06Q30/01;;G06Q30/01;;G06F16/285,G06F16/28;;G06Q30/01,,0,0,,,,PENDING
747,WO,A1,WO 2025/057049 A1,158-128-678-014-688,3/20/2025,2025,IB 2024058770 W,9/10/2024,IN 202341061344 A,9/12/2023,"SYSTEM FOR INTEGRATED LANGUAGE LEARNING AND COMMUNICATION AND METHOD THEREOF, METHOD FOR TEACHING PARA-AUXILIARY LANGUAGE","Embodiments of the present disclosure provide a system (100) and method (300) for integrated language learning and communication and a method (400) for teaching an intermediary language to a user. The system (100) can include a user interface (102), and a control unit (106), in communication with the user interface (102) configured to: receive, using the user interface (102), a user input in a first language; convert, the user input into a para-auxiliary language input; analyze, using one or more language processing techniques, the para-auxiliary language input; prune, using the one or more language processing techniques, a set of letters of the user input corresponding to the first, para-auxiliary and/or a second language; and generate, using the one or more language processing techniques, an output response in the second language, corresponding to the user input.",MANIKUTTY SANKARAN,MANIKUTTY SANKARAN;;MANIKUTTY ANAND,,https://lens.org/158-128-678-014-688,Patent Application,yes,2,0,1,158-128-678-014-688,WO,1,158-128-678-014-688,WO,0,G06F40/58;;G09B19/06;;G06Q50/20;;G06Q10/10;;G06Q50/22;;G06Q50/26;;G06F40/40;;G06F40/20;;G06F40/268;;G06F40/279,G09B19/06;;G06F40/58;;G06Q50/20,,0,0,,,,PENDING
748,WO,A1,WO 2025/003970 A1,086-499-320-398-851,1/2/2025,2025,IB 2024056299 W,6/27/2024,US 202363523588 P,6/27/2023,DATABASE WITH INTEGRATED GENERATIVE AI,"A system and method for managing, categorizing and manipulating data within a server environment utilizing a user interface, a generative AI field in database, and database datastores. The generative AI field accepts natural language requests from a user and determines appropriate prompts for a generative AI model. The generated prompt is configured to generate data providing the functionality specified in the natural language request. The functionality may include categorizing data, generating fields in a database, assisting prompt generation and producing functions for further data manipulation.",FORMAGRID INC,KEENAN SEAN WILLIAM;;HONG JERRY;;LIU HOWARD THOMAS;;MAGGIO ANTHONY H;;CAI EMILY YIMING,,https://lens.org/086-499-320-398-851,Patent Application,yes,2,0,2,155-702-606-992-639;;086-499-320-398-851,US;;WO,2,155-702-606-992-639;;086-499-320-398-851,US;;WO,0,G06F16/288;;G06F16/288,G06F16/25;;G06F16/22;;G06N3/0475,,3,2,192-405-054-144-500;;113-406-659-115-242,10.18653/v1/2023.emnlp-main.258;;10.1109/cai54212.2023.00105,"AHUJA KABIR, DIDDEE HARSHITA, HADA RISHAV, OCHIENG MILLICENT, RAMESH KRITHIKA, JAIN PRACHI, NAMBI AKSHAY, GANU TANUJA, SEGAL SAMEE: ""MEGA: Multilingual Evaluation of Generative AI"", PROCEEDINGS OF THE 2023 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, 1 January 2023 (2023-01-01), pages 4232 - 4267, XP093254331, DOI: 10.18653/v1/2023.emnlp-main.258;;WONG MELVIN; ONG YEW-SOON; GUPTA ABHISHEK; BALI KAVITESH KUMAR; CHEN CAISHUN: ""Prompt Evolution for Generative AI: A Classifier-Guided Approach"", 2023 IEEE CONFERENCE ON ARTIFICIAL INTELLIGENCE (CAI), IEEE, 5 June 2023 (2023-06-05), pages 226 - 229, XP034389454, DOI: 10.1109/CAI54212.2023.00105;;YUNLONG WANG; SHUYUAN SHEN; BRIAN Y. LIM: ""RePrompt: Automatic Prompt Editing to Refine AI-Generative Art Towards Precise Expressions"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 19 February 2023 (2023-02-19), 201 Olin Library Cornell University Ithaca, NY 14853, XP091442931, DOI: 10.1145/3544548.3581402",PENDING
749,US,A1,US 2025/0156455 A1,014-622-478-150-724,5/15/2025,2025,US 202418946571 A,11/13/2024,US 202418946571 A;;US 202363598341 P,11/13/2023,GENERATIVE ARTIFICIAL INTELLIGENCE (AI) CONSTRUCTION SPECIFICATION INTERFACE,"A method and system provide the ability to process a construction domain query. A natural language user query is obtained within a construction software system. The user query is pre-processed to validate the query. Text from the query is embed into search vectors for a semantic search. A data source having multiple different sections is obtained. The semantic search is performed within each of the sections and identifies semantically relevant sections. The relevant sections are consolidated into a contextual data prompt that is input into an LLM. The LLM, which is trained based on construction data, generates a response that identifies the relevant sections. The response and an identification of the relevant sections is output.",AUTODESK INC,SUBBIAH SURENDRAN;;HAN MO;;SAKARAY VIKAS;;PYDA VARADARAJULU;;KEANEY PATRICIA;;GARLAND GRAHAM MICHAEL;;GUERRA BEATRIZ CHINELATO;;NUTI GOPI KRISHNA,AUTODESK INC (2024-11-14),https://lens.org/014-622-478-150-724,Patent Application,yes,0,1,2,014-622-478-150-724;;139-943-100-123-564,US;;WO,2,014-622-478-150-724;;139-943-100-123-564,US;;WO,0,G06F16/3335;;G06F40/30;;G06F16/3329;;G06F16/3329;;G06F40/30;;G06F16/3335,G06F16/332;;G06F16/33;;G06F40/30,,0,0,,,,PENDING
750,WO,A1,WO 2025/010024 A1,153-568-542-718-210,1/9/2025,2025,SG 2024050424 W,6/28/2024,US 202318346727 A,7/3/2023,TECHNICAL ARCHITECTURES FOR MEDIA CONTENT EDITING USING MACHINE LEARNING,"Examples are provided relating to media content editing architectures utilizing machine learning techniques One aspect includes a method for media content editing, the method comprising: receiving a media content from a user; receiving an editing request for the media content from the user; and editing the media content based on the editing request to generate edited media content by: retrieving a prompt from a prompt pool, wherein the retrieved prompt is selected based on the editing request; parsing the retrieved prompt and the editing request using a large language model to generate one or more editing actions to be performed on the media content; and performing the one or more editing actions on the media content to generate the edited media content.",LEMON INC,CHEN FAN;;WONG KIN CHUNG,,https://lens.org/153-568-542-718-210,Patent Application,yes,4,0,2,061-386-903-793-804;;153-568-542-718-210,US;;WO,2,061-386-903-793-804;;153-568-542-718-210,US;;WO,0,G06F40/35;;G06F16/3329;;G11B27/02;;G06F40/166;;G11B27/02;;G06F16/3329;;G06F40/35,G06F40/166;;G06F16/248;;G06N20/00,,0,0,,,,PENDING
751,WO,A1,WO 2025/090899 A1,023-839-700-119-327,5/1/2025,2025,US 2024/0053008 W,10/25/2024,US 202363592992 P;;US 202363593004 P;;US 202463617505 P,10/25/2023,SYSTEM AND METHOD FOR GENERATION OF USER ADVISORIES USING GENERATIVE AI IN CONTRACT ANALYSIS,"A system for contract classification includes a computing device configured to perform several tasks. The device first receives a contract containing multiple contractual elements. It identifies the involved party and the contract's class category. Using an advisory classifier, the system determines a contract parameter based on the contractual elements and calculates an advisory recommendation by considering the parameter, the party, and the class category. The system then ranks the contract according to its parameter and generates a change recommendation. Finally, it notifies the user interface, displaying correlations between specific contractual elements and advisory recommendations.",PRAMATA CORP,SAKLANI PRAFUL;;ABRARI PEDRAM;;AGARWAL ACHINT,,https://lens.org/023-839-700-119-327,Patent Application,yes,3,0,3,096-398-498-919-706;;023-839-700-119-327;;124-570-427-889-47X,WO,3,096-398-498-919-706;;023-839-700-119-327;;124-570-427-889-47X,WO,0,G06N5/022;;G06Q50/18;;G06N20/00;;G06N3/045;;G06F40/30;;G06Q10/0635;;G06N3/09;;G06Q10/10;;G06F40/284;;G06F40/295;;G06F40/197;;G06F18/24,G06F16/332;;G06N5/022;;G06Q10/0635,,0,0,,,,PENDING
752,US,A1,US 2025/0139382 A1,114-744-680-521-905,5/1/2025,2025,US 202318498400 A,10/31/2023,US 202318498400 A,10/31/2023,USING GENERATIVE ARTIFICIAL INTELLIGENCE TO IMPROVE USER INTERACTIONS,"The present disclosure generally relates to systems, software, and computer-implemented methods for using generative artificial intelligence to improve user interactions. One example method includes identifying, in a contact center application of an agent, a start of an assisted leg of an interaction of a user with a system. A user interaction summary is retrieved that summarizes events that have previously occurred in the interaction. A generative large language model (LLM) artificial intelligence (AI) context prompt is extracted based on the user interaction summary. The context prompt is provided to a generative LLM AI engine to set a context for the generative LLM AI engine. Event information is received that includes a query for the generative LLM AI engine. The query is provided to and a query response is received from the generative LLM AI engine. The contact center application is updated in response to the query response.",TORONTO DOMINION BANK,MOHAMMED SHAHZAD;;D'AGOSTINO DINO PAUL,THE TORONTO-DOMINION BANK (2024-07-23),https://lens.org/114-744-680-521-905,Patent Application,yes,0,0,1,114-744-680-521-905,US,1,114-744-680-521-905,US,0,G06F40/40;;H04M3/5133;;H04M3/523;;G06F40/40;;H04M3/523;;H04M3/5133,G06F40/40;;H04M3/51;;H04M3/523,,0,0,,,,PENDING
753,US,A1,US 2025/0014607 A1,047-693-284-119-564,1/9/2025,2025,US 202318346737 A,7/3/2023,US 202318346737 A,7/3/2023,SYSTEM EVOLVING ARCHITECTURES FOR REFINING MEDIA CONTENT EDITING SYSTEMS,"Examples are provided relating to system evolving architectures for refining media content editing systems. One aspect includes a method of refining a media content editing architecture, the method comprising: editing a media content using a large language model and a back-end tool service comprising a prompt pool and a plurality of application programming interfaces corresponding to a plurality of editing tools; publishing the edited media content; storing contextual information relating to the editing of the media content; and refining the media content editing architecture using the stored contextual information.",LEMON INC,CHEN FAN;;WONG KIN CHUNG,,https://lens.org/047-693-284-119-564,Patent Application,yes,2,0,3,047-693-284-119-564;;093-083-277-952-435;;126-726-109-939-997,US;;WO;;CN,3,047-693-284-119-564;;126-726-109-939-997;;093-083-277-952-435,US;;WO;;CN,0,G11B27/031;;G11B27/031,G11B27/031,,0,0,,,,PENDING
754,WO,A1,WO 2025/006538 A1,106-650-584-011-393,1/2/2025,2025,US 2024/0035527 W,6/26/2024,US 202318342461 A,6/27/2023,GENERATIVE AI SYSTEMS AND METHODS FOR ECONOMIC ANALYTICS AND FORECASTING,"Generative Al systems and methods are provided to produce leading indicators of economic activity based on, for example, agricultural, fishing, mining, lumber harvesting, environmental, or ecological attributes and other factors determined from a range of available data sources. A consistent, semantic metadata structure is described as well as a hypothesis generating and testing system capable of generating predictive analytics models in a non-supervised or partially supervised mode. Users may then subscribe to the date for the use in economic forecasting.",MCCARSON BRIAN,MCCARSON BRIAN,,https://lens.org/106-650-584-011-393,Patent Application,yes,0,0,1,106-650-584-011-393,WO,14,047-561-968-866-355;;195-152-679-664-772;;060-821-074-818-847;;106-650-584-011-393;;016-101-423-428-10X;;057-596-683-832-509;;198-724-866-588-373;;104-276-531-633-519;;004-535-549-272-828;;042-466-929-911-734;;193-145-554-233-76X;;130-365-423-350-594;;139-867-629-060-653;;126-237-643-161-188,US;;WO,0,G06F16/587;;G06N20/00;;G06Q10/04,G06F16/587,,4,1,119-304-887-662-281,10.1016/j.agsy.2018.04.002,"LÓPEZ-LOZANO RAÚL, BARUTH BETTINA: ""An evaluation framework to build a cost-efficient crop monitoring system. Experiences from the extension of the European crop monitoring system"", AGRICULTURAL SYSTEMS, ELSEVIER, AMSTERDAM, NL, vol. 168, 1 January 2019 (2019-01-01), AMSTERDAM, NL , pages 231 - 246, XP093257534, ISSN: 0308-521X, DOI: 10.1016/j.agsy.2018.04.002;;KOLANOVIC MARKO, KRISHNAMACHARI RAJESH T, DALMIA RAHUL, LAU ADA, SMITH ROBERT, CHENG PENG, BRAM KAPLAN, BEROWNE HLAVATY, MATTHIAS : ""Big Data and AI Strategies - Machine Learning and Alternative Data Approach to Investing "", J.P . MORGAN, GLOBAL QUANTITATIVE AND DERIVATIVES STRATEGY, 18 May 2017 (2017-05-18), XP093257538, Retrieved from the Internet <URL:https://cpb-us-e2.wpmucdn.com/faculty.sites.uci.edu/dist/2/51/files/2018/05/JPM-2017-MachineLearningInvestments.pdf>;;RADFORD ALEC, WU JEFFREY, CHILD REWON, LUAN DAVID, AMODEI DARIO, SUTSKEVER ILYA: ""Language Models are Unsupervised Multitask Learners"", 15 February 2019 (2019-02-15), XP055921855, Retrieved from the Internet <URL:https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf> [retrieved on 20220517];;CONG LIN WILLIAM, LI BEIBEI, QINGQUAN TONY ZHANG : ""Alternative Data in FinTech and Business Intelligence "", SSRN, 10 October 2019 (2019-10-10), XP093257540, Retrieved from the Internet <URL:https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3521349>",PENDING
755,WO,A1,WO 2024/192036 A1,120-123-133-977-829,9/19/2024,2024,US 2024/0019584 W,3/12/2024,US 202363490178 P,3/14/2023,USING MACHINE LEARNING TO POWER A BRAND INTEGRITY PLATFORM,"Transcribed text associated with a predetermined source is accessed by a brand integrity platform. Features of the transcribed text are input into a classifier that is configured to detect presence of sensitive content of a predetermined category in the input features. The features are input into a tonal model that is trained to detect a neutral emotion score. A plurality of neutral score thresholds associated with the predetermined category of sensitive content whose presence is detected in the input features are accessed. The accessed plurality of neutral score thresholds are applied to the detected neutral emotion score to determine, for the predetermined source, a risk level associated with the predetermined category of sensitive content. An action is performed when the risk level for the predetermined category of sensitive content for the predetermined source meets a tolerance threshold associated with a user.",VERICRYPT INC,ZUBATIY TAMARA;;PALANISWAMY DIVYA;;NELSON GRANT,,https://lens.org/120-123-133-977-829,Patent Application,yes,3,1,1,120-123-133-977-829,WO,1,120-123-133-977-829,WO,0,G06F16/36;;G06N5/00;;G06N20/00,G06F16/28;;G06F16/906,,0,0,,,,PENDING
756,US,A1,US 2025/0124308 A1,198-968-474-094-025,4/17/2025,2025,US 202418913541 A,10/11/2024,US 202418913541 A;;US 202363543933 P,10/13/2023,METHOD AND SYSTEM FOR INTERACTIVE VISUALIZATION OF LARGE LANGUAGE MODEL DESIGN KNOWLEDGE,"A system and method for interactive visualization of knowledge provided by large language models (LLMs) is disclosed. The system advantageously organizes LLM responses into an interactive knowledge graph visualization. Additionally, the system enables the user to interactively expand a knowledge graph by further prompting the LLM to provide additional responses that include additional knowledge. When applied to the task of design ideation, the interactive knowledge graph visualization helps to mitigate design fixation and enhances the overall efficiency, quality, quantity, and depth of concepts in the ideation process.",PURDUE RESEARCH FOUNDATION;;MASSACHUSETTS INST TECHNOLOGY,RAMANI KARTHIK;;DUAN RUNLIN;;YANG MARIA,PURDUE RESEARCH FOUNDATION (2024-10-28),https://lens.org/198-968-474-094-025,Patent Application,yes,0,1,1,198-968-474-094-025,US,1,198-968-474-094-025,US,0,G06N5/022;;G06N5/022,G06N5/022,,0,0,,,,PENDING
757,US,A1,US 2025/0181613 A1,140-287-019-437-390,6/5/2025,2025,US 202318525122 A,11/30/2023,US 202318525122 A,11/30/2023,SYSTEM FOR THE INTERPRETATION AND QUERYING OF CONTENT GENERATED BY AN ARTIFICIAL INTELLIGENCE MODEL,"A system for querying interpreted content from a generative artificial intelligence model is disclosed. The system includes a generative artificial intelligence model and one or more processors. The model is configured to accept a natural language text input and produce a human-like text response. The system performs operations including receiving a natural language text input representative of a query subject and a query context, receiving an input representative of a query response structure, amplifying a combination of the inputs, providing the amplified query to the model, receiving the human-like text response generated by the model, accumulating the responses to form a global query response, and providing the global query response to a computerized interface.",PIERRE DELBET RES,ALIAGA CHRISTOPHE;;ERBS YVAN,PIERRE DELBET RESEARCH (2023-12-07),https://lens.org/140-287-019-437-390,Patent Application,yes,0,0,2,053-317-348-275-944;;140-287-019-437-390,US;;WO,2,053-317-348-275-944;;140-287-019-437-390,US;;WO,0,G06F16/33295;;G06F16/3329;;G06F16/338;;G06F40/289,G06F16/332;;G06F16/338;;G06F40/289,,0,0,,,,PENDING
758,US,A1,US 2025/0238991 A1,140-210-809-870-687,7/24/2025,2025,US 202519026990 A,1/17/2025,US 202519026990 A;;US 202463622351 P,1/18/2024,SYSTEM AND METHOD FOR AUTHORING CONTEXT-AWARE AUGMENTED REALITY INSTRUCTION THROUGH GENERATIVE ARTIFICIAL INTELLIGENCE,"A method for generating augmented reality (AR) instructional content is disclosed. The method advantageously provides an AR graphical user interface for generating AR instructional content for performing a task from user-input text descriptions of the task. The method advantageously leverages generative artificial intelligence to enable a code-free and motion-capture-free experience for authoring the AR instructional content, including virtual avatar animations demonstrating performance of the steps of the task. Additionally, the method advantageously overcomes the contextual barrier by enabling the user to author context-aware AR instructions that understand the context and blend physical reality with virtual components.",PURDUE RES FOUNDATION,RAMANI KARTHIK;;CHI SEUNGGEUN;;CHI HYUNG-GUN;;JAIN RAHUL;;SHI JINGYU,,https://lens.org/140-210-809-870-687,Patent Application,yes,0,0,1,140-210-809-870-687,US,1,140-210-809-870-687,US,0,G06T13/40;;G06T19/006;;G06V20/20;;G06F40/284;;G06F3/012;;G09B5/02;;G06T7/70,G06T13/40;;G06F3/01;;G06F40/284;;G06T7/70;;G06T19/00;;G06V20/20;;G09B5/02,,0,0,,,,PENDING
759,US,A1,US 2024/0427832 A1,086-507-223-223-811,12/26/2024,2024,US 202418750403 A,6/21/2024,US 202418750403 A;;US 202463662175 P;;US 202363509893 P,6/23/2023,SYSTEM AND METHOD FOR AI-BASED GENERATION OF RESPONSIVE WEBSITES USING A WEBSITE BUILDING SYSTEM,"Embodiments provide for responsive optimization of websites. In some examples, a layout graph data structure is generated based on applying a trained layout model to extracted website elements from an input object including one or more website building tools. A webpage layout data structure is generated based on applying a trained structure optimization model to the layout graph data structure. An optimized webpage that is configured to render according to a plurality of screen parameters is generated based on applying a trained responsive optimization model to the webpage layout data structure and a plurality of screen parameters.",WIX COM LTD,RONEN NAAMA BEN OLIEL;;BROSH ELIAHU;;MONITZ LIRON;;HOSHKOVER SHAI;;PEREZ MEIR,WIX.COM LTD (2024-06-27),https://lens.org/086-507-223-223-811,Patent Application,yes,0,0,2,171-598-196-038-836;;086-507-223-223-811,US;;WO,2,171-598-196-038-836;;086-507-223-223-811,US;;WO,0,G06F16/958;;G06F16/9577;;G06F16/9577;;G06F3/04845,G06F16/957;;G06F3/04845,,0,0,,,,PENDING
760,US,A1,US 2025/0200284 A1,168-200-604-923-295,6/19/2025,2025,US 202519067844 A,3/1/2025,US 202519067844 A;;US 202419000557 A;;US 202318336026 A;;US 202217714317 A,4/6/2022,SYSTEM AND METHOD FOR STRATIFIED SAMPLING AND DYNAMIC TOKEN MANAGEMENT IN ADAPTIVE THOUGHT OBJECT THEMING,"A system and method for adaptive theming of thought objects comprising stratified sampling to categorize thought objects from communication environments and maintains proportional representation across categories. A dynamic token capacity threshold is determined based on factors including query complexity, quantity of thought objects, and computational resource availability. The system selects thought objects from each category until specific word limits are reached and removes objects when token thresholds are exceeded while preserving proportional representation. A transformer receives these sampled thought objects and a prompt providing context and instructions for theme assignment. An object-theming transformer determines probability scores for mapping thought objects to known themes, assigning themes when scores exceed predefined thresholds. Unthemed objects are processed by a topic identification transformer to generate new theme names. The system displays themed thought objects on a graphical user interface, enabling efficient categorization and analysis of qualitative responses across diverse domains.",FULCRUM MAN SOLUTIONS LTD,IMANI FARHAD;;PROCTER THOMAS JOHN,,https://lens.org/168-200-604-923-295,Patent Application,yes,0,0,2,110-419-412-983-578;;168-200-604-923-295,US,6,103-910-759-054-088;;168-200-604-923-295;;110-419-412-983-578;;161-107-891-874-156;;190-326-282-131-738;;017-803-028-252-346,US;;CA,0,G06F40/242;;G06F40/284;;G06F40/117;;G06F40/30;;G06F40/284;;G06F40/117;;G06F40/242,G06F40/284;;G06F40/117;;G06F40/242,,0,0,,,,PENDING
761,US,A1,US 2024/0256791 A1,001-575-918-889-063,8/1/2024,2024,US 202318129571 A,3/31/2023,US 202318129571 A;;US 202363442711 P,2/1/2023,MACHINE LEARNING EXECUTION FRAMEWORK,"In examples, an execution chain used to process includes one or more blocks, where each block includes at least one of a machine learning (ML) definition and/or a set of programmatic operations. As an example, an ML definition of an ML block includes a prompt to be processed by an ML model. As another example, the ML definition includes a prompt template, which may be populated based on a previous block of the execution chain. Further, a programmatic block of the execution chain can include any of a variety of operations, for example to obtain data from a data source and/or to prompt a user for input, thereby obtaining additional data that may be used to ground an ML model for a subsequent machine learning block of the execution chain.",MICROSOFT TECHNOLOGY LICENSING LLC,SANTHANAM DEEPAK;;GALKIN ALEXANDER;;CHOKSEY SHIROY;;ARAYARUNGSARIT RITTHA;;ABIB ELBIO RENATO TORRES,MICROSOFT TECHNOLOGY LICENSING LLC (2023-04-24),https://lens.org/001-575-918-889-063,Patent Application,yes,0,1,1,001-575-918-889-063,US,2,016-906-055-270-043;;001-575-918-889-063,US;;WO,0,G06N20/00;;G06Q50/01;;G06Q10/10;;G06Q10/067;;G06F40/284;;G06F40/40,G06F40/40;;G06F40/284,,0,0,,,,PENDING
762,US,A1,US 2025/0209176 A1,024-116-401-557-957,6/26/2025,2025,US 202318390254 A,12/20/2023,US 202318390254 A,12/20/2023,SOFTWARE VULNERABILITY DETECTION,"Disclosed herein are system, method, and computer program product embodiments for using a combination of large language models (LLMs), generative adversarial networks (GANs), and/or quantum GANs to detect software vulnerabilities. A vulnerability scanning system receives source code. The vulnerability scanning system generates quantum source code by transforming the source code into a quantum computing data format. The vulnerability scanning system determines that the source code includes a potential vulnerability by applying a quantum generative adversarial network (QGAN) model to the quantum source code. In response to determining that the source code includes a potential vulnerability, the vulnerability scanning system determines that the source code includes code corresponding to a vulnerability by applying a large language model to the source code. The vulnerability scanning system may then apply a vulnerability policy to the source code to mitigate the vulnerability and/or to prevent its spread.",AMERICAN EXPRESS TRAVEL RELATED SERVICES CO INC,PALANKI HIRANMAYI,AMERICAN EXPRESS TRAVEL RELATED SERVICES COMPANY INC (2023-12-13),https://lens.org/024-116-401-557-957,Patent Application,yes,0,0,1,024-116-401-557-957,US,1,024-116-401-557-957,US,0,G06F2221/033;;G06F21/577;;G06F2221/033;;G06F21/577,G06F21/57,,0,0,,,,PENDING
763,US,A1,US 2024/0265047 A1,060-821-074-818-847,8/8/2024,2024,US 202418625612 A,4/3/2024,US 202418625612 A;;US 202318342461 A;;US 202217840390 A;;US 202016797640 A,2/21/2020,GENERATIVE AI SYSTEMS AND METHODS FOR SECURITIES TRADING,"Generative AI systems and methods are provided to provide recommendations as to whether a particular security associated with a corporate entity and/or its competitors should be purchased, sold, or held, as determined from a range of available data sources. A consistent, semantic metadata structure is described as well as a hypothesis generating and testing system capable of generating predictive analytics models in a non-supervised or partially supervised mode. Users may then subscribe to the date for the use in economic forecasting.",MCCARSON BRIAN,MCCARSON BRIAN,AIECONOMY LLC (2024-11-19),https://lens.org/060-821-074-818-847,Patent Application,yes,4,5,2,060-821-074-818-847;;016-101-423-428-10X,US,14,047-561-968-866-355;;195-152-679-664-772;;060-821-074-818-847;;106-650-584-011-393;;016-101-423-428-10X;;057-596-683-832-509;;198-724-866-588-373;;104-276-531-633-519;;004-535-549-272-828;;042-466-929-911-734;;193-145-554-233-76X;;130-365-423-350-594;;139-867-629-060-653;;126-237-643-161-188,US;;WO,0,G06F16/587;;G06F18/217;;G06N3/044;;G06N3/0464;;G06N3/0675;;G06N3/092;;G06V10/70;;G06V20/13;;G06V20/52;;G06V2201/10;;G08G1/0133;;G08G3/00;;G06F16/907;;G06F18/2133;;G06F18/24155;;G06F18/29;;G06N3/08;;G06N7/01;;G06V10/764;;G06V10/84;;G06V20/188;;G06V20/56;;G08G3/00;;G06F16/907;;G08G1/0133;;G06N3/08;;G06V20/13;;G06F18/29;;G06F18/2133;;G06F18/24155;;G06N7/01;;G06F16/587;;G06V10/764;;G06V10/84;;G06V20/188;;G08G5/20,G06F16/907;;G06F16/587;;G06F18/20;;G06F18/2133;;G06F18/2415;;G06N3/08;;G06N7/01;;G06V10/764;;G06V10/84;;G06V20/10;;G06V20/13;;G08G1/01;;G08G3/00;;G08G5/00,,0,0,,,,ACTIVE
764,US,A1,US 2024/0411989 A1,185-523-214-337-031,12/12/2024,2024,US 202418735896 A,6/6/2024,US 202418735896 A;;US 202363471391 P,6/6/2023,METHODS AND SYSTEMS FOR ENHANCING USER INTERACTION WITH ASSISTIVE TECHNOLOGY,Methods and systems are described for enhancing user interaction with assistive technology. An input associated with a message may be received from an assistive communication device. A next likely input associated with the message may be determined. The input associated with the message and the next likely input associated with the message may be sent to a user device via a secure communication session. Output of the input associated with the message and output of a prompt to query a user of the assistive communication device of the accuracy of the next likely input associated with the message may be caused via an interface of the user device. An indication that the next likely input associated with the message is accurate may be received via the secure communication session. The message may be updated based on the next likely input associated with the message and caused to be output.,US GOV VETERANS AFFAIRS,HILL NICHOLAS JEREMY,UNITED STATES GOVERNMENT AS REPRESENTED BY THE DEPARTMENT OF VETERANS AFFAIRS (2024-09-11),https://lens.org/185-523-214-337-031,Patent Application,yes,0,0,1,185-523-214-337-031,US,1,185-523-214-337-031,US,0,G06F40/274;;G06F40/166;;G06F40/166;;G06F40/274,G06F40/274;;G06F40/166,,0,0,,,,PENDING
765,US,A1,US 2025/0005916 A1,093-813-824-349-451,1/2/2025,2025,US 202318217133 A,6/30/2023,US 202318217133 A,6/30/2023,SYSTEM AND METHOD FOR LEVARGING MULTIPLE DESCRIPTIVE FEATURES FOR ROBUST FEW-SHOT IMAGE LEARNING,"A system including a machine learning network that includes a controller configured to, utilizing numerical values assigned at an image-text similarity matrix, output at the machine learning network including a text encoder and an image encoder, update parameters of a untrained layer of the machine learning network utilizing sparse logistic regression to generate a sparse logistic regression layer, wherein the image-text similarity matrix is associated with a plurality of input images received at the controller, freeze one or more entries of the sparse logistic regression layer that include zero values, run a plurality of input images at both (1) the image encoder and (2) one or more unfrozen entries at the sparse logistic regression layer, and update, in response to the running of the plurality of input images, parameters of the image encoder and parameters associated with one or more unfrozen entries, and output a tuned machine learning model until a threshold is met.",BOSCH GMBH ROBERT;;UNIV CARNEGIE MELLON,WILLMOTT DEVIN T;;FENG ZHILI;;BAIR ANNAMARIE ELIZABETH;;KOLTER JEREMY,ROBERT BOSCH GMBH (2023-07-12);;CARNEGIE MELLON UNIVERSITY (2023-07-04),https://lens.org/093-813-824-349-451,Patent Application,yes,0,0,3,062-617-005-550-087;;187-519-828-387-480;;093-813-824-349-451,US;;DE;;CN,3,062-617-005-550-087;;187-519-828-387-480;;093-813-824-349-451,US;;DE;;CN,0,G06V10/774;;G06V10/46;;G06V10/761;;G06V10/764;;G06V10/766;;G06V10/82;;G06N3/0895;;G06N3/045;;G06N20/00;;G06V10/761;;G06V10/82;;G06V10/761;;G06V10/82,G06V10/82;;G06V10/74,,0,0,,,,PENDING
766,US,A1,US 2025/0209557 A1,020-902-893-320-691,6/26/2025,2025,US 202418904097 A,10/2/2024,US 202418904097 A;;US 202418437200 A;;US 202363614022 P;;US 202463626075 P;;US 202463554360 P,12/22/2023,ADAPTIVE MISSION STRATEGY OPTIMIZATION THROUGH AI-GENERATED AMBIENT RECOMMENDATIONS FOR TACTICAL COMMAND,"Disclosed are a method, system, and apparatus of adaptive mission strategy optimization through ai-generated ambient recommendations for tactical command. According to one embodiment, the method includes simultaneously listening to multiple communications surrounding a wearer, amplifying a human speech detected in the multiple communications through a wearable microphone, and using an artificial intelligence model to generate a tactical recommendation to the wearer through a mobile device accessible to the wearer.",GOVERNMENTGPT INC,ADDY FRED;;SACCA GIACOMO;;ABHYANKER RAJ,GOVERNMENTGPT INC (2024-10-03),https://lens.org/020-902-893-320-691,Patent Application,yes,0,0,1,020-902-893-320-691,US,4,076-838-759-550-152;;000-039-866-900-076;;089-085-983-111-574;;020-902-893-320-691,US,0,G06V10/82;;G06V20/17;;H04W4/029;;G06Q50/265;;G06V20/52;;G10K11/17837;;G10K2210/1082;;H04R1/406;;H04R3/005;;H04R1/326;;G10L21/0208;;G10L15/26;;G06Q50/265;;G10L15/26;;G10L21/0208;;H04W4/029;;H04R1/326;;G10K2210/1082;;G06V20/17;;G06V20/52;;G06V10/82;;G10L2021/02087;;G10L2021/02166;;G10K11/17837,G06Q50/26;;G06V10/82;;G06V20/17;;G06V20/52;;G10K11/178;;G10L15/26;;G10L21/0208;;G10L21/0216;;H04R1/32;;H04W4/029,,0,0,,,,PENDING
767,US,A1,US 2025/0200108 A1,139-867-629-060-653,6/19/2025,2025,US 202519061636 A,2/24/2025,US 202519061636 A;;US 202318157981 A;;US 202217840390 A;;US 202318342461 A;;US 202016797640 A,2/21/2020,"Agentic AI, Contextual AI, and Generative AI Systems and Methods for Medical and Genetic Analytics, Diagnostics, and Treatment Recommendations","Agentic AI, Contextual AI, and Generative AI systems and methods are provided for quantitative or qualitative patient analytics, blood work analytics, medical image analytics (x-ray, ultrasound, CT Scan, MRI and the like), brain scan analytics, present or historical genetic analytics and the like, to be used to guide, assist or even replace some of these physician functions with improved patient outcomes or with an improved understanding of the source of ailments, the analysis of treatment efficacy or treatment side-effects for individuals or populations of individuals. Genetic information is used to create individualized or population-based analysis, diagnostics, or treatment plans with even better outcomes.",AIECONOMY LLC,MCCARSON BRIAN,AIECONOMY LLC (2025-02-19),https://lens.org/139-867-629-060-653,Patent Application,yes,0,0,1,139-867-629-060-653,US,14,047-561-968-866-355;;195-152-679-664-772;;060-821-074-818-847;;106-650-584-011-393;;016-101-423-428-10X;;057-596-683-832-509;;198-724-866-588-373;;104-276-531-633-519;;004-535-549-272-828;;042-466-929-911-734;;193-145-554-233-76X;;130-365-423-350-594;;139-867-629-060-653;;126-237-643-161-188,US;;WO,0,G06N3/045;;G06N3/08;;G06N5/01;;G06N7/01;;G06N20/00;;G06N20/10;;G06N20/20;;G06Q30/0202;;G06V20/13;;G06V20/52;;G08G1/0116;;G08G1/0133;;G08G3/00;;G08G5/20;;G06F16/587;;G06F16/907;;G06F18/2133;;G06F18/24155;;G06F18/29;;G06V10/764;;G06V10/84;;G06V20/188;;G16H50/00;;G16H50/20;;G16H50/30;;G16H50/70;;G06F16/587;;G08G3/00;;G06F16/907;;G08G1/0133;;G06N3/08;;G06V20/13;;G08G5/20;;G06F18/2133;;G06F18/24155;;G06N7/01;;G06V10/764;;G06V10/84;;G06V20/188;;G06F18/29;;G16H50/70;;G16H50/00;;G16H50/30;;G16H50/20,G06F16/587;;G06F16/907;;G06F18/20;;G06F18/2133;;G06F18/2415;;G06N3/08;;G06N7/01;;G06V10/764;;G06V10/84;;G06V20/10;;G06V20/13;;G08G1/01;;G08G3/00;;G08G5/20,,0,0,,,,PENDING
768,EP,A1,EP 4524824 A1,131-674-749-120-84X,3/19/2025,2025,EP 23197867 A,9/18/2023,EP 23197867 A,9/18/2023,IMPROVED METHOD AND SYSTEM FOR GENERATING CONCEPT-BASED EXPLANATIONS FOR A TARGET MODEL,Some embodiments are directed to a computing a measure quantifying the influence of a concept defined by a concept model on classifications of a target model. This may include computing for sensor data in an evaluation set the output of a similarity function applied to the output of a target model and the output of a concept model.,BOSCH GMBH ROBERT;;UNIV CARNEGIE MELLON,MOSHKOVITZ MICHAL;;FENG ZHILI;;DI CASTRO DOTAN;;KOLTER JEREMY ZIEG,,https://lens.org/131-674-749-120-84X,Patent Application,yes,0,0,3,131-674-749-120-84X;;054-307-581-260-72X;;184-681-603-572-614,US;;EP;;CN,3,131-674-749-120-84X;;054-307-581-260-72X;;184-681-603-572-614,US;;EP;;CN,0,G06N5/045;;G06N20/00;;G06N20/00,G06N5/045;;G06N20/00,,2,0,,,"BAI ANDREW ET AL: ""Concept Gradient: Concept-based Interpretation Without Linear Assumption"", ARXIV (CORNELL UNIVERSITY), 31 August 2022 (2022-08-31), Ithaca, XP093134455, Retrieved from the Internet <URL:https://arxiv.org/pdf/2208.14966v1.pdf> [retrieved on 20240223], DOI: 10.48550/arxiv.2208.14966;;AVINASH KORI ET AL: ""GLANCE: Global to Local Architecture-Neutral Concept-based Explanations"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 5 July 2022 (2022-07-05), XP091263559",PENDING
769,US,A1,US 2025/0124488 A1,006-774-361-417-15X,4/17/2025,2025,US 202419002124 A,12/26/2024,US 202419002124 A,12/26/2024,SYNTHETIC DATA GENERATION FOR SERVICE RECOMMENDATION,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for synthetic data generation for service recommendation models. One of the methods includes generating a plurality of synthetic data items, each synthetic data item including user data, context data, service data of a service, and user action data characterizing one or more user actions with respect to the service; for each synthetic data item of the plurality of synthetic data items, processing the synthetic data item using an evaluator to generate a score indicating quality of the synthetic data item; selecting a subset of synthetic data items from the plurality of synthetic data items; and providing the subset of synthetic data items into a service recommendation model for recommending one or more services to one or more users based on the subset of synthetic data items.",LEMON INC;;BEIJING YOUZHUJU NETWORK TECH CO LTD,ZHANG YU;;CHEN YUXI;;CHEN ZHIHAN;;ZHOU FEIYU;;WANG SHEN;;DU ZHENZE,,https://lens.org/006-774-361-417-15X,Patent Application,yes,0,0,1,006-774-361-417-15X,US,1,006-774-361-417-15X,US,0,G06Q30/0631;;G06Q30/0251;;G06Q30/0251;;G06Q30/0631,G06Q30/0251;;G06Q30/0601,,0,0,,,,PENDING
770,WO,A1,WO 2024/163109 A1,016-906-055-270-043,8/8/2024,2024,US 2023/0086518 W,12/29/2023,US 202363442711 P;;US 202318129571 A,2/1/2023,MACHINE LEARNING EXECUTION FRAMEWORK,"In examples, an execution chain used to process includes one or more blocks, where each block includes at least one of a machine learning (ML) definition and/or a set of programmatic operations. As an example, an ML definition of an ML block includes a prompt to be processed by an ML model. As another example, the ML definition includes a prompt template, which may be populated based on a previous block of the execution chain. Further, a programmatic block of the execution chain can include any of a variety of operations, for example to obtain data from a data source and/or to prompt a user for input, thereby obtaining additional data that may be used to ground an ML model for a subsequent machine learning block of the execution chain.",MICROSOFT TECHNOLOGY LICENSING LLC,SANTHANAM DEEPAK;;GALKIN ALEXANDER;;CHOKSEY SHIROY;;ARAYARUNGSARIT RITTHA;;ABIB ELBIO RENATO TORRES,,https://lens.org/016-906-055-270-043,Patent Application,yes,0,0,1,016-906-055-270-043,WO,2,016-906-055-270-043;;001-575-918-889-063,US;;WO,0,G06N20/00;;G06N3/045;;G06F40/20,G06N3/045;;G06F40/10;;G06N20/00,,2,1,019-067-430-804-866,10.1109/ojpel.2020.3039117,"ZHANG SONGYANG ET AL: ""Machine Learning Building Blocks for Real-Time Emulation of Advanced Transport Power Systems"", IEEE OPEN JOURNAL OF POWER ELECTRONICS, IEEE, vol. 1, 18 November 2020 (2020-11-18), pages 488 - 498, XP011824273, DOI: 10.1109/OJPEL.2020.3039117;;TOMER RAVIV ET AL: ""Online Meta-Learning For Hybrid Model-Based Deep Receivers"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 27 March 2022 (2022-03-27), XP091185190",PENDING
771,US,A1,US 2025/0060948 A1,112-432-946-904-511,2/20/2025,2025,US 202418798217 A,8/8/2024,US 202418798217 A;;US 202463564921 P;;US 202363609607 P;;US 202363545461 P;;US 202363533463 P,8/18/2023,COMPUTING PLATFORM AND SYSTEMS CONFIGURED TO ENHANCE INTERACTIONS WITH CHATBOT SYSTEMS,"Disclosed herein is a computing platform for providing enhanced interactivity with a chatbot system and other forms of artificial intelligence. The computing platform includes computer programming languages and systems thereof configured to interact with chatbots and chatbot systems. In some examples, the platform interacts, via at least one of the programming languages, with a large language model-based chatbot system—such as ChatGPT. In some examples, the platform includes the chatbot or the chatbot system. In some examples, the platform, via the programming language(s), interacts with a large language model-based chatbot system to input, record, organize, distribute, adapt, or perform creative works. The platform can also implement a money flow model (MFM) through at least one of the languages. Also, the platform can provide functions, via at least one of the languages, to interact with games and competitions where humans and artificial intelligence compete with and against each other.",SULLIVAN LYNO,SULLIVAN LYNO,,https://lens.org/112-432-946-904-511,Patent Application,yes,0,0,1,112-432-946-904-511,US,1,112-432-946-904-511,US,0,G06F8/34;;G06F8/34,G06F8/34,,0,0,,,,PENDING
772,WO,A1,WO 2025/090852 A1,041-408-777-118-371,5/1/2025,2025,US 2024/0052937 W,10/25/2024,US 202363593648 P,10/27/2023,"SCALABLE SYSTEMS AND METHODS FOR CREATING INTERACTIVE, DYNAMIC, AND CLINICALLY REALISTIC MEDICAL SIMULATIONS USING ARTIFICIAL INTELLIGENCE-BASED ASSISTANCE","Systems and methods are described for creating and deploying immersive, interactive, and dynamic medical simulation training experiences within augmented reality (AR) and virtual reality (VR) environments. Embodiments include a creation framework that decomposes complex clinical scenarios into modular components, allowing users to construct simulations using an intuitive, block-based interface without requiring programming expertise. These components capture the medical, physiological, and psychological elements of the scenario, enabling the creation of detailed, multidimensional simulations. An integrated AI engine further enhances the system by leveraging a large language model (LLM) to automate and assist in the scenario creation process. The AI engine interprets high-level natural language inputs, predicting and generating detailed simulation instructions, thereby accelerating the development and deployment of custom training scenarios. Once created, the scenarios are processed by a scenario engine that controls various elements of the simulation, including virtual characters, environments, tools, physiological responses, and assessable actions within AR/VR settings.",SIMX INC,SARMA KARTHIK VENKATARAMAN;;NAMPERUMAL SRIHARI;;POLSON JENNIFER,,https://lens.org/041-408-777-118-371,Patent Application,yes,0,0,1,041-408-777-118-371,WO,1,041-408-777-118-371,WO,0,G06T19/00;;G06F3/01;;G16H50/50;;G09B23/28;;G16H50/20;;G16H50/70,G16H50/50;;G06F3/01;;G06T19/00;;G09B23/28;;G16H20/10,,0,0,,,,PENDING
773,US,A1,US 2025/0061324 A1,052-945-365-960-274,2/20/2025,2025,US 202418420710 A,1/23/2024,US 202418420710 A;;US 202363481024 P,1/23/2023,METHODS FOR THE EFFICIENT MANAGEMENT OF ARTIFICIAL INTELLIGENCE TRAINING WITHIN VIRTUAL ENVIRONMENTS,"Systems and methods capable of determining appropriate prioritization of Artificial Intelligence training in a virtual environment and in a multi-agent system. A generation system may provide a heatmap to an avatar during gameplay, using the generation system, identifying an area of movement of the avatar within a game. The generation system may perform an analysis of the positioning of the heatmap using machine learning on the heatmap to identify a movement pattern of the avatar based. The generation system may, in response to inferring the areas of movement within the game, divide the areas based on movement, wherein the areas of the heatmap having lower values of movement have a lower priority area and the areas of the heatmap having the greater values of movement have a higher priority area. The generation system allows for the generation of soft/rigid body elements from evolution and expansion of singular elements.",SPACEBRAINZ PRIVATE LTD,GERTZ FREDERICK;;BUCHANAN WARRICK,,https://lens.org/052-945-365-960-274,Patent Application,yes,0,0,1,052-945-365-960-274,US,1,052-945-365-960-274,US,0,G06N3/08;;G06N3/044;;G06N3/084;;G06N3/045;;G06N3/08,G06N3/08,,0,0,,,,PENDING
774,US,A1,US 2025/0068653 A1,003-331-126-785-17X,2/27/2025,2025,US 202418805907 A,8/15/2024,US 202418805907 A;;US 202363578329 P,8/23/2023,MATCHING DATABASE RECORD IDENTITY THROUGH INTELLIGENT LABELING,"The disclosed embodiments relate to devices, computer-readable media, and methods for generating training data for training an ordinal, regression-based classifier, the method including grouping client data based on client keys associated with the client data, pairwise matching records in the client data to generate feature signatures and inferring a label based on client key statuses for the pairwise-matched records, and building a training dataset from the inferred labels and feature signatures, the training dataset used to train the classifier.",AMPERITY INC,YAN YAN;;RESNICK NICHOLAS;;RUGGIERO JEAN;;CHRISTIANSON JOSEPH,AMPERITY INC (2024-08-09),https://lens.org/003-331-126-785-17X,Patent Application,yes,5,0,1,003-331-126-785-17X,US,1,003-331-126-785-17X,US,0,G06F16/285;;G06F16/285,G06F16/28,,0,0,,,,PENDING
775,WO,A1,WO 2025/042388 A1,012-600-122-355-534,2/27/2025,2025,US 2023/0030850 W,8/22/2023,US 2023/0030850 W,8/22/2023,VIDEO CONTEXT AWARE EDITING AGENT,"Techniques for using an artificial intelligent (AI) agent to modify audiovisual data is described herein. The system can obtain audiovisual data descriptive of one or more segments of audiovisual content. Additionally, the system can generate a semantic contextual description of each of the one or more segments of audiovisual content, the semantic contextual description generated based on one or more content understanding models. Moreover, the system can provide the semantic contextual description to a user. Furthermore, the system can receive a prompt from the user comprising one or more user-requested modifications to the semantic contextual description. The system can provide the prompt from the user and the semantic contextual description to the one or more content understanding models. Subsequently, the system can receive a second semantic contextual description from the one or more content understanding models, the second semantic contextual description reflecting the one or more user-requested modifications.",GOOGLE LLC,CHEN FEIFAN;;WALKER IV;;FERRARI MELISSA;;MURAD NOAH;;PADFIELD DIRK;;ZAYATS VICTORIA,,https://lens.org/012-600-122-355-534,Patent Application,yes,3,0,1,012-600-122-355-534,WO,1,012-600-122-355-534,WO,0,G06F40/30,G06F40/30,,0,0,,,,PENDING
776,US,A1,US 2024/0303882 A1,080-380-509-579-123,9/12/2024,2024,US 202318350876 A,7/12/2023,US 202318350876 A;;US 202363489131 P,3/8/2023,SYSTEMS AND METHODS FOR FEEDBACK BASED INSTRUCTIONAL VISUAL EDITING,"Embodiments described herein provide a feedback based instructional image editing framework that employs a diffusion process to follow user instruction for image editing. A diffusion model is fine-tuned using a reward model, which may be trained via human annotation. The training of the reward model may be done by having the image editing model output a number of images, which a human annotator ranks based on their alignment with the original image and a given instruction.",SALESFORCE INC,ZHANG SHU;;YANG XINYI;;FENG YIHAO;;XU RAN;;YU NING;;CHEN CHIA-CHIH,SALESFORCE INC (2023-07-17),https://lens.org/080-380-509-579-123,Patent Application,yes,0,1,1,080-380-509-579-123,US,1,080-380-509-579-123,US,0,G06T11/60;;G06T5/60;;G06T5/70;;G06T11/60;;G06T2207/20084;;G06T2207/20081;;G06T5/70,G06T11/60;;G06T5/00,,0,0,,,,PENDING
777,US,B1,US 11748577 B1,062-165-840-690-839,9/5/2023,2023,US 202318190791 A,3/27/2023,US 202318190791 A;;US 202263399932 P,8/22/2022,"Computer-generated content based on text classification, semantic relevance, and activation of deep learning large language models","The disclosure relates to systems and methods of automatically generating unique content including natural language text based on a corpus of previously generated response documents and discrete requirements defined in a requirements specification. The system may use generative stitching that includes multi-layer processes that execute to influence the generation of unique content including natural language text through an artificial intelligence (AI) language transformer model trained to output the content based on previously written material that is semantically relevant to the discrete requirements and is weighted against labeled attributes. The labeled attributes may determine the influence asserted against the language transformer, thereby generating unique on-target content that may be combined to create a computer-generated response document.",ROHIRRIM INC,ABERLE STEVEN THOMAS,ROHIRRIM INC (2022-08-19),https://lens.org/062-165-840-690-839,Granted Patent,yes,14,28,1,062-165-840-690-839,US,12,167-952-184-433-323;;067-080-768-671-463;;176-795-255-128-028;;077-160-578-799-776;;048-995-946-983-686;;183-531-797-707-467;;182-856-102-564-527;;046-749-966-763-211;;062-165-840-690-839;;194-725-746-693-602;;130-863-944-657-956;;046-913-270-759-689,US;;GB;;WO;;EP;;AU;;CA,0,G06F40/30;;G06F40/169;;G06F40/289;;G06F40/56;;G06N3/045;;G06N3/09;;G06F40/40;;G06F40/169;;G06F40/30;;G06N20/00,G06F17/00;;G06F40/169;;G06F40/30;;G06F40/40;;G06N20/00,,0,0,,,,ACTIVE
778,US,A1,US 2024/0104125 A1,039-231-839-627-508,3/28/2024,2024,US 202318497675 A,10/30/2023,US 202318497675 A;;US 202363584086 P,9/20/2023,MULTIAGENT DEBATE,"There are provided solutions for multiagent debate. In a method, a first and a second response representation are determined by a first and a second agent in a plurality of agents based on a first query representation for a query in a natural language, respectively, and the first and second response representations are convertible to a first and a second answer to the query in the natural language, respectively. A second query representation is obtained based on the first query representation, and at least one of the first and second response representations. A response representation is determined based on the second query representation by at least one of the first and second agents, and the response representation is convertible to an answer to the query in the natural language. These agents communicate in an embedding space without a conversion between a natural language format and an embedding format.",LEMON INC,PHAM MINH CHAU;;LIU BOYI;;CHEN ZHENGYU;;YANG YINGXIANG;;YUAN JIANBO;;YANG HONGXIA;;LIU TIANYI,,https://lens.org/039-231-839-627-508,Patent Application,yes,0,3,2,023-017-034-698-239;;039-231-839-627-508,US;;CN,2,023-017-034-698-239;;039-231-839-627-508,US;;CN,0,G06F16/3344;;G06F16/3329;;G06F16/3344;;G06F16/3329,G06F16/332;;G06F16/33,,0,0,,,,PENDING
779,US,A1,US 2025/0139429 A1,036-493-841-599-463,5/1/2025,2025,US 202318498605 A,10/31/2023,US 202318498605 A,10/31/2023,"SYSTEM AND METHOD FOR RAPID LEARNING, RESPONSE GENERATION AND RETENTION OF INTERACTIVE SESSIONS","Aspects of the subject disclosure may include, for example, a device having a processing system including a processor; and a memory that stores executable instructions that, when executed by the processing system, facilitate performance of operations of: receiving, from a user interface, a sample input format specification and output format specification for transforming data; searching a repository for a tag and associated data; merging or updating the sample input format specification and the output format specification with the associated data responsive to finding the tag in the repository, thereby creating updated data; providing the updated data as a prompt to a large language model; receiving a response to the prompt from the large language model; verifying that the response is satisfactory; and storing a context comprising the tag, the updated data and the response in the repository. Other embodiments are disclosed.",AT & T IP I LP,PARVANGADA SUDHARANI;;CHAN MERCY;;SIDDABATHULA MURALIDHAR;;BARAN ISILAY,AT&T INTELLECTUAL PROPERTY I L.P (2023-10-31),https://lens.org/036-493-841-599-463,Patent Application,yes,0,0,1,036-493-841-599-463,US,1,036-493-841-599-463,US,0,G06N3/0455;;G06N3/08;;G06N3/0455;;G06N3/08,G06N3/08;;G06N3/0455,,0,0,,,,PENDING
780,US,A1,US 2025/0209273 A1,093-449-053-543-871,6/26/2025,2025,US 202418983889 A,12/17/2024,IN 202321087441 A,12/20/2023,SYSTEMS AND METHODS FOR IDEATION OF RESEARCH PROPOSAL USING LARGE LANGUAGE MODELS AGENT-BASED ARCHITECTURE,"Ideation phase of research life cycle is challenging for researchers. The present disclosure provides a system and method for ideation of research proposal using a large language models (LLM) agent-based architecture. Ideation process is emulated using the LLM agent-based architecture having a colleague persona and mentor personas to execute a motivation validation and method synthesis. The motivation validation and the method synthesis engage users in an interactive manner to develop a research proposal document. The research proposal document comprises a validated motivation and a set of plausible solutions addressing a research problem based on a plurality of tasks performed by agents of the LLM agent-based architecture. The present disclosure alleviates hallucinations of LLMs, addresses unanswerability, and ensure relevant outcomes using two-stage aspect based retrieval where first stage introduces higher recall reducing False Negatives and correcting False Positives and second stage provides more precise fine-grained aspect based retrieval.",TATA CONSULTANCY SERVICES LTD,NIGAM HARSHIT;;PATWARDHAN MANASI SAMARTH;;VIG LOVEKESH;;SHROFF GAUTAM,TATA CONSULTANCY SERVICES LIMITED (2024-01-24),https://lens.org/093-449-053-543-871,Patent Application,yes,0,0,3,049-325-916-027-080;;186-051-087-945-387;;093-449-053-543-871,US;;EP;;JP,3,049-325-916-027-080;;186-051-087-945-387;;093-449-053-543-871,US;;EP;;JP,0,G06F40/30;;G06F16/93;;G06F40/289,G06F40/289;;G06F16/93,,0,0,,,,PENDING
781,US,A1,US 2024/0312087 A1,090-146-294-473-512,9/19/2024,2024,US 202318360919 A,7/28/2023,US 202318360919 A;;US 202363490937 P,3/17/2023,CUSTOM CONTENT GENERATION,Systems and methods for document processing are provided. One aspect of the systems and methods includes identifying a theme and an input image of a product. Another aspect of the systems and methods includes generating an output image depicting the product and the theme based on the input image using an image generation model that is trained to generate images consistent with a brand. Another aspect of the systems and methods includes generating text based on the product and the theme using a text generation model. Another aspect of the systems and methods includes generating custom content consistent with the brand and the theme based on the output image and the text.,ADOBE INC,AGRAWAL SHRADHA;;BASU DEBRAJ DEBASHISH;;PAI DEEPAK;;SRIVASTAV NIMISH;;MACHA MEGHANATH;;REVANUR AMBAREESH,ADOBE INC (2023-07-05),https://lens.org/090-146-294-473-512,Patent Application,yes,0,3,1,090-146-294-473-512,US,1,090-146-294-473-512,US,0,G06F40/186;;G06Q30/0276;;G06F40/40;;G06T11/60;;G06T11/60;;G06T7/90;;G06F40/186;;G06T2207/10024;;G06Q30/0276;;G06T2207/20081;;G06F40/40,G06T11/60;;G06F40/186;;G06F40/40;;G06Q30/0241;;G06T7/90,,0,0,,,,PENDING
782,US,A1,US 2024/0420389 A1,045-475-030-135-128,12/19/2024,2024,US 202318526855 A,12/1/2023,US 202318526855 A;;US 202363507808 P,6/13/2023,GENERATING TILE-ABLE PATTERNS FROM TEXT,"Systems and methods for generating tile-able patterns from text include obtaining a text prompt and generating, by a generation prior model, a latent vector based on the text prompt, where the generation prior model is trained to output vectors within a distribution of tile-able patterns. An image generation model then generates an output image based on the latent vector. The output image comprises a tile-able pattern including an element from the text prompt.",ADOBE INC,BATRA VINEET;;CHATURVEDI SUMIT;;RAI ABHISHEK;;AGGARWAL PRANAV VINEET;;KALE AJINKYA GORAKHNATH;;JEPH AMAN;;PHOGAT ANKIT;;DHINGRA SUMIT;;CHEN FENGBIN;;GARG KSHITIZ;;HASAN MILOS;;HARIKUMAR MIDHUN;;PATHAK GAURAV SURESH;;CHAKRABORTY SOUYMODIP,ADOBE INC (2023-11-29),https://lens.org/045-475-030-135-128,Patent Application,yes,0,2,1,045-475-030-135-128,US,1,045-475-030-135-128,US,0,G06T2200/24;;G06V10/764;;G06T11/20;;G06V10/774;;G06F40/40;;G06V10/82;;G06T11/001;;G06F40/40;;G06T2200/24;;G06T3/40;;G06T3/4038;;G06T2200/32;;G06T11/001,G06T11/20;;G06V10/764;;G06V10/774,,0,0,,,,PENDING
783,US,A1,US 2025/0232500 A1,197-228-558-172-561,7/17/2025,2025,US 202519012143 A,1/7/2025,US 202519012143 A;;US 202463619768 P,1/11/2024,SYSTEMS AND METHODS FOR GENERATING AN AI-ASSISTED USER INTERFACE AND PROCESSING A USER REQUEST TO SAID INTERFACE,"Described are systems and methods for providing AI and ML-assisted workflows, and more specifically, to improved systems and methods for creating user interfaces for software applications that interact with AI models. A computer-implemented system and method for generating an AI-assisted user interface comprises providing, at a memory, a page element database comprising a plurality of page element configurations; receiving, at a network device, a page generation request from a user at a user device; generating, at a processor in communication with the memory and the network device, an AI-assisted user interface comprising a plurality of page elements, each of the plurality of page elements generated based on a corresponding page element configuration in the plurality of page element configurations; outputting, at a display device in communication with the processor, the AI-assisted user interface; and wherein the plurality of page element configurations comprises at least one AI-based page element configuration.",KLICK INC,BASHER CURT,,https://lens.org/197-228-558-172-561,Patent Application,yes,0,0,1,197-228-558-172-561,US,1,197-228-558-172-561,US,0,G06T11/60;;G06T2200/24;;G06F40/18;;G06F40/40,G06T11/60;;G06F40/18;;G06F40/40,,0,0,,,,PENDING
784,US,A1,US 2024/0386015 A1,004-434-942-408-821,11/21/2024,2024,US 202418783404 A,7/24/2024,US 202418783404 A;;US 202418668137 A;;US 202418656612 A;;US 202318191876 A;;US 202017084263 A;;US 202016864133 A;;US 201715847443 A;;US 201715790457 A;;US 201715790327 A;;US 201715616427 A;;US 201514925974 A;;US 201615141752 A;;US 201615091563 A;;US 201514986536 A;;US 201715489716 A;;US 201715409510 A;;US 201615379899 A;;US 201615376657 A;;US 201615237625 A;;US 201615206195 A;;US 201615186453 A;;US 201615166158 A;;US 202463551328 P;;US 201762568291 P;;US 201762568298 P,10/28/2015,COMPOSITE SYMBOLIC AND NON-SYMBOLIC ARTIFICIAL INTELLIGENCE SYSTEM FOR ADVANCED REASONING AND SEMANTIC SEARCH,"A semantic search system integrates with an AI platform to provide advanced search capabilities by leveraging automatically generated ontologies and knowledge graphs. The system employs natural language processing, machine learning, and large language models to create, update, and align ontologies from diverse data sources. It supports context-aware query interpretation, personalized results, and complex reasoning by incorporating user context, feedback, and domain knowledge. The system optimizes search performance and efficiency through indexing techniques, distributed computing, and continuous learning. With a modular architecture and scalable infrastructure, the semantic search system enables users to retrieve relevant, meaningful, and context-specific information from vast amounts of structured and unstructured data. The integration of the semantic search system with the AI platform's components, such as knowledge graphs and model blending, enhances the platform's overall reasoning, decision-making, and problem-solving capabilities, empowering users with intelligent and intuitive search experiences across various domains and applications.",QOMPLX LLC,CRABTREE JASON;;KELLEY RICHARD;;HOPPER JASON;;PARK DAVID,QOMPLX LLC (2024-06-19),https://lens.org/004-434-942-408-821,Patent Application,yes,3,67,1,004-434-942-408-821,US,578,037-154-257-628-181;;026-779-470-212-557;;192-775-538-408-179;;051-177-220-968-114;;052-352-453-837-213;;158-783-234-553-331;;054-879-412-445-807;;133-705-672-195-350;;085-570-486-304-387;;131-181-059-848-846;;132-833-285-988-836;;008-670-386-928-50X;;170-038-557-276-089;;127-909-821-536-460;;193-256-330-379-091;;180-524-544-621-601;;125-131-656-407-907;;080-450-366-102-563;;003-842-080-904-026;;172-829-757-014-570;;153-645-799-362-009;;023-324-891-925-125;;165-772-840-997-741;;087-602-344-308-16X;;008-401-263-205-920;;181-484-588-987-501;;040-327-555-235-635;;108-602-315-004-87X;;150-224-578-671-129;;180-683-180-148-347;;169-279-819-725-473;;039-990-697-566-320;;119-836-745-834-196;;114-890-291-110-112;;154-344-527-132-119;;079-405-865-194-601;;015-812-699-933-62X;;080-215-142-304-844;;107-757-576-944-579;;048-876-789-559-846;;119-465-459-964-504;;172-790-697-398-393;;135-518-918-888-018;;197-881-544-654-764;;090-295-722-832-69X;;132-494-291-766-291;;101-765-648-888-249;;038-403-919-152-33X;;021-805-870-860-689;;077-763-435-353-163;;075-028-174-347-254;;152-853-258-831-079;;133-064-284-131-980;;125-262-596-697-50X;;063-306-274-750-632;;054-305-135-974-678;;138-722-806-573-588;;134-553-255-508-893;;128-471-135-100-790;;001-420-406-036-933;;006-140-484-263-280;;071-096-388-602-141;;134-998-818-751-494;;007-347-164-795-864;;035-410-443-521-078;;171-720-399-746-521;;175-746-154-241-630;;117-905-175-606-59X;;028-837-539-183-199;;127-262-016-473-933;;076-994-416-562-746;;143-831-828-697-438;;168-085-406-192-62X;;096-760-448-920-468;;124-872-389-039-522;;104-799-454-946-02X;;161-837-317-168-104;;103-822-902-908-489;;080-131-016-761-51X;;192-830-520-504-751;;019-088-815-151-256;;053-118-208-742-06X;;056-303-716-290-219;;131-638-342-848-769;;005-754-072-354-784;;187-297-841-980-800;;125-174-869-985-698;;180-264-763-292-192;;016-383-893-604-161;;188-288-369-132-622;;015-253-533-470-911;;197-949-044-788-406;;121-414-540-038-42X;;075-761-481-704-735;;096-041-127-373-239;;156-714-318-502-855;;181-249-118-121-535;;108-857-816-973-884;;156-184-203-979-455;;012-345-119-923-259;;111-774-031-604-805;;117-642-872-264-108;;025-847-591-070-300;;055-188-765-410-398;;070-097-015-696-892;;121-587-173-958-560;;014-453-562-149-334;;140-999-857-633-847;;055-343-015-110-465;;105-282-159-769-838;;040-564-101-493-604;;149-755-186-391-125;;130-015-728-409-753;;194-532-778-624-336;;163-595-907-546-308;;177-278-902-893-596;;145-585-587-743-588;;155-540-548-103-119;;193-934-571-047-442;;185-664-206-749-529;;127-704-477-633-915;;110-416-603-986-719;;032-786-057-601-068;;008-374-093-288-207;;108-907-809-853-481;;014-246-422-230-315;;149-940-585-858-33X;;027-061-421-057-726;;146-230-367-962-31X;;064-335-677-286-781;;115-802-053-250-762;;173-295-267-595-213;;124-201-072-441-516;;024-542-796-067-398;;147-258-217-637-838;;196-067-950-022-786;;006-058-429-744-847;;058-136-034-848-059;;125-906-404-070-886;;065-063-014-426-659;;004-461-496-948-855;;045-917-971-050-56X;;069-194-973-718-724;;091-833-359-236-851;;041-281-890-750-525;;139-937-135-074-052;;080-566-767-838-47X;;103-114-371-775-543;;118-279-455-322-111;;037-982-084-311-787;;188-674-366-808-979;;055-903-940-567-078;;110-351-467-572-989;;014-739-606-719-102;;071-988-212-130-180;;021-675-104-144-445;;111-073-595-869-372;;160-571-262-420-277;;195-650-568-942-751;;032-598-622-351-105;;147-011-126-807-569;;029-660-878-137-344;;151-696-187-988-34X;;015-328-647-228-799;;048-192-302-857-722;;117-801-500-567-584;;059-944-182-190-705;;154-860-068-782-470;;029-243-465-483-305;;107-672-595-990-826;;030-174-392-464-531;;022-847-643-542-201;;055-524-762-178-036;;107-489-943-484-626;;195-839-818-513-941;;093-208-015-729-299;;021-558-362-611-744;;160-450-640-172-266;;077-783-261-149-506;;095-377-229-980-681;;133-292-239-870-375;;154-356-244-638-409;;031-352-297-708-759;;049-056-708-944-463;;068-170-442-972-229;;182-432-926-199-498;;189-753-829-322-396;;162-131-738-285-968;;119-187-664-144-76X;;177-271-896-528-32X;;039-022-512-400-247;;043-267-234-154-815;;169-243-590-009-342;;036-028-001-089-731;;103-477-783-950-291;;153-058-907-719-786;;071-806-202-555-740;;171-546-189-945-812;;073-713-769-727-494;;136-480-712-243-666;;052-963-291-923-41X;;136-574-935-289-538;;104-638-509-577-202;;080-671-539-609-40X;;065-170-374-274-971;;026-186-698-928-734;;189-625-816-692-893;;091-371-713-692-46X;;100-783-433-341-126;;131-128-001-633-700;;166-942-852-231-992;;017-768-934-473-414;;001-317-406-379-391;;021-389-305-075-979;;151-137-309-371-284;;098-907-119-613-391;;044-191-182-507-882;;007-389-607-938-031;;123-321-763-235-770;;185-127-509-038-974;;160-715-381-644-126;;162-384-848-216-31X;;182-700-396-052-074;;129-952-794-667-401;;074-240-537-909-757;;000-597-495-310-814;;040-266-056-016-458;;155-110-500-893-086;;172-708-395-558-130;;042-934-102-630-453;;083-983-202-187-530;;004-166-358-275-953;;161-495-650-262-973;;076-637-575-690-977;;000-709-674-481-081;;087-182-225-707-637;;123-484-837-782-635;;155-910-546-986-355;;043-405-349-939-957;;103-425-520-233-843;;083-324-191-334-70X;;112-456-615-712-52X;;150-820-621-367-909;;083-903-894-483-425;;197-114-070-350-824;;049-028-516-768-655;;178-349-455-789-034;;073-430-035-592-80X;;008-064-859-265-815;;000-038-902-909-621;;133-002-373-744-021;;048-279-739-950-067;;086-485-075-219-428;;040-845-969-026-139;;070-352-069-345-700;;021-079-503-611-265;;175-495-496-188-020;;183-511-956-429-444;;065-680-750-346-802;;178-846-706-765-553;;049-890-567-654-589;;080-081-217-032-345;;027-066-977-165-899;;191-240-978-834-668;;132-133-759-842-71X;;018-088-624-287-349;;061-497-697-206-884;;126-037-593-729-516;;129-906-538-555-657;;099-264-755-545-57X;;072-247-216-528-290;;009-846-049-780-690;;045-328-154-501-02X;;079-660-520-290-41X;;154-492-113-635-386;;186-959-289-691-389;;118-724-487-120-496;;182-633-890-280-382;;076-376-030-977-668;;086-985-098-575-311;;093-141-887-021-964;;010-455-868-836-106;;065-648-185-387-723;;036-825-187-272-252;;154-230-032-513-096;;113-501-055-080-187;;174-612-974-303-470;;090-735-414-483-316;;121-801-592-381-617;;013-381-805-754-357;;013-095-413-454-913;;038-816-881-922-305;;027-329-988-277-302;;100-217-067-155-684;;014-827-400-640-212;;029-914-300-591-644;;011-562-412-366-329;;133-727-860-994-552;;101-135-325-800-138;;110-216-990-843-69X;;154-519-584-244-864;;126-611-010-718-203;;165-782-104-054-453;;148-737-413-742-728;;066-338-354-411-572;;025-060-142-473-519;;116-772-778-631-652;;104-738-742-266-791;;009-005-289-876-142;;004-434-942-408-821;;143-973-436-078-842;;164-967-662-048-677;;169-787-555-684-938;;195-227-968-704-893;;105-859-471-411-05X;;180-657-958-950-99X;;142-038-055-730-469;;064-634-698-781-255;;153-055-980-262-66X;;015-812-671-795-376;;012-017-411-640-86X;;107-754-063-563-072;;117-494-039-277-097;;024-690-213-354-681;;199-512-678-380-42X;;125-466-315-926-236;;152-494-705-574-843;;003-760-855-042-662;;085-052-960-069-32X;;141-339-840-935-585;;083-774-515-610-167;;102-978-916-788-777;;035-392-941-606-940;;019-318-746-775-604;;186-803-715-049-938;;158-393-312-453-210;;104-573-774-575-721;;182-149-428-548-452;;109-480-476-119-858;;001-639-636-991-22X;;024-395-701-195-470;;166-061-512-788-786;;087-458-637-270-456;;130-059-342-072-611;;066-682-704-432-73X;;058-075-461-036-518;;178-838-919-599-069;;187-160-099-485-495;;103-080-609-508-064;;022-448-222-186-183;;070-102-620-731-530;;139-862-995-392-954;;132-832-554-023-705;;062-196-356-634-765;;108-332-517-102-921;;145-988-468-831-661;;117-641-165-329-019;;085-210-721-709-87X;;167-909-715-949-326;;064-761-756-293-121;;108-582-708-972-032;;037-260-814-519-084;;021-295-609-309-853;;170-124-147-957-843;;072-847-784-173-124;;019-859-720-492-763;;180-694-854-374-695;;182-093-288-289-742;;023-933-112-090-776;;057-123-744-810-742;;147-597-875-076-485;;198-870-840-595-044;;136-078-534-118-76X;;000-296-368-111-872;;171-152-301-182-412;;139-710-050-486-182;;039-538-267-429-560;;136-912-601-845-732;;196-391-835-696-835;;022-915-563-273-963;;000-536-856-313-465;;133-810-480-576-815;;054-285-468-825-720;;051-647-934-342-985;;133-965-591-339-720;;089-232-307-907-363;;040-251-717-505-653;;041-876-411-976-475;;060-927-214-452-10X;;149-204-391-984-367;;027-902-066-189-831;;102-745-043-366-737;;128-846-474-291-42X;;172-901-964-435-101;;132-906-454-317-828;;027-879-065-052-099;;061-955-529-156-158;;115-450-998-992-89X;;093-783-952-647-256;;087-671-644-225-162;;082-203-791-029-269;;162-406-931-508-609;;183-065-763-307-144;;190-613-105-844-894;;070-109-425-956-71X;;179-687-548-881-946;;114-875-928-799-290;;181-309-519-837-78X;;196-041-560-476-12X;;170-229-078-848-82X;;075-282-849-667-576;;045-652-081-194-018;;198-402-416-554-06X;;194-445-489-074-002;;060-892-480-987-951;;055-085-895-924-889;;084-363-068-228-491;;170-620-942-428-927;;193-391-823-339-284;;096-702-410-515-824;;083-768-096-673-313;;114-571-787-948-076;;034-716-329-436-000;;187-063-295-984-852;;144-476-586-622-902;;093-611-777-921-084;;045-202-166-877-864;;193-422-150-038-506;;021-329-379-658-240;;097-234-496-193-062;;192-675-634-874-622;;052-059-789-553-166;;147-195-340-266-520;;071-696-457-139-904;;194-227-374-582-968;;113-501-017-599-156;;118-902-966-890-171;;070-452-081-561-244;;078-561-597-336-228;;114-488-925-608-399;;142-585-568-390-116;;056-936-930-529-366;;137-287-553-424-233;;029-189-340-565-222;;050-203-411-376-891;;008-857-479-067-163;;128-491-075-052-384;;174-310-672-604-848;;122-358-915-403-896;;062-446-755-582-201;;083-350-553-415-427;;084-094-561-358-190;;193-279-570-818-331;;116-387-661-145-676;;188-217-959-572-232;;197-886-230-839-566;;151-294-727-872-793;;071-718-147-875-265;;047-538-862-310-257;;002-385-103-394-413;;048-792-342-952-15X;;019-495-936-711-609;;125-167-199-425-708;;118-125-542-986-723;;060-510-775-281-976;;040-913-584-420-591;;025-468-821-684-384;;023-849-985-263-398;;077-090-854-196-197;;111-114-577-294-884;;085-897-643-354-041;;055-432-328-819-058;;057-315-027-521-995;;177-733-336-930-533;;196-044-725-401-358;;063-927-942-204-381;;145-050-894-270-572;;183-336-332-885-622;;127-879-776-921-09X;;017-132-357-346-699;;198-615-615-891-543;;052-792-568-847-103;;000-319-657-499-550;;027-484-045-457-746;;027-481-945-197-130;;017-390-887-154-856;;033-501-473-103-759;;179-619-578-529-367;;116-362-275-848-217;;138-542-048-114-834;;126-765-455-776-483;;156-393-972-996-170;;038-748-734-766-451;;087-679-756-879-992;;137-312-722-747-052;;104-276-098-918-424;;111-341-246-938-702;;073-508-864-364-182;;049-072-378-638-892;;061-707-666-299-734;;044-987-220-762-643;;123-930-852-651-964;;121-678-385-649-755;;022-530-649-397-986;;138-890-046-052-810;;058-768-672-787-786;;195-998-346-296-106;;018-465-551-415-290;;121-569-357-502-219;;120-768-539-121-615;;056-853-528-304-042;;000-700-770-801-419;;016-238-739-232-485;;041-102-746-837-769;;167-603-067-966-088;;023-901-754-663-920;;194-673-951-169-189;;059-927-962-068-028;;060-460-016-582-353;;182-618-894-149-220;;178-645-610-606-223;;129-164-109-835-79X;;197-077-457-073-454;;005-466-616-725-55X;;003-537-389-243-00X;;103-699-274-581-751;;129-731-022-200-191;;068-856-645-258-312;;063-147-555-951-048;;180-331-323-588-173;;135-222-397-719-848;;140-674-265-766-042;;164-132-307-319-588;;116-059-560-935-908;;138-363-646-907-419;;051-181-106-775-29X;;067-239-494-680-70X;;028-870-183-960-608;;076-700-976-390-042;;080-376-581-712-310;;095-867-167-500-428;;178-747-472-734-856;;102-602-839-299-13X;;120-886-060-343-539;;197-208-522-876-972;;126-876-084-817-670;;074-338-551-378-222;;113-564-524-220-276;;105-294-500-738-719;;124-004-714-460-784;;099-524-911-821-301;;085-797-537-316-326;;071-706-755-734-222;;044-567-921-028-686;;179-234-156-117-509;;112-703-143-713-529;;066-129-850-694-558;;138-161-071-533-827;;003-806-385-394-25X;;195-055-953-058-579;;109-759-429-228-830;;193-976-187-522-099;;127-790-040-938-082;;166-684-166-297-239;;073-718-671-991-142;;150-697-523-144-129;;002-838-097-104-449;;104-060-925-131-711;;043-394-058-432-688;;098-515-068-077-601;;089-867-569-003-195;;031-295-313-605-242;;152-249-199-790-404;;028-166-882-002-231;;150-659-573-759-677;;076-553-285-158-562;;072-737-409-579-731;;065-438-385-254-508,US;;WO;;EP;;AU;;CN,0,G06F40/30;;G06N5/04;;G06F16/248;;G06F16/245;;G06F16/9024;;G06N5/022;;G06F16/245;;G06F16/248;;G06F40/30;;G06N5/04;;G06F16/9024,G06F16/245;;G06F16/248;;G06F16/901;;G06F40/30;;G06N5/04,,0,0,,,,PENDING
785,WO,A1,WO 2024/205899 A1,017-675-178-147-61X,10/3/2024,2024,US 2024/0019616 W,3/13/2024,US 202363454949 P;;US 202318335064 A,3/27/2023,FINDING SEMANTICALLY RELATED SECURITY INFORMATION,"Methods and apparatuses for improving the performance and energy efficiency of machine learning systems that generate security specific machine learning models and generate security related information using security specific machine learning models are described. A security specific machine learning model may comprise a security specific large language model (LLM). The security specific LLM may be trained and deployed to generate semantically related security information. The security specific LLM may be pretrained with a security specific data set that was generated using similarity deduplication and long line handling, and with security specific objectives, such as next log line prediction based on host, system, application, and cyber attacker behavior. The security specific large language model may be fine-tuned using a security specific similarity dataset that may be generated to align the security specific LLM to capture similarity between different security events.",MICROSOFT TECHNOLOGY LICENSING LLC,BULUT MUHAMMED FATIH;;GREENWALD LLOYD GEOFFREY;;SHAH ADITI KAMLESH;;BETTHAUSER LEO MORENO;;LIU YINGQI;;XIA NING;;WANG SIYUE,,https://lens.org/017-675-178-147-61X,Patent Application,yes,5,0,1,017-675-178-147-61X,WO,2,017-675-178-147-61X;;027-700-854-480-448,US;;WO,0,G06N3/045;;G06N3/08;;H04L63/1425;;G06F40/284;;G06F21/552;;G06F21/577,G06F21/55;;G06F21/57;;G06F40/284;;G06N3/045;;G06N3/08;;H04L9/40,,0,0,,,,PENDING
786,US,A1,US 2025/0156384 A1,076-636-574-201-567,5/15/2025,2025,US 202418948748 A,11/15/2024,US 202418948748 A;;US 202363599294 P,11/15/2023,MIGRATION PLATFORM FOR LEGACY DATABASE MIGRATION WITH A LARGE LANGUAGE MODEL,"A method, apparatus, and computer-readable medium of a migration platform for analyzing a legacy database based on applying a large language model to the legacy database and legacy application code to extract legacy database values and legacy application values, determining destination database values corresponding to a destination database based on the legacy database values and the legacy application values, generating migration code for migrating the legacy database to the destination database based on code generation templates, user preferences, and code generation procedures configured to create one or more files and one or more directories based on the code generation templates, validating the migration code based on generating mock data, storing the mock data in the legacy database, and applying the migration code to the mock data to migrate the mock data to the destination database, and executing the validated migration code to perform a migration of the legacy database.",PEERISLANDS HOLDINGS LLC,RAJAGOPALAN RAJESH;;SATHYANARAYANA KRISHNAKUMAR;;VINAYAGAM RAJESH;;MUTHUSAMY SURESHKANNAN;;SENTHIL PUVIARASU;;MUNIYASAMY NAVEEN;;RAMAYA MADHU,PEERISLANDS HOLDINGS LLC (2024-12-17),https://lens.org/076-636-574-201-567,Patent Application,yes,0,0,1,076-636-574-201-567,US,1,076-636-574-201-567,US,0,H04L51/02;;G06F16/214;;G06F16/213;;H04L51/02;;G06F16/214,G06F16/21;;H04L51/02,,0,0,,,,PENDING
787,US,A1,US 2024/0330446 A1,027-700-854-480-448,10/3/2024,2024,US 202318335064 A,6/14/2023,US 202318335064 A;;US 202363454949 P,3/27/2023,FINDING SEMANTICALLY RELATED SECURITY INFORMATION,"Methods and apparatuses for improving the performance and energy efficiency of machine learning systems that generate security specific machine learning models and generate security related information using security specific machine learning models are described. A security specific machine learning model may comprise a security specific large language model (LLM). The security specific LLM may be trained and deployed to generate semantically related security information. The security specific LLM may be pretrained with a security specific data set that was generated using similarity deduplication and long line handling, and with security specific objectives, such as next log line prediction based on host, system, application, and cyber attacker behavior. The security specific large language model may be fine-tuned using a security specific similarity dataset that may be generated to align the security specific LLM to capture similarity between different security events.",MICROSOFT TECHNOLOGY LICENSING LLC,BULUT MUHAMMED FATIH;;GREENWALD LLOYD GEOFFREY;;SHAH ADITI KAMLESH;;BETTHAUSER LEO MORENO;;LIU YINGQI;;XIA NING;;WANG SIYUE,MICROSOFT TECHNOLOGY LICENSING LLC (2023-06-14),https://lens.org/027-700-854-480-448,Patent Application,yes,1,3,1,027-700-854-480-448,US,2,017-675-178-147-61X;;027-700-854-480-448,US;;WO,0,G06N3/0895;;G06F21/554;;G06N3/045;;G06F2221/034;;G06N3/0895;;G06N3/045;;G06F21/554,G06F21/55;;G06N3/0895,,0,0,,,,PENDING
788,US,A1,US 2025/0014469 A1,127-266-542-331-060,1/9/2025,2025,US 202318506815 A,11/10/2023,US 202318506815 A;;US 202363512363 P,7/7/2023,ONLINE LEARNING PLATFORMS WITH ENHANCED PROMPT ASSIGNMENTS,"The technology disclosed herein includes a method of operating a learning platform that includes observing the prompt drafting activities of an observed user with respect to a prompt assignment, submitting a prompt to a foundation model via the learning platform, and displaying a reply from the foundation model in a user interface to learning platform. The technology disclosed herein further includes a method of surfacing, based on the prompting activities, an option suggesting a revision to a prompt constructed by an observed user via the user interface.",MICROSOFT TECHNOLOGY LICENSING LLC,THOLFSEN MICHAEL;;GRAY EMMA MARGARET;;BEN TOV ELLA;;BEN-ELAZAR SHAY,MICROSOFT TECHNOLOGY LICENSING LLC (2023-10-10),https://lens.org/127-266-542-331-060,Patent Application,yes,0,0,1,127-266-542-331-060,US,1,127-266-542-331-060,US,0,G09B5/02;;G09B5/02,G09B5/02,,0,0,,,,PENDING
789,US,A1,US 2025/0232139 A1,067-080-768-671-463,7/17/2025,2025,US 202519171609 A,4/7/2025,US 202519171609 A;;US 202318343683 A;;US 202318190791 A;;US 202263399932 P,8/22/2022,"COMPUTER-GENERATED CONTENT BASED ON TEXT CLASSIFICATION, SEMANTIC RELEVANCE, AND ACTIVATION OF DEEP LEARNING LARGE LANGUAGE MODELS","The disclosure relates to systems and methods of automatically generating unique content including natural language text based on a corpus of previously generated response documents and discrete requirements defined in a requirements specification. The system may use generative stitching that includes multi-layer processes that execute to influence the generation of unique content including natural language text through an artificial intelligence (AI) language transformer model trained to output the content based on previously written material that is semantically relevant to the discrete requirements and is weighted against labeled attributes. The labeled attributes may determine the influence asserted against the language transformer, thereby generating unique on-target content that may be combined to create a computer-generated response document.",ROHIRRIM INC,ABERLE STEVEN THOMAS,,https://lens.org/067-080-768-671-463,Patent Application,yes,0,0,6,167-952-184-433-323;;067-080-768-671-463;;130-863-944-657-956;;194-725-746-693-602;;048-995-946-983-686;;183-531-797-707-467,US;;WO;;EP;;AU,12,167-952-184-433-323;;067-080-768-671-463;;176-795-255-128-028;;077-160-578-799-776;;048-995-946-983-686;;183-531-797-707-467;;182-856-102-564-527;;046-749-966-763-211;;062-165-840-690-839;;194-725-746-693-602;;130-863-944-657-956;;046-913-270-759-689,US;;GB;;WO;;EP;;AU;;CA,0,G06F40/56;;G06F40/131;;G06N20/00;;G06F40/40;;G06F40/169;;G06F40/30,G06F40/40;;G06F40/169;;G06F40/30;;G06N20/00,,0,0,,,,PENDING
790,US,A1,US 2025/0106019 A1,103-273-870-697-349,3/27/2025,2025,US 202418899444 A,9/27/2024,US 202418899444 A;;US 202363540787 P,9/27/2023,SYSTEM AND METHOD FOR PRIVATELY HOSTING MACHINE LEARNING MODELS AND COLLABORATIVE COMPUTATIONS,"Systems and methods are disclosed for offering a secure model as a service. A system can be configured to implement, via a trusted execution environment comprising an enclave virtual machine and a customer key host, a distributed privacy policy in which a master decryption key is split-shared between the trusted execution environment the customer key host; perform a decryption of the master decryption key according to the distributed privacy policy to obtain a decrypted master key; and, based on the decrypted master key, perform, in the trusted execution environment, a private collaborative computation using one or more of customer data and a customer model. Secure multiparty computation can be used to perform the decryption of the master decryption key.",IDEEM INC,RADEMACHER ANDREW;;GHARIBI GHARIB;;GENTRY CRAIG;;DAS RIDDHIMAN,,https://lens.org/103-273-870-697-349,Patent Application,yes,0,0,1,103-273-870-697-349,US,1,103-273-870-697-349,US,0,H04L9/088;;H04L9/088,H04L9/08,,0,0,,,,PENDING
791,US,A1,US 2024/0256598 A1,126-237-643-161-188,8/1/2024,2024,US 202418631529 A,4/10/2024,US 202418631529 A;;US 202318342461 A;;US 202217840390 A;;US 202016797640 A,2/21/2020,GENERATIVE AI AND AGENTIC AI SYSTEMS AND METHODS FOR PRODUCT DATA ANALYTICS AND OPTIMIZATION,"Generative AI systems and methods are developed to provide recommendations regarding product sales, pricing, inventory, orders, manufacturing, distribution, shipping, packaging or other product analytics as determined from a range of available data sources. A consistent, semantic metadata structure is described as well as a hypothesis generating and testing system capable of generating predictive analytics models in a non-supervised or partially supervised mode. Users and/or AI agents (i.e., a form “agentic AI”) may then subscribe to the date for the use in economic forecasting.",MCCARSON BRIAN,MCCARSON BRIAN,AIECONOMY LLC (2024-11-19),https://lens.org/126-237-643-161-188,Patent Application,yes,0,7,1,126-237-643-161-188,US,14,047-561-968-866-355;;195-152-679-664-772;;060-821-074-818-847;;106-650-584-011-393;;016-101-423-428-10X;;057-596-683-832-509;;198-724-866-588-373;;104-276-531-633-519;;004-535-549-272-828;;042-466-929-911-734;;193-145-554-233-76X;;130-365-423-350-594;;139-867-629-060-653;;126-237-643-161-188,US;;WO,0,G06F16/587;;G06F18/217;;G06N3/044;;G06N3/0464;;G06N3/0675;;G06N3/092;;G06V10/70;;G06V20/13;;G06V20/52;;G06V2201/10;;G08G1/0133;;G08G3/00;;G06F16/907;;G06F18/2133;;G06F18/24155;;G06F18/29;;G06N3/08;;G06N7/01;;G06V10/764;;G06V10/84;;G06V20/188;;G06V10/82;;G06V20/17;;G08G3/00;;G06F16/907;;G08G1/0133;;G06N3/08;;G06V20/13;;G06F18/29;;G06F18/2133;;G06F18/24155;;G06N7/01;;G06F16/587;;G06V10/764;;G06V10/84;;G06V20/188;;G08G5/20,G06F16/587;;G06F16/907;;G06F18/20;;G06F18/2133;;G06F18/2415;;G06N3/08;;G06N7/01;;G06V10/764;;G06V10/84;;G06V20/10;;G06V20/13;;G08G1/01;;G08G3/00;;G08G5/00,,0,0,,,,PENDING
792,US,A1,US 2025/0068845 A1,154-309-105-459-003,2/27/2025,2025,US 202418792282 A,8/1/2024,US 202418792282 A;;US 202363534214 P,8/23/2023,DATA EXTRACTION FROM PRINTED DOCUMENTS,"A computer-implemented method for extracting data from printed documents comprises receiving a printed document and identifying the printed document as one of a structured form (including fully structured and semi-structured) and an unstructured form. Where the printed document is identified as a structured form, the method identifies first text features corresponding to keys for key-value pairs and identifies second text features that satisfy a proximity threshold (and optionally one or more key constraints) relative to the respective first text feature as the respective values of the respective key-value pairs, and records the values of the key-value pairs. Where the printed document is identified as a semi-structured form, the method may further comprise identifying at least one unstructured portion of the printed document and applying a trained machine learning model to the unstructured portion of the printed document to obtain additional values for additional key-value pairs.",ROYAL BANK OF CANADA,PATEL TIRTHKUMAR;;WONG AVELYN;;MISTRY KASHISH TRUSHARKUMAR,ROYAL BANK OF CANADA (2025-02-06),https://lens.org/154-309-105-459-003,Patent Application,yes,0,0,1,154-309-105-459-003,US,1,154-309-105-459-003,US,0,G06V30/412;;G06V30/10;;G06F40/279;;G06F40/279;;G06V30/10;;G06V30/412,G06F40/279;;G06V30/10;;G06V30/412,,0,0,,,,PENDING
793,EP,A1,EP 4390872 A1,039-206-244-000-840,6/26/2024,2024,EP 23217543 A,12/18/2023,JP 2022207689 A,12/23/2022,"INFORMATION PROCESSING PROGRAM, INFORMATION PROCESSING METHOD, AND INFORMATION PROCESSING DEVICE",An information processing program that causes a computer to execute a process that includes acquiring video data that includes a registration machine; extracting image data that include products; specifying a timing when first information regarding a first product registered to the registration machine; specifying certain image data of the image data that includes a second product held in the hand of the user within a certain time period from the timing and placed in a place in an angle of view of the video data that is not a place where a product that has been registered to the registration machine is placed for most of the certain time period; specifying second information regarding the second product by inputting the certain image data to a machine learning model; and generating an alert when the first information and the second information do not match.,FUJITSU LTD,OBINATA YUYA;;YAMAMOTO TAKUMA;;UCHIDA DAISUKE,,https://lens.org/039-206-244-000-840,Patent Application,yes,3,0,4,039-206-244-000-840;;072-672-602-065-789;;166-674-179-873-857;;061-325-981-074-494,US;;EP;;KR;;JP,4,039-206-244-000-840;;072-672-602-065-789;;166-674-179-873-857;;061-325-981-074-494,US;;EP;;KR;;JP,0,G06Q20/208;;G06V20/52;;G07G1/0009;;G07G1/0045;;G07G3/00;;G06V10/82;;G06Q20/18;;G06Q20/202;;G07G1/0054;;G07G3/003;;G07G3/003;;G07G1/0009;;G07G1/0045;;G07G1/14;;G06V10/25;;G06N20/00;;H04N23/57;;G06V10/25;;G06V20/52;;G06V10/70;;G06V40/107;;G06Q20/4016;;G08B13/196,G06V10/82;;G06Q20/20;;G06V20/52;;G07G1/00;;G07G3/00,,0,0,,,,PENDING
794,WO,A1,WO 2024/187286 A1,109-994-797-220-082,9/19/2024,2024,CA 2024050320 W,3/15/2024,US 202363490264 P,3/15/2023,"METHODS, DEVICES AND SYSTEMS FOR RERANKING DIGITAL INFORMATION WITH A MACHINE LEARNING MODEL","Methods, devices and systems for reranking digital information using a machine learning model are provided herein. A method for reranking digital information using a machine learning model includes receiving input data including an object of interest and a set of candidate items. The method further includes processing, by a machine learning model, the input data based on a contextual understanding of the input data. The method further includes generating output data based on the processing, wherein the output data includes candidate items ranked according to relevance to the object of interest. A device is provided configured to execute the methods disclosed herein. A system is provided configured to execute the methods disclosed herein.",PRIMAL FUSION INC,MA XUEGUANG;;ZHANG XINYU;;PRADEEP RONAK;;LIN JIMMY;;WILSON MATHEW,,https://lens.org/109-994-797-220-082,Patent Application,yes,3,0,1,109-994-797-220-082,WO,1,109-994-797-220-082,WO,0,G06N20/00;;G06F16/903,G06F18/20;;G06F16/903;;G06N20/00,,0,0,,,,PENDING
795,US,A1,US 2025/0071394 A1,011-909-613-504-29X,2/27/2025,2025,US 202418810123 A,8/20/2024,US 202418810123 A;;US 202363520718 P,8/21/2023,SYSTEM AND METHOD FOR DIGITAL COMMUNICATION,"Provided is a system and method for generating and posting tailored digital content. The system includes a processor and memory. The memory is configured to store campaign data and model data. The processor includes a goals and objectives module configured to apply goals application data to a goals application model, and generate and provide to a recommendations module goals and objectives data. The processor further includes the recommendations module configured to apply the goals and objectives data and creative feedback to a recommendations model, generate and provide to a creations module, the recommendations data including an engineered prompt, and update the recommendations model based on received creative feedback. The processor further includes an evaluation module configured to receive and evaluate the status of creative data, and where the creative data is in progress, generate and provide to the recommendations modules, the creative feedback.",VIRAL NATION INC,MICHELI MATHEW;;KANDOLA MANMINDER,,https://lens.org/011-909-613-504-29X,Patent Application,yes,0,0,2,011-909-613-504-29X;;090-294-257-439-213,US;;EP,2,011-909-613-504-29X;;090-294-257-439-213,US;;EP,0,G06Q30/0276;;G06Q30/0277;;G06Q30/0244;;H04N21/2743;;H04N21/854,H04N21/854;;H04N21/2743,,0,0,,,,PENDING
796,WO,A1,WO 2025/051551 A1,038-001-205-077-639,3/13/2025,2025,EP 2024073587 W,8/22/2024,US 202318243281 A,9/7/2023,DATA LEAKAGE PROTECTION USING GENERATIVE LARGE LANGUAGE MODELS,"Mechanisms are provided for automatically detecting data leakages and generating data leakage detection rules for a rules engine. The rules engine is configured with rules for identifying first sensitive data patterns in input data, and a large language model (LLM) is trained to identify second sensitive data patterns in input data. New input data is processed via the rules engine to determine whether it comprises any of the first sensitive data patterns. In response to the rules engine making a negative determination, the LLM is executed on the new input data to determine whether the new input data comprises any of the second sensitive data patterns. Responsive to a positive determination by the LLM, the rules engine is updated with a new rule based on the at least one second data pattern.",IBM;;IBM UK,CRUME JEFFERY;;BHATIA AANKUR;;RJAIBI WALID;;PARK YOUNGJA,,https://lens.org/038-001-205-077-639,Patent Application,yes,1,0,2,038-001-205-077-639;;035-936-698-034-50X,US;;WO,2,038-001-205-077-639;;035-936-698-034-50X,US;;WO,0,G06F21/6245;;G06F21/554;;G06N20/00;;G06N5/025;;G06F16/2433;;G06F21/6245,G06F21/55;;G06F21/62;;G06N5/025;;G06N20/00,,4,2,063-549-131-926-115;;118-594-072-135-204,10.1109/iccwamtip56608.2022.10016592;;10.23919/mipro52101.2021.9596735,"LIU ZHENGLIANG ET AL: ""DeID-GPT: Zero-shot Medical Text De-Identification by GPT-4"", 20 March 2023 (2023-03-20), XP093215750, Retrieved from the Internet <URL:https://arxiv.org/pdf/2303.11032v1>;;CHONG PENG: ""Deep Learning Based Sensitive Data Detection"", 2022 19TH INTERNATIONAL COMPUTER CONFERENCE ON WAVELET ACTIVE MEDIA TECHNOLOGY AND INFORMATION PROCESSING (ICCWAMTIP), IEEE, 16 December 2022 (2022-12-16), pages 1 - 6, XP034279056, ISBN: 978-1-6654-9387-1, [retrieved on 20230119], DOI: 10.1109/ICCWAMTIP56608.2022.10016592;;KUZINA VJEKO ET AL: ""Methods for Automatic Sensitive Data Detection in Large Datasets: a Review"", 2021 44TH INTERNATIONAL CONVENTION ON INFORMATION, COMMUNICATION AND ELECTRONIC TECHNOLOGY (MIPRO), CROATIAN SOCIETY MIPRO, 27 September 2021 (2021-09-27), pages 187 - 192, XP034020548, DOI: 10.23919/MIPRO52101.2021.9596735;;""International Business Machines (IBM"", CORPORATION OF ARMONK",PENDING
797,US,A1,US 2025/0157235 A1,020-935-779-655-034,5/15/2025,2025,US 202318509072 A,11/14/2023,US 202318509072 A,11/14/2023,SEMANTIC LABELING OF IMAGES WITH GENERATIVE LANGUAGE MODEL,"A computing system including one or more processing devices configured to receive an image. The processing devices are further configured to compute a segmentation mask that identifies a region of interest included in the image. At a feature extractor, the processing devices are further configured to compute encoded image features based on the image. The processing devices are further configured to receive a text instruction. At a visual resampler, the processing devices are further configured to compute a mask query based on the segmentation mask, the encoded image features, and the text instruction. At a generative language model, the processing devices are further configured to receive a natural language query that includes the mask query and the text instruction. Based on the natural language query, at the generative language model, the processing devices are further configured to generate and output a semantic label associated with the region of interest.",LEMON INC,YU QIHANG;;SHEN XIAOHUI;;CHEN LIANG-CHIEH,,https://lens.org/020-935-779-655-034,Patent Application,yes,0,0,2,020-935-779-655-034;;137-351-602-669-899,US;;CN,2,020-935-779-655-034;;137-351-602-669-899,US;;CN,0,G06V10/774;;G06V20/70;;G06V10/25;;G06V10/7715;;G06V10/267;;G06F40/30;;G06V20/50;;G06F16/3344;;G06V10/82;;G06V20/70;;G06V10/25;;G06V10/267;;G06F16/3344;;G06V20/50;;G06V10/774;;G06F40/30;;G06V10/7715,G06V20/70;;G06F16/33;;G06F40/30;;G06V10/25;;G06V10/26;;G06V10/77;;G06V10/774;;G06V20/50,,0,0,,,,PENDING
798,US,B1,US 12063123 B1,164-793-772-645-600,8/13/2024,2024,US 202318211884 A,6/20/2023,US 202318211884 A,6/20/2023,Techniques for inferring context for an online meeting,"Described herein are techniques for generating insights, including summary descriptions, for an online meeting. During an online meeting, various pre-trained computer vision algorithms are used to identify regions of interest within one or more video streams depicting a meeting participant, and any video stream via which content is being shared. These detected regions of interest are further processed with additional pre-trained computer vision algorithms to detect non-verbal communications, including gestures made by meeting participants, facial expressions or emotions, and text or graphics shared as part of a content sharing feature. From these non-verbal communications, textual descriptions of the detected communications are derived. These textual descriptions of the detected communications are then provided as an input to a software-based meeting analyzer service, which is configured to generate various insights based on end-user queries, and automated requests.",MICROSOFT TECHNOLOGY LICENSING LLC,RIVERA-RODRIGUEZ JUAN C,MICROSOFT TECHNOLOGY LICENSING LLC (2023-08-08),https://lens.org/164-793-772-645-600,Granted Patent,yes,14,3,3,184-044-479-167-387;;005-712-583-063-318;;164-793-772-645-600,US;;WO,3,184-044-479-167-387;;005-712-583-063-318;;164-793-772-645-600,US;;WO,0,H04L12/1831;;G06V40/20;;G06V10/25;;G06V40/174;;G06V40/28;;H04N7/155;;H04L12/1831;;G06V40/20;;G06V10/25,H04L12/18;;G06V10/25;;G06V40/20,,1,0,,,"Abdollahpour, Mohammad Mahdi, “Zero-shot Question Answering with Large Language Models in Python”, Retrieved from: https://medium.com/nlplanet/zero-shot-question-answering-with-large-language-models-in-python-9964c55c3b38, Aug. 30, 2022, 9 Pages.",ACTIVE
799,WO,A1,WO 2025/106674 A1,114-662-872-889-860,5/22/2025,2025,US 2024/0055928 W,11/14/2024,US 202363548456 P;;US 202463555651 P,11/14/2023,SYSTEMS AND METHODS FOR DIGITAL ENGAGEMENT AND HEALTH BIOMETRIC ANALOG DATA COLLECTION FOR PATIENTS WITH DEMENTIA,"In an embodiment, a system for digital engagement is disclosed that is configured to operate an application for a patient with dementia. The application includes at least one applied virtual environment. The system is further configured to evaluate input of the patient based on a mixed model for observing digital engagement, and to engage the patient with the application using dialogue delivered by at least one virtual avatar, the virtual avatar being supported by artificial intelligence and the dialogue being determined based on the evaluated input. The system is further configured to log and evaluate progress data of the patient and to provide feedback and support based on the evaluated progress data.",MENTIA HEALTH INC,SALOMON MANDY;;SOUDOPLATOFF SERGE;;FENTRESS PAUL;;VIALIKOV ILIA;;LIN ZHONQIAO,,https://lens.org/114-662-872-889-860,Patent Application,yes,3,0,2,110-708-911-036-55X;;114-662-872-889-860,US;;WO,2,110-708-911-036-55X;;114-662-872-889-860,US;;WO,0,G06T2210/41;;G16H50/20;;G16H20/70;;G16H10/60;;G06T13/40;;A61B5/746;;A61B5/7275;;A61B5/4803;;A61B5/165;;A61B5/4088;;A61B5/0077;;G16H20/70;;G16H10/60;;G16H50/20;;G06T13/40;;A61B5/4088;;G06T2210/41;;A61B5/7275;;A61B5/746;;A61B5/165;;A61B5/0077;;A61B5/4803,A61B5/00;;A61B5/16;;G06N20/00;;G10L15/22;;G16H40/67,,0,0,,,,PENDING
800,US,A1,US 2025/0005691 A1,187-092-700-336-123,1/2/2025,2025,US 202318344203 A,6/29/2023,US 202318344203 A,6/29/2023,EXECUTING AN ACTION USING EXTRACTED INFORMATION FROM A DOCUMENT,A method includes extracting an action from a document using a machine learning model. The action is associated with an action parameter. The method further includes extracting a plurality of action events corresponding to the action from the document using the machine learning model. The method further includes generating a record associated with the document based on the extracted action. The method further includes populating the record with the action parameter. The method further includes executing an action event in the plurality of action events using the record.,ADOBE INC,LIPKA NEDIM;;ROSSI RYAN;;SO JIANNA AUDREY REYES;;DERNONCOURT FRANCK;;SIU ALEXA,ADOBE INC (2023-06-23),https://lens.org/187-092-700-336-123,Patent Application,yes,4,0,1,187-092-700-336-123,US,1,187-092-700-336-123,US,0,G06Q50/18;;G06Q50/18,G06Q50/18,,1,1,087-196-244-670-101,10.2308/acch-52457,"Yan Zhaokai, Kevin C. Moffitt; Contract Analytics in Auditing. Accounting Horizons 1 September 2019; 33 (3): 111–126, 2019. DOI 10.2308/acch-52457. (Year: 2019)",PENDING
801,US,A1,US 2025/0200334 A1,130-889-642-516-336,6/19/2025,2025,US 202318542399 A,12/15/2023,US 202318542399 A,12/15/2023,TRACKING MACHINE LEARNING DATA PROVENANCE VIA A BLOCKCHAIN,"Methods, systems, and devices for data management are described. A middleware component may receive, for generating a machine learning model, one or more user inputs associated with the machine learning model and an indication of a data source for training the machine learning model. After receiving the user inputs and the data source, the middleware component may broadcast one or more first blockchain messages that are configured to store first information associated with the one or more user inputs and the data source on a blockchain network. The middleware component may receive input prompts for the machine learning model and one or more responses generated by the machine learning model, and, after receiving the input prompts, broadcast one or more second blockchain messages that are configured to store second information associated with the one or more input prompts and the one or more responses on the blockchain network.",COINBASE INC,DIALANI VIJAY KODU;;GUPTA RAJARSHI;;KRISHNAMACHARI BHASKAR,,https://lens.org/130-889-642-516-336,Patent Application,yes,0,0,1,130-889-642-516-336,US,1,130-889-642-516-336,US,0,G06N3/0455;;G06N3/084;;G06N20/00;;G06Q20/389;;G06Q20/36;;G06Q20/3672;;G06Q20/382;;G06Q40/04;;G06Q20/123;;G06N3/0455;;G06N3/084;;G06Q20/382;;G06Q20/3672;;G06Q20/389,G06N3/0455;;G06N3/084;;G06Q20/36;;G06Q20/38,,0,0,,,,PENDING
802,WO,A1,WO 2024/182729 A1,125-562-643-957-795,9/6/2024,2024,US 2024/0018131 W,3/1/2024,US 202363449601 P;;US 202363548523 P,3/2/2023,SYSTEM AND METHOD FOR ARTIFICIAL INTELLIGENCE-BASED LANGUAGE SKILL ASSESSMENT AND DEVELOPMENT USING AVATARS,"Systems and methods for artificial intelligence-based language skill assessment and development using avatars provide for: determining a target language and a natural language of a user; generating a first avatar corresponding to the target language and a second avatar corresponding to the natural language on a graphical user interface; generating a first interaction for the first avatar using the target language where the first avatar is associated with a first generative artificial intelligence model; receiving a user input to select the second avatar; and in response to the user input, generating a second interaction for the second avatar using the natural language where the second interaction corresponds to the first interaction, the second avatar is associated with a second generative artificial intelligence model, and the second generative artificial intelligence model communicates with the first generative artificial intelligence model to produce the second interaction.",PEARSON EDUCATION INC,GOGIN ILYA;;REILLY SION;;ILIESCU ALEXANDRU,,https://lens.org/125-562-643-957-795,Patent Application,yes,1,0,2,125-562-643-957-795;;103-063-800-734-567,US;;WO,6,103-063-800-734-567;;168-649-688-416-652;;019-887-996-003-615;;119-119-516-449-68X;;125-562-643-957-795;;079-687-554-609-556,US;;WO,0,G09B5/08;;G09B7/02;;G09B19/06;;G06F40/58;;G06T13/40;;G09B19/06,G09B5/08;;G09B7/02;;G09B19/06,,0,0,,,,PENDING
803,US,A1,US 2024/0330381 A1,038-763-065-750-65X,10/3/2024,2024,US 202418622051 A,3/29/2024,US 202418622051 A;;US 202363492842 P,3/29/2023,User-Specific Content Generation Using Text-To-Image Machine-Learned Models,"Techniques for presenting a content item using text-to-image machine-learned models are presented. For example, a system can obtain user personalization data associated with a user and merchant assets data of a merchant. Additionally, the system can process the user personalization data and the merchant assets data with a text generation model to generate one or more model-generated terms. Moreover, the system can process the one or more model-generated terms with an image generation model to generate one or more model-generated images. Furthermore, the system can determine a content item based on the one or more model-generated images. Subsequently, the system can present, on a display of a user device of the user, a graphical user interface having the content item.",GOOGLE LLC,SADR ARASH,GOOGLE LLC (2023-03-27),https://lens.org/038-763-065-750-65X,Patent Application,yes,0,2,2,171-273-807-132-261;;038-763-065-750-65X,US;;WO,2,171-273-807-132-261;;038-763-065-750-65X,US;;WO,0,G06Q30/0271;;G06Q30/0276;;G06F16/53;;G06Q30/0641;;G06F16/9535;;G06F16/9538;;G06F3/04845;;G06T11/00;;G06T2200/24,G06F16/9535;;G06F3/04845;;G06F16/9538;;G06T11/00,,0,0,,,,PENDING
804,WO,A2,WO 2025/054324 A2,047-359-850-940-290,3/13/2025,2025,US 2024/0045382 W,9/5/2024,US 202363537297 P,9/8/2023,METHODS AND APPARATUSES INVOLVING AUTOMATED TASK COMPLETION FOR WEBSITE REFINEMENT/CUSTOMIZATION,"In certain examples, methods and semiconductor structures are directed to a data- processing computer circuit and/or method to: determine a subset of multiple aspects or elements of an existing website to modify by analyzing user inputs, pertaining to desired changes in the existing website with respect to at least one of content and design; construct prompts for one or more large language models (LLMs) incorporating said user inputs and data structures characterizing the subset of multiple aspects or elements; drive one or more AI/ML algorithms of at least one computing-processor circuit, based on the constructed prompts, to output modifications of at least some of the subset of multiple aspects or elements; and generate a custom website, including the desired changes and based on the user input.",ZENFOLIO INC,BARRACLOUGH KEITH;;FERRIER MICHAEL;;FAUST GEORGE;;LECHOW ROSS,,https://lens.org/047-359-850-940-290,Patent Application,yes,0,0,2,107-743-538-914-304;;047-359-850-940-290,WO,2,107-743-538-914-304;;047-359-850-940-290,WO,0,G06N3/0475;;G06Q10/103;;G06Q10/101;;G06N20/00,G06N3/0475;;G06Q10/10,,0,0,,,,PENDING
805,US,A1,US 2025/0014321 A1,130-461-666-619-543,1/9/2025,2025,US 202318539746 A,12/14/2023,US 202318539746 A;;US 202363511822 P,7/3/2023,USING NEURAL LANGUAGE MODELS FOR LONG-TERM ACTION ANTICIPATION FROM VIDEOS,"An electronic device and method for using neural language models for long-term action anticipation from videos is provided. The electronic device receives a video that includes one or more objects performing a physical task and generates, based on the video, a first set of tags that corresponds to a first sequence of actions associated with the physical task. The electronic device generates a first prompt for a neural language model based on the first set of tags and predicts, by application of the neural language model on the first prompt, a second set of tags that corresponds to a second sequence of actions associated with the physical task. The second sequence of actions succeeds the first sequence of actions. The electronic device controls a display device to display first prediction information based on the second set of tags.",HONDA MOTOR CO LTD;;UNIV BROWN,ZHANG CE;;FU CHANGCHENG;;WANG SHIJIE;;ZHAO QI;;SUN CHEN;;AGARWAL NAKUL;;LEE KWONJOON,HONDA MOTOR CO. LTD (2023-11-27);;BROWN UNIVERSITY (2023-12-06),https://lens.org/130-461-666-619-543,Patent Application,yes,0,0,1,130-461-666-619-543,US,1,130-461-666-619-543,US,0,G06V10/82;;G06V20/41;;G06V40/20;;G06V20/41;;G06V10/82,G06V10/82;;G06V20/40,,0,0,,,,PENDING
806,US,B1,US 12140915 B1,130-365-423-350-594,11/12/2024,2024,US 202418664045 A,5/14/2024,US 202418664045 A;;US 202318342461 A,6/27/2023,"Generative AI and agentic AI systems and methods for industrial equipment and manufacturing systems analytics, control, and optimization","Generative AI systems and methods are developed to provide recommendations regarding the control, optimization, and troubleshooting of industrial equipment and manufacturing systems as determined from a range of available data sources. A consistent, semantic metadata structure is described as well as a hypothesis generating and testing system capable of generating predictive analytics models in a non-supervised or partially supervised mode. Users and/or AI agents (i.e., a form of “agentic AI”) may then subscribe to such information for the use in connection with their own manufacturing systems.",MCCARSON BRIAN,MCCARSON BRIAN,AIECONOMY LLC (2024-11-19),https://lens.org/130-365-423-350-594,Granted Patent,yes,20,1,1,130-365-423-350-594,US,14,047-561-968-866-355;;195-152-679-664-772;;060-821-074-818-847;;106-650-584-011-393;;016-101-423-428-10X;;057-596-683-832-509;;198-724-866-588-373;;104-276-531-633-519;;004-535-549-272-828;;042-466-929-911-734;;193-145-554-233-76X;;130-365-423-350-594;;139-867-629-060-653;;126-237-643-161-188,US;;WO,0,G06F18/217;;G06N3/044;;G06N3/0464;;G06N3/0675;;G06N3/092;;G06V20/13;;G06V20/52;;G06V2201/10;;G08G1/0133;;G08G3/00;;G05B13/0265;;G05B13/042;;G06V10/82;;G06V10/764;;G08G1/04;;G08G1/0116;;G08G1/012;;G08G1/0129;;G05B13/0265;;G05B13/042,G05B13/04;;G05B13/02,,16,9,119-304-887-662-281;;018-037-449-090-564;;107-413-415-585-561;;083-720-177-999-11X;;025-685-448-467-197;;084-327-175-192-828;;089-697-842-803-881;;002-671-442-244-660;;047-543-432-840-756,10.1016/j.agsy.2018.04.002;;10.1007/s12665-014-4000-4;;10.1016/j.techfore.2017.07.027;;10.1109/icccsp.2017.7944096;;10.5089/9781513521121.001;;10.1007/s00500-018-3645-4;;10.1186/s40537-019-0234-z;;pmc7021790;;32060351;;10.1038/s41598-020-59505-2;;10.1080/01431161.2017.1323282,"Search Report and Written Opinion of the ISA, Issued Aug. 29, 2024 in PCT/US2024/035527.;;Lopez-Lozano et al. (“An evaluation framework to build a cost-efficient crop monitoring system. Experiences from the extension of the European crop monitoring system,” Agricultural Systems 168, 302, pp. 231-246) (Year: 2019) entire document.;;Kolanovic et al. (“Big Data and AI Strategies: Machine Learning and Alternative Data Approach to Investing”, JP Morgan, Global Quantitative and Derivatives Strategy, May 18, 2017, pp. 1-280) (Year: 2017).;;Radford et al. (“Language Models are Unsupervised Multitask Learners”, OpenAI blog, 1(8), 2019, pp. 1-24) (Year: 2019) entire document.;;Cong et al. (“Alternative Data for FinTech and Business Intelligence”, Available at SSRN: https://ssrn.com/abstract=3521349 or http://dx.doi.org/10.2139/ssrn.3521349, Oct. 1, 2019, p. 1-31) (Year: 2019) entire document.;;Hu et al. (“Improved monitoring of urbanization processes in China for regional climate impact assessment”, Environ Earth Sci 73, pp. 8387-8404, 2015) (Year: 2015).;;Ayush et al. (“Generating Interpretable Poverty Maps using Object Detection in Satellite Images”, https://arxiv.org/pdf/2002.01612v1.pdf, arXiv:202.01612v1 [cs.CV], Feb. 5, 2020, pp. 1-9) (Year: 2020).;;Nakajima et al. (“Bayesian Analysis of Latent Threshold Dynamic Models”, 2011 Seminar on Bayesian Inference in Econometrics and Statistic (SBIES), 2011 pp. 1-36) (Year: 2011).;;Blazquez et al. (“Big Data sources and methods for social and economic analyses”, Technological Forecasting and Social Change 130, 2018, pp. 99-113) (Year: 2016).;;Dandala et al. (“Internet of Vehicles (IoV) for Traffic Management”, IEEE International Conference on Computer, Communication and Signal Processing (ICCCSP-2017), 2017, pp. 1-4) (Year: 2017).;;Suraj et al. (“On monitoring development indicators using high resolution satellite images”, https://arxiv.org/abs/1712.022822,arXiv:1712.02282v3 [econ.EM] Jun. 25, 2018, pp. 1-36) (Year: 2018).;;Arslanalp et al. (“Big Data on Vessel Traffic: Nowcasting Trade Flows in Real Time: IMP Working paper”, WP/19/275, Dec. 13, 2019, pp. 1-34) (Year: 2019).;;Joseph et al. (“A novel vessel detection and classification algorithm using deep learning neural network model with morphological processing (M-DLNN)”, Soft Computing 23, 2019, pp. 2693-2700) (Year: 2019).;;Fedorov et al. (“Traffic flow estimation with data from a video surveillance camera”, Journal Big Data, 6:73, 2019, pp. 1-15) (Year: 2019).;;Li et al. (“Estimation of regional economic development indicator from transportation network analytics”, Scientific reports, 10(1), Feb. 14, 2020, pp. 1-15) (Year: 2020).;;Saeed et al. (“Forecasting wheat yield from weather data and MODIS NDVI using Random Forests for Punjab province, Pakistan”, International Journal of Remote Sensing, 38:17, 2017, pp. 4831-4854) (Year: 2017).",ACTIVE
807,US,A1,US 2024/0412029 A1,177-022-031-319-88X,12/12/2024,2024,US 202318207616 A,6/8/2023,US 202318207616 A,6/8/2023,AUGMENTING ARTIFICIAL INTELLIGENCE PROMPT DESIGN WITH EMOTIONAL CONTEXT,"In addition to an original prompt that is manually provided by a user, contextual information is sent to a generative AI to elicit a higher quality response. Sensors collect audio, video, physiological, cognitive, environmental, and digital data from the user. Machine-learning models evaluate the sensor data to infer the emotional state of the user. The emotional state is used to augment the original prompt with contextual information. The augmented prompt is fed into the generative AI to make it context-aware. Accordingly, the generative AI can automatically pick up on non-verbal cues that the user did not manually articulate in the original prompt. Just as a human-to-human conversation involves a combination of verbal and non-verbal communications, the present concepts enable the generative AI to also leverage non-verbal communication when interacting with human users.",MICROSOFT TECHNOLOGY LICENSING LLC,YANG WEIWEI;;LYTVYNETS KATERYNA;;PATEL PRACHI MANISHKUMAR;;HOAK AMBER;;FOWERS SPENCER;;O'DOWD CHRISTOPHER PATRICK;;BRITTO MATTOS LIMA ANDREA;;VALLIN SPINA THIAGO;;HELM HAYDEN,MICROSOFT TECHNOLOGY LICENSING LLC (2023-08-07),https://lens.org/177-022-031-319-88X,Patent Application,yes,0,8,2,066-526-902-495-390;;177-022-031-319-88X,US;;WO,2,066-526-902-495-390;;177-022-031-319-88X,US;;WO,0,G06F40/30;;G10L25/63;;G06N20/00;;G06N3/045;;G06V40/174;;G06N3/045;;G06N3/0475;;G06N3/006,G06N3/006;;G06N3/045;;G06N3/0475,,0,0,,,,PENDING
808,US,A1,US 2025/0131004 A1,170-106-811-728-602,4/24/2025,2025,US 202318382606 A,10/23/2023,US 202318382606 A,10/23/2023,FILE EXTRACTION AND VECTORIZATION FOR ONBOARDING WITH LLM,"Systems and methods for adapting an onboarding session to a user are disclosed. An example method is performed by one or more processors of a system and includes receiving a transmission over a communications network from a computing device associated with a user of the onboarding system, the transmission including one or more files, extracting data from each of the one or more files using one or more parser plugins, transforming the extracted data into a set of arrays, feeding a prompt including the set of arrays to a large language model (LLM), inferring characteristics of the user based on a response to the prompt from the LLM, mapping the inferred characteristics to a predefined list of system features, and optimizing components of an onboarding session for the user based on the mapping.",INTUIT INC,BUDJADE GAURAV;;SUNDARAM SUJAY;;GABBITI ANJANEYA MURTHY;;SHANMUGAM PUSHPARAJ;;KUMARI NEHA,INTUIT INC (2023-10-20),https://lens.org/170-106-811-728-602,Patent Application,yes,0,0,1,170-106-811-728-602,US,1,170-106-811-728-602,US,0,G06N3/0455;;G06F16/254;;G06N3/0455;;G06F16/254,G06F16/25;;G06N3/0455,,0,0,,,,PENDING
809,EP,A1,EP 4592840 A1,171-624-113-226-556,7/30/2025,2025,EP 25152517 A,1/17/2025,US 202418422753 A,1/25/2024,ARTIFICIAL INTELLIGENCE DRIVEN USER INTERFACE STRUCTURE GROUNDING FOR AUTOMATED GENERATION OF ACTIONABLE TASKS,"A data processing system implements obtaining an image of a user interface of an application and a textual representation of a structure of the user interface from a client-side proxy on a client device; analyzing the image of the user interface using a vision language model to obtain one or more task recommendations; analyzing the textual representation of the structure of the user interface and the one or more task recommendations using a completion language model to generate one or more workflows, each workflow being associated with a task recommendation of the one or more task recommendations and comprising one or more actions and executable code to perform the one or more actions in the application; providing the one or more workflows to the client-side proxy; causing the client-side proxy to present a representation of each task recommendation of the one or more task recommendations on the user interface;",MICROSOFT TECHNOLOGY LICENSING LLC,BONACCI FRANCESCO,,https://lens.org/171-624-113-226-556,Patent Application,yes,0,0,1,171-624-113-226-556,EP,1,171-624-113-226-556,EP,0,G06N3/045;;G06N3/08;;G06F9/451;;G06F8/30;;G06N20/00;;G06N3/044,G06F9/451;;G06F8/30;;G06N3/045;;G06N3/08;;G06N20/00,,0,0,,,,PENDING
810,US,A1,US 2025/0190592 A1,138-466-188-657-628,6/12/2025,2025,US 202318537595 A,12/12/2023,US 202318537595 A,12/12/2023,Service Security Control,"A system for managing access to services in a computing system. The system includes processes to allow users to request access to services, and the automated review of such requests. The system is configured to consider a wide range of factors, including the content of the request and the service requested, information relating to the user, and metadata relating to the service, as well as user behaviours. Natural language analysis is utilised to analyse a user's request for access and the service to which access is requested.",VARONIS SYSTEMS INC,SNE RON;;BELGI AMIR;;NEYSTADT JOHN EUGENE,VARONIS SYSTEMS INC (2023-11-30),https://lens.org/138-466-188-657-628,Patent Application,yes,0,0,2,134-977-478-759-373;;138-466-188-657-628,US;;WO,2,134-977-478-759-373;;138-466-188-657-628,US;;WO,0,G06F21/629;;G06F21/6218;;G06F2221/2141;;G06F21/604;;G06F40/30;;G06F21/604,G06F21/60;;G06F40/30,,0,0,,,,PENDING
811,US,B1,US 12088599 B1,193-145-554-233-76X,9/10/2024,2024,US 202418652441 A,5/1/2024,US 202418652441 A;;US 202318342461 A,6/27/2023,"Generative AI and agentic AI systems and methods for prevention, detection, mitigation and remediation of cybersecurity threats","Generative AI systems and methods are developed to provide recommendations regarding the prevention, detection, mitigation, and/or remediation of cybersecurity threats as determined from a range of available data sources. A consistent, semantic metadata structure is described as well as a hypothesis generating and testing system capable of generating predictive analytics models in a non-supervised or partially supervised mode. Users and/or AI agents (i.e., a form of “agentic AI”) may then subscribe to the data for the use in cybersecurity analytics, protection, mitigation, containment, remediation, and/or counterattacks of cybersecurity threats.",MCCARSON BRIAN,MCCARSON BRIAN,AIECONOMY LLC (2024-11-19),https://lens.org/193-145-554-233-76X,Granted Patent,yes,4,5,1,193-145-554-233-76X,US,14,047-561-968-866-355;;195-152-679-664-772;;060-821-074-818-847;;106-650-584-011-393;;016-101-423-428-10X;;057-596-683-832-509;;198-724-866-588-373;;104-276-531-633-519;;004-535-549-272-828;;042-466-929-911-734;;193-145-554-233-76X;;130-365-423-350-594;;139-867-629-060-653;;126-237-643-161-188,US;;WO,0,G06F16/587;;G06N3/044;;G06N3/0464;;G06N3/0675;;G06N3/092;;G08G3/00;;G06N3/08;;G06N20/00;;H04L63/14;;G08G9/00;;G08G1/04;;H04L63/14;;G06F18/2133;;G06N3/092;;G06N3/08;;G06N20/00;;G06F18/217,H04L9/40;;G06F18/21;;G06F18/2133;;G06N3/08;;G06N3/092;;G06N20/00,,0,0,,,,ACTIVE
812,US,A1,US 2025/0245592 A1,168-679-192-634-098,7/31/2025,2025,US 18422753,1/25/2024,,,ARTIFICIAL INTELLIGENCE DRIVEN USER INTERFACE STRUCTURE GROUNDING FOR AUTOMATED GENERATION OF ACTIONABLE TASKS,"A data processing system implements obtaining an image of a user interface of an application and a textual representation of a structure of the user interface from a client-side proxy on a client device; analyzing the image of the user interface using a vision language model to obtain one or more task recommendations; analyzing the textual representation of the structure of the user interface and the one or more task recommendations using a completion language model to generate one or more workflows, each workflow being associated with a task recommendation of the one or more task recommendations and comprising one or more actions and executable code to perform the one or more actions in the application; providing the one or more workflows to the client-side proxy; causing the client-side proxy to present a representation of each task recommendation of the one or more task recommendations on the user interface;","Microsoft Technology Licensing, LLC",Francesco BONACCI,,https://lens.org/168-679-192-634-098,Patent Application,yes,0,0,1,168-679-192-634-098,US,1,168-679-192-634-098,US,0,G06Q10/06316;;G06F11/3668;;G06F40/40;;G06Q10/0633;;G06V10/40,G06Q10/0631;;G06F11/36;;G06F40/40;;G06Q10/0633;;G06V10/40,,0,0,,,,UNKNOWN
813,US,A1,US 2024/0045935 A1,189-763-738-148-985,2/8/2024,2024,US 202318485175 A,10/11/2023,US 202318485175 A;;US 202217733644 A,4/29/2022,FINE-GRAINED AUTHORIZATION AS A SERVICE VIA RELATIONSHIP- BASED ACCESS CONTROL WITHIN A MULTI-TENANT SYSTEM,"An authorization is performed based on data types—an authorization model, and relationship tuples—that are applicable across different organizations. Each organization wishing to use a system for authorization specifies its own authorization models representing types of objects that can exist within the organization and types of relations those objects can have. When a given organization submits an authorization query to determine whether a given user and a given object are in a given type of relation within that organization, the system analyzes the authorization model and relationship tuples to make the determination. Query response latency may be reduced through techniques such as geographic distribution of servers and sharding of data so that the data for a given query can be found within the same shard.",OKTA INC,SCHENKELMAN DAMIAN EZEQUIEL;;ALLIE JONATHAN CORNELIUS;;ASUSTA YAMIL;;CENTURION JAVIER ALBERTO;;HAMZEH RAGHD;;IACOMUZZI SEBASTIAN;;WOLOSKI MATIAS ADRIAN,,https://lens.org/189-763-738-148-985,Patent Application,yes,0,1,1,189-763-738-148-985,US,6,039-620-248-480-419;;096-747-436-100-407;;189-763-738-148-985;;005-480-934-524-041;;031-800-824-779-273;;178-350-433-394-881,US;;WO;;EP;;AU;;JP,0,H04L63/10;;H04L63/20;;H04L67/10;;G06F21/31;;H04L63/102;;H04L63/08;;G06F21/31;;G06F21/604;;G06F2221/2141,G06F21/31,,0,0,,,,PENDING
814,US,A1,US 2024/0412226 A1,022-540-781-775-955,12/12/2024,2024,US 202318330446 A,6/7/2023,US 202318330446 A,6/7/2023,SYSTEM AND METHOD OF EVALUATING RESPONSES PROVIDED BY LARGE LANGUAGE MODELS,"A system and method for evaluating performance of a model used in providing a response to a product help inquiry includes receiving the product help inquiry, classifying the product help inquiry as being associated with a topic related to a product, and retrieving a path of actions provided in a help documentation associated with the topic. A prompt is also generated based on the product help inquiry for transmission to the model and a response is provided by the model, before a path of actions included the response is extracted. Contextual embeddings for the extracted path are generated and semantic similarities between contextual embeddings for the extracted path and embeddings generated for an expected response are measured. By generating contextual embeddings for the extracted path instead of the entire response, resources required for evaluating the response are significantly reduced. A path coverage metric is measured for the extracted path. A total evaluation value for the response is determined based on a weighted combination of one or more of the measured semantic similarity, path coverage metric, a path length metric or a path frequency metric.",MICROSOFT TECHNOLOGY LICENSING LLC,MATHUR KARTIK;;MYERS ANDREW DAVID;;QUAN YINYU JIN;;SWELLUM DALIA AHMED ESSA;;TANG FA QIANG;;TRAENKENSCHUH JUSTIN JACK,MICROSOFT TECHNOLOGY LICENSING LLC (2023-05-30),https://lens.org/022-540-781-775-955,Patent Application,yes,0,3,1,022-540-781-775-955,US,1,022-540-781-775-955,US,0,G06Q30/016;;G06F9/453;;G06F9/453;;G06Q30/016,G06Q30/016;;G06F9/451,,0,0,,,,PENDING
815,US,A1,US 2025/0193135 A1,122-502-361-929-733,6/12/2025,2025,US 202418977576 A,12/11/2024,US 202418977576 A;;US 202363609282 P,12/12/2023,"AGENT-BASED, CONTEXT-PROVIDING FRONT END FOR LARGE LANGUAGE MODEL CHATBOT","A system interposed between a user and a chatbot includes a processor with instructions to: with a conversational interface, receive a user input; with a broker agent, based on the user input and a conversation history, pass the user input to at least one assistant agent (an action agent or a data agent). If the at assistant agent is an action agent: the system determines an action consistent with the user input; and executes the action. If the assistant agent is a data agent: the system fetches data from at least one database; and, based on the user input and the fetched data, generates a reply. The broker agent, in real time, based on the user input and the reply, formulates a chatbot prompt; passes the chatbot prompt to the chatbot; receives an answer from the chatbot; and with the conversational interface, presents the answer to the user.",PLANVIEW INC,SONNENBLICK RICHARD;;KERSTEN MIK;;REHWINKEL LEE;;MANUEL ALAN,PLANVIEW INC (2025-01-22),https://lens.org/122-502-361-929-733,Patent Application,yes,0,0,1,122-502-361-929-733,US,1,122-502-361-929-733,US,0,G06N20/00;;H04L51/02;;G06N20/00;;H04L51/02,H04L51/02;;G06N20/00,,0,0,,,,PENDING
816,US,A1,US 2025/0240313 A1,053-438-286-900-476,7/24/2025,2025,US 202418416669 A,1/18/2024,US 202418416669 A,1/18/2024,LARGE LANGUAGE MODEL (LLM) POWERED DETECTION REASONING SOLUTION,"Various techniques for LLM powered detection reasoning solutions are disclosed. In some embodiments, a system, a process, and/or a computer program product for an LLM powered detection reasoning solution includes monitoring network traffic at a security platform, wherein the security platform generates a sample based on the monitored network traffic; sending the sample to a security service to generate a Large Language Model (LLM) powered detection and reason, wherein the LLM is prompted to automatically generate a malware or benign verdict and a reason for explaining the verdict; and reporting the LLM powered detection and reason.",PALO ALTO NETWORKS INC,ZHANG ZHIBIN;;FU YU;;DAI YUWEN;;FENG QIAN;;SU ZHEMIN;;WANG MEI,,https://lens.org/053-438-286-900-476,Patent Application,yes,0,0,1,053-438-286-900-476,US,1,053-438-286-900-476,US,0,H04L41/16;;H04L63/1425,H04L9/40;;H04L41/16,,0,0,,,,PENDING
817,US,B1,US 12111747 B1,169-310-367-816-659,10/8/2024,2024,US 202418661532 A,5/10/2024,US 202418661532 A;;US 202418661519 A;;US 202418633293 A,4/11/2024,Dynamic input-sensitive validation of machine learning model outputs and methods and systems of the same,"The systems and methods disclosed herein enable evaluation of machine learning model outputs within a virtual environment. The disclosed model validation platform enables testing of code generated for detection of malicious or anomalous outputs. For example, the model validation platform can construct a virtual machine isolated from the system and test model-generated code for validation of LLM-generated outputs. In some implementations, the model validation platform determines parameters of the virtual machine and/or associated validation test based on an evaluation of the machine learning model's output and/or the associated underlying prompt. For example, the parameters of the validation test depend on an evaluation of the user or the provided input (e.g., depending on the presence of sensitive data within the prompt). By doing so, the system enables dynamic evaluation of machine learning model outputs to improve the security and robustness of associated generated code.",CITIBANK NA,JAIN PAYAL;;MAONAH TARIQ HUSAYN;;SATERNUS MARIUSZ;;LEWANDOWSKI DANIEL;;RATH BIRAJ KRUSHNA;;MURRAY STUART;;DAVIES PHILIP,CITIBANK N.A (2024-05-14),https://lens.org/169-310-367-816-659,Granted Patent,yes,19,2,1,169-310-367-816-659,US,36,166-860-055-274-237;;192-529-172-020-159;;117-165-481-521-817;;062-084-390-952-648;;009-332-012-767-769;;130-711-467-813-772;;150-084-174-776-205;;134-859-487-724-028;;136-076-696-451-742;;174-498-778-674-614;;135-411-020-650-37X;;082-042-370-293-809;;081-164-654-051-886;;126-999-415-386-749;;101-393-155-626-043;;028-517-317-595-400;;183-393-311-078-435;;120-491-497-842-713;;071-444-314-653-665;;151-710-271-944-022;;169-310-367-816-659;;114-332-483-825-36X;;176-222-606-932-299;;109-693-731-347-460;;187-959-165-043-749;;165-235-788-605-427;;184-797-936-150-334;;129-627-428-962-735;;132-864-126-338-301;;147-316-129-152-657;;087-574-341-939-358;;052-233-397-211-176;;154-552-332-382-958;;158-104-528-887-831;;122-629-432-281-208;;053-045-267-490-224,US;;WO;;EP,0,G06N3/0455;;G06N3/084;;G06F8/41;;G06F8/41;;G06F11/3608,G06F11/36;;G06F8/41,,1,0,,,"Generative machine learning models; IPCCOM000272835D, Aug. 17, 2023. (Year: 2023).",ACTIVE
818,US,A1,US 2025/0117671 A1,079-352-426-527-199,4/10/2025,2025,US 202418912428 A,10/10/2024,US 202418912428 A;;US 202363589267 P,10/10/2023,ASSESSING PERFORMANCE OF OPERATIONS IDENTIFIED FROM NATURAL LANGUAGE QUERIES,"Methods and systems are described herein for a system that enables individual users or entities to assess high-level concepts expressed in natural language by identifying quantitative evaluation criteria for evaluating the concept. For example, a query evaluation system is provided herein that receives a user's query including natural language, e.g., indicative of a higher-level concept or idea to be deployed. The system may identify quantitative evaluation criteria for evaluating the concept, perform back-testing (e.g., to see how a particular strategy would have performed in the past) and allow the user to create a specific investment portfolio that tracks the original intent of the user. The concept may be tested, and its performance evaluated before deploying it to a user portfolio.",QDECK INC,DEVOS LUKE THOMAS;;IRELAND II TIMOTHY JAMES;;IRELAND ABIGAIL LYNN;;LEUNG SIU TANG;;MODORAN ANDREI;;OSTERCAMP BRAD STEVEN;;PRAKASAM JAGDEESH;;JAYARAMAN ANANDHAN;;KUMAR SAURAV;;NARLA BHARATH,QDECK INC (2024-10-10),https://lens.org/079-352-426-527-199,Patent Application,yes,0,2,1,079-352-426-527-199,US,1,079-352-426-527-199,US,0,G06N5/025;;G06F16/243;;G06F16/243;;G06N5/025,G06N5/025;;G06F16/242,,0,0,,,,PENDING
819,US,A1,US 2025/0200673 A1,181-891-975-292-070,6/19/2025,2025,US 202418954896 A,11/21/2024,JP 2023212053 A,12/15/2023,"DIALOG ABILITY ENHANCEMENT ASSISTANCE DEVICE, DIALOG ABILITY ENHANCEMENT ASSISTANCE CONTROL METHOD, AND NON-TRANSITORY RECORDING MEDIUM","A dialog ability enhancement assistance device 30 includes a reception unit 31 that receives information for selecting a scene 312 in which participants including a user and one or more machine learning models 311 have a dialog with each other, and the machine learning models 311 included in the participants, a construction unit 32 that constructs an environment 321 in which the participants have a dialog with each other in the selected scene 312, an acquisition unit 33 that acquires dialog content 331 between the user and the machine learning models 311 in the environment 321, and an evaluation unit 34 that evaluates, based on an evaluation criterion 341 for evaluating a dialog ability according to the dialog content 331, the dialog ability of the user from the acquired dialog content 331.",NEC CORP,NISHIMOTO SHINNOSUKE;;UEDA KENICHI;;NAKAMURA TSUYOSHI;;KOBAYASHI YUKI,NEC CORPORATION (2024-10-02),https://lens.org/181-891-975-292-070,Patent Application,yes,0,0,2,029-270-643-972-333;;181-891-975-292-070,US;;JP,2,029-270-643-972-333;;181-891-975-292-070,US;;JP,0,G06Q50/01;;G06Q50/01,G06Q50/00,,0,0,,,,PENDING
820,US,A1,US 2025/0232872 A1,160-525-876-009-100,7/17/2025,2025,US 202418411102 A,1/12/2024,US 202418411102 A,1/12/2024,Assistant System Using Multimodal Multitask Medical Machine-Learned Models to Perform Image Processing to Answer Natural Language Queries,"An example assistant system can use a multimodal multitask medical machine-learned model to perform image processing to answer natural language queries. A device can process speech data or other natural language inputs to obtain a query. The query can be processed alongside image data that provides context for the query. The example system can receive a query associated with a particular task domain; generate, based on the query, a query input that comprises query instruction data from a first modality and query context data from a second modality; generate a combined input comprising the query input and an exemplar input, wherein the exemplar input comprises exemplar instruction data from the first modality and an exemplar context placeholder in lieu of exemplar context data from the second modality; process the combined input with a multimodal machine-learned model to generate output data; and output a query response based on the output data.",GOOGLE LLC,NATARAJAN VIVEK;;AZIZI SHEKOOFEH;;KARTHIKESALINGAM ALAN PRASANA;;DRIESS DANNY MICHAEL;;FLORENCE PETER RAYMOND;;SINGHAL KARAN;;TU TAO,,https://lens.org/160-525-876-009-100,Patent Application,yes,0,0,1,160-525-876-009-100,US,1,160-525-876-009-100,US,0,G16H50/20;;G16H20/00;;G16H15/00;;G16H30/40;;G16H40/67,G16H50/20;;G16H15/00;;G16H20/00;;G16H30/40;;G16H40/67,,0,0,,,,PENDING
821,US,A1,US 2025/0111139 A1,001-998-346-205-416,4/3/2025,2025,US 202418903274 A,10/1/2024,US 202418903274 A;;RO 202300544 A;;US 202363587213 P,10/2/2023,DESIGN DOCUMENT GENERATION FROM TEXT,"A method, apparatus, non-transitory computer readable medium, and system for generating a design document from a text prompt include obtaining a design prompt that describes a document type and selecting a design template for the document type based on the design prompt. An image generation model generates an image for the design template based on the design prompt and a design document is generated based on the design template. The design document has the document type and includes the image at a location indicated by the design template.",ADOBE INC,MIRONICÄ IONUT;;BRDICZKA OLIVER;;SHARMA ASHUTOSH;;KHANNA ANAND;;DUMITRESCU STEFAN DANIEL;;VLASSIS NIKOLAOS;;SINGH ALOK KUMAR,ADOBE INC (2024-08-23),https://lens.org/001-998-346-205-416,Patent Application,yes,0,0,1,001-998-346-205-416,US,1,001-998-346-205-416,US,0,G06T11/60;;G06F40/40;;G06F40/186;;G06F40/186;;G06T11/60;;G06F40/40,G06F40/186;;G06F40/40;;G06T11/60,,0,0,,,,PENDING
822,WO,A2,WO 2024/036228 A2,030-160-886-384-921,2/15/2024,2024,US 2023/0071956 W,8/9/2023,US 202263397141 P;;US 202363439833 P,8/11/2022,CLINICAL EVENT DETECTION AND RECORDING SYSTEM USING ACTIVE LEARNING,"Clinical event detection and recording using active learning are disclosed. The claimed techniques include maintaining sequences of sentences. Each sequence of sequences is associated with an entity, and each sentence in each sequence is associated with a label and a timestamp. The techniques include iteratively training a machine-learning model using each sentence of the sequences as input and the label as a ground-truth value. Each iteration of training includes generating a prediction indicating whether the timestamp of each sentence occurred before or after an event of the entity. Each iteration of training includes validating the machine-learning model based on the prediction and the label of each sentence and the ground-truth value.",MEMORIAL SLOAN KETTERING CANCER CENTER;;MEMORIAL HOSPITAL FOR CANCER AND ALLIED DISEASES;;SLOAN KETTERING INST CANCER RES,MANTHA SIMON,,https://lens.org/030-160-886-384-921,Patent Application,yes,0,0,3,174-279-323-673-404;;030-160-886-384-921;;166-030-065-188-604,WO;;EP,3,174-279-323-673-404;;030-160-886-384-921;;166-030-065-188-604,WO;;EP,0,G16H10/60;;G16H50/70;;G16H50/20;;G16H10/20;;G06N3/09;;G06N3/088;;G06N3/0464;;G06N3/0442;;G06N20/10;;G06N7/01;;G06N3/084;;G06N3/0455;;G06N3/0475,G16B20/00;;G06N20/00,,0,0,,,,PENDING
823,US,A1,US 2025/0140012 A1,192-713-276-985-924,5/1/2025,2025,US 202318383799 A,10/25/2023,US 202318383799 A,10/25/2023,MULTI-MODAL MACHINE LEARNING MODEL FOR DIGITAL DOCUMENT PROCESSING,"A method including receiving a digital image including text arranged in a layout. The method also includes generating, by an optical character recognition model, a layout text vector that encodes at least one word in the text of the digital image and a position of the at least one word in the layout of the digital image. The method also includes generating, by a visual encoder model, a visual representation vector embedding a content of the digital image. The method also includes converting both the layout text vector and the visual representation vector into a projected text vector including a digital format suitable for input to a large language model. The method also includes combining, into a prompt, the projected text vector, a system message, and a task instruction. The method also includes generating an output including a key-value pair.",INTUIT INC,RIMCHALA THARATHORN;;LADOR SHIR MEIR;;LI XIANGRU,INTUIT INC (2024-09-09),https://lens.org/192-713-276-985-924,Patent Application,yes,0,0,1,192-713-276-985-924,US,1,192-713-276-985-924,US,0,G06V30/19147;;G06V30/416;;G06V30/414;;G06V10/82;;G06V30/1916;;G06V30/416;;G06V30/414;;G06V30/1916;;G06V10/82;;G06V30/19147,G06V30/416;;G06V10/82;;G06V30/19;;G06V30/414,,0,0,,,,PENDING
824,US,A1,US 2025/0244965 A1,051-383-858-693-946,7/31/2025,2025,US 18426627,1/30/2024,,,SECURING SOFTWARE DEVELOPMENT CYCLES WITH ARTIFICIAL INTELLIGENCE CUSTOMIZATION,"Techniques are provided for securing software development cycles with artificial intelligence customization. Operations may include identifying a software generation task; providing the software generation task to a language model; identifying, from the language model, a plurality of queries associated with specific attributes of the software generation task; creating, based on the software generation task and responses to the plurality of queries, a reconstructed software generation task; assigning, based on a machine learning model, one or more security labels to the reconstructed software generation task; determining one or more prioritization scores for one or more security rules based on the one or more security labels; and generating, based on the one or more prioritization scores, at least one security action for the reconstructed software generation task.",CyberArk Software Ltd.,Avishay Bar;;Erez Waisbard,,https://lens.org/051-383-858-693-946,Patent Application,yes,0,0,1,051-383-858-693-946,US,1,051-383-858-693-946,US,0,G06F8/35;;G06F40/20,G06F8/35;;G06F40/20,,0,0,,,,UNKNOWN
825,US,A1,US 2025/0238757 A1,177-703-111-398-569,7/24/2025,2025,US 202519173087 A,4/8/2025,US 202519173087 A;;US 202217817392 A;;US 202163203916 P,8/4/2021,Digital Story Generation,"A digital story includes textual, visual, and/or audio aspects. Generation of a new digital story and/or editing of an existing digital story can include, for instance, coordinating presentation of textual, visual, and/or audio aspects of the digital story. A digital story can be viewed and/or accessed by a user remote from one or more authors of the digital story.",STORYFORGE LLC,HOWELL ERIC DENNIS;;SCHULTZ WILLIAM DANIEL,,https://lens.org/177-703-111-398-569,Patent Application,yes,0,0,1,177-703-111-398-569,US,2,177-703-111-398-569;;174-289-998-649-372,US,0,G06Q10/101;;G06F40/197;;G06Q20/36;;G06Q50/184,G06Q10/101;;G06F40/197;;G06Q20/36;;G06Q50/18,,0,0,,,,PENDING
826,US,A1,US 2025/0246188 A1,193-716-067-243-561,7/31/2025,2025,US 18422736,1/25/2024,,,AUTOMATED SUSPICIOUS ACTIVITY REPORT NARRATIVE GENERATION USING GENERATIVE ARTIFICIAL INTELLIGENCE,"An autonomous fraud/AML reporting system and methods are provided that are configured to automate SAR narrative generations using prompts to a generative AI service by an automated SAR narrative system. The system includes a processor and a computer readable medium operably coupled thereto, the computer readable medium comprising a plurality of instructions stored in association therewith that are accessible to, and executable by, the processor, to perform narrative generation operations which include receiving a SAR, loading a prompt template that is associated with generating a SAR narrative by the generative AI service, extracting SAR data corresponding to one or more of prompt input fields for the prompt template, creating an updated prompt based on the extracted SAR data and the prompt template, calling the generative AI service using the updated prompt, receiving a response to the updated prompt, combining the responses and generating and storing the SAR narrative.",ACTIMIZE LTD.,Kiran Kumar BATHULA,,https://lens.org/193-716-067-243-561,Patent Application,yes,0,0,1,193-716-067-243-561,US,1,193-716-067-243-561,US,0,G10L15/22;;G06N20/00;;G06Q50/26,G10L15/22;;G06N20/00;;G06Q50/26,,0,0,,,,UNKNOWN
827,WO,A1,WO 2024/263659 A1,179-337-958-705-275,12/26/2024,2024,US 2024/0034647 W,6/20/2024,US 202318340708 A,6/23/2023,CONNECTING NATURAL AND SECURITY LANGUAGE IN THE EMBEDDING SPACE FOR BETTER THREAT HUNTING AND INCIDENT RESPONSE,"Methods and apparatuses for improving the speed, quality, and relevance of automated responses provided by a question answering system for security data are described. The question answering system may generate and utilize a large language model that is trained to combine the language of security data, such as the language found in security logs and alerts, with natural language text. Given an input prompt (or a search query) from an end user of the question answering system, the question answering system may identify relevant content from the security data and display a response based on the relevant content. The question answering system may allow the end user of the question answering system to query security logs using natural language text without requiring the end user to provide a structured query and without requiring the security data be parsed and ingested into a database system.",MICROSOFT TECHNOLOGY LICENSING LLC,BULUT MUHAMMED FATIH;;SHAH ADITI KAMLESH,,https://lens.org/179-337-958-705-275,Patent Application,yes,1,0,2,011-098-059-187-349;;179-337-958-705-275,US;;WO,2,011-098-059-187-349;;179-337-958-705-275,US;;WO,0,H04L63/1425;;H04L63/1441;;G06F21/554;;G06F21/552;;G06F16/24522;;G06F21/552;;G06F2221/2101,G06F21/55;;H04L9/40,,2,0,,,"ANONYMOUS: ""Parsing - Wikipedia"", 9 May 2023 (2023-05-09), pages 1 - 12, XP093209577, Retrieved from the Internet <URL:https://en.wikipedia.org/w/index.php?title=Parsing&oldid=1153935128> [retrieved on 20240927];;ANONYMOUS: ""Large language model - Wikipedia"", 22 June 2023 (2023-06-22), XP093213769, Retrieved from the Internet <URL:https://en.wikipedia.org/w/index.php?title=Large_language_model&oldid=1161462207> [retrieved on 20241010]",PENDING
828,US,A1,US 2025/0245664 A1,075-190-562-010-624,7/31/2025,2025,US 18422858,1/25/2024,,,AUTOMATED VALIDATION OF SUSPICIOUS ACTIVITY REPORT NARRATIVES USING GENERATIVE ARTIFICIAL INTELLIGENCE,"An autonomous fraud/AML reporting system and methods are provided that are configured to automate validations of SAR narratives using a generative AI service by an automated SAR narrative system. The system includes a processor and a computer readable medium operably coupled thereto, the computer readable medium comprising a plurality of instructions stored in association therewith that are accessible to, and executable by, the processor, to perform narrative validation operations which include receiving a SAR narrative for a SAR, loading a prompt template associated with validating the SAR narrative by the generative AI service, injecting the narrative into the prompt templates, and generating and storing the validation based on the comparing.",ACTIMIZE LTD,Kiran Kumar BATHULA,,https://lens.org/075-190-562-010-624,Patent Application,yes,0,0,1,075-190-562-010-624,US,1,075-190-562-010-624,US,0,G06Q20/4016,G06Q20/40,,0,0,,,,UNKNOWN
829,US,A1,US 2025/0117753 A1,103-700-184-510-445,4/10/2025,2025,US 202418908152 A,10/7/2024,US 202418908152 A;;US 202363542589 P,10/5/2023,"SYSTEM, METHOD AND COMPUTER-ACCESSIBLE MEDIUM FOR INVESTIGATING ALGORITHMIC HIRING BIAS","Exemplary systems, methods and computer-accessible medium according to the exemplary embodiments of the present disclosure are provided for determining bias in at least one large language model (LLMs). Thus, exemplary systems, methods, and computer-accessible medium can receive a plurality of baseline resumes, create or generate a plurality of flagged resumes from the plurality of baseline resumes, create or generate a resume corpus from the plurality of baseline resumes and the plurality of flagged resumes, input the resume corpus into the LLM, receive an LLM classification output for the resume corpus, and measure a LLM bias based on the classification output.",UNIV NEW YORK,VELDANDA AKSHAJ KUMAR;;GROB FABIAN;;THAKUR SHAILJA;;PEARCE HAMMOND;;TAN PENG SENG BENJAMIN;;KARRI RAMESH;;GARG SIDDHARTH,,https://lens.org/103-700-184-510-445,Patent Application,yes,0,0,1,103-700-184-510-445,US,1,103-700-184-510-445,US,0,G06Q10/1053;;G06Q10/1053,G06Q10/1053,,0,0,,,,PENDING
830,US,A1,US 2025/0200635 A1,056-320-519-557-716,6/19/2025,2025,US 202318545452 A,12/19/2023,US 202318545452 A,12/19/2023,SEARCH RESULTS SUMMARIZATION TUNING,"One or more aspects of the method, apparatus, and non-transitory computer readable medium include receiving a query relating to an item and a summarization type indicating an emphasis on item similarities or item differences, obtaining, using a search component, descriptions of items relevant to the query, generating input data for a machine learning model based on the descriptions and the summarization type, and generating, using the machine learning model, a summarization of the descriptions based on the input data in response to the query, wherein the summarization emphasizes the item similarities or item differences based on the summarization type.",ADOBE INC,UNNIKRISHNAN SOUMYA;;LAJEVARDI SAINA;;SAAD MICHELE,ADOBE INC (2023-12-15),https://lens.org/056-320-519-557-716,Patent Application,yes,0,0,1,056-320-519-557-716,US,1,056-320-519-557-716,US,0,G06Q30/0629;;G06Q30/0631;;G06Q30/0204;;G06F40/247;;G06F40/40;;G06Q30/0631;;G06Q30/0629;;G06F40/247;;G06F40/40;;G06Q30/0204,G06Q30/0601;;G06F40/247;;G06F40/40;;G06Q30/0204,,0,0,,,,PENDING
831,WO,A1,WO 2025/030094 A1,011-227-601-599-078,2/6/2025,2025,US 2024/0040717 W,8/2/2024,US 202363517336 P,8/2/2023,LANGUAGE ALIGNED MEDICAL IMAGE EMBEDDINGS,"A method includes receiving training data comprising medical images and associated text reports. The method further includes training an image encoder to associate image embeddings generated by the image encoder when the image encoder is applied to the medical images with text embeddings generated by a text encoder when the text encoder is applied to the associated text reports. The method additionally includes training a vision-language model based on the image embeddings generated by the trained image encoder to represent the medical images and the associated text reports in a language-aligned embeddings space. The method further includes training an adaptor which connects the vision-language model to an LLM to generate LLM-aligned tokens which emphasize portions of medical image information to the LLM via an attention mechanism. The method further includes providing the trained image encoder, the trained vision-language model, and the trained adaptor to perform one or more inference tasks.",GOOGLE LLC,SELLERGREN ANDREW BECKMANN;;XU JINHUA;;YANG LIN;;GOLDEN DANIEL IRVING;;PILGRIM RORY BRIAN;;KELLY CHRISTOPHER JOHN;;ESWARAN KRISHNAN;;PRABHAKARA SHRUTHI;;SHETTY SHRAVYA RAMESH;;SIENIEK MARCIN TOMASZ;;STEINER DAVID F;;AHMED FARUK;;WULCZYN ELLERY ALYOSHA;;LIU YUN,,https://lens.org/011-227-601-599-078,Patent Application,yes,1,0,1,011-227-601-599-078,WO,1,011-227-601-599-078,WO,0,G06F16/55;;G16H30/40;;G16H50/20;;G16H50/70;;G06V2201/031;;G06V10/82;;G06V30/41,G06F16/55,,1,0,,,"BINGQIAN LIN ET AL: ""Towards Medical Artificial General Intelligence via Knowledge-Enhanced Multimodal Pretraining"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 26 April 2023 (2023-04-26), XP091496001",PENDING
832,US,A1,US 2025/0138408 A1,058-273-272-634-954,5/1/2025,2025,US 202519011137 A,1/6/2025,US 202519011137 A,1/6/2025,SCALABLE AND AUTONOMOUS CAMERA TUNING SYSTEM,"Camera tuning process is a time consuming and labor-intensive process. To address this issue, camera tuning system including a multi-modal large language model and a retrieval-augmented generation system can be implemented to intelligently and efficiently handle a camera tuning task in real-time. The multi-modal large language model can evaluate image quality and can be finetuned using high-quality labeled data and synthetically generated labeled data. The retrieval-augmented generation system can incorporate camera configuration knowledge into a vector database and can leverage a retrieved context to generate a configuration solution that addresses image quality issues identified by the multi-modal large language model. The resulting camera tuning system is a unified process that can identify image quality issues and provide configuration solutions that address both technical and aesthetic image quality concerns.",BARBER DOR;;BUGDARY SHLOMO;;NASSER JAMIL;;KRISHNAMURTHY LAKSHMAN;;COHEN UZI;;LEVY NOAM;;ZATZARINNI RONY;;HOROVITZ DAN;;SAGI TAMIR,BARBER DOR;;BUGDARY SHLOMO;;NASSER JAMIL;;KRISHNAMURTHY LAKSHMAN;;COHEN UZI;;LEVY NOAM;;ZATZARINNI RONY;;HOROVITZ DAN;;SAGI TAMIR,INTEL CORPORATION (2025-01-05),https://lens.org/058-273-272-634-954,Patent Application,yes,0,0,1,058-273-272-634-954,US,1,058-273-272-634-954,US,0,G06T2207/20081;;G03B43/00;;G03B43/00;;G06T7/80;;G06T7/90;;G06T7/97;;G06T2207/20081;;G06T7/0002,G03B43/00;;G06T7/00;;G06T7/80;;G06T7/90,,0,0,,,,PENDING
833,US,A1,US 2025/0247303 A1,181-146-825-750-62X,7/31/2025,2025,US 18428698,1/31/2024,,,CLOUD ARCHITECT,"A cloud architect guides cloud architecture design and deployment for users of all skill levels. Generative artificial intelligence (AI) interprets user specifications to provide architectural diagrams for a wide variety of application scenarios. A cloud architect generates search results responsive to a request for a cloud architecture. The search results indicate at least one example cloud architectural diagram. The cloud architect generates a request to a large language model (LLM) for a recommended cloud architecture based on the user request and the search results. The cloud architect receives a response generated by the LLM indicating at least one recommended cloud architecture. The cloud architect provides an interactive LLM response. The cloud architect enables selection of a recommended cloud architectural diagram, e.g., for deployment, manual editing, or dialog leading to automated customization. The cloud architect deploys a workload to a cloud using cloud resources determined based on the selected diagram.","Microsoft Technology Licensing, LLC",Belinda LEI;;Qasim IJAZ;;Sandeep GUSAIN;;Shi CHENG;;Vijaya Lakshmi Sri Pallavi DAMERA;;Ross James LORDON;;Fan MAI;;Julia Anne CHENG;;Rui WU,,https://lens.org/181-146-825-750-62X,Patent Application,yes,0,0,1,181-146-825-750-62X,US,1,181-146-825-750-62X,US,0,H04L41/16;;G06F16/9038;;G06F40/40;;H04L41/04;;H04L41/0806;;H04L41/084;;H04L41/22,H04L41/16;;G06F16/9038;;G06F40/40;;H04L41/04;;H04L41/0806;;H04L41/084;;H04L41/22,,0,0,,,,UNKNOWN
834,US,A1,US 2024/0346233 A1,005-671-925-500-138,10/17/2024,2024,US 202318300238 A,4/13/2023,US 202318300238 A,4/13/2023,EFFICIENT GENERATION OF REVIEW SUMMARIES,"Methods, computer systems, computer-storage media, and graphical user interfaces are provided for efficiently generating review summaries. In embodiments, reviews associated with an item are obtained. A set of the reviews are then determined or selected based on an attribute associated with the corresponding review. Thereafter, a model prompt to be input into a trained machine learning model is generated. The model prompt can include an indication of the item and the determined set of the reviews. As output from the trained machine learning model, a review summary that summarizes the set of the reviews associated with the item is obtained.",MICROSOFT TECHNOLOGY LICENSING LLC,PAULINO EDY DANIEL;;UNGER KYLE MATTHEW;;HIMANGO JUDAH GABRIEL;;LOW WEY HSUAN,MICROSOFT TECHNOLOGY LICENSING LLC (2023-04-13),https://lens.org/005-671-925-500-138,Patent Application,yes,0,1,1,005-671-925-500-138,US,1,005-671-925-500-138,US,0,G06F16/345;;G06N3/08;;G06F40/166;;G06N20/00;;G06F40/40;;G06F40/166;;G06F40/40;;G06N3/08;;G06N20/00;;G06F16/345,G06F40/166;;G06F40/40;;G06N3/08,,0,0,,,,PENDING
835,US,A1,US 2025/0190230 A1,145-169-780-603-541,6/12/2025,2025,US 202318533674 A,12/8/2023,US 202318533674 A,12/8/2023,DYNAMICALLY SYNTHESIZED USER INTERFACE WIDGETS,Systems for dynamically synthesizing widgets for chart modification are provided. A method can include receiving data indicating a dataset of structured data. The data can be provided by a user through a user interface (UI). The UI can display the data on a chart. A request can be received by the UI. The request can be provided by the user. The request can indicate an alteration to a representation of the data on the chart. A widget can be dynamically synthesized based on the request. The widget can be operable to alter the representation of the data on the chart based on user interaction with the widget. The UI can present the widget on the UI alongside the chart. The chart can be altered based on user interaction with the widget.,MICROSOFT TECHNOLOGY LICENSING LLC,INALA JEEVANA PRIYA;;WANG CHENGLONG;;VAITHILINGAM PRIYAN,MICROSOFT TECHNOLOGY LICENSING LLC (2023-12-13),https://lens.org/145-169-780-603-541,Patent Application,yes,0,0,2,145-169-780-603-541;;022-264-654-383-168,US;;WO,2,145-169-780-603-541;;022-264-654-383-168,US;;WO,0,G06F9/451;;G06T11/206;;G06F3/0482;;G06F3/04842;;G06F9/451;;G06F40/40;;G06T11/206;;G06F8/35;;G06F8/38;;G06N3/0475;;G06F3/0484;;G06F8/31,G06F9/451;;G06F8/30;;G06F40/40,,0,0,,,,PENDING
836,WO,A1,WO 2025/096210 A1,189-460-200-063-05X,5/8/2025,2025,US 2024/0051678 W,10/17/2024,US 202363596290 P;;US 202418616944 A,11/5/2023,GENERATIVE ARTIFICIAL INTELLIGENCE OUTPUT VALIDATION ENGINE IN AN ARTIFICIAL INTELLIGENCE SYSTEM,"Methods, systems, and computer storage media for providing generative artificial intelligence (AI) output validation using a generative AI output validation engine in an artificial intelligence system. The generative AI output validation engine assesses and determines the quality (e.g., quantified as an output validation score) of generative AI output (e.g., LLM output). In operation, a generative AI output comprising summary data is accessed. Raw data from which summary data is generated is accessed. A plurality of output validation operations associated with a generative AI output validation engine are executed. The generative AI output validation engine comprises multi-categorical analytical models that provide corresponding output validation operations for quantifying quality of generative AI outputs. Using the generative AI output validation engine, generating an output validation score for the summary data. Communicating the output validation score. A feedback loop is established to incorporate human feedback for fine-tuning the generative AI output validation engine models.",MICROSOFT TECHNOLOGY LICENSING LLC,VINAY VAISHALI;;DENNIS JOHN CURTIS;;DUNCAN MATTHEW ALBERT;;DURAN DUSTIN;;STROM BLAKE EDWARD,,https://lens.org/189-460-200-063-05X,Patent Application,yes,2,0,2,189-460-200-063-05X;;154-419-059-029-64X,US;;WO,2,189-460-200-063-05X;;154-419-059-029-64X,US;;WO,0,G06F40/284;;G06F40/30;;G06F40/56;;G06N20/00;;G06F21/6218;;G06N5/022,G06F40/284;;G06F40/30;;G06F40/56;;G06N20/00,,3,1,145-964-865-475-561,10.1109/access.2023.3294090,"EVAN CROTHERS ET AL: ""Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 8 May 2023 (2023-05-08), XP091503118;;ANONYMOUS: ""nlp - How do we evaluate the outputs of text generation models? - Data Science Stack Exchange"", 27 May 2023 (2023-05-27), XP093236610, Retrieved from the Internet <URL:https://web.archive.org/web/20230527234621/https://datascience.stackexchange.com/questions/118739/how-do-we-evaluate-the-outputs-of-text-generation-models>;;ZHANG TIANYI ET AL: ""BERTSCORE: EVALUATING TEXT GENERATION WITH BERT"", 1 January 2020 (2020-01-01), XP093236616, Retrieved from the Internet <URL:https://openreview.net/pdf?id=SkeHuCVFDr>",PENDING
837,WO,A1,WO 2025/096357 A1,091-888-683-854-449,5/8/2025,2025,US 2024/0053289 W,10/28/2024,US 202363594367 P;;US 202363611031 P;;US 202463640814 P;;US 202418767882 A;;US 202418767896 A;;US 202418767905 A;;US 202463680490 P;;US 202463698515 P,10/30/2023,SILENT SPEECH SYSTEMS AND METHODS,"Provided herein is a method for non-audible speech detection and output. The method comprises providing a radio frequency (RF) sensing device configured to be coupled to a head of a user. The method further comprises using the RF sensing device to collect RF signal data associated with movement of one or more speech articulators of the user. The method further comprises outputting or facilitating an output comprising a non-audible speech translation using at least in part processed RF signal data, wherein the non-audible speech of the user comprises continuous speech by the user.",REFLEX TECH INC;;BENSTER TYLER STEPHEN;;ELISHA RESHEF HAIM;;WILSON GUY HALLECK;;MOUSSAKHANI KAVEH,BENSTER TYLER STEPHEN;;ELISHA RESHEF HAIM;;WILSON GUY HALLECK;;MOUSSAKHANI KAVEH,,https://lens.org/091-888-683-854-449,Patent Application,yes,3,0,1,091-888-683-854-449,WO,4,022-155-065-833-965;;159-702-398-715-72X;;169-589-711-393-191;;091-888-683-854-449,US;;WO,0,G06F3/01;;G10L13/08;;G06F40/40;;G10L15/24;;G06F40/186,G10L15/24;;G06F3/01;;G06F40/166;;G06F40/40;;G10L13/08,,0,0,,,,PENDING
838,US,A1,US 2025/0055867 A1,115-748-201-523-466,2/13/2025,2025,US 202418797798 A,8/8/2024,IN 202341053821 A,8/10/2023,DYNAMIC THREAT MITIGATING OF GENERATIVE ARTIFICIAL INTELLIGENCE MODELS,"The disclosure relates to a method and system for dynamically mitigating threats of generative Artificial Intelligence (AI) models. Conventional systems often suffer from inefficiencies due to sequentially applying threat detection checks leading to unnecessary preprocessing and increased computational demands. Additionally, such systems typically focus only on input data, neglecting potential threats in outputs. The disclosed system and method addresses these drawbacks by employing a hierarchical structure of macro and nano classifiers. The system utilizes macro classifiers for broad initial threat categorization followed by specialized nano classifiers for detailed analysis of specific threat subtypes, thereby optimizing processing time and computational resources. The system operates in real time, applying predefined moderation rules to both input and output data to ensure comprehensive threat mitigation. Additionally, continuous telemetry data updates refine nano classifiers and threat identification mechanisms, maintaining high accuracy and adaptability. The disclosed method enhances safety efficiency and reliability of generative AI models.",INFOSYS LTD,AHMED SYED;;CHAKRABORTY RITARSHI;;VARADARAJAN NAVEEN,INFOSYS LIMITED (2024-08-08),https://lens.org/115-748-201-523-466,Patent Application,yes,0,2,2,033-228-242-286-514;;115-748-201-523-466,US,2,033-228-242-286-514;;115-748-201-523-466,US,0,H04L63/205;;G06N3/0475;;G06F16/2365;;G06F16/2423;;H04L63/1425;;G06F16/2423;;G06F16/2365;;G06N3/0475;;H04L63/1425;;H04L63/205,H04L9/40,,0,0,,,,PENDING
839,US,B2,US 12354723 B2,071-329-651-886-626,7/8/2025,2025,US 202418638368 A,4/17/2024,US 202418638368 A;;US 202363496521 P;;US 202363510250 P,4/17/2023,System and method for radiology reporting,"A method for radiology reporting includes any or all of: determining a set of inputs, determining a template, generating a radiology report, processing the radiology report, adjusting the radiology report, and/or any other suitable steps. A system for radiology reporting includes and/or interfaces with any or all of: a set of models, a computing system, a set of databases, a user interface, user devices, and/or any other suitable system components.",RAD AI INC,PAULETT JOHN;;BOONN WILLIAM;;KIM WOOJIN;;CHANG JEFFREY;;GURSON DOKTOR,,https://lens.org/071-329-651-886-626,Granted Patent,yes,61,0,3,185-561-928-998-71X;;071-329-651-886-626;;043-854-676-000-975,US;;WO,3,185-561-928-998-71X;;071-329-651-886-626;;043-854-676-000-975,US;;WO,0,G16H30/20;;G16H30/40;;G16H15/00;;G16H10/60;;G16H15/00;;G16H30/40;;G16H30/20,G16H15/00;;G06F40/289;;G16H30/20;;G16H30/40,,33,0,,,"“Improving and automating lung cancer screening”, Nuance, Data Sheet, Nov. 2020, https://www.nuance.com/asset/en_us/collateral/healthcare/data-sheet/ds-powerscribe-lung-cancer-screening-en-US.pdf.;;“Lung Cancer Orchestrator”, Philips, first downloaded May 19, 2023, https://www.usa.philips.com/healthcare/product/HC841017/lung-cancer-orchestrator.;;“Lung Cancer Screening”, Eon Health, first downloaded May 19, 2023, https://eonhealth.com/lung-cancer-screening-software/.;;“Merge Announces Release of Fusion PACS MX(TM) 3.0 Featuring Integrated Digital Mammography, and Release of Merge Mammo(TM) 7.10”, Business Wire, May 19, 2008, p. NA. ProQuest. Web. Aug. 29, 2023. (Year: 2008).;;“PowerScribe One for radiology reporting, Next-generation radiology reporting”, Nuance, https://www.nuance.com/healthcare/diagnostics-solutions/workflow-radiology-reporting/powerscribe-one.html#, first downloaded Mar. 11, 2024.;;“Radiology reports designed for patients”, Scanslated, first downloaded May 19, 2023, https://scanslated.com.;;Agarwal, Sheela , et al., “Beyond the impression: How AI-driven clinical intelligence transforms the radiology experience”, Radiology Business Journal sponsored webinar, Nov. 16, 2022.;;Chang, Jeffrey , et al., “Method and System for the Computer-Assisted Implementation of Radiology Recommendations”, U.S. Appl. No. 18/215,354, filed Jun. 28, 2023.;;Dai, Ning , et al., “Style transformer: Unpaired text style transfer without disentangled latent representation”, Ithaca: Cornell University Library, arXiv.org. (Year: 2019).;;Deng, Mingkai , “RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning”, Machine Learning, Carnegie Mellon University, published Feb. 24, 2023.;;Ebesu, Travis Akira, “Deep learning for recommender systems”, (Order No. 13900137). Available from ProQuest Dissertations & Theses Global. (2293976827). (Year: 2019).;;Garud, Hrishkesh Deepak, et al., “Transforming human pose forecasting”, (Order No. 27814956). Available from ProQuest Dissertations & Theses Global. (2399247743). (Year: 2019).;;Jettaku, Amarin , et al., “Relation extraction between bacteria and biotopes from biomedical texts with X attention mechanisms and domain-specific contextual representations”, BMC Bioinformatics, 20, 1-17, (2019).;;Koncel-Kedziorski, Rik , et al., “Understanding and generating multi-sentence texts”, (Order No. 13814316). Available from ProQuest Dissertations & Theses Global. (2305944561). (Year: 2019).;;Lambert, Nathan , et al., “Illustrating Reinforcement Learning from Human Feedback (RLHF)”, Hugging Face, https://huggingface.co/blog/rlhf, published Dec. 9, 2022.;;Lou, Robert , et al., “Automated detection of radiology reports that require follow-up imaging using natural language processing feature engineering and machine learning classification”, Journal of digital imaging, 33(1), 131-136. (Year: 2020).;;Lu, Edward , et al., “Lora: Low-Rank Adaptation of Large LAN-Guage Models”, arXiv:2106.09685, https://doi.org/10.48550/arXiv.2106.09685, Jun. 17, 2021.;;Malhotra, Tanya , “Exploring The Differences Between ChatGPT/GPT-4 and Traditional Language Models: The Impact of Reinforcement Learning from Human Feedback (RLHF)”, MarkTestPost, https://www.marktechpost.com/2023/03/21/exploring-the-differences-between-chatgpt-gpt-4-and-traditional-language-models-the-impact-of-reinforcement-learning-from-human-feedback-rlhf/, Mar. 21, 2023.;;Nandhakumar, Nidhin , et al., “Clinically Significant Information Extraction from Radiology Report”, DocEng '17: Proceedings of the 2017 ACM Symposium on Document Engineering, Aug. 2017, pp. 153-162.;;Paulett, John , et al., “System and Method for Radiology Reporting”, U.S. Appl. No. 18/638,368, filed Apr. 17, 2024.;;Sanjabi, Nima , “Abstractive text summarization with attention-based mechanism”, (Projecte Final de Master Oficial). UPC, Facultat d'Informatica de Barcelona. (Year: 2018).;;Sean, Xiao , “Fine-tuning LLMs Made Easy with LoRA and Generative AI-Stable Diffusion LoRA”, Medium, https://xiaosean5408.medium.com/fine-tuning-Ilms-made-easy-with-lora-and-generative-ai-stable-diffusion-lora-39ff27480fda, Mar. 11, 2023.;;Song, Huan , “Data-driven representation learning in multimodal feature fusion”, (Order No. 10838232). Available from ProQuest Dissertations & Theses Global. (2094858110). (Year: 2018).;;Van Veen, Dave , et al., “RadAdapt: Radiology Report Summarization via Lightweight Domain Adaptation of Large Language Models”, arXiv:2305.01146, https://doi.org/10.48550/arXiv.2305.01146, May 2, 2023.;;Witteveen, Sam , “Building a Summarization System with LangChain and GPT-3—Part 2”, https://www.youtube.com/watch?v=d-yeHDLgKHw, Mar. 11, 2023.;;Xue, Y. , et al., “Multimodal Recurrent Model with Attention for Automated Radiology Report Generation”, Medical Image Computing and Computer Assisted Intervention—MICCAI 2018. MICCAI 2018. Lecture Notes in Computer Science, vol. 11070. Springer, Cham. https://doi.org/10.1007/978-3-030-00928-1_52 (Year: 2018).;;Yao, Shunyu , et al., “ReAct: Synergizing Reasoning and Acting in Language Models”, https://react-Im.github.io, Oct. 6, 2022.;;Zech, John , et al., “Natural Language-based Machine Learning Models for the Annotation of Clinical Radiology Reports”, Radiology Reports. Jan. 30, 2018 (Jan. 30, 2018).;;Zhang, Yuhao , et al., “Learning to Summarize Radiology Findings”, Oct. 8, 2018 (Oct. 8, 2018). 1-20 [retrieved on Nov. 18, 2020].;;Chang, et al., “Method and System for the Computer-Aided Processing of Medical Images”, U.S. Appl. No. 18/952,233, filed Nov. 19, 2024.;;Chang, et al., “System and Method for Automatically Displaying Information at a Radiologist Dashboard”, U.S. Appl. No. 18/952,147, filed Nov. 19, 2024.;;Li, et al., “BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models”, arXiv:2301.12597v1, Jan. 30, 2023.;;Xu, et al., “ELIXR: Towards a general purpose X-ray artificial intelligence system through alignment of large language models and radiology vision encoders”, arXiv:2308.01317 [cs. Cv], Aug. 2, 2023.",ACTIVE
840,US,A1,US 2024/0256582 A1,080-367-854-030-418,8/1/2024,2024,US 202318330999 A,6/7/2023,US 202318330999 A;;US 202363482040 P,1/28/2023,Search with Generative Artificial Intelligence,"Methods and apparatuses for utilizing generative artificial intelligence (AI) techniques to automatically generate and display summaries of search results are described. A search and knowledge management system may generate a set of search results for a given search query and provide the set of search results (e.g., a set of verified documents that are the most relevant verified documents for the search query) as part of an input prompt to guide a generative AI model in generating a summary response of the set of search results. The generative AI model may comprise a Generative Pre-trained Transformer (GPT) model. The summary response may comprise a natural language text response and the set of search results may comprise electronic documents and messages and/or portions thereof.",GLEAN TECH INC,JAIN ARVIND;;QI CALVIN;;TRAN CHAU HAI;;ZHOU EDDIE;;JHUNJHUNWALA MEGHA;;MOHIT MRINAL;;YADAV PANCHAM;;OPHUS PHILIP;;ROY SHIVAAL;;CHOKSI VIVEK,GLEAN TECHNOLOGIES INC (2023-05-30),https://lens.org/080-367-854-030-418,Patent Application,yes,0,17,1,080-367-854-030-418,US,1,080-367-854-030-418,US,0,G06F16/338;;G06F16/3329;;G06N20/00;;G06N3/045;;G06F16/345;;G06F16/3329;;G06F16/338;;G06N20/00,G06F16/332;;G06F16/338;;G06N20/00,,0,0,,,,PENDING
841,US,A1,US 2024/0420491 A1,135-247-483-575-415,12/19/2024,2024,US 202418745027 A,6/17/2024,US 202418745027 A;;US 202363508650 P,6/16/2023,NETWORK INFRASTRUCTURE FOR USER-SPECIFIC GENERATIVE INTELLIGENCE,"Network infrastructure for user-specific generative intelligence. Providing user-specific context to a generically trained LLM introduces a variety of complications (privacy, resource utilization, training costs, etc.). Various aspects of the present disclosure provide novel user-specific data structures, privacy and access control, layers of data, and session management, within a network infrastructure for generative intelligence. For example, user-specific embedding vectors may be used to provide user context to a generically trained foundation model. In some variants, edge devices capture multiple modalities of user context (images, audio; not just text). Privacy and access control mechanisms also allow a user to control information that is captured and sent to the foundation model. Session management further decouples a user's conversational state from the foundation model's session state. These concepts and others may be used to emulate e.g., a chatbot based virtual assistant that responds based on user context.",SOFTEYE INC,PARK EDWIN CHONGWOO;;LEE TE-WON;;LEE DOYOUNG;;NATARAJAN ARAVIND,SOFTEYE INC (2025-05-12),https://lens.org/135-247-483-575-415,Patent Application,yes,0,2,1,135-247-483-575-415,US,5,112-840-231-039-758;;135-247-483-575-415;;184-808-711-246-969;;094-058-628-572-592;;104-159-937-725-787,US,0,G06V20/70;;G06V10/764;;G06F40/284;;G06F16/245;;G06V20/70;;G06F16/245;;G06F40/284;;G06V10/764,G06V20/70;;G06F16/245;;G06F40/284;;G06V10/764,,0,0,,,,PENDING
842,US,A1,US 2025/0094429 A1,065-847-649-844-016,3/20/2025,2025,US 202318467724 A,9/14/2023,US 202318467724 A,9/14/2023,INTELLIGENT GROUPING OF MESSAGES INTO CONVERSATION DOCUMENTS FOR RANKING AND RETRIEVAL,"Methods and apparatuses for identifying groups of electronic messages, generating conversation documents using the groups of electronic messages, and indexing the conversation documents to improve search ranking and retrieval for content contained within the electronic messages are described. In some cases, understanding the contents of a group of electronic messages may require context from outside the group of electronic messages, such as context provided by electronic messages outside of the group of electronic messages or context provided by electronic documents linked to by messages of the group of electronic messages. The identification of a group of electronic messages includes detecting a conversation boundary that separates a first set of messages from a second set of messages, which may be determined using machine learning approaches or various heuristics.",GLEAN TECH INC,RAGHAVAN KRISHNAN;;PRAHLADKA PIYUSH;;CHODIPILLI HEMANT KUMAR;;KUMAR PRASHANT;;CHANDNANI YASH;;DAS DEBARGHYA,GLEAN TECHNOLOGIES INC (2023-08-20),https://lens.org/065-847-649-844-016,Patent Application,yes,22,0,1,065-847-649-844-016,US,1,065-847-649-844-016,US,0,G06F16/24578;;G06F16/22;;G06F16/248;;G06F16/285;;G06F16/24578;;G06F16/248;;G06F16/22;;G06F16/285,G06F16/2457;;G06F16/22;;G06F16/248;;G06F16/28,,0,0,,,,PENDING
843,US,A1,US 2024/0419727 A1,104-159-937-725-787,12/19/2024,2024,US 202418745353 A,6/17/2024,US 202418745353 A;;US 202463565974 P;;US 202363508650 P,6/16/2023,NETWORK INFRASTRUCTURE FOR USER-SPECIFIC GENERATIVE INTELLIGENCE,"Network infrastructure for user-specific generative intelligence. Providing user-specific context to a generically trained LLM introduces a variety of complications (privacy, resource utilization, training costs, etc.). Various aspects of the present disclosure provide novel user-specific data structures, privacy and access control, layers of data, and session management, within a network infrastructure for generative intelligence. For example, user-specific embedding vectors may be used to provide user context to a generically trained foundation model. In some variants, edge devices capture multiple modalities of user context (images, audio; not just text). Privacy and access control mechanisms also allow a user to control information that is captured and sent to the foundation model. Session management further decouples a user's conversational state from the foundation model's session state. These concepts and others may be used to emulate e.g., a chatbot based virtual assistant that responds based on user context.",SOFTEYE INC,PARK EDWIN CHONGWOO;;LEE TE-WON;;LEE DOYOUNG;;NATARAJAN ARAVIND,SOFTEYE INC (2025-05-12),https://lens.org/104-159-937-725-787,Patent Application,yes,0,0,4,112-840-231-039-758;;184-808-711-246-969;;094-058-628-572-592;;104-159-937-725-787,US,5,112-840-231-039-758;;135-247-483-575-415;;184-808-711-246-969;;094-058-628-572-592;;104-159-937-725-787,US,0,H04N23/64;;G06V10/235;;G06F40/284;;G06F21/6227;;G06F21/6218;;G06F16/587;;G06F21/6254;;G06F16/3329;;G06F40/40;;G06F16/242;;G06F16/583;;G06F16/3347;;G06V10/25;;G06F40/35;;G06F9/547;;G06F16/242;;G06F21/6254;;G06F21/6227;;G06F40/284;;G06F16/583;;G06F16/587;;G06V10/25;;G06V10/235;;G06F40/40;;H04N23/64;;G06F9/547;;G06F21/6218;;G06F16/3347;;G06F16/3329,G06F16/587;;G06F16/583;;G06F40/284;;G06V10/22;;G06V10/25,,0,0,,,,PENDING
844,US,A1,US 2025/0132049 A1,002-976-506-793-608,4/24/2025,2025,US 202418908302 A,10/7/2024,US 202418908302 A;;US 202363591381 P,10/18/2023,PERFORMING PREDICTIVE HEALTH RISK MODELING AND RISK MITIGATION TRADE-OFF ANALYSIS,"In an illustrative embodiment, systems and methods for deriving risk patterns corresponding to a set of medical conditions through analyzing historic treatment of a population of individuals involve segmenting treatment data records of the population into a set of risk segments, analyzing the treatment data records to identify risk patterns indicative of each of a set of medical conditions, and calculating relative impact of each of the set of medical conditions based at least in part on prevalence of each medical condition among the population.",AON CONSULTING INC,PENEV TODOR;;OZMINKOWSKI RONALD J;;RAUSCH MEGHAN;;PERSICO ANTHONY;;METCALFE LEANNE;;BOWEN JONATHAN;;LI JAX;;LEE JAE HYUNG;;CHIANG MINGMIN;;PATEL DIPTI R,AON CONSULTING INC (2024-12-19),https://lens.org/002-976-506-793-608,Patent Application,yes,0,0,1,002-976-506-793-608,US,1,002-976-506-793-608,US,0,G16H40/20;;G16H50/70;;G16H50/30;;G16H50/20;;G16H10/60;;G16H50/50;;G16H50/30;;G16H40/20;;G16H50/70,G16H50/30;;G16H40/20;;G16H50/70,,0,0,,,,PENDING
845,US,B1,US 12307919 B1,105-995-622-193-042,5/20/2025,2025,US 202318496268 A,10/27/2023,US 202318496268 A,10/27/2023,Apparatus and method for delivering adaptive educational content,"In a first aspect, an apparatus for delivering adaptive educational content using an automated tutoring model includes a processor and a memory communicatively connected to the processor is presented. The memory contains instructions configuring the processor to receive a prompt from a user. The processor, extract linguistic data from the prompt through an automated tutoring model. The processor is configured to determine, through the automated tutoring model, relevant educational data for the user based on the linguistic data of the prompt. The automated tutoring model is configured to classify the user to a learner group based on the prompt. The automated tutoring model is in communication with and selects the relevant educational data from an educational database based at least on the learner group. The processor is configured to present the selected relevant educational data to the user through a display device in communication with the processor.",CENGAGE LEARNING INC,CHILTON JAMES;;QIAN CHARLES;;GRIFFITHS PETER;;MEHTA JAY;;ALENCAR THAIS,CENGAGE LEARNING INC (2024-03-25),https://lens.org/105-995-622-193-042,Granted Patent,yes,0,0,1,105-995-622-193-042,US,1,105-995-622-193-042,US,0,G09B7/04;;G06Q50/2053;;G09B7/04;;G06Q50/2053;;G10L15/02;;G10L15/08;;G10L15/30;;G10L15/22,G09B7/04;;G06Q50/20;;G10L15/02;;G10L15/08;;G10L15/22;;G10L15/30,,0,0,,,,ACTIVE
846,WO,A1,WO 2025/151253 A1,134-622-671-896-297,7/17/2025,2025,US 2024/0060544 W,12/17/2024,US 202418408866 A,1/10/2024,PROACTIVE DETERMINATION OF DATA INSIGHTS,"Methods, systems, and computer programs are presented for providing contextual suggestions and automated responses to users managing incidents within production or security environments. The system utilizes a combination of user-provided data and contextual analysis to proactively offer solutions and insights without requiring explicit queries from the user. The system integrates out-of-the-box insights, natural language interactions, and remediation flows into a cohesive user experience, incorporating playbooks enhanced by automation while leveraging user data and interaction history to tailor suggestions. The system includes a predictive analysis mechanism that runs analyses on relevant data sources, identifying unusual results and generating potential queries. A large language model (ELM) is integrated for generating questions and analyses, with a ranking system prioritizing insights based on machine learning models. A user interface features a suggestions panel with distinct categories for exploration, refinement, and action, enhancing the user interface with contextually relevant and actionable insights.",SUMO LOGIC INC,TCA BASHYAM;;ANDRZEJEWSKI DAVID M;;REDKAR TEJASWI;;BANSAL AAISHWARYA;;POSHALA ROHITH KUMAR;;HASKELL MICHAEL J;;GHATAK AYAN,,https://lens.org/134-622-671-896-297,Patent Application,yes,1,0,1,134-622-671-896-297,WO,4,186-324-638-158-090;;133-584-877-512-630;;087-074-480-093-320;;134-622-671-896-297,US;;WO;;EP,0,G06F16/90324,G06F16/9032,,0,0,,,,PENDING
847,WO,A1,WO 2025/081750 A1,038-878-849-772-566,4/24/2025,2025,CN 2024089328 W,4/23/2024,RU 2023000317 W,10/20/2023,METHOD AND APPARATUS FOR PROGRAMMING,"Embodiments of the present application provide a method and an apparatus for programming. The method includes: identifying a first target profile from a set of profiles according to information related to a target user, where the set of profiles is obtained according to information related to users, and each profile in the set of profiles corresponds to a category of the information related to the users; determining one or more candidate models from a model database according to the first target profile, where the models in the model database are trained models obtained through subsets of a training dataset, the models are used for programming tasks, and the subsets are obtained by dividing the training dataset based on the set of profiles; and obtaining a target action from one or more candidate actions generated by applying the one or more candidate models to context. According to the above technical solution, the personalized support may be provided for a user.",HUAWEI CLOUD COMPUTING TECH CO LTD,KOVALCHUK SERGEY VALERIEVICH;;ALIEV ARTEM;;LOMSHAKOV VADIM;;HU KANG,,https://lens.org/038-878-849-772-566,Patent Application,yes,3,0,1,038-878-849-772-566,WO,1,038-878-849-772-566,WO,0,G06F8/35;;G06F8/20,G06F8/35,,0,0,,,,PENDING
848,US,A1,US 2025/0200356 A1,073-845-930-448-606,6/19/2025,2025,US 202318542375 A,12/15/2023,US 202318542375 A,12/15/2023,AUTOMATED LABEL GENERATION USING A MACHINE-LEARNED LANGUAGE MODEL,An online system may provide an instruction prompt to a machine-learned language model. The instruction prompt may include an instruction to generate an evaluation label of a training sample of a classification model and a textual format related to how data is arranged. The evaluation label may be used in a supervised training of the classification model. The online system may provide a batch of evaluation request prompts to the machine-learned language model. Each evaluation request prompt includes data that is at least partially arranged in the textual format described in the instruction prompt. The online system may receive a plurality of responses from the machine-learned language model. Each response includes the evaluation label corresponding to each evaluation request prompt. The online system may store at least evaluation labels and the data in the evaluation request prompts as training samples for the supervised training of the classification model.,MAPLEBEAR INC,ZHANG XUAN;;TENNETI TEJASWI;;WANG HAIXUN,MAPLEBEAR INC (2023-12-18),https://lens.org/073-845-930-448-606,Patent Application,yes,0,0,1,073-845-930-448-606,US,1,073-845-930-448-606,US,0,G06N3/08;;G06N3/08,G06N3/08,,0,0,,,,PENDING
849,US,A1,US 2025/0124471 A1,040-787-003-950-38X,4/17/2025,2025,US 202418957529 A,11/22/2024,SG 10202302940X A;;IB 2024060079 W,10/17/2023,SYSTEM AND METHOD FOR AUTOMATICALLY GENERATING EMAIL AND ASSOCIATED EMAIL STRATEGIES,"A method for efficiently generating a plurality of personalized email strategies and corresponding personalized emails for campaign recipients is disclosed. Multi-dimensional data comprising account data, recipient data, and seller data is received from one or more data sources. The received multi-dimensional data is processed to extract relevant features. A dynamic feature hierarchy is generated using the extracted features. A pre-trained machine learning model is fine-tuned using the dynamic feature hierarchy to generate email strategies, wherein model parameters are adjusted based on the hierarchy during fine-tuning. A plurality of email strategies is generated for each recipient by applying the fine-tuned model's recommendations. An email strategy is selected from the plurality of strategies based on one or more factors. A personalized email corresponding to the selected email strategy is generated. The personalized email and the selected email strategy used to generate it are displayed to a user.",6SENSE INSIGHTS INC,TAN MARCEL CHENG WEI;;LIM KEN JYI;;CHAN EDWIN KHAI ERN;;LIM YAO JIE;;WU ZHUOYI;;KEYS JAMES CHRISTOPHER;;RODRIGUEZ GABRIEL MATTHEW GALUPO;;RODRIGUEZ VINCENT JAMES GALUPO;;KIM YUL LEE;;TAN JUN YU,6SENSE INSIGHTS INC (2024-10-08),https://lens.org/040-787-003-950-38X,Patent Application,yes,3,0,1,040-787-003-950-38X,US,2,019-358-282-789-931;;040-787-003-950-38X,US;;WO,0,G06Q30/0201;;G06Q30/0271;;G06Q10/107;;G06Q30/0271;;G06Q30/0201;;G06Q10/107,G06Q30/0251;;G06Q10/107;;G06Q30/0201,,0,0,,,,PENDING
850,WO,A1,WO 2025/049598 A1,057-820-795-527-14X,3/6/2025,2025,US 2024/0044217 W,8/28/2024,US 202363580341 P,9/1/2023,REMOTE OPERATIONS FORENSICS,"The present disclosure is related to endpoint monitoring and forensic artifact collection. In some embodiments, forensic artifacts and endpoint monitoring data are collected on an endpoint using the same agent. In some embodiments, forensic artifacts are chunked prior to being transferred to a cloud server for analysis. In some embodiments, forensic artifacts are categorized and processed according to the category. In some embodiments, the agent operates in memory and does not write to disk. In some embodiments, the agent does not write to disk during the transfer of forensic artifacts to a cloud server. In some embodiments, a cloud server can enable natural language queries of monitoring data and/or forensic artifacts. In some embodiments, the cloud server provides summaries. In some embodiments, the cloud server identifies the most relevant data in monitoring data and/or forensic artifacts.",SENTINELONE INC,BARNES MATAN-EL;;ARNON OMRI;;ZIMBALIST AMIT,,https://lens.org/057-820-795-527-14X,Patent Application,yes,3,0,2,057-820-795-527-14X;;028-110-925-458-579,US;;WO,2,057-820-795-527-14X;;028-110-925-458-579,US;;WO,0,H04L63/1425;;G06F21/552;;H04L63/1416,G06F21/55;;H04L9/40,,0,0,,,,PENDING
851,US,A1,US 2024/0370509 A1,118-629-492-668-186,11/7/2024,2024,US 202418642288 A,4/22/2024,US 202418642288 A;;US 202363463146 P,5/1/2023,"SYSTEM, METHOD AND APPARATUS FOR REAL TIME INTERNET SEARCHING USING LARGE LANGUAGE MODELS","The present specification provides, amongst other things, a novel system, method and apparatus for real time travel searches. Certain implementations contemplate a collaboration platform that can receive a natural language query from an electronic platform that includes unstructured travel search queries. The collaboration engine cooperates with a large language model engine to generate a natural language response and structured queries from the unstructured queries. The structured queries are sent to travel actor engines. Itinerary responses from the travel actor engines are substituted for the structured query by the collaboration platform, so that the natural language response along with the itinerary responses are sent back to the electronic device.",AMADEUS SAS,GUILLON NICOLAS;;GREALOU YVES;;PRENGERE ALEX;;RAVANEL ALEXIS;;PRONESTI MASSIMILIANO;;BUIBAS RAUL;;DEMOLLIERE COME;;TOPALLI XHESIAND;;ISPAS CORINA;;DEVAUX YANNICK,,https://lens.org/118-629-492-668-186,Patent Application,yes,5,1,4,061-943-546-938-946;;072-946-610-763-662;;035-193-511-202-661;;118-629-492-668-186,US;;EP,6,061-943-546-938-946;;072-946-610-763-662;;035-193-511-202-661;;014-070-693-292-845;;118-629-492-668-186;;070-024-724-158-117,US;;EP,0,G06N20/00;;G06F16/90332;;G06F16/3329;;G06F16/3338;;G06F16/9532;;G06F16/9024;;G06F40/35;;G06N3/0455;;G06N3/006;;G06F16/9536;;G06N3/0895,G06F16/9536;;G06N3/0895,,0,0,,,,PENDING
852,WO,A2,WO 2024/243558 A2,133-741-876-178-163,11/28/2024,2024,US 2024/0031108 W,5/24/2024,US 202363504278 P,5/25/2023,IMPLEMENTATION OF GENERATIVE ARTIFICIAL INTELLIGENCE IN OILFIELD OPERATIONS,A method for monitoring a risk to a stability of a wellbore in a subsurface formation includes receiving first input data representing the wellbore or the subsurface formation. The method also includes extracting parameter-value pairs from the first input data. The method also includes determining an expected pore pressure gradient based upon the parameter-value pairs. The method also includes determining an expected fracture gradient based upon the parameter-value pairs. The method also includes determining a mud weight uncertainty profile for the wellbore based upon the expected pore pressure gradient and the expected fracture gradient.,SCHLUMBERGER TECHNOLOGY CORP;;SCHLUMBERGER CA LTD;;SERVICES PETROLIERS SCHLUMBERGER;;GEOQUEST SYSTEMS BV,MASSOT JEROME,,https://lens.org/133-741-876-178-163,Patent Application,yes,0,0,2,133-741-876-178-163;;198-263-797-880-709,WO,2,133-741-876-178-163;;198-263-797-880-709,WO,0,G06N20/00;;E21B44/00;;E21B47/06;;E21B2200/20;;E21B2200/22,E21B44/00;;G06N20/00,,0,0,,,,PENDING
853,US,A1,US 2024/0265205 A1,108-643-774-624-833,8/8/2024,2024,US 202318315789 A,5/11/2023,US 202318315789 A;;US 202363483196 P,2/3/2023,METHODS AND SYSTEMS FOR PARSING A MIX OF FEATURES AND INSTRUCTIONS INTO A PROMPT,"A computer system and computer-implemented method, the method including receiving text input, the text input including feature inputs and prompt instructions; analyzing the text input to identify the feature inputs and the prompt instructions; and generating a prompt to be provided to a Large Language Model (LLM) based on a prompt template, the feature inputs, and the prompt instructions.",SHOPIFY INC,GOLIGORSKY DAVID,SHOPIFY SWEDEN AB (2023-05-26);;SHOPIFY INTERNATIONAL LIMITED (2023-09-27);;SHOPIFY INC (2023-06-30),https://lens.org/108-643-774-624-833,Patent Application,yes,2,7,1,108-643-774-624-833,US,1,108-643-774-624-833,US,0,G06F40/289;;G06F40/205;;G06F40/205;;G06F40/289,G06F40/289;;G06F40/205,,0,0,,,,PENDING
854,WO,A1,WO 2025/083542 A1,019-358-282-789-931,4/24/2025,2025,IB 2024060079 W,10/15/2024,SG 10202302940X A,10/17/2023,SYSTEM AND METHOD FOR AUTOMATICALLY GENERATING EMAIL AND ASSOCIATED EMAIL STRATEGIES,"A method for efficiently generating a plurality of personalized email strategies and corresponding personalized emails for campaign recipients is disclosed. Multi-dimensional data comprising account data, recipient data, and seller data is received from one or more data sources. The received multi-dimensional data is processed to extract relevant features. A dynamic feature hierarchy is generated using the extracted features. A pre-trained machine learning model is fine- tuned using the dynamic feature hierarchy to generate email strategies, wherein model parameters are adjusted based on the hierarchy during fine-tuning. A plurality of email strategies is generated for each recipient by applying the fine-tuned model's recommendations. An email strategy is selected from the plurality of strategies based on one or more factors. A personalized email corresponding to the selected email strategy is generated. The personalized email and the selected email strategy used to generate it are displayed to a user.",6SENSE INSIGHTS INC,TAN MARCEL CHENG WEI;;LIM KEN JYI;;CHAN EDWIN KHAI ERN;;LIM YAO JIE;;WU ZHUOYI;;KEYS JAMES CHRISTOPHER;;RODRIGUEZ GABRIEL MATTHEW GALUPO;;RODRIGUEZ VINCENT JAMES GALUPO;;KIM YUL LEE;;TAN JUN YU,,https://lens.org/019-358-282-789-931,Patent Application,yes,6,0,1,019-358-282-789-931,WO,2,019-358-282-789-931;;040-787-003-950-38X,US;;WO,0,G06N20/00;;G06Q10/107;;G06Q30/01;;G06Q30/0271;;G06Q30/0276,G06Q30/0251;;G06N20/00,,0,0,,,,PENDING
855,WO,A1,WO 2025/067807 A1,018-976-940-869-063,4/3/2025,2025,EP 2024074229 W,8/29/2024,US 202363586404 P;;US 202363541699 P,9/28/2023,ROBOT CONTROL USING TRAJECTORIES,"Systems, methods, and computer program code for controlling a robot that is interacting with an environment to perform a particular task The technique involves generating a 2D trajectory image representing a 2D trajectory sketch. The 2D trajectory sketch indicates a desired trajectory for a part of the robot, e.g. an end effector, when performing the task. A neural network system uses the 2D trajectory image as deliberately underspecified guidance for how to perform the task. Techniques for training the neural network system are also described.",DEEPMIND TECH LTD,GU JIAYUAN;;XIAO TEDDEY MING;;FINN CHELSEA BREANNA;;KIRMANI SEAN ADAM;;VUONG QUAN HO;;HAUSMAN KAROL;;WOHLHART PAUL;;LU YAO;;RAO KANURY KANISHKA;;GONZALEZ ARENAS MONTSERRAT;;FU CHUYUAN;;P G KEERTHANA;;XU ZHUO;;YU WENHAO;;XU PENG;;SUNDARESAN PRIYA ANANDHI,,https://lens.org/018-976-940-869-063,Patent Application,yes,1,0,1,018-976-940-869-063,WO,1,018-976-940-869-063,WO,0,G06V10/82;;B25J9/163;;B25J9/1697;;G05B19/4205;;B25J9/1684;;B25J9/1664;;G05B2219/36436;;G05B2219/36439;;G05B2219/36442;;G05B2219/36441;;G06N3/0455;;G06N3/0464;;G06N3/006;;G06N3/092;;G06N3/096;;G06N3/09;;G06N3/094;;G06N3/0475,B25J9/16;;G05B19/42;;G06N3/045;;G06N3/08;;G06V10/82,,21,1,058-232-745-039-485,10.1109/iccv48922.2021.00180,"JIANG YUNFAN ET AL: ""VIMA: General Robot Manipulation with Multimodal Prompts"", ARXIV (CORNELL UNIVERSITY), 31 October 2022 (2022-10-31), Ithaca, XP093127975, Retrieved from the Internet <URL:https://openreview.net/references/pdf?id=CrIxBNLOCR> [retrieved on 20240206], DOI: 10.48550/arxiv.2210.03094;;WEIMING ZHI ET AL: ""Learning from Demonstration via Probabilistic Diagrammatic Teaching"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 7 September 2023 (2023-09-07), XP091607752;;WEIMING ZHI ET AL: ""Learning Orbitally Stable Systems for Diagrammatically Teaching"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 19 September 2023 (2023-09-19), XP091617411;;ANTHONY BROHAN ET AL: ""RT-1: Robotics Transformer for Real-World Control at Scale"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 13 December 2022 (2022-12-13), XP091393451;;BROHAN ET AL.: ""RT-1: Robotics Transformer for Real-World Control at Scale"", ARXIV:2212.06817V1, 2023;;DRIESS ET AL.: ""PaLM-E: An Embodied Multimodal Language Model"", ARXIV:2303.03378, 2023;;BROHAN ET AL., RT-2: VISION-LANGUAGE-ACTION MODELS TRANSFER WEB KNOWLEDGE TO ROBOTIC CONTROL;;VASWANI ET AL., ARXIV:1706.03762, 2017;;REED ET AL., ARXIV:2205.06175V3, 2022;;DOSOVITSKIY ET AL., ARXIV:2010.11929;;TAN ET AL., ARXIV:1905.11946V5, 2020;;PEREZ ET AL., ARXIV:1709.07871;;RYOO ET AL., TOKENLEARNER, 2021;;LUGARESI ET AL., ARXIV: 1906.08172, 2019;;GU ET AL.: ""Open-vocabulary object detection via vision and language knowledge distillation"", ARXIV:2104.13921, 2021;;KAMATH ET AL.: ""Mdetr-modulated detection for end-to-end multimodal understanding"", ICCV, 2021;;LIANG ET AL.: ""Code as Policies: Language Model Programs for Embodied Control"", ARXIV:2209.07753;;DRIESS ET AL.: ""PaLM-E: An Embodied Multimodal Language Model"", ARXIV:2303.03378;;YU ET AL.: ""Vector-Quantized Image Modeling with Improved VQGAN"", ARXIV:2110.04627;;TAN ET AL., ARXIV:1905.11946;;ABRAMSON ET AL.: ""Creating Multimodal Interactive Agents with Imitation and Self-Supervised Learning"", ARXIV:2112.03762",PENDING
856,US,A1,US 2025/0175497 A1,167-721-488-256-065,5/29/2025,2025,US 202318521888 A,11/28/2023,US 202318521888 A,11/28/2023,DEFENDING LARGE GENERATIVE MODELS FROM PROMPT INJECTION ATTACKS,"This disclosure describes utilizing an attack defense system to improve the defense robustness of a targeted large generative model (LGM) by generating a set of variant prompt injection attacks that are successful against the targeted LGM, where the set of variants is based on a prompt injection attack (e.g., jailbreak) against the targeted LGM or another LGM. For example, the attack defense system utilizes a two-phase framework to generate variant prompt injection attacks and evaluate their attack effectiveness against a targeted LGM. The attack defense system achieves improved variant prompt injection attacks by repeating the two-phase framework and gaining insights from the effectiveness scores of previously generated variants. In addition to generating enhanced variants, the attack defense system generates diverse variants to safeguard the targeted LGM against a broader range of prompt injection attacks that employ more creative and complex styles.",MICROSOFT TECHNOLOGY LICENSING LLC,SALEM AHMED MOHAMED GAMAL;;PAVERD ANDREW JAMES;;KÖPF BORIS ALEXANDER,MICROSOFT TECHNOLOGY LICENSING LLC (2023-11-21),https://lens.org/167-721-488-256-065,Patent Application,yes,0,0,1,167-721-488-256-065,US,1,167-721-488-256-065,US,0,H04L63/1466;;H04L63/1433;;H04L63/1466,H04L9/40,,0,0,,,,PENDING
857,US,A1,US 2025/0077582 A1,186-324-638-158-090,3/6/2025,2025,US 202418408866 A,1/10/2024,US 202418408866 A;;US 202318241487 A,9/1/2023,PROACTIVE DETERMINATION OF DATA INSIGHTS,"Methods, systems, and computer programs are presented for providing contextual suggestions and automated responses to users managing incidents within production or security environments. The system utilizes a combination of user-provided data and contextual analysis to proactively offer solutions and insights without requiring explicit queries from the user. The system integrates out-of-the-box insights, natural language interactions, and remediation flows into a cohesive user experience, incorporating playbooks enhanced by automation while leveraging user data and interaction history to tailor suggestions. The system includes a predictive analysis mechanism that runs analyses on relevant data sources, identifying unusual results and generating potential queries. A large language model (LLM) is integrated for generating questions and analyses, with a ranking system prioritizing insights based on machine learning models. A user interface features a suggestions panel with distinct categories for exploration, refinement, and action, enhancing the user interface with contextually relevant and actionable insights.",SUMO LOGIC INC,TCA BASHYAM;;ANDRZEJEWSKI DAVID M;;REDKAR TEJASWI;;BANSAL AAISHWARYA;;POSHALA ROHITH KUMAR;;HASKELL MICHAEL J;;GHATAK AYAN,SUMO LOGIC INC (2024-01-16),https://lens.org/186-324-638-158-090,Patent Application,yes,0,0,1,186-324-638-158-090,US,4,186-324-638-158-090;;133-584-877-512-630;;087-074-480-093-320;;134-622-671-896-297,US;;WO;;EP,0,G06F16/242;;G06F16/24578;;G06F16/90328;;G06F16/24578;;G06F16/90328,G06F16/9032;;G06F16/2457,,0,0,,,,PENDING
858,US,A1,US 2025/0217598 A1,157-807-958-004-626,7/3/2025,2025,US 202318398200 A,12/28/2023,US 202318398200 A,12/28/2023,MACHINE LEARNING BASED SYSTEMS AND METHODS FOR GENERATING EMAILS,"A machine learning based computing method for generating electronic mails for accounts receivables management is disclosed. The machine learning based computing method includes steps of: receiving inputs from first electronic devices of first users; extracting data associated with second users from databases; retrieving pre-defined electronic mails from electronic mail repositories based on first input associated with the first electronic mails to be generated and second input associated with the second electronic mails to be generated in response to third electronic mails received from second electronic devices of the second users, by a machine learning model; generating augmented prompts for the first electronic mails, and the second electronic mails; generating the first and second electronic mails by the machine learning model, based on the generated augmented prompts; and providing an output of generated first and second electronic mails, to the first users on user interface associated with first electronic devices.",HIGHRADIUS CORP,SAHOO DIBYA PRAKASH;;GUPTA SUMIT;;MISHRA LIPSA;;CHOUDHARY MANISH KUMAR,,https://lens.org/157-807-958-004-626,Patent Application,yes,0,0,1,157-807-958-004-626,US,1,157-807-958-004-626,US,0,G06F40/284;;G06N20/00;;G06F40/289;;G06F40/35;;G06F40/40;;G06F40/40;;G06N20/00;;G06F40/35;;G06F40/284;;G06F40/289,G06F40/40;;G06F40/284;;G06F40/289;;G06F40/35;;G06N20/00,,0,0,,,,PENDING
859,WO,A2,WO 2025/042771 A2,021-650-355-898-371,2/27/2025,2025,US 2024/0042768 W,8/16/2024,US 202363520643 P,8/20/2023,ARTIFICIAL INTELLIGENCE (AI) ASSISTED AUTOMATION OF TESTING IN SOFTWARE ENVIRONMENTS,"Methods and systems for artificial intelligence (Al) assisted automation of testing of a software functionality related to a user intent on a software platform is provided. In one embodiment, the method includes receiving user action data indicating the user intent related to a software platform and generating a human-readable test scenario. The test scenario, which includes a sequence of human-readable testing steps and an expected outcome, is generated using a scenario machine learning (ML) model. The method includes generating an interpretable test script based on the test scenario using a script ML model. The test script is interpreted to implement testing steps on the software platform, generating a test outcome. A human-readable test report is also generated to evaluate the test scenario on the software platform, based on the test outcome and the expected outcome.",ISTARI DIGITAL INC,ROPER WILLIAM;;BENSON CHRISTOPHER;;KRISHNAN SRIRAM;;RMAILEH NAJEM ALDEEN;;SHALABI MOAATH;;BAQAIN ANTOINE;;PAVUR JAMES;;ABUNOJAIM BAHA ALDEEN,,https://lens.org/021-650-355-898-371,Patent Application,yes,0,1,2,189-175-173-383-02X;;021-650-355-898-371,WO,2,189-175-173-383-02X;;021-650-355-898-371,WO,0,G06N20/00,G06N20/00,,0,0,,,,PENDING
860,US,A1,US 2025/0224944 A1,026-730-718-009-548,7/10/2025,2025,US 202418440413 A,2/13/2024,US 202418440413 A;;US 202463618022 P,1/5/2024,CUSTOM CODE ASSISTANT SYSTEM FACILITATING CODE CONVERSION METHODOLOGY,"Systems and methods obtain a translation request accompanying source code of source file(s) for conversion. Formatting of the source code of the source file(s) is verified and the source code is converted to target code that includes target file(s). The converting (i) maps programming language functions of the source code to corresponding programming language functions of the target code and (ii) utilizes, through customized prompt template(s), one or more large language models (LLMs) hosted by a cloud platform during the code conversion, where a source application that uses the source code includes TIBCO™ software. The target file(s) are distributed.",TRUIST BANK,KAVURI KRISHNAVENI;;CARICATO DANIEL;;AUSTRAAT BJORN,,https://lens.org/026-730-718-009-548,Patent Application,yes,0,0,3,136-852-717-545-369;;026-623-082-111-104;;026-730-718-009-548,US,3,026-730-718-009-548;;026-623-082-111-104;;136-852-717-545-369,US,0,G06F21/629;;G06F8/447;;G06F40/30;;G06F8/60;;G06F21/31;;G06F8/51;;G06F11/3688,G06F8/41;;G06F8/71;;G06F11/36,,0,0,,,,PENDING
861,US,A1,US 2024/0403697 A1,065-071-414-245-160,12/5/2024,2024,US 202318205431 A,6/2/2023,US 202318205431 A,6/2/2023,PARALLEL INTERACTION INTERFACE FOR MACHINE LEARNING MODELS,"Certain aspects of the present disclosure provide techniques for parallel interaction with machine learning models. A method includes receiving first data in a first machine learning (ML) model interface window of a parallel interaction user interface, the first window is associated with a first identifier; receiving, within a prompt entry field in a second ML model interface window of the parallel interaction user interface, second data, wherein the second data includes the first identifier; responsive to a presence of the first identifier, generating a first ML model prompt based on the first data and the second data; providing the first ML model prompt to an ML model; receiving, from the ML model, a first model response; and displaying the first model response in the second ML model interface window.",BOLD LTD,NORDFORS DAVID,BOLD LIMITED (2023-07-31),https://lens.org/065-071-414-245-160,Patent Application,yes,0,0,5,091-546-444-998-12X;;022-861-764-993-376;;065-071-414-245-160;;160-333-868-579-094;;107-778-704-373-479,US;;GB;;EP;;AU,5,091-546-444-998-12X;;022-861-764-993-376;;065-071-414-245-160;;160-333-868-579-094;;107-778-704-373-479,US;;GB;;EP;;AU,0,G06N20/00;;G06F9/451;;G06F3/048;;G06F16/3329;;G06F16/90332;;G06F16/90332;;G06N20/00;;G06N20/00,G06N20/00,,0,0,,,,PENDING
862,US,A1,US 2023/0280989 A1,073-578-002-146-732,9/7/2023,2023,US 202217687577 A,3/4/2022,US 202217687577 A,3/4/2022,SYNTHESIZING A COMPUTER PROGRAM TO INCLUDE IDIOMATIC FUNCTION(S) AND SEMANTICALLY-MEANINGFUL VARIABLE(S) USING PROGRAMMING BY EXAMPLE,"Techniques are described herein that are capable of synthesizing a computer program to include idiomatic function(s) and semantically-meaningful variable(s) using programming by example. For instance, an intent of a user to synthesize a computer program to include functionality configured to generate sample output(s) from respective input(s) is determined based at least in part on receipt of the sample input(s) and the respective sample output(s) from the user. Based at least in part on the determined intent, the computer program is synthesized to include the idiomatic function(s) by configuring the idiomatic function(s) to have the target functionality and to conform to a convention of the target domain-specific language associated with a textual representation of the computer program to be displayed to the user. Non-semantically-meaningful variable(s) included among the idiomatic function(s) are replaced with the respective semantically-meaningful variable(s). The textual representation of the computer program is caused to be displayed to the user.",MICROSOFT TECHNOLOGY LICENSING LLC,CAMBRONERO SÁNCHEZ JOSÉ PABLO;;GULWANI SUMIT;;LE VU MINH;;PERELMAN DANIEL;;RADHAKRISHNA ARJUN;;SIMMONS DANIEL GALEN;;SIMON CLINT MICHAEL;;TIWARI ASHISH,MICROSOFT TECHNOLOGY LICENSING LLC (2022-03-03),https://lens.org/073-578-002-146-732,Patent Application,yes,10,1,3,073-578-002-146-732;;194-558-495-734-493;;030-674-006-939-676,US;;WO;;EP,3,030-674-006-939-676;;194-558-495-734-493;;073-578-002-146-732,US;;WO;;EP,0,G06F8/51;;G06F40/211;;G06F40/30;;G06F8/427;;G06F8/436,G06F40/211;;G06F8/41;;G06F40/30,,0,0,,,,PENDING
863,WO,A1,WO 2024/064249 A1,127-383-915-001-199,3/28/2024,2024,US 2023/0033324 W,9/21/2023,US 202263376508 P,9/21/2022,SYSTEMS AND METHODS FOR PROMPT-BASED QUERY GENERATION FOR DIVERSE RETRIEVAL,"An example method for prompt-based query generation is provided. The method includes receiving, by a computing device, at least two prompts associated with a retrieval task to be performed on a corpus of documents associated with the task. The method includes applying, based on the at least two prompts and the corpus of documents, a large language model to generate a synthetic training dataset comprising a plurality of query-document pairs, wherein each query-document pair comprises a synthetically generated query and a document from the corpus of documents. The method includes training, on the plurality of query- document pairs from the synthetic training dataset, a document retrieval model to take an input query associated with the retrieval task and predict an output document retrieved from the corpus of documents. The method includes providing, by the computing device, the trained document retrieval model.",GOOGLE LLC,DAI ZHUYUN;;ZHAO YUZHE;;MA JI;;LUAN YI;;NI JIANMO;;LU JING;;BAKALOV ANTON;;GU KELVIN;;HALL KEITH;;CHANG MING-WEI,,https://lens.org/127-383-915-001-199,Patent Application,yes,1,6,3,032-082-545-745-612;;068-825-574-374-380;;127-383-915-001-199,WO;;EP;;CN,3,032-082-545-745-612;;068-825-574-374-380;;127-383-915-001-199,WO;;EP;;CN,0,G06F16/3344,G06F16/33,,1,0,,,"ZHUYUN DAI ET AL: ""Promptagator: Few-shot Dense Retrieval From 8 Examples"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 23 September 2022 (2022-09-23), XP091326449",PENDING
864,US,A1,US 2024/0256423 A1,050-053-073-490-948,8/1/2024,2024,US 202318159712 A,1/26/2023,US 202318159712 A,1/26/2023,PROGRAM IMPROVEMENT USING LARGE LANGUAGE MODELS,"Some embodiments generate prompts and submit them in queries to a language model trained on code to perform automated program repair. Some embodiments fix syntactic mistakes and semantic mistakes by combining multimodal prompts, iterative querying, test-case-based selection of few-shots, and program chunking. In some cases, edit distance is minimized between an initial flawed program and the automatically created improved version of that program. The initial flawed program is obtained from a programming student, or from a source code generator.",MICROSOFT TECHNOLOGY LICENSING LLC,ZHANG JIALU;;CAMBRONERO SÁNCHEZ JOSÉ PABLO;;ARAUJO SOARES GUSTAVO;;LE VU MINH;;GULWANI SUMIT;;VERBRUGGEN GUST BEN ANNELOES,MICROSOFT TECHNOLOGY LICENSING LLC (2023-01-23),https://lens.org/050-053-073-490-948,Patent Application,yes,8,11,2,174-294-386-356-030;;050-053-073-490-948,US,2,174-294-386-356-030;;050-053-073-490-948,US,0,G06F8/71;;G06F8/42;;G06F11/3608;;G06F11/3608;;G06F8/42;;G06F8/71,G06F11/36;;G06F8/41;;G06F8/71,,1,1,009-208-661-526-318,10.1109/saner.2018.8330219,"Santos et al., ""Syntax and Sensibility:Using Language Models to Detect and Correct Syntax Errors"" (Year: 2018)",ACTIVE
865,US,A1,US 2025/0141769 A1,089-049-476-717-223,5/1/2025,2025,US 202318496346 A,10/27/2023,US 202318496346 A,10/27/2023,Multi-Model Switching and Distributed Multi-Stage Machine Learning to Enhance Field Diagnostics and Services,"Improved solutions that enable more effective and efficient communications with users, in particular with respect to field diagnostics and services. Some solutions can enable users to better communicate with a provider to obtain more useful diagnostic and service information. Certain solutions can employ multi-model switching machine learning techniques to enhance a user's communication with the provider and/or the provider's response.",AVAGO TECH INT SALES PTE LID,LI GORDON;;CHEN XUEMIN,AVAGO TECHNOLOGIES INTERNATIONAL SALES PTE. LIMITED (2023-10-24),https://lens.org/089-049-476-717-223,Patent Application,yes,0,1,3,089-049-476-717-223;;186-254-676-424-723;;046-509-164-392-946,US;;EP;;CN,3,089-049-476-717-223;;186-254-676-424-723;;046-509-164-392-946,US;;EP;;CN,0,H04L41/5061;;H04L41/5074;;H04L41/16;;G10L15/22;;G10L15/30;;G10L15/16;;G10L15/063;;G06N20/00;;G10L2015/0638;;H04W24/04;;H04L41/16;;H04L41/5074;;H04L41/0686;;H04L41/0631;;H04L43/08;;G06N20/20;;H04L41/083;;H04L51/02,H04L43/08;;G06N20/20;;H04L41/083;;H04L51/02,,0,0,,,,PENDING
866,US,A1,US 2025/0245124 A1,006-352-074-571-218,7/31/2025,2025,US 19038670,1/27/2025,,,EVALUATION SYSTEM FOR AGENTIC APPLICATIONS,The subject technology includes an evaluation system for agentic applications. The evaluation system may use one or more evaluation applications to grade the performance of an agentic application based on one or more performance metrics. Scores determined for individual metrics may be combined using a set of weights to tailor the importance of each metric in the overall performance evaluation to a particular industry or application. An optimization engine may improve the performance of target agentic applications that are deficient in one or more metrics by training a portion of the agent application on a training dataset that includes example responses that score well for the one or more metrics where the target applications are deficient.,Zeta Global Corp.,Zachary Jones;;Danny Portman,,https://lens.org/006-352-074-571-218,Patent Application,yes,0,0,1,006-352-074-571-218,US,1,006-352-074-571-218,US,0,G06F11/3608;;G06N3/0475;;G06N3/09,G06F11/3604;;G06N3/0475;;G06N3/09,,0,0,,,,UNKNOWN
867,WO,A2,WO 2024/229082 A2,101-320-610-140-786,11/7/2024,2024,US 2024/0027179 W,5/1/2024,US 202363463149 P,5/1/2023,SEISMIC SURVEY FRAMEWORK,"A method can include accessing a seismic data file for a seismic survey defined in part by a bin grid, where seismic data in the seismic data file are organized according to a data structure that includes headers and seismic trace data; performing an assessment of orthogonality of the bin grid of the seismic data file; responsive to detection of an orthogonality issue by the assessment, determining an orthogonal bin grid; extracting a trace header template using at least one of one or more introductory headers, where the trace header template specifies at least trace locations; performing a validation operation for validation of the trace header template; and, responsive to validation of the trace header template, outputting metadata that comports with the orthogonal bin grid and the validated trace header template for loading of the seismic data file to a data storage system.",SCHLUMBERGER TECHNOLOGY CORP;;SCHLUMBERGER CA LTD;;SERVICES PETROLIERS SCHLUMBERGER;;GEOQUEST SYSTEMS BV,KATOLE ATUL LAXMAN;;ZHAO TAO;;HU WENYI;;ABUBAKAR ARIA;;DOMBROWSKY THOMAS;;GEHRMANN THOMAS;;DAHL ERIK;;CLEMINSON MICHAEL,,https://lens.org/101-320-610-140-786,Patent Application,yes,0,0,2,094-854-943-954-723;;101-320-610-140-786,WO,2,094-854-943-954-723;;101-320-610-140-786,WO,0,G06N20/00;;G01V1/003;;G01V1/24,G01V1/00;;G06N20/00,,0,0,,,,PENDING
868,US,A1,US 2025/0244975 A1,125-888-998-891-414,7/31/2025,2025,US 18428909,1/31/2024,,,USING GENERATIVE AI TO MAKE A NATURAL LANGUAGE INTERFACE,"An operations computing system receives, from a user computing device, initial natural language text input associated with an incident and generates, based on the initial natural language text input, a set of prompts. The operations computing system provides the set of prompts as input to a machine learning model and receives, from the model, text output for each prompt, in which the text output includes a clarifying question or a clarifying instruction. The operations computing system sends, to the user computing device, the text output, and receives, from the user computing device, additional natural language text input. The operations computing system applies the model to the natural language text input to generate respective initial structured text data for each prompt. The operations computing system applies the model to the respective initial structured text data for each prompt to generate updated structured text data including instructions for creating an incident workflow.","PagerDuty, Inc.",Dylan Lingelbach;;Weiyu Max Li;;Justan Fee;;Ralph A. Bird;;Gordon R. Towne;;Nate M. Meierpolys,,https://lens.org/125-888-998-891-414,Patent Application,yes,0,0,1,125-888-998-891-414,US,1,125-888-998-891-414,US,0,G06F8/38;;G06F40/20,G06F8/38;;G06F40/20,,0,0,,,,UNKNOWN
869,US,A1,US 2025/0103305 A1,120-404-497-832-058,3/27/2025,2025,US 202318538895 A,12/13/2023,US 202318538895 A;;US 202363585734 P,9/27/2023,ITERATIVE POLICY-GUIDED PROGRAM SYNTHESIS,"Systems and techniques are described for providing iterative policy-guided program synthesis. For example, a device may generate, based on a policy that receives input-output data of one or more tasks as input, a first set of programs, add the first set of programs and the input-output data to the training dataset to generate an updated training dataset, train the policy based on the first set of programs and the input-output data to generate an updated policy, identify, based on the updated policy, a second set of programs for second input-output data for a second set of tasks, add the second set of programs and second input-output data to the updated training dataset to generate a second updated training dataset; and train the updated policy based on the second set of programs and the second input-output data to generate a second updated policy.",QUALCOMM TECHNOLOGIES INC,BUTT NATASHA;;WIGGERS AUKE JORIS;;RAINONE CORRADO;;MANCZAK BLAZEJ JAKUB;;COHEN TACO SEBASTIAAN,UNIVERSITEIT VAN AMSTERDAM (2024-02-16);;QUALCOMM TECHNOLOGIES INC (2024-04-12);;QUALCOMM INCORPORATED (2024-02-02),https://lens.org/120-404-497-832-058,Patent Application,yes,0,0,1,120-404-497-832-058,US,1,120-404-497-832-058,US,0,G06F8/35;;G06F8/35,G06F8/35,,0,0,,,,PENDING
870,US,A1,US 2024/0412051 A1,033-993-438-840-407,12/12/2024,2024,US 202318207755 A,6/9/2023,US 202318207755 A,6/9/2023,SPARSITY-AWARE NEURAL NETWORK PROCESSING,"Various embodiments discussed herein are directed to improving hardware consumption and computing performance by performing neural network operations on dense tensors using sparse value information from original tensors. Such dense tensors are condensed representations of other original tensors that include zeros or other sparse values. In order to perform these operations, particular embodiments provide an indication, via a binary map, of a position of where the sparse values and non-sparse values are in the original tensors. Particular embodiments additionally or alternatively determine shape data of the original tensors so that these operations are accurate.",MICROSOFT TECHNOLOGY LICENSING LLC,RUAN ZHUO,MICROSOFT TECHNOLOGY LICENSING LLC (2023-06-08),https://lens.org/033-993-438-840-407,Patent Application,yes,0,0,2,033-993-438-840-407;;199-065-881-000-275,US;;WO,2,033-993-438-840-407;;199-065-881-000-275,US;;WO,0,G06N3/063;;G06N3/045;;G06N3/0495;;G06T1/20,G06N3/0495;;G06T1/20,,0,0,,,,PENDING
871,US,B2,US 12148119 B2,028-734-797-961-545,11/19/2024,2024,US 202217576091 A,1/14/2022,US 202217576091 A,1/14/2022,Utilizing a generative neural network to interactively create and modify digital images based on natural language feedback,"The present disclosure relates to systems, non-transitory computer-readable media, and methods that implement a neural network framework for interactive multi-round image generation from natural language inputs. Specifically, the disclosed systems provide an intelligent framework (i.e., a text-based interactive image generation model) that facilitates a multi-round image generation and editing workflow that comports with arbitrary input text and synchronous interaction. In particular embodiments, the disclosed systems utilize natural language feedback for conditioning a generative neural network that performs text-to-image generation and text-guided image modification. For example, the disclosed systems utilize a trained model to inject textual features from natural language feedback into a unified joint embedding space for generating text-informed style vectors. In turn, the disclosed systems can generate an image with semantically meaningful features that map to the natural language feedback. Moreover, the disclosed systems can persist these semantically meaningful features throughout a refinement process and across generated images.",ADOBE INC,ZHANG RUIYI;;ZHOU YUFAN;;TENSMEYER CHRISTOPHER;;GU JIUXIANG;;YU TONG;;SUN TONG,ADOBE INC (2022-01-11),https://lens.org/028-734-797-961-545,Granted Patent,yes,4,0,3,133-344-355-687-780;;028-734-797-961-545;;009-133-597-345-868,US,3,133-344-355-687-780;;028-734-797-961-545;;009-133-597-345-868,US,0,G06T11/00;;G06N3/045;;G06N3/047;;G06T11/60;;G06N3/08;;G06N3/088;;G06N3/084;;G06N3/04;;G06F3/167;;G10L15/26;;G06T11/00;;G10L2015/223;;G10L15/26;;G06N3/04;;G10L15/22;;G06T3/10,G06T5/00;;G06N3/04;;G06T3/10;;G06T5/60;;G06T11/00;;G06T11/80;;G10L15/22;;G10L15/26,,29,18,134-112-254-120-64X;;125-397-527-755-225;;118-513-927-146-674;;054-819-045-052-125;;036-833-936-567-876;;111-214-104-821-363;;171-918-793-283-354;;069-480-623-909-181;;180-753-886-573-784;;180-753-886-573-784;;074-433-853-665-425;;037-124-268-751-356;;051-695-677-264-846;;072-294-402-565-070;;082-688-905-469-704;;082-688-905-469-704;;099-825-369-429-711;;071-833-164-876-589,10.1145/3394171.3413551;;10.1109/iccv.2019.01040;;10.18653/v1/2020.emnlp-main.357;;10.1145/3422622;;10.1109/cvpr.2019.00453;;32012000;;10.1109/tpami.2020.2970919;;10.1109/cvpr42600.2020.00813;;10.1109/cvpr42600.2020.00790;;10.1007/978-3-319-10602-1_48;;10.1109/iccv48922.2021.00209;;10.1109/iccv48922.2021.00209;;10.1109/cvpr46437.2021.01267;;10.1109/cvpr46437.2021.00229;;10.1109/cvpr.2018.00143;;10.1109/cvpr.2014.32;;10.1109/cvpr46437.2021.00089;;10.1109/cvpr46437.2021.00089;;10.1109/cvpr.2018.00068;;10.1109/cvpr.2019.00595,"Cheng, Y.; Gan, Z.; Li, Y.; Liu, J.; and Gao, J. 2020. Sequential attention GAN for interactive image editing. In ACMMM.;;Ding, M.; Yang, Z.; Hong, W.; Zheng, W.; Zhou, C.; Yin, D.; Lin, J.; Zou, X.; Shao, Z.; Yang, H.; and Tang, J. 2021. CogView: Mastering Text-to-Image Generation via Transformers. arXiv:2105.13290.;;El-Nouby, A.; Sharma, S.; Schulz, H.; Hjelm, D.; Asri, L. E.; Kahou, S. E.; Bengio, Y.; and Taylor, G. W. 2019. Tell, draw, and repeat: Generating and modifying images based on continual linguistic instruction. In ICCV.;;Fu, T.-J.; Wang, X.; Grafton, S.; Eckstein, M.; and Wang, W. Y. 2020. Iterative language-based image editing via self-supervised counterfactual reasoning. In EMNLP.;;Goodfellow, I.; Pouget-Abadie, J.; Mirza, M.; Xu, B.; Warde-Farley, D.; Ozair, S.; Courville, A.; and Bengio, Y. 2014. Generative adversarial nets. Advances in neural information processing systems, 27.;;Heusel, M.; Ramsauer, H.; Unterthiner, T.; Nessler, B.; and Hochreiter, S. 2017. Gans trained by a two time-scale update rule converge to a local nash equilibrium. Advances in neural information processing systems, 30.;;Karras, T.; Laine, S.; and Aila, T. 2019. A style-based generator architecture for generative adversarial networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 4401-4410.;;Karras, T.; Laine, S.; Aittala, M.; Hellsten, J.; Lehtinen, J.; and Aila, T. 2020. Analyzing and improving the image quality of stylegan. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 8110-8119.;;Li, B.; Qi, X.; Lukasiewicz, T.; and Torr, P. H. 2020. Manigan: Text-guided image manipulation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 7880-7889.;;Lin, T.- H.; Bui, T.; Kim, D. S.; and Oh, J. 2018. A multimodal dialogue system for conversational image editing.;;Lin, T.-Y.; Maire, M.; Belongie, S.; Hays, J.; Perona, P.; Ramanan, D.; Dollar, P.; and Zitnick, C.L. 2014. Microsoft coco: Common objects in context. In European conference on computer vision, 740-755. Springer.;;Liu, Y.; Li, Q.; Sun, Z.; and Tan, T. 2020. Style Intervention: How to Achieve Spatial Disentanglement with Style-based Generators? arXiv:2011.09699. Part 1.;;Liu, Y.; Li, Q.; Sun, Z.; and Tan, T. 2020. Style Intervention: How to Achieve Spatial Disentanglement with Style-based Generators? arXiv:2011.09699. Part 2.;;Liu, Y.; Li, Q.; Sun, Z.; and Tan, T. 2020. Style Intervention: How to Achieve Spatial Disentanglement with Style-based Generators? arXiv:2011.09699. Part 3.;;Patashnik, O.; Wu, Z.; Shechtman, E.; Cohen-Or, D.; and Lischinski, D. 2021. Styleclip: Text-driven manipulation of stylegan imagery. arXiv preprint arXiv:2103.17249. Part 1.;;Patashnik, O.; Wu, Z.; Shechtman, E.; Cohen-Or, D.; and Lischinski, D. 2021. Styleclip: Text-driven manipulation of stylegan imagery. arXiv preprint arXiv:2103.17249. Part 2.;;Radford, A.; Kim, J. W.; Hallacy, C.; Ramesh, A.; Goh, G.; Agarwal, S.; Sastry, G.; Askell, A.; Mishkin, P.; Clark, J.; et al. 2021. Learning transferable visual models from natural language supervision. arXiv preprint arXiv:2103.00020.;;Ramesh, A.; Pavlov, M.; Goh, G.; Gray, S.; Voss, C.; Radford, A.; Chen, M.; and Sutskever, I. 2021. Zero-shot text- to-image generation. arXiv preprint arXiv:2102.12092.;;Salimans, T.; Goodfellow, I.; Zaremba, W.; Cheung, V.; Radford, A.; and Chen, X. 2016. Improved techniques for training gans. Advances in neural information processing systems, 29: 2234-2242.;;Van den Oord, A.; Vinyals, O.; and Kavukcuoglu, K. 2017. Neural discrete representation learning. In Proceedings of the 31st International Conference on Neural Information Processing Systems, 6309-6318.;;Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A. N.; Kaiser, Ł.; and Polosukhin, I. 2017. Attention is all you need. In NIPS.;;Wu, Z.; Lischinski, D.; and Shechtman, E. 2021. Stylespace analysis: Disentangled controls for stylegan image generation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 12863-12872.;;Xia, W.; Yang, Y.; Xue, J.-H.; and Wu, B. 2021. TediGAN: Text-Guided Diverse Face Image Generation and Manipulation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR).;;Xu, T.; Zhang, P.; Huang, Q.; Zhang, H.; Gan, Z.; Huang, X.; and He, X. 2018. Attngan: Fine-grained text to image generation with attentional generative adversarial networks. In Proceedings of the IEEE conference on computer vision and pattern recognition, 1316-1324.;;Yu, A.; and Grauman, K. 2014. Fine-Grained Visual Comparisons with Local Learning. In Computer Vision and Pattern Recognition (CVPR).;;Zhang, H.; Koh, J. Y.; Baldridge, J.; Lee, H.; and Yang, Y. 2021. Cross-Modal Contrastive Learning for Text-to-Image Generation. arXiv:2101.04702. Part 1.;;Zhang, H.; Koh, J. Y.; Baldridge, J.; Lee, H.; and Yang, Y. 2021. Cross-Modal Contrastive Learning for Text-to-Image Generation. arXiv:2101.04702. Part 2.;;Zhang, R.; Isola, P.; Efros, A. A.; Shechtman, E.; and Wang, O. 2018. The unreasonable effectiveness of deep features as a perceptual metric. In Proceedings of the IEEE conference on computer vision and pattern recognition, 586-595.;;Zhu, M.; Pan, P.; Chen, W.; and Yang, Y. 2019. Dm-gan: Dynamic memory generative adversarial networks for text-to-image synthesis. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 5802-5810.",ACTIVE
872,WO,A1,WO 2025/053989 A1,105-095-890-369-581,3/13/2025,2025,US 2024/0042901 W,8/19/2024,US 202318461865 A,9/6/2023,SECURITY-PRESERVING GENERATION AND PERFORMANCE OF CLOUD ACTIONS,"Methods are provided for leveraging generative artificial intelligence to generate commands and other aspects of modification actions that can be used by users to create, delete, and/or modify virtual machines in a cloud computing environment or to interact with aspects of some other computing environment. The generation and execution of such modification actions can implicate extensive computational and other requirements and may also require the performance of multiple tasks requiring differing levels of access credential. For example, updating a database to reflect changes made to a computing environment by execution of a modification action may require a higher level of credential than performing the changes themselves. The action generation and execution methods described herein allow users with such lower-level credentials to enact such changes while also performing associated database updates or other higher-credential actions.",SERVICENOW INC,BHAT GANESH;;DEVANATHAN RAMKUMAR,,https://lens.org/105-095-890-369-581,Patent Application,yes,5,0,2,158-218-867-350-874;;105-095-890-369-581,US;;WO,2,158-218-867-350-874;;105-095-890-369-581,US;;WO,0,G06F2009/45562;;G06F9/45558;;G06F2009/45562;;G06F9/45558,H04L9/40;;G06F9/455;;G06F16/23;;G06N3/0475;;H04L41/28;;H04L41/40,,0,0,,,,PENDING
873,US,A1,US 2025/0138818 A1,142-779-648-000-216,5/1/2025,2025,US 202318498858 A,10/31/2023,US 202318498858 A,10/31/2023,EFFICIENT GENERATION OF CODE DEVELOPMENT SUMMARIES,"Methods, computer systems, computer-storage media, and graphical user interfaces are provided for efficiently generating code development summaries. In embodiments, commit message data for a commit message associated with code is obtained. In embodiments, the commit message includes a description associated with a corresponding modification in the code. Thereafter, a model prompt to be input into a large language model is generated. The model prompt includes the commit message data. As output from the large language model, a code development summary is obtained that summarizes the commit message data for the commit message associated with the code.",MICROSOFT TECHNOLOGY LICENSING LLC,EDWARDS CRYSTAL ANNAR;;ZOLLINGER CHOHFI ALEXANDRE,MICROSOFT TECHNOLOGY LICENSING LLC (2023-10-31),https://lens.org/142-779-648-000-216,Patent Application,yes,0,0,1,142-779-648-000-216,US,1,142-779-648-000-216,US,0,G06F8/73;;G06F8/71;;G06F8/75;;G06F8/73,G06F8/73,,0,0,,,,PENDING
874,US,A1,US 2025/0131023 A1,136-510-662-882-092,4/24/2025,2025,US 202318492360 A,10/23/2023,US 202318492360 A,10/23/2023,User's Attention Based Context Weighting And Selection For Prompting Large Generative AI Models,"Various embodiments include systems and methods for generating a prompt for a large generative AI model (LXM), such as a large language model (LLM), large speech model (LSM), large/language vision model (LVM), vision language models (VLMs), hybrid model, multi-modal model, etc. A computing device may be equipped with components configured to receive a user's prompt for the LXM, determine a user's attention to the subject matter at the time or prior to receipt of the user's prompt, generate an enhanced prompt based on the user's prompt and the subject matter to which the user is paying attention at the time or prior to receipt of the user's prompt, and submit the enhanced prompt to the LLM.",QUALCOMM INC,SHIM KYUHONG;;YOU JAESEONG;;PARK SUNGHYUN;;LEE GEUNHO;;TAVEIRA MICHAEL FRANCO,QUALCOMM INCORPORATED (2023-11-05),https://lens.org/136-510-662-882-092,Patent Application,yes,6,0,2,136-510-662-882-092;;179-578-169-238-907,US;;WO,2,136-510-662-882-092;;179-578-169-238-907,US;;WO,0,G06F3/013;;G06F2203/0381;;G06F40/284;;G06F40/30;;G06F3/167;;G06F9/453;;G06N3/0475;;G06F40/56;;G06F16/90332;;G06N3/045;;G06N3/044;;G06F16/3334;;G06F16/3344;;G06F16/335;;G06F16/345;;G06F3/013;;G06F3/0412,G06F16/33;;G06F3/01;;G06F3/041;;G06F16/335;;G06F16/34,,0,0,,,,PENDING
875,US,A1,US 2025/0181998 A1,126-436-132-238-501,6/5/2025,2025,US 202318529228 A,12/5/2023,US 202318529228 A,12/5/2023,"SYSTEM, METHOD AND APPARATUS FOR NETWORK SEARCH INCLUDING A CHATBOT","The present specification provides, amongst other things, a novel system, method and apparatus for real time searches. A search engine is provided that generates search parameters based on a natural language conversation with a chatbot. The parameters are parsed into a plurality of portions according to a refinement protocol. At least one of the portions is sent to a first engine for a search, and the results of are transformed using the refinement protocol.",AMADEUS SAS,LORENTE PARAMO ANGEL;;MARTINEZ AVELLANA RAQUEL;;HEREDIA MOTAS DIEGO,AMADEUS S.A.S (2023-11-29),https://lens.org/126-436-132-238-501,Patent Application,yes,0,0,1,126-436-132-238-501,US,1,126-436-132-238-501,US,0,G06F16/9532;;G06F16/256;;G06Q10/025;;G06Q30/0625;;G06F16/24578;;G06Q50/14;;G06F16/24578;;G06F16/9532;;G06Q30/0625;;G06Q10/025;;G06Q50/14;;G06F16/256,G06F16/9532;;G06F16/2457,,0,0,,,,PENDING
876,US,A1,US 2025/0165650 A1,026-971-024-814-419,5/22/2025,2025,US 202418951413 A,11/18/2024,US 202418951413 A;;US 202363600444 P,11/17/2023,SYSTEM AND METHOD FOR PERFORMING ARTIFICIAL INTELLIGENCE GOVERNANCE,"A method for identifying and anonymizing confidential information in input data where the method is performed by at least one computer processor executing computer-readable instructions tangibly stored on at least one computer-readable medium. The method includes extracting one or more of textual data and document data from the input data, wherein the document data includes one or more of second textual data and image data, processing the textual data and the second textual data to identify the confidential information therein, anonymizing the confidential information, processing the image data to identify image-based confidential information therein, and anonymizing the image-based confidential information.",POLYGRAF INC,RAHIMOV YAGUB;;KARUMBAYA VIGNESH;;TAHIROV TOGHRUL;;SHAHBAZZADE VUSAL;;MUKHTAROV YUSIF,POLYGRAF INC (2024-08-06),https://lens.org/026-971-024-814-419,Patent Application,yes,0,0,1,026-971-024-814-419,US,1,026-971-024-814-419,US,0,G06F21/6254;;G06F21/6254,G06F21/62,,0,0,,,,PENDING
877,US,A1,US 2024/0296643 A1,050-967-873-119-101,9/5/2024,2024,US 202418591743 A,2/29/2024,US 202418591743 A;;US 202363576444 P,3/1/2023,USER-INTERACTIVITY ENABLED SEARCH FILTER TOOL POTIMIZED FOR VITUALIZED WORLDS,"Systems, methods, and/or computer readable media for generating representations of searchable experiences in a virtual environment are disclosed. The virtual environment comprising a sector having one or more virtual structures is generated. A position of an avatar in the virtual environment is detected, and based on the detection, a sector data layer comprising data items related to a predetermined dataset is generated. The data items are associated with the sector, and an attribute of the sector is configured and displayed to the user. A second position of the avatar in the virtual environment is detected, and based on the detection, a subset of data using the set of items in the sector data layer is generated. An attribute of the virtual structure within the sector is configured and displayed to the user.",WOODARD JR KENNETH LA VERNE,WOODARD JR KENNETH LA-VERNE,,https://lens.org/050-967-873-119-101,Patent Application,yes,0,1,3,042-691-053-428-211;;114-324-613-596-48X;;050-967-873-119-101,US,3,042-691-053-428-211;;114-324-613-596-48X;;050-967-873-119-101,US,0,G06T19/20;;G06T19/003;;G06T7/70;;G06T2207/20084;;G06T19/20;;G06T2219/2004;;G06T7/70;;G06T19/003,G06T19/20;;G06T7/70;;G06T19/00,,0,0,,,,ACTIVE
878,US,A1,US 2025/0013446 A1,126-126-977-104-966,1/9/2025,2025,US 202418892338 A,9/21/2024,US 202418892338 A;;US 202418641166 A;;US 202318497854 A;;US 202318359843 A;;US 202318124543 A,3/21/2023,FACILITATING UPDATES TO DATA PIPELINES USING MODULARLY-GENERATED PLATFORM-AGNOSTIC DATA PIPELINE PORTIONS SYSTEMS AND METHODS,"Systems and methods for facilitating updates to data pipelines using modularly-generated platform-agnostic data pipeline portions are disclosed. The system receives a user selection of a portion of a data pipeline comprising (i) a set of nodes each indicating a data pipeline component and (ii) a set of links linking the set of nodes. The system then generates a modular-portion of the data pipeline architecture, via a transformation component, based on the user selection and stores the modular-portion of the data pipeline architecture in a remote database. The system then receives an update to at least one node of the set of nodes of the modular-portion of the data pipeline architecture. The system then updates at least a subset of a set of pre-existing data pipelines that use the generated modular-portion of the data pipeline to incorporate the update to the at least one node of the set of nodes.",CITIBANK NA,BENAMU DAVID;;GARDI HILA;;GELBERG MOR;;KARBY HADAR;;KUMAR VAIBHAV;;PANDEY ASHUTOSH;;SILVER MIRIAM,CITIBANK N.A (2024-04-23),https://lens.org/126-126-977-104-966,Patent Application,yes,0,0,3,126-126-977-104-966;;073-770-082-912-061;;182-228-625-529-934,US,9,046-513-230-226-201;;182-228-625-529-934;;022-566-140-256-86X;;126-126-977-104-966;;114-460-879-905-485;;010-538-797-266-989;;137-155-381-118-883;;073-770-082-912-061;;115-298-376-575-991,US;;GB,0,G06F8/4452;;G06F21/577;;G06F21/577;;G06F8/4452,G06F8/41;;G06F21/57,,0,0,,,,PENDING
879,US,A1,US 2025/0147957 A1,046-672-054-018-603,5/8/2025,2025,US 202418935017 A,11/1/2024,US 202418935017 A;;US 202363547840 P,11/8/2023,ACCURACY AND PROVIDING EXPLAINABILITY AND TRANSPARENCY FOR QUERY RESPONSE USING MACHINE LEARNING MODELS,"The implementations herein disclose advanced systems and methods for integrating, analyzing, and reasoning over heterogeneous data at scale. In some implementations, the system comprises a synergistic data processing infrastructure featuring: a graph database core for unified data representation; specialized loaders for concurrent ingestion and processing of structured, unstructured, and time series data; a natural language reasoning engine leveraging large language models; and a multi-modal user interface.",DATA SQUARED USA INC,VERKRUYSE MICHAEL AUGUST;;DALGLIESH JEFFREY JAMES;;BREWTON JON TRAVIS;;ELKHOLY ALEXANDER;;MITTAL ASHMITA,DATA SQUARED (2024-11-05),https://lens.org/046-672-054-018-603,Patent Application,yes,0,0,2,036-396-989-826-875;;046-672-054-018-603,US,2,036-396-989-826-875;;046-672-054-018-603,US,0,G06F16/24522;;G06F16/288;;G06F16/9024;;G06F16/243;;G06F16/288;;G06F16/24522,G06F16/2452;;G06F16/28,,0,0,,,,ACTIVE
880,WO,A1,WO 2025/119887 A1,001-111-398-198-609,6/12/2025,2025,EP 2024084461 W,12/3/2024,US 202363605819 P,12/4/2023,HANDSFREE DOCUMENTATION OF PHARMACEUTICAL OPERATIONS USING AN EXTENDED REALITY DEVICE,"Documentation of pharmaceutical operations is typically performed as a combination of paper and electronic records. As a result of good manufacturing practice guidelines, operators constantly move between reading, executing, and documenting. The present disclosure describes a method of handsfree accessing and updating of data during execution of operations, using an extended reality (XR) device. The XR device enables verification of an operator's identity, and connection to a private cloud. A task is initiated by the operator or a third-party user, and the task identifier is sent to the cloud. The cloud retrieves and sends the associated data cluster. The display-only fields of the data cluster are displayed on the screen. The editable fields of the data cluster are presented in specific forms, and the operator uses voice commands to fill in each field. The software sends the updated data cluster to the cloud to replace the original data cluster.",BIONTECH SE,SOMMER SIMON;;SPANNENBERGER RITA;;BRUNEN MANFRED JOSEPH,,https://lens.org/001-111-398-198-609,Patent Application,yes,3,0,1,001-111-398-198-609,WO,1,001-111-398-198-609,WO,0,G06F3/167,G06F3/16,,0,0,,,,PENDING
881,US,A1,US 2025/0232351 A1,082-661-133-469-367,7/17/2025,2025,US 202418412329 A,1/12/2024,US 202418412329 A,1/12/2024,PRODUCT RECOMMENDATION BASED ON CONNECTED PROFILE,"An example operation includes one or more of connecting a local user profile hosted within a software application hosted by a first platform with a profile hosted by a data source on a second platform, extracting a first set of profile features from the profile hosted by the data source and a second set of profile features from the local user profile, determining a new profile feature to add to the local user profile based on the execution of an artificial intelligence (AI) model on a combination of the first and second sets of profile features, and displaying information about the new profile feature on a user interface of the first or second platform.",TORONTO DOMINION BANK,TAO LINDA LING;;PANDEY ANAND;;TRIVEDI PRERAK;;LEE JOHN JONG-SUK,,https://lens.org/082-661-133-469-367,Patent Application,yes,0,0,1,082-661-133-469-367,US,1,082-661-133-469-367,US,0,G06Q30/0631;;H04L63/102;;G06Q30/0641,G06Q30/0601;;H04L9/40,,0,0,,,,PENDING
882,US,A1,US 2025/0232375 A1,041-674-643-845-380,7/17/2025,2025,US 202418412285 A,1/12/2024,US 202418412285 A,1/12/2024,PREDICTING GRAPHICAL USER INTERFACE DATA THAT IS MISSING,"An example operation includes one or more of ingesting profile data of a user from an external data source, identifying a plurality of features of a profile hosted by the external data source based on an execution of an artificial intelligence (AI) model on the ingested profile data of the user from the external data source, identifying a feature from among the plurality of features of the profile hosted by the external data source that is not connected to a local user profile of the user, and displaying a connection request on a user interface, wherein the connection request includes a link to a page associated with the identified feature hosted by the external data source.",TORONTO DOMINION BANK,TAO LINDA LING;;PANDEY ANAND;;TRIVEDI PRERAK;;LEE JOHN JONG-SUK,,https://lens.org/041-674-643-845-380,Patent Application,yes,0,0,1,041-674-643-845-380,US,1,041-674-643-845-380,US,0,G06Q40/06,G06Q40/06,,0,0,,,,PENDING
883,US,A1,US 2024/0320424 A1,192-711-298-281-363,9/26/2024,2024,US 202418611634 A,3/20/2024,US 202418611634 A;;US 202363453468 P,3/20/2023,SYSTEMS AND METHODS FOR OPTIMIZING LANGUAGE MODELS BASED ON USER CONTEXT,"The subject technology uses context models to improve the performance of language models. The technology may introduce one or more context insights into the prompts for language models to personalize the outputs of the language models for particular users. The context insights may include consumer dimensions determined based on identity data for a user. The consumer dimensions may be generated using machine learning techniques that are applied to consumer data, event data, and transaction data. A unique context model may be trained for each consumer dimension to increase the accuracy and specificity of the context models. The personalized content generated by the language models may be included in a piece of content published on a publication network. The performance the language models may be optimized based on the performance of the published content.",ZETA GLOBAL CORP,GORE NEEJ;;SHEN WINNIE,,https://lens.org/192-711-298-281-363,Patent Application,yes,0,0,1,192-711-298-281-363,US,1,192-711-298-281-363,US,0,G06F40/20;;G06F40/30;;G06F40/20,G06F40/20,,0,0,,,,PENDING
884,US,A1,US 2025/0209700 A1,109-274-975-780-619,6/26/2025,2025,US 202418981120 A,12/13/2024,US 202418981120 A;;US 202363613658 P,12/21/2023,DIFFUSION-BASED PERSONALIZED ADVERTISING IMAGE GENERATION,"A system has a server to train an artificial intelligence model on training data characterizing a good or service to form a trained model. A client device is associated with a user. The client device executes instructions on a processor to receive the trained model via a network connection to the server, collect user data and obtain a personalized digital image advertisement from the trained model and user data. The personalized digital image advertisement includes a synthetic digital image formed by a trained machine learning model. The personalized digital image advertisement is transformed with fine-grained image control modifications, quality assurance operations, and branding assurance operations to form a final personalized digital image advertisement. The final personalized digital image advertisement is presented on the client device.",IKIN INC,WESTCOTT BRYAN LLOYD;;FOX BLAKE;;VELA CHRISTOPHER HENRY;;STIEFELMAIER JAMES CHARLES;;TIPTON KRISTY;;ROMERO RICHIE;;COLEMAN DUSTY;;XIONG SEE,IKIN INC (2024-12-17),https://lens.org/109-274-975-780-619,Patent Application,yes,10,0,1,109-274-975-780-619,US,1,109-274-975-780-619,US,0,G06T2207/20081;;G06T2207/20084;;G06T11/60;;G06Q30/0204;;G06Q30/0271;;G06T11/60;;G06T5/60;;G06T5/77;;G06T2207/20081;;G06Q30/0271;;G06Q30/0204;;G06T2207/20084;;G06T7/11,G06T11/60;;G06Q30/0204;;G06Q30/0251;;G06T5/60;;G06T5/77;;G06T7/11,,0,0,,,,PENDING
885,US,B1,US 12347573 B1,186-071-673-213-814,7/1/2025,2025,US 202418902532 A,9/30/2024,US 202418902532 A;;US 202418823175 A,9/3/2024,Artificial intelligence (AI) to create a patient visit note based on a conversation between a doctor and a patient,"In some aspects, an artificial intelligence (AI) performs an analysis of a conversation between a doctor and a patient, determines a first trigger phrase in the conversation, and determines a template of a patient visit note based on the first trigger phrase. The AI determines a second trigger phrase in the conversation, determines a particular treatment plan from a plurality of treatment plans based on the second trigger phrase, and adds the particular treatment plan to the template. A first instance of the AI adds a first portion of the conversation to the template and a second instance of the AI, in parallel with the first portion of the conversation being added to the template, adds a second portion of the conversation to the template. The AI provides the template of the patient visit note to a device associated with the doctor.",SULLY AI,GHARPURE CHAITANYA;;OMAR AHMED;;NASSER AHMED,,https://lens.org/186-071-673-213-814,Granted Patent,yes,14,0,1,186-071-673-213-814,US,2,186-071-673-213-814;;078-646-442-871-034,US,0,G16H10/60;;G16H15/00;;G16H50/20;;G16H80/00;;G16H20/00;;G16H80/00;;G16H20/00;;G16H10/60;;G16H15/00,G16H80/00;;G16H10/60;;G16H15/00;;G16H20/00,,7,0,,,"Malgaroli et al., Natural language processing for mental health interventions: a systematic review and research framework, Oct. 6, 2023, Translational Psychiatry, pp. 1-17 (Year: 2023).;;Biao et al, Root Mean Square Layer Normalization, School of Informatics, University of Edinburgh, Retrieved on Jun. 6, 2024, 12 pages. [NeurIPS 2019].;;Gao et al. Retrieval-Augmented Generation for Large Language Models: A Survey, Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University, Mar. 27, 2024, 21 pages. [Url: arXiv:2312.10997].;;Karan et al, Large Language Models Encode Clinical Knowledge, Google Research, Dec. 26, 2022, 44 pages. [arXiv:2212.13138].;;Peter et al, Benefits, Limits, and Risks of GPT-4 as an AI Chatbot for Medicine. The New England Journal of Medicine, Mar. 30, 2023, 7 pages [N ENGL MED 388;13].;;Tao et al, Towards Conversational Diagnostic AI, Google Research, Jan. 11, 2024, 46 pages. [arXiv:2401.05654].;;Yu et a,l. Leveraging Generative AI and Large Language Models: AComprehensive Roadmap for Healthcare Integration, Oct. 20, 2023, Healthcare, pp. 1-19. (Year: 2023).",ACTIVE
886,US,A1,US 2025/0124024 A1,171-098-701-022-691,4/17/2025,2025,US 202318488544 A,10/17/2023,US 202318488544 A,10/17/2023,GENERATED CONTENT SOURCE,"A large language model (LLM) may receive a query via a user interface of a client device. The LLM may generate one or more data queries from the query to query one or more data sets. The LLM may then transmit the one or more data queries to the one or more data sets. The LLM may then receive information associated with the query and a source for the information from the one or more data sets. The source may be indicative of a location within the one or more data sets from where the information was obtained. Following, the LLM may generate a response to the query that includes the information associated with the query and the source for the information and transmit the response to the user interface of the client device for display.",SALESFORCE INC,KIRK DUSTIN ALLEN,SALESFORCE.COM INC (2023-09-26),https://lens.org/171-098-701-022-691,Patent Application,yes,10,0,1,171-098-701-022-691,US,1,171-098-701-022-691,US,0,G06F16/243;;G06F21/602;;G06F16/248;;G06F16/243;;G06F21/602;;G06F16/248,G06F16/242;;G06F16/248;;G06F21/60,,0,0,,,,PENDING
887,US,A1,US 2025/0181324 A1,158-778-374-587-609,6/5/2025,2025,US 202418920561 A,10/18/2024,KR 20230173446 A;;KR 2024014494 W,12/4/2023,ELECTRONIC DEVICE AND METHOD FOR PROVIDING CODE BY USING GENERATIVE ARTIFICIAL INTELLIGENCE MODEL,"Provided are an electronic device and a method implemented by the electronic device for providing code by using a generative artificial intelligence (AI) model. The method may include obtaining a user input corresponding to a first document, based on the user input, obtaining first context information available for code generation, based on the first context information and the user input, generating a first prompt for the code generation, based on a length of the first prompt, selecting, from the first context information, second context information according to priority information, based on the second context information and the user input, generating a second prompt corresponding to the first prompt, transmitting the first prompt or the second prompt to a server; and receiving, from the server, recommended code generated through the generative AI model based on the first prompt or the second prompt and providing the recommended code.",SAMSUNG ELECTRONICS CO LTD,LEE KANGWOOK,SAMSUNG ELECTRONICS CO. LTD (2024-09-06),https://lens.org/158-778-374-587-609,Patent Application,yes,0,0,1,158-778-374-587-609,US,3,095-430-027-358-800;;146-295-285-765-694;;158-778-374-587-609,US;;WO;;KR,0,G06F8/35;;G06F40/40;;G06F8/30;;G06F40/40;;G06F8/35,G06F8/35;;G06F40/40,,0,0,,,,PENDING
888,WO,A1,WO 2025/085483 A1,059-055-576-189-344,4/24/2025,2025,US 2024/0051517 W,10/16/2024,US 202363591297 P,10/18/2023,DRILLING EVENT REMEDIATION FRAMEWORK,"A method may include receiving a description of an event occurring at a wellsite; extracting a failure mode from the description using a fine-tuned large language model (LLM); identifying a matching failure mode from historical data processed using the fine-tuned LLM, where the matching failure mode is associated with one or more remedial actions that successfully resolved the matching failure mode; and outputting the one or more remedial actions for implementation at the wellsite.",SCHLUMBERGER TECHNOLOGY CORP;;SCHLUMBERGER CA LTD;;SERVICES PETROLIERS SCHLUMBERGER;;GEOQUEST SYSTEMS BV,GUILLOT VALERIAN;;SHARMA ARVIND;;NAFI MOHAMED KHALIL;;WU JING;;RUZHNIKOV ALEXEY,,https://lens.org/059-055-576-189-344,Patent Application,yes,3,0,2,156-375-678-557-944;;059-055-576-189-344,US;;WO,2,156-375-678-557-944;;059-055-576-189-344,US;;WO,0,E21B21/00;;E21B41/00;;G06F40/30;;E21B2200/22;;G06N3/0455;;G06N3/096;;G06N3/0475,E21B21/00;;E21B41/00;;G06F40/30,,3,3,106-713-120-031-009;;122-602-615-620-823;;184-117-925-305-562,10.2118/216267-ms;;10.2118/209870-ms;;10.2118/216336-ms,"SINGH AJAY ET AL: ""Generative AI Enabled Conversational Chatbot for Drilling and Production Analytics"", AMAZON WEB SERVICES, HOUSTON, TX, USA, 2 October 2023 (2023-10-02), XP093233259, Retrieved from the Internet <URL:https://onepetro.org/SPEADIP/proceedings-pdf/doi/10.2118/216267-MS/3274110/spe-216267-ms.pdf> DOI: 10.2118/216267-MS;;RUZHNIKOV ALEXEY ET AL: ""Development and Application of Digital Solutions for Automatic Hazard Identification During Well Planning Stage"", SCHLUMBERGER, 8 August 2022 (2022-08-08), pages 1 - 7, XP093233246, Retrieved from the Internet <URL:https://onepetro.org/SPEAPDT/proceedings-pdf/doi/10.2118/209870-MS/4106057/spe-209870-ms.pdf> DOI: 10.2118/209870-MS;;ABIJITH P Y ET AL: ""Large Language Models Trained on Equipment Maintenance Text"", EXXONMOBIL SERVICES AND TECHNOLOGY PRIVATE LTD., BENGALURU, KARNATAKA, INDIA, 2 October 2023 (2023-10-02), XP093233262, Retrieved from the Internet <URL:https://onepetro.org/SPEADIP/proceedings-pdf/doi/10.2118/216336-MS/3274541/spe-216336-ms.pdf> DOI: 10.2118/216336-MS",PENDING
889,US,B1,US 12254966 B1,078-646-442-871-034,3/18/2025,2025,US 202418823175 A,9/3/2024,US 202418823175 A,9/3/2024,Artificial intelligence (AI) to provide decision support insights including while a doctor is engaged in conversation with a patient,"In some aspects, orchestration logic is configured to receive, from a multi-modal interface, an upstream conversation between a doctor and a patient, provide, to at least one large language model (LLM), the upstream conversation and the patient's medical history, and cause the LLM to generate raw decision support insights. The LLM generates the raw decision support insights based at least in part on the upstream conversation and the patient's medical history. Real-time decision support logic is configured to: transform the raw decision support insights into prioritized, conversation-responsive decision support insights. The prioritized, conversation-responsive decision support insights are prioritized based on medical urgency. Presentation of the prioritized, conversation-responsive decision support insights to the doctor is responsive to downstream conversation between the patient and the doctor. The prioritized, conversation-responsive decision support insights are delivered to the multi-modal interface for presentation to the doctor.",SULLY AI,GHARPURE CHAITANYA;;OMAR AHMED;;NASSER AHMED,SULLY.AI (2024-09-01),https://lens.org/078-646-442-871-034,Granted Patent,yes,11,0,1,078-646-442-871-034,US,2,186-071-673-213-814;;078-646-442-871-034,US,0,G16H15/00;;G16H80/00;;G16H50/20;;G16H10/60;;G16H80/00;;G16H15/00,G16H15/00;;G16H80/00,,6,2,062-310-958-646-735;;138-347-338-635-749,pmc10606429;;10.3390/healthcare11202776;;37893850;;10.1056/nejmc2305286;;37342941;;37342939;;37342940,"Yu et al., Leveraging Generative AI and Large Language Models: A Comprehensive Roadmap for Healthcare Integration, Oct. 20, 2023, Healthcare, pp. 1-19. (Year: 2023).;;Biao et al, Root Mean Square Layer Normalization, School of Informatics, University of Edinburgh, Retrieved on Jun. 6, 2024, 12 pages. [NeurIPS 2019].;;Gao et al. Retrieval-Augmented Generation for Large Language Models: A Survey, Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University, Mar. 27, 2024, 21 pages. [Url: arXiv:2312.10997].;;Karan et al, Large Language Models Encode Clinical Knowledge, Google Research, Dec. 26, 2022, 44 pages. [arXiv:2212.13138].;;Peter et al, Benefits, Limits, and Risks of GPT-4 as an AI Chatbot for Medicine. The New England Journal of Medicine, Mar. 30, 2023, 7 pages [N Engl Med 388;13].;;Tao et al, Towards Conversational Diagnostic AI, Google Research, Jan. 11, 2024, 46 pages. [arXiv:2401.05654].",ACTIVE
890,US,A1,US 2025/0231774 A1,157-954-214-604-696,7/17/2025,2025,US 202418412116 A,1/12/2024,US 202418412116 A,1/12/2024,MEMORIALIZING A GRAPHICAL USER INTERFACE WITH GENERATIVE ARTIFICIAL INTELLIGENCE,"An example operation includes one or more of rendering a graphical user interface within a software application including a plurality of elements, modifying locations of the plurality of elements within the graphical user interface based on user inputs on the graphical user interface, generating a dynamic mapping of the graphical user interface including the modified locations of the plurality of elements based on an execution of an artificial intelligence (AI) model on the rendered graphical user interface, and storing the dynamic mapping of the graphical user interface within a storage.",TORONTO DOMINION BANK,TAO LINDA LING;;PANDEY ANAND;;TRIVEDI PRERAK;;LEE JOHN JONG-SUK,,https://lens.org/157-954-214-604-696,Patent Application,yes,0,0,1,157-954-214-604-696,US,1,157-954-214-604-696,US,0,G06F9/451;;G06F3/0484;;G06F3/0482,G06F9/451;;G06F3/0482;;G06F3/0484,,0,0,,,,PENDING
891,US,A1,US 2025/0231775 A1,106-542-524-948-944,7/17/2025,2025,US 202418412255 A,1/12/2024,US 202418412255 A,1/12/2024,DYNAMIC PRESENTATION OF GRAPHICAL USER INTERFACE CONTENT WITH GENERATIVE ARTIFICIAL INTELLIGENCE,"An example operation includes one or more of establishing a communication session between a first user device and a second user device from among the plurality of user devices, training an artificial intelligence (AI) model to learn user interface preferences of a plurality of user devices during the communication session, receiving a description associated with the communication session, generating a plurality of windows of content and displaying the plurality of windows of content on a user interface of the first user device during the communication session based on execution of the AI model on the description associated with the communication session, and generating a second plurality of windows of content and displaying the second plurality of windows of content on a user interface of the second user device based on an execution of the AI model on the description associated with the communication session.",TORONTO DOMINION BANK,TAO LINDA LING;;PANDEY ANAND;;TRIVEDI PRERAK;;LEE JOHN JONG-SUK,,https://lens.org/106-542-524-948-944,Patent Application,yes,0,0,1,106-542-524-948-944,US,1,106-542-524-948-944,US,0,G06F9/451,G06F9/451,,0,0,,,,PENDING
892,US,A1,US 2025/0068671 A1,016-265-307-862-33X,2/27/2025,2025,US 202318515995 A,11/21/2023,US 202318515995 A;;US 202363520785 P,8/21/2023,MACHINE LEARNING TECHNIQUES FOR CLASSIFYING DOCUMENT DATA OBJECTS,"Various embodiments of the present disclosure provide methods, apparatus, systems, computing devices, computing entities, and/or the like for identifying one or more evidence text portions comprising one or more bases relied on by a generative machine learning model for assigning a plurality of model-assigned categorical identifiers to a plurality of text segment data objects associated with a document data object, and verifying the one or more evidence text portions with a verifier machine learning model to generate one or more classifications of the document data object and provide the one or more verified evidence text portions along with the one or more classifications.",OPTUM INC,YANG ZHICHAO;;STREMMEL JOEL DAVID;;BATRA SANJIT SINGH;;HALPERIN ERAN,OPTUM INC (2023-10-23),https://lens.org/016-265-307-862-33X,Patent Application,yes,0,0,1,016-265-307-862-33X,US,1,016-265-307-862-33X,US,0,G06F16/355;;G16H50/20;;G06F40/289;;G06F16/355;;G16H50/20;;G06F40/289,G06F16/35;;G06F40/289;;G16H50/20,,0,0,,,,PENDING
893,US,A1,US 2025/0103965 A1,048-773-793-612-310,3/27/2025,2025,US 202418971998 A,12/6/2024,US 202418971998 A,12/6/2024,ARTIFICIAL INTELLIGENCE MODEL PROMPT ADAPTATION IN PROGRAMMABLE NETWORK INTERFACE DEVICES,"An apparatus includes a host interface, a network interface, and programmable circuitry communicably coupled to the host interface and the network interface, the programmable circuitry comprising one or more processors are to implement network interface functionality and are to receive a prompt directed to an artificial intelligence (AI) model hosted by a host device communicably coupled to the host interface, apply a prompt tuning model to the prompt to generate an initial augmented prompt, compare the initial augmented prompt for a match with stored data of a prompt augmentation tracking table comprising real-time datacenter trend data and cross-network historical augmentation data from programmable network interface devices in a datacenter hosting the apparatus, generate, in response to identification of the match with the stored data, a final augmented prompt based on the match, and transmit the final augmented prompt to the AI model.",INTEL CORP,KUMAR KARTHIK;;CARRANZA MARCOS;;WILLHALM THOMAS;;CONNOR PATRICK,INTEL CORPORATION (2024-12-03),https://lens.org/048-773-793-612-310,Patent Application,yes,0,0,1,048-773-793-612-310,US,1,048-773-793-612-310,US,0,G06F16/3344;;G06N20/00;;G06N3/006;;G06F16/3344;;G06N20/00,G06N20/00;;G06F16/334,,0,0,,,,PENDING
894,US,A1,US 2025/0053876 A1,046-131-114-146-876,2/13/2025,2025,US 202418800900 A,8/12/2024,US 202418800900 A;;US 202363532199 P;;US 202363588591 P;;US 202363598879 P,8/11/2023,PROMPT ROUTING SYSTEM AND METHOD,"In variants, the method can include determining training data, determining a router, and using the router. In variants, using the router can include receiving a runtime prompt, predicting performance scores for the runtime prompt for each of a set of candidate models, optionally predicting operational metrics for responding to the runtime prompt for each of the set of candidate models, selecting a candidate model based on the predicted performance scores and optionally the predicted operational metrics, and optionally determining a response based on the runtime prompt.",MARTIAN LEARNING INC,UPADHYAY SHRIYASH K;;GINSBERG ETAN J;;ZIDON DORY,MARTIAN LEARNING INC (2024-08-20),https://lens.org/046-131-114-146-876,Patent Application,yes,8,0,3,038-693-619-617-746;;046-131-114-146-876;;064-136-465-571-175,US;;WO,3,064-136-465-571-175;;046-131-114-146-876;;038-693-619-617-746,US;;WO,0,G06N20/00;;G06N3/006;;G06N20/00,G06N20/00,,0,0,,,,ACTIVE
895,US,A1,US 2025/0232376 A1,095-835-337-696-085,7/17/2025,2025,US 202418412299 A,1/12/2024,US 202418412299 A,1/12/2024,DISPLAY RECOMMENDATIONS BASED ON SIMILARITY OF CONTENT,"An example operation includes one or more of storing portfolio content from a plurality of users, receiving a portfolio of a user during a call, determining that the user is similar to a subset of users from among the plurality of users based on execution of an artificial intelligence (AI) model on the portfolio of the user and the portfolio content from the plurality of users, identifying an item that is included in portfolios of the subset of users which is not included in the portfolio of the user, and displaying content about the item on a user interface.",TORONTO DOMINION BANK,TAO LINDA LING;;PANDEY ANAND;;TRIVEDI PRERAK;;LEE JOHN JONG-SUK,,https://lens.org/095-835-337-696-085,Patent Application,yes,0,0,1,095-835-337-696-085,US,1,095-835-337-696-085,US,0,G06Q40/06,G06Q40/06,,0,0,,,,PENDING
896,US,A1,US 2024/0249081 A1,153-093-164-665-265,7/25/2024,2024,US 202418421353 A,1/24/2024,US 202418421353 A;;US 202363441057 P,1/25/2023,METHOD AND SYSTEM FOR AUTOMATED CUSTOMIZED CONTENT GENERATION FROM EXTRACTED INSIGHTS,"Disclosed embodiments may provide techniques for generating customizable content based on extracted insights. A computer-implemented method can include accessing input data that includes initial content. The computer-implemented method can also include determining a content format of customized content to be generated by processing the input data. In some instances, the content format specifies how the customized content is to be formatted for a target recipient. The computer-implemented method can also include generating one or more prompts to be processed by a content machine-learning model for generating the customized content. The one or more prompts can be generated based on the input data and the content format. The computer-implemented method can also include applying the content machine-learning model to the one or more prompts to generate the customized content. The computer-implemented method can also include outputting the customized content.",SOCIALTRENDLY INC D/B/A BLACKBIRD AI,UZZAMAN NAUSHAD;;BURKARD PAUL;;WISSINGER JOHN;;KHALED WASIM,SOCIALTRENDLY INC. D/B/A BLACKBIRD.AI (2024-01-26),https://lens.org/153-093-164-665-265,Patent Application,yes,0,8,1,153-093-164-665-265,US,1,153-093-164-665-265,US,0,G06F40/40;;G06F40/40;;G06F16/245,G06F40/40,,0,0,,,,PENDING
897,US,A1,US 2025/0231668 A1,122-017-773-611-407,7/17/2025,2025,US 202418412076 A,1/12/2024,US 202418412076 A,1/12/2024,ECHOING A DISPLAY OF CONTENT BASED ON FAMILIARITY OF CONTENT TYPE,"An example operation includes one or more of logging user actions with respect to placement of objects of content on a user interface including respective content types of the objects of content, training an artificial intelligence (AI) model to learn location preferences for a content type on the user interface based on the logged user actions including the respective content types, receiving a request to open an object on the user interface with the content type, determining a display location on the user interface for the object based on execution of the AI model on the content type, and displaying the object at the determined display location on the user interface.",TORONTO DOMINION BANK,TAO LINDA LING;;PANDEY ANAND;;TRIVEDI PRERAK;;LEE JOHN JONG-SUK,,https://lens.org/122-017-773-611-407,Patent Application,yes,0,0,1,122-017-773-611-407,US,1,122-017-773-611-407,US,0,G06F3/0484;;G06T7/70;;G06T2207/20092;;G06T2207/20081;;G06T2200/24;;G06T7/20,G06F3/0484;;G06T7/20;;G06T7/70,,0,0,,,,PENDING
898,US,B1,US 12210949 B1,037-391-572-754-742,1/28/2025,2025,US 202418781985 A,7/23/2024,US 202418781985 A;;US 202318535001 A,12/11/2023,Systems and methods for detecting required rule engine updated using artificial intelligence models,"The systems and methods provide a model deployment criterion. The model deployment criterion indicates a difference in a value against which the proxy model may be measured to determine when, if ever, the proxy model should be deployed to replace the existing rule engine. The model deployment criterion may be keyed to the proxy model (e.g., based on a difference in its size, throughput speed, number of changes, etc.), the existing rule engine (e.g., based on a difference in its age, update occurrences to its rule base, etc.), and/or comparisons between models (e.g., based on differences in results, throughput speed, efficiency, etc.).",CITIBANK NA,SILVER MIRIAM;;MYERS JAMES,CITIBANK N.A (2024-07-22),https://lens.org/037-391-572-754-742,Granted Patent,yes,30,2,2,193-633-581-788-608;;037-391-572-754-742,US,9,029-896-635-687-836;;153-832-473-000-677;;193-633-581-788-608;;008-197-963-435-473;;095-237-791-646-678;;075-469-762-619-491;;088-458-232-557-850;;064-693-030-404-249;;037-391-572-754-742,US;;WO;;EP,0,G06F8/60;;G06F8/77;;G06N5/025;;G06N20/00;;G06N20/20;;G06N20/20,G06N20/20,,6,6,021-518-970-532-517;;122-032-890-311-118;;068-631-189-807-914;;164-595-711-832-843;;141-992-154-799-079;;072-929-642-951-014,10.1145/3660853.3660877;;10.1109/iotaai62601.2024.10692405;;10.1145/3672456;;10.1145/3468264.3478688;;10.1109/icse.2005.1553639;;10.1109/tefse.2013.6620155,"Idrizi “Exploring the Role of Explainable Artificial Intelligence(XAI) in Adaptive learning systems”, ACM, pp. 100-105 (Year: 2024).;;Wang et al, “Design and realization of distributed Rule Engine for scene linkage of Internet of Things”, IEEE, pp. 396-401 (Year: 2024).;;Jiang et al., “Self-Planning Code Generation with Large Language Models”, ACM, pp. 1-30 (Year: 2024).;;Mezini, Programming and Execution Models for Next Generation Code Intelligence Systems (Keynote), ACM, pp. 1-2 (Year: 2021).;;Ge et al, “Automatic Generation of Rule-based Software Configuration Management Systems”, ACM, pp. 659 (Year: 2005).;;Guana et al, “Backward Propagation of Code Refinements on Transformational Code Generation Environments”, IEEE, pp. 55-60 (Year: 2013).",ACTIVE
899,US,B1,US 12321862 B1,158-104-528-887-831,6/3/2025,2025,US 202418830573 A,9/11/2024,US 202418830573 A;;US 202418821880 A;;US 202418661532 A;;US 202418661519 A;;US 202418633293 A,4/11/2024,"Latency-, accuracy-, and privacy-sensitive tuning of artificial intelligence model selection parameters and systems and methods of the same","The disclosed data generation platform enables generation of an output in response to an output generation request based on tuning a routing model that enables model selection in a dynamic, system-sensitive manner. For example, the disclosed data generation platform receives an output generation request for a user device and generates a risk indicator associated with the output generation request. The platform can determine a current system state and generate a set of performance indicators and associated weighting values based on the risk indicator and the system state. The data generation platform can select a first routing model based on the weighting values. The data generation platform can provide the output generation request to the first routing model to generate an indication of a model with which to generate a model output responsive to the input. The data generation platform can enable access to the generated model output.",CITIBANK NA,LEVIN AVI;;SILVER MIRIAM;;JAIN PAYAL;;RATH BIRAJ KRUSHNA;;MURRAY STUART;;BARAK NIMROD,CITIBANK N.A (2025-05-05),https://lens.org/158-104-528-887-831,Granted Patent,yes,22,0,1,158-104-528-887-831,US,36,166-860-055-274-237;;192-529-172-020-159;;117-165-481-521-817;;062-084-390-952-648;;009-332-012-767-769;;130-711-467-813-772;;150-084-174-776-205;;134-859-487-724-028;;136-076-696-451-742;;174-498-778-674-614;;135-411-020-650-37X;;082-042-370-293-809;;081-164-654-051-886;;126-999-415-386-749;;101-393-155-626-043;;028-517-317-595-400;;183-393-311-078-435;;120-491-497-842-713;;071-444-314-653-665;;151-710-271-944-022;;169-310-367-816-659;;114-332-483-825-36X;;176-222-606-932-299;;109-693-731-347-460;;187-959-165-043-749;;165-235-788-605-427;;184-797-936-150-334;;129-627-428-962-735;;132-864-126-338-301;;147-316-129-152-657;;087-574-341-939-358;;052-233-397-211-176;;154-552-332-382-958;;158-104-528-887-831;;122-629-432-281-208;;053-045-267-490-224,US;;WO;;EP,0,G06N3/091;;G06N20/00;;G06N3/091,G06N3/091,,3,0,,,"Generative machine learning models; IPCCOM000272835D, Aug. 17, 2023. (Year: 2023).;;Hu, Q., J., et al., “Routerbench: A Benchmark for Multi-LLM Routing System,” arXiv:2403.12031v2 [cs.LG] Mar. 28, 2024, 16 pages.;;Peers, M., “What California AI Bill Could Mean,” The Briefing, published and retrieved Aug. 30, 2024, 8 pages, https://www.theinformation.com/articles/what-california-ai-bill-could-mean.",ACTIVE
900,US,A1,US 2024/0380711 A1,120-482-627-364-509,11/14/2024,2024,US 202418767770 A,7/9/2024,US 202418767770 A;;US 202418444500 A;;US 202363485426 P,2/16/2023,SYSTEMS AND METHODS FOR IMPROVING INTERACTIONS WITH ARTIFICIAL INTELLIGENCE MODELS,"An example system may comprise a control module associated with a computing device. After receiving input from a user device the control module may provide the input to a filter AI model. When the filter AI model returns an indication that the input is legitimate, the control module may create a prompt and provide it to an AI model, which determines at least one configuration a response to the prompt should be configured and return at least one short code associated with the at least one determined configuration. The control module may provide the prompt to at least one tuned AI model associated with the associated configuration(s). The control module may receive a response from the AI model(s). Before the control module may transmit the response to the user device, a second filter AI model may return an indication that the response does not violate established standards of quality.",PRACTICAL CREATIVITY LLC,LAI MIN-TIH,PRACTICAL CREATIVITY LLC (2024-02-13),https://lens.org/120-482-627-364-509,Patent Application,yes,0,0,3,044-210-674-110-380;;071-340-369-028-334;;120-482-627-364-509,US,3,044-210-674-110-380;;071-340-369-028-334;;120-482-627-364-509,US,0,G16H20/70;;H04L51/02;;G06Q50/205;;G06Q10/1093;;G06Q10/0637;;H04L51/216;;H04L51/02;;G16H20/70;;H04L51/216;;G06Q10/0637;;G06Q50/205;;G06Q10/1093,H04L51/02;;G06Q10/0637;;G06Q10/1093;;G06Q50/20;;G16H20/70;;H04L51/216,,0,0,,,,PENDING
901,US,B1,US 12254035 B1,161-118-423-023-557,3/18/2025,2025,US 202418648956 A,4/29/2024,US 202418648956 A,4/29/2024,Method and system for recommending test cases using machine learning models,"A method for recommending a test case (TC) includes: obtaining TCs; obtaining a document associated with the TCs; analyzing the TCs and document to generate a reference document (RD); transforming, the RD into a first embedding vector (EV); receiving a query about a recommendation from an administrator; analyzing the query to infer a length of the query; making a first determination that the length of the query is greater than an input length of a model; based on the first determination, employing a summarizer model to obtain a summarized query; transforming, the summarized query into a second EV; performing a search for a most matching asset; analyzing the summarized query and most matching asset to generate the recommendation; making a second determination that the recommendation is generated; and initiating displaying of the recommendation to the administrator.",DELL PRODUCTS LP,JASORIYA SHREYANS SURESH;;NATU GAJANAN SURESH;;CATALANOTTI MICHAEL JOHN,DELL PRODUCTS L.P (2024-04-25),https://lens.org/161-118-423-023-557,Granted Patent,yes,1,0,1,161-118-423-023-557,US,1,161-118-423-023-557,US,0,G06F16/358;;G06F16/3347;;G06F16/358;;G06F16/3347,G06F16/33;;G06F16/334;;G06F16/358,,0,0,,,,ACTIVE
902,WO,A1,WO 2025/068771 A1,198-167-701-388-104,4/3/2025,2025,IB 2024000597 W,9/12/2024,US 202318477680 A,9/29/2023,AUTOMATIC LANGUAGE MODEL (LM) INPUT OPTIMIZATION USING TEXTUAL GRADIENTS,"Systems and methods are provided for implementing automatic prompt optimization using textual gradients. In various embodiments, a feedback prompt, input into a large language model (""LLM""), is used to generate textual gradients that criticize a current prompt. The feedback prompt includes the current prompt and predictions that are incorrect compared with corresponding labels associated with minibatch data processed by the LLM using the current prompt. The textual gradients and current prompt are used in an editing prompt to the LLM to obtain a set of optimized prompts, which may be expanded using a paraphrasing prompt that is input into the LLM to generate a set of paraphrased prompts. A selection algorithm is used to select one or more optimized prompts from the set of optimized prompts and/or the set of paraphrased prompts, and the process is repeated with the selected one or more optimized prompts replacing the current prompt.",MICROSOFT TECHNOLOGY LICENSING LLC,PRYZANT REID ALLEN;;LI JERRY ZHENG;;ITER DAN;;LEE YIN TAT;;ZHU CHENGUANG;;ZENG NANSHAN;;SHIRGAONKAR ANUP,,https://lens.org/198-167-701-388-104,Patent Application,yes,1,0,2,198-167-701-388-104;;073-483-692-148-898,US;;WO,2,198-167-701-388-104;;073-483-692-148-898,US;;WO,0,G06F40/56;;G06F40/30;;G06F40/166;;G06F40/20;;G06F16/90,G06F40/30,,1,1,189-040-808-117-414,10.18653/v1/2023.emnlp-main.494,"REID PRYZANT ET AL: ""Automatic Prompt Optimization with ""Gradient Descent"" and Beam Search"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 4 May 2023 (2023-05-04), XP091502614",PENDING
903,US,A1,US 2024/0281600 A1,096-718-590-488-136,8/22/2024,2024,US 202418648312 A,4/26/2024,US 202418648312 A;;US 202117452047 A;;US 202363462816 P;;US 202063105176 P,10/23/2020,"Method, System, and Computer Program Product for Code Generation Using LLMs",Disclosed is an approach to implement code generation for integration with a third-party application. Automated code generation is used to generate code to interact with a system that is provided by a separate company or organization from the system that has generated the code. A large language model may be used to generate the code.,KOGNITOS INC,BROWN AARON DEAN;;GILL BINNY SHER,KOGNITOS INC (2024-05-01),https://lens.org/096-718-590-488-136,Patent Application,yes,0,2,1,096-718-590-488-136,US,9,096-718-590-488-136;;068-774-369-125-839;;119-988-762-912-785;;184-268-805-174-324;;149-120-199-704-785;;013-155-097-375-317;;079-879-207-420-27X;;081-759-126-328-207;;077-471-962-740-558,US,0,G06F8/30;;G06F9/453;;G06F11/0793;;G06F11/36;;G06F40/20,G06F40/20;;G06F11/36,,0,0,,,,PENDING
904,US,B1,US 12271720 B1,153-832-473-000-677,4/8/2025,2025,US 202418781965 A,7/23/2024,US 202418781965 A;;US 202318535001 A,12/11/2023,System and methods for detecting required rule engine updates using artificial intelligence models,"The systems and methods provide a model deployment criterion. The model deployment criterion indicates a difference in a value against which the proxy model may be measured to determine when, if ever, the proxy model should be deployed to replace the existing rule engine. The model deployment criterion may be keyed to the proxy model (e.g., based on a difference in its size, throughput speed, number of changes, etc.), the existing rule engine (e.g., based on a difference in its age, update occurrences to its rule base, etc.), and/or comparisons between models (e.g., based on differences in results, throughput speed, efficiency, etc.).",CITIBANK NA,SILVER MIRIAM;;MYERS JAMES,CITIBANK N.A (2024-07-22),https://lens.org/153-832-473-000-677,Granted Patent,yes,30,0,1,153-832-473-000-677,US,9,029-896-635-687-836;;153-832-473-000-677;;193-633-581-788-608;;008-197-963-435-473;;095-237-791-646-678;;075-469-762-619-491;;088-458-232-557-850;;064-693-030-404-249;;037-391-572-754-742,US;;WO;;EP,0,G06F8/30;;G06F8/60;;G06F8/77;;G06N5/025;;G06N20/00;;G06F9/4482;;G06F9/45512;;G06F8/60,G06F8/60,,6,6,123-493-797-658-14X;;050-586-324-044-478;;080-708-213-999-643;;046-154-139-584-700;;120-733-405-124-108;;075-793-976-009-167,10.1145/2023598.2023604;;10.1109/icsec.2013.6694743;;10.1109/socpar.2009.37;;10.1145/3613372.3613419;;10.1109/access.2018.2837692;;10.1145/219717.219768,"Sottara et al, “Enhancing a Production Rule Engine With Predictive Models Using PMML”, ACM, pp. 39-47 (Year: 2011).;;Rattanasawad et al, “A Review and Comparison of Rule Languages and Rule-based Inference Engines for the Semantic Web”, IEEE, pp. 1-6 (Year: 2013).;;Behravesh et al, “Rule Modeling Engine for Optimizing Complex Event Processing Patterns”, IEEE, pp. 128-135 (Year: 2009).;;Genesis et al “ClRef: A Tool for Visualizing the Historical Data of Software Refactorings in Java Projects”, ACM, pp. 174-179 (Year: 2023).;;Kibria et al, “Big Data Analytics, Machine Learning, andArtificial Intelligence in Next-Generation Wireless Networks”, IEEE, pp. 32328-32338 (Year: 2018).;;Langley et al, “Applications of Machine Learning and Rule Induction”, ACM, pp. 54-64 (Year: 1995).",ACTIVE
905,WO,A1,WO 2024/228863 A1,076-557-929-282-285,11/7/2024,2024,US 2024/0025791 W,4/23/2024,US 202363463374 P,5/2/2023,SYSTEM AND METHODS FOR EXTRACTING STATISTICAL INFORMATION FROM DOCUMENTS,"Embodiments of the disclosure provide an end-to-end system for extracting statistical relationships from scientific literature using a variety of machine learning (ML) and statistical models, including generative large language models (LLMs). The system is designed to identify and extract two types of statistical relationships: ""generic"" or effect size relationships and ""paired"" or group comparison relationships.",SYSTEM INC,NAING THET;;WANG ALISSA;;CHAWLA SUGREEV;;JAMEI MEHDI;;BLY ADAM,,https://lens.org/076-557-929-282-285,Patent Application,yes,5,10,2,076-557-929-282-285;;196-226-168-522-209,US;;WO,2,076-557-929-282-285;;196-226-168-522-209,US;;WO,0,G06F16/2462;;G06F16/9024;;G06F16/93;;G06F16/248;;G06F16/2462;;G06F16/248;;G06F16/9024;;G06F16/93,G06F16/901;;G06F16/2458;;G06F40/16,,0,0,,,,PENDING
906,US,A1,US 2024/0354676 A1,104-370-493-027-972,10/24/2024,2024,US 202418648011 A,4/26/2024,US 202418648011 A,4/26/2024,SERVICE CAPABILITY PREDICTION AND PROVISIONING,"At least one processor may predict a customer demand for a resource using a first machine learning (ML) model, predict a resource availability for the resource using a second ML model, predict a resource capability for the resource using a third ML model, and predict a process capability for the resource using a fourth ML model. The at least one processor may determine a gap between the customer demand and a resource ability to meet the customer demand exists due to a combination of the resource availability, the resource capability, and the process capability. The at least one processor may adjust at least one resource parameter to reduce or eliminate the gap.",HSBC GROUP MAN SERVICES LIMITED,RAMASWAMY ASHWATH KADUR,HSBC GROUP MANAGEMENT SERVICES LIMITED (2024-06-28),https://lens.org/104-370-493-027-972,Patent Application,yes,11,0,1,104-370-493-027-972,US,1,104-370-493-027-972,US,0,G06Q30/018;;G06Q10/06315;;G06Q30/0202;;G06Q40/03;;G06Q10/06315;;G06Q40/03;;G06Q30/018;;G06Q30/0202,G06Q10/0631;;G06Q30/018;;G06Q30/0202;;G06Q40/03,,0,0,,,,PENDING
907,US,A1,US 2025/0173630 A1,195-442-050-566-484,5/29/2025,2025,US 202418938380 A,11/6/2024,JP 2023201564 A,11/29/2023,"SERVER APPARATUS, CONTROL METHOD OF SERVER APPARATUS AND NON-TRANSITORY COMPUTER-READABLE STORAGE MEDIUM","A server apparatus includes a request acquiring means, an answer acquiring means, and an answer providing means. The request acquiring means acquires a request related to a specific theme from a user, which is a first request to at least two or more learning models. The answer acquiring means acquires answers from each of the at least two or more learning models by using at least a scene showing a situation related to the specific theme and the first request. The answer providing means provides the answers acquired from each of the at least two or more learning models to the user.",NEC CORP,NISHIMOTO SHINNOSUKE;;UEDA KENICHI;;KOBAYASHI YUKI;;ARAI YOSHIKAZU,NEC CORPORATION (2024-10-23),https://lens.org/195-442-050-566-484,Patent Application,yes,0,0,2,195-442-050-566-484;;014-504-319-752-907,US;;JP,2,195-442-050-566-484;;014-504-319-752-907,US;;JP,0,G06N20/20;;G06V20/30;;G06N20/00;;G06V20/30;;G06N20/20,G06N20/20;;G06V20/30,,0,0,,,,PENDING
908,US,A1,US 2024/0378526 A1,042-078-058-696-324,11/14/2024,2024,US 202418413382 A,1/16/2024,US 202418413382 A;;US 202363466271 P,5/13/2023,"System and Method for an Intelligent Framework, Flow, and Agent","The present invention relates to a system and a method implemented by an intelligent module. The system comprises an interface, an artificial intelligence module, and an intelligent flow framework module. The intelligent flow framework module is communicatively coupled to the interface and the artificial intelligence module. The intelligent flow framework module is configured to define at least one task based on an event and contextual data for completing a mission. The system provides the ability to adapt quickly to changing circumstances and make intelligent decisions to ensure the successful completion of missions/objectives.",YAN DAVID;;MERTVETSOV ALEKSANDR;;SELEDKIN VIACHESLAV;;NEWO AI,YAN DAVID;;MERTVETSOV ALEKSANDR;;SELEDKIN VIACHESLAV,,https://lens.org/042-078-058-696-324,Patent Application,yes,0,1,1,042-078-058-696-324,US,1,042-078-058-696-324,US,0,G06Q10/06316;;G06Q10/06316,G06Q10/0631,,0,0,,,,PENDING
909,US,B1,US 12210858 B1,075-469-762-619-491,1/28/2025,2025,US 202418781977 A,7/23/2024,US 202418781977 A;;US 202318535001 A,12/11/2023,Systems and methods for detecting required rule engine updated using artificial intelligence models,"The systems and methods provide a model deployment criterion. The model deployment criterion indicates a difference in a value against which the proxy model may be measured to determine when, if ever, the proxy model should be deployed to replace the existing rule engine. The model deployment criterion may be keyed to the proxy model (e.g., based on a difference in its size, throughput speed, number of changes, etc.), the existing rule engine (e.g., based on a difference in its age, update occurrences to its rule base, etc.), and/or comparisons between models (e.g., based on differences in results, throughput speed, efficiency, etc.).",CITIBANK NA,SILVER MIRIAM;;MYERS JAMES,CITIBANK N.A (2024-07-22),https://lens.org/075-469-762-619-491,Granted Patent,yes,30,1,1,075-469-762-619-491,US,9,029-896-635-687-836;;153-832-473-000-677;;193-633-581-788-608;;008-197-963-435-473;;095-237-791-646-678;;075-469-762-619-491;;088-458-232-557-850;;064-693-030-404-249;;037-391-572-754-742,US;;WO;;EP,0,G06F8/60;;G06F8/77;;G06N5/025;;G06N20/00;;G06F9/45512;;G06F8/60,G06F8/60,,6,6,045-899-605-857-295;;123-493-797-658-14X;;072-929-642-951-014;;141-992-154-799-079;;164-595-711-832-843;;068-631-189-807-914,10.1109/tcomm.2019.2951403;;10.1145/2023598.2023604;;10.1109/tefse.2013.6620155;;10.1109/icse.2005.1553639;;10.1145/3468264.3478688;;10.1145/3672456,"Huang et al., “AI Coding: Learning to Construct Error Correction Codes”, IEEE, pp. 26-39 (Year: 2020).;;Sottara et al., “Enhancing A Production Rule Engine With Predictive Models Using PMML”, ACM, pp. 39-47 (Year: 2022).;;Guana et al., “Backward Propagation of Code Refinements on Transformational Code Generation Environments”, IEEE, pp. 55-60 ( Year: 2013).;;Ge et al., “Automatic Generation of Rule-based Software Configuration Management Systems”, ACM, pp. 659 (Year: 2005).;;Mezini, Programming and Execution Models for Next Generation Code Intelligence Systems (Keynote), ACM, pp. 1-2 (Year: 2021).;;Jiang et al., “Self-Planning Code Generation with Large Language Models”, ACM, pp. 1-30 (Year: 2024).",ACTIVE
910,US,A1,US 2025/0209544 A1,111-697-632-346-438,6/26/2025,2025,US 202318395153 A,12/22/2023,US 202318395153 A,12/22/2023,CONTENT EVENT MANAGER FOR PROVIDING CONTENT EVENTS BASED ON RELEVANCE SCORES,"Systems and methods for providing content events that are relevant to a first user of a social network are provided. In particular, a computing device may obtain content data associated with one or more content events, obtain user engagement data associated with the first user, determine a relevance score for each of the one or more content events using a relevance predictive model based on the user engagement data and attributes associated with the respective content event, the relevance score of each of the one or more content events representing a likelihood of the first user to engage with the respective content event, ranking the content events based on the relevance score for each of the one or more content events, and presenting a subset of the content events to the first user on a user interface of a device based on the ranking.",MICROSOFT TECHNOLOGY LICENSING LLC,KONG TAMMY;;MALLADI RAKESH;;GOEL NAMAN;;MALAGI NETRA;;PEZZUTI BERARDINO F;;YU SHIPENG;;WANG XUKAI;;ROY CHOWDHURY RISHAV;;HUANG JINGSHU;;VAIDYA CHINMAYEE NITIN;;NI DAN;;HUANG HESONG;;MELTSNER ELAN ARIEL,,https://lens.org/111-697-632-346-438,Patent Application,yes,3,0,1,111-697-632-346-438,US,1,111-697-632-346-438,US,0,G06Q50/01;;G06Q50/01,G06Q50/00,,1,1,089-449-088-266-857,10.1007/s11277-020-07818-w,"When Machine Learning Algorithms Meet User Engagement Parameters to Predict Video QoE. Published in: Wireless Personal Communications,2021 Database:Computers & Applied Sciences Complete (Year: 2021)",PENDING
911,WO,A1,WO 2024/158398 A1,053-662-486-536-88X,8/2/2024,2024,US 2023/0011797 W,1/29/2023,US 202318102071 A,1/26/2023,SYSTEM AND METHOD FOR CREATING PATENT DRAWINGS USING GENERATIVE ARTIFICIAL INTELIGENCE (AI),"Systems and methods for the creation of patent drawings using generative Al are disclosed; providing inventors with the novel ability to create original patent drawings using natural-language text prompts, which can be coupled with visual examples such as images and videos for better results. Simply put: ""describe your invention, just as you would to a human patent designer, and hit 'Enter.' ""Systems and methods for exponentially increasing the capabilities of present-day natural -language processing (NLP) models are also disclosed herein, namely, by way of providing models with the novel ability to ask questions.",EDSON ALEX,EDSON ALEX,,https://lens.org/053-662-486-536-88X,Patent Application,yes,6,0,1,053-662-486-536-88X,WO,1,053-662-486-536-88X,WO,0,G06N20/00;;G06N3/08;;G06F40/35;;G06F40/205;;G06F40/103;;G06F40/279;;G06Q10/10;;G06Q50/184;;G06V10/82;;G06N3/045;;G06N3/088;;G06N3/047;;G06N3/044,G06Q50/18;;G06F40/10;;G06F40/30;;G06N3/08;;G06N20/00;;G06V10/70,,1,1,000-183-299-966-082,10.1109/cvprw50498.2020.00095,"BHATTARAI MANISH; OYEN DIANE; CASTORENA JUAN; YANG LIPING; WOHLBERG BRENDT: ""Diagram Image Retrieval using Sketch-Based Deep Learning and Transfer Learning"", 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION WORKSHOPS (CVPRW), 14 June 2020 (2020-06-14), pages 663 - 672, XP033799066, DOI: 10.1109/CVPRW50498.2020.00095",PENDING
912,US,A1,US 2025/0208936 A1,077-161-526-820-267,6/26/2025,2025,US 202318395842 A,12/26/2023,US 202318395842 A,12/26/2023,Systems and methods for detailed cloud posture remediation recommendations utilizing custom Large Language Models (LLMs),Systems and methods for detailed cloud posture remediation recommendations utilizing custom Large Language Models (LLMs). The present systems and methods are configured to perform the steps of scanning a cloud environment for posture control data; generating one or more alerts related to any of risky configurations and risky activities associated with the cloud environment; generating one or more remediation recommendations based on the one or more alerts; and providing the one or more alerts and the one or more remediation recommendations to administrators of the cloud environment.,ZSCALER INC,DANINO SHOHAM,ZSCALER INC (2023-12-24),https://lens.org/077-161-526-820-267,Patent Application,yes,15,0,1,077-161-526-820-267,US,2,179-352-342-947-386;;077-161-526-820-267,US,0,G06F11/008;;G06F11/008,G06F11/00,,0,0,,,,PENDING
913,US,A1,US 2025/0209085 A1,132-152-197-115-433,6/26/2025,2025,US 202418777023 A,7/18/2024,IN 202341088141 A,12/22/2023,TABLE EXTRACTION FROM IMAGES USING LANGUAGE MODELS,"Techniques for extracting tables from images using a Language Model. The techniques include detecting, within an image, an area that includes a table. The techniques further include extracting, from the area of the image, tabular data for the table, the extracted tabular data comprising a plurality of content items in the table and structural information for the table. The techniques further include generating a prompt that includes the plurality of content items and the structural information. The techniques further include providing the prompt as input to a language model. The techniques further include responsive to providing the prompt as input to the language model, generating, by the language model, a parsable representation of the table, wherein the parsable representation is in a format and includes the plurality of content items of the table and the structural information of the table in the image.",ORACLE INT CORP,RAI AVINASH RAJESHCHANDRA;;PANDA SRIKANT;;PACHAURI KULBHUSHAN,ORACLE INTERNATIONAL CORPORATION (2024-07-17),https://lens.org/132-152-197-115-433,Patent Application,yes,5,0,1,132-152-197-115-433,US,1,132-152-197-115-433,US,0,G06F16/254;;G06F16/254,G06F16/25,,0,0,,,,PENDING
914,WO,A2,WO 2024/263820 A2,092-350-667-009-060,12/26/2024,2024,US 2024/0034874 W,6/20/2024,US 202363509107 P;;US 202463553704 P,6/20/2023,OBJECT MESSAGING AND INTELLIGENT OBJECTS (OMIO),"An intelligent, self-aware system of objects is disclosed. An intelligent object may include structured data, comprising workflow parameters, and unstructured data, comprising messages, emails, multimedia, and the like. A stakeholder module may be configured to establish communication channels for stakeholder natural language dialog associated with the object. A generative artificial intelligence (AI) module may be embedded within the object. The AI module may be configured to process each object module's activity. It may facilitate natural language communication between the object, the stakeholders of the object, related objects, and related stakeholders associated with the related objects, in a designated communications channel based on stakeholder class. The AI module may transmit messages in the communications channels, update the structured data, and operate a deterministic code module to execute at least one action related to the object or related objects, thereby updating a state of a workflow in which the object operates.",XEBA TECH LLC,ALIBAKHSH MASSOUD,,https://lens.org/092-350-667-009-060,Patent Application,yes,0,0,2,092-350-667-009-060;;028-257-898-101-983,WO,2,092-350-667-009-060;;028-257-898-101-983,WO,0,G06N3/0475;;G06N3/045;;G06N20/00;;G06N3/044,G06N3/0475,,0,0,,,,PENDING
915,US,A1,US 2024/0281487 A1,073-108-288-440-825,8/22/2024,2024,US 202418443838 A,2/16/2024,US 202418443838 A;;US 202363446750 P,2/17/2023,ENHANCED SEARCH RESULT GENERATION USING MULTI-DOCUMENT SUMMARIZATION,"Enhanced search results are generated using multi-document summarization. A multi-document summarization system receives a search query from a user and retrieves a plurality of search result documents based on the search query. The summarization system generates a summary of each of the plurality of search result documents using distinct per-document summarization machine learning models, where the distinct per-document summarization machine learning models are trained on a training dataset. The summarization system synthesizes the summary of each of the plurality of search result documents into a single-consolidated answer responsive to the received search query. The multi-document summarization system formats the single-consolidated answer to include citations to the plurality of search result documents.",SNOWFLAKE INC,BATHWAL RAHIL;;CAMPOS DANIEL FERNANDO;;DEVARAJ ASHWIN;;LI SETH MICHAEL;;NGAN MUHUA;;RAGHUNATHAN VIVEK;;RAMASWAMY SRIDHAR;;SAMDANI RAJHANS;;SO CHIU WAH;;TARAKAD NITYA KANNAN,SNOWFLAKE INC (2024-03-04),https://lens.org/073-108-288-440-825,Patent Application,yes,0,12,5,176-201-229-329-116;;073-108-288-440-825;;002-940-054-403-87X;;181-535-139-346-474;;140-032-866-318-873,US,5,176-201-229-329-116;;073-108-288-440-825;;002-940-054-403-87X;;181-535-139-346-474;;140-032-866-318-873,US,0,G06F16/24575;;G06F16/93;;G06F16/9558;;G06F16/9538;;G06F16/248;;G06F16/90328;;G06F16/345;;G06F16/90328;;G06F16/93;;G06F16/9558;;G06F16/9538;;G06F16/24575;;G06F16/248,G06F16/9538;;G06F16/93;;G06F16/955,,0,0,,,,PENDING
916,WO,A1,WO 2025/128189 A1,008-197-963-435-473,6/19/2025,2025,US 2024/0051150 W,10/11/2024,US 202318535001 A;;US 202418669421 A;;US 202418781965 A;;US 202418781977 A;;US 202418781985 A,12/11/2023,SYSTEMS AND METHODS FOR DETECTING REQUIRED RULE ENGINE UPDATED USING ARTIFICIAL INTELLIGENCE MODELS,"The systems and methods provide a model deployment criterion. The model deployment criterion indicates a difference in a value against which the proxy model may be measured to determine when, if ever, the proxy model should be deployed to replace the existing rule engine. The model deployment criterion may be keyed to the proxy model (e.g., based on a difference in its size, throughput speed, number of changes, etc.), the existing rule engine (e.g., based on a difference in its age, update occurrences to its rule base, etc.), and/or comparisons between models (e.g., based on differences in results, throughput speed, efficiency, etc.).",CITIBANK NA,MYERS JAMES;;SILVER MIRIAM,,https://lens.org/008-197-963-435-473,Patent Application,yes,5,0,1,008-197-963-435-473,WO,9,029-896-635-687-836;;153-832-473-000-677;;193-633-581-788-608;;008-197-963-435-473;;095-237-791-646-678;;075-469-762-619-491;;088-458-232-557-850;;064-693-030-404-249;;037-391-572-754-742,US;;WO;;EP,0,G06F8/77;;G06N5/025;;G06N3/045;;G06N3/047;;G06N3/0475;;G06N3/088;;G06N3/0455;;G06N3/094;;G06N3/084;;G06N3/09,G06F8/77;;G06N5/025,,0,0,,,,PENDING
917,US,A1,US 2025/0165711 A1,167-581-288-579-44X,5/22/2025,2025,US 202418649251 A,4/29/2024,US 202418649251 A;;US 202318512781 A,11/17/2023,CONSTRAINING OUTPUT OF A GENERATIVE LANGUAGE MODEL TO CONFORM TO A GRAMMAR,"One problem of a generative language model (e.g. a large language model) is the generation of syntactically-invalid or misinformed output. This may be mitigated by utilizing a grammar defining valid sequences of output. The grammar may constrain the token generation. A method may include obtaining values generated using the generative language model, where each value is indicative of a probability of a respective token being a next token in the token sequence. The method may further include obtaining a mask based on the token sequence already generated and the grammar. The method may further include applying the mask to the values. The mask may operate on each value that corresponds to a token not compliant with the grammar to reduce or zero the probability of the corresponding token being the next token. The next token is then determined based on the values after the mask is applied.",SHOPIFY INC,LIBBEY DAVID;;PADGETT NEIL LEONARD,SHOPIFY INC (2024-09-23),https://lens.org/167-581-288-579-44X,Patent Application,yes,0,0,2,167-581-288-579-44X;;175-880-671-598-926,US;;AU,3,175-880-671-598-926;;167-581-288-579-44X;;156-958-271-710-059,US;;AU,0,G06F40/284;;G06F40/284,G06F40/284,,0,0,,,,PENDING
918,WO,A1,WO 2023/204944 A1,195-150-712-035-734,10/26/2023,2023,US 2023/0016788 W,3/30/2023,EP 22168875 A,4/19/2022,TRAINING OF TEXT AND IMAGE MODELS,"A method of training a text model using a plurality of text passage combinations, each text passage combination comprising a respective first text passage and a respective second text passage describing a same matter as the respective first text passage but being differently worded than the respective first text passage. The training comprises minimizing a measure of statistical difference between a respective value of a first text embedding and the corresponding value of a second text embedding over the plurality of text passage combinations. The method then comprises jointly training the text model and an image model based on plurality of image-text combinations, each comprising a respective image and a respective textual report describing the respective image. The joint training comprises minimizing a measure of statistical difference between the value of an image embedding and the corresponding value of a third text embedding over the plurality of image-text combinations.",MICROSOFT TECHNOLOGY LICENSING LLC,OKTAY OZAN;;ALVAREZ-VALLE JAVIER;;USUYAMA NAOTO;;BANNUR SHRUTHI JAISIMHA;;POON HOIFUNG;;NORI ADITYA;;SCHWAIGHOFER ANTON;;COELHO DE CASTRO DANIEL;;HYLAND STEPHANIE;;NAUMANN TRISTAN,,https://lens.org/195-150-712-035-734,Patent Application,yes,0,8,4,132-492-745-405-978;;195-150-712-035-734;;056-910-265-019-466;;048-814-073-089-89X,US;;WO;;EP,4,132-492-745-405-978;;195-150-712-035-734;;056-910-265-019-466;;048-814-073-089-89X,US;;WO;;EP,0,G06F16/55;;G06F16/45;;G16H50/20;;G16H15/00;;G16H50/70;;G16H30/40;;G06N3/092;;G06N3/09;;G06N3/088;;G06N3/0464;;G16H15/00;;G06N20/00,G06F16/45;;G06F16/55;;G06N3/04;;G06N3/045;;G06N3/08;;G16H15/00;;G16H30/00;;G16H30/40;;G16H50/20;;G16H50/70,,1,0,,,"MÜLLER PHILIP ET AL: ""JOINT LEARNING OF LOCALIZED REPRESENTATIONS FROM MEDICAL IMAGES AND REPORTS"", 6 December 2021 (2021-12-06), XP055967126, Retrieved from the Internet <URL:https://arxiv.org/pdf/2112.02889v1.pdf> [retrieved on 20221003]",PENDING
919,US,A1,US 2025/0217673 A1,095-237-791-646-678,7/3/2025,2025,US 202519061982 A,2/24/2025,US 202519061982 A;;US 202418781965 A;;US 202318535001 A,12/11/2023,SYSTEMS AND METHODS FOR GENERATING ARTIFICIAL INTELLIGENCE MODELS AND/OR RULE ENGINES WITHOUT REQUIRING TRAINING DATA THAT IS SPECIFIC TO MODEL COMPONENTS AND OBJECTIVES,"Systems and methods for generating code for artificial intelligence models without requiring training data that is specific to model components and objectives. For example, the system may receive an original version of a rule engine. The system may input the original version, using a first input condition, into a regeneration model to generate a first regenerated version of the rule engine. The system may determine whether the first regenerated version includes a first hallucination based on comparing the first regenerated version to alternative versions of the rule engine, wherein each of the alternative versions were generated using a respective alternative input condition. The system may, in response to determining that the first regenerated version includes the first hallucination, determining whether the first hallucination comprises a positive mutation.",CITIBANK NA,SILVER MIRIAM;;MYERS JAMES,,https://lens.org/095-237-791-646-678,Patent Application,yes,0,0,1,095-237-791-646-678,US,9,029-896-635-687-836;;153-832-473-000-677;;193-633-581-788-608;;008-197-963-435-473;;095-237-791-646-678;;075-469-762-619-491;;088-458-232-557-850;;064-693-030-404-249;;037-391-572-754-742,US;;WO;;EP,0,G06F8/30;;G06F8/77;;G06F9/4482;;G06F9/45512;;G06N5/025;;G06N20/00;;G06F8/427;;G06F8/427;;G06N5/025,G06N5/025;;G06F8/41,,0,0,,,,PENDING
920,US,A1,US 2025/0156122 A1,046-904-332-212-757,5/15/2025,2025,US 202519020864 A,1/14/2025,US 202519020864 A;;US 202418774010 A;;US 202318465253 A;;US 202217931418 A;;US 202016842427 A;;US 201916353775 A;;US 202117537624 A;;US 201816174488 A;;US 201815987875 A;;US 202363579258 P;;US 202263378768 P;;US 202263375868 P;;US 201962838738 P;;US 201862769277 P;;US 201862768952 P;;US 201862692602 P;;US 201862643641 P;;US 201862674688 P;;US 201762575966 P;;US 201762549399 P;;US 201762518146 P;;US 201862674703 P,6/12/2017,Dynamic User Interfaces For Storage System Management Using Generative Artificial Intelligence (AI),"Dynamic user interfaces for storage system management using generative artificial intelligence (AI), including: receiving a natural language request via a natural language interface of a graphical user interface (GUI) for a storage system; generating, by a generative AI model and based on the natural language request, one or more GUI components for presenting information associated with the natural language request; and presenting, via the GUI for the storage system, the one or more GUI components.",PURE STORAGE INC,YU LIUJIN;;SO DEREK;;DARJI PRAKASH,PURE STORAGE INC (2025-01-08),https://lens.org/046-904-332-212-757,Patent Application,yes,0,0,1,046-904-332-212-757,US,506,168-196-150-565-833;;083-055-333-946-742;;003-228-719-288-229;;195-250-718-141-640;;064-363-341-639-510;;091-097-515-257-863;;102-603-530-034-496;;061-713-169-778-583;;146-576-933-493-983;;076-682-576-518-311;;038-764-155-962-415;;139-607-353-004-202;;029-528-288-589-828;;001-550-477-577-054;;183-312-491-958-570;;040-748-164-169-621;;154-574-183-489-803;;029-829-277-764-765;;019-442-865-017-783;;116-554-660-790-302;;061-184-161-780-696;;042-462-914-443-490;;005-217-566-221-830;;028-643-842-918-500;;035-458-700-615-925;;093-770-051-702-665;;007-360-657-020-115;;113-878-148-513-623;;171-948-585-294-101;;050-610-252-605-906;;030-207-781-249-753;;135-563-775-890-091;;157-551-932-979-189;;038-610-260-690-19X;;100-567-482-281-020;;137-046-008-575-418;;166-382-182-861-764;;112-020-396-547-132;;192-326-189-845-149;;099-310-592-914-08X;;102-687-388-371-731;;133-063-763-970-998;;086-720-550-596-108;;079-174-165-447-377;;069-633-966-447-788;;180-797-302-444-28X;;150-072-765-961-033;;120-865-943-324-750;;157-180-683-659-271;;056-784-370-712-508;;182-427-855-586-039;;161-141-313-871-892;;196-451-966-109-428;;071-402-686-452-033;;124-460-451-541-636;;160-075-268-842-224;;139-943-790-314-922;;078-192-195-744-578;;017-718-280-362-831;;058-727-037-756-621;;134-367-898-373-188;;003-235-826-024-515;;027-902-042-697-794;;151-754-840-061-663;;075-375-040-788-173;;048-343-478-645-26X;;052-899-253-994-344;;075-272-201-266-447;;194-047-990-623-34X;;097-311-620-306-148;;123-127-605-172-277;;152-275-758-591-583;;002-495-567-899-230;;181-893-327-241-207;;063-554-494-925-951;;174-228-513-126-129;;196-645-286-600-104;;069-066-931-035-46X;;138-116-550-784-209;;085-774-281-987-617;;167-194-786-441-718;;104-660-015-284-371;;165-270-506-224-460;;000-608-981-133-594;;010-812-006-531-942;;171-588-073-610-59X;;158-556-161-596-604;;167-176-334-673-519;;179-013-474-936-893;;194-852-954-637-359;;137-278-496-142-939;;153-007-854-915-061;;159-252-559-230-761;;150-201-097-652-339;;040-522-738-277-049;;181-443-231-358-250;;054-635-362-900-718;;013-760-184-850-96X;;159-307-350-058-88X;;038-829-049-954-096;;140-334-441-753-427;;077-140-990-306-146;;131-108-752-710-705;;103-148-515-513-514;;101-877-159-468-354;;029-525-000-944-840;;123-946-435-388-903;;169-311-066-416-293;;131-181-792-330-003;;166-660-230-696-634;;190-384-555-411-563;;196-782-256-178-011;;002-773-701-420-823;;160-858-281-648-97X;;009-936-881-601-522;;128-566-345-991-095;;035-957-255-402-986;;191-533-238-098-086;;009-362-414-412-562;;023-859-203-626-705;;022-574-397-254-579;;154-167-222-675-644;;160-015-408-743-865;;175-970-853-294-869;;068-721-245-591-230;;034-405-229-761-211;;026-568-178-345-248;;016-556-684-013-202;;080-673-856-143-366;;150-015-910-520-55X;;128-012-442-516-646;;108-439-976-237-948;;198-276-521-186-727;;076-596-195-504-37X;;048-389-110-952-441;;013-268-901-112-480;;064-965-858-945-164;;061-507-822-093-097;;109-024-136-253-250;;073-232-562-825-76X;;054-058-816-315-891;;167-408-333-885-448;;185-089-199-406-06X;;191-486-355-103-068;;061-019-052-628-178;;025-533-608-524-718;;152-072-229-179-083;;082-892-578-797-687;;060-753-712-680-933;;019-814-363-577-11X;;053-660-731-873-179;;050-635-784-185-683;;171-995-154-182-863;;046-904-332-212-757;;134-077-108-235-19X;;071-364-907-741-919;;019-724-188-763-433;;059-108-374-932-474;;027-496-688-855-13X;;196-064-894-852-801;;004-078-745-297-423;;100-998-667-422-55X;;056-420-512-464-267;;100-062-902-488-164;;103-746-641-270-55X;;045-783-295-228-690;;163-813-237-065-558;;076-795-835-580-971;;002-556-082-125-68X;;112-475-668-686-277;;189-454-568-479-917;;168-697-100-067-137;;160-883-195-619-43X;;054-132-589-442-657;;136-364-515-449-43X;;180-305-781-767-188;;017-200-565-782-139;;133-796-430-435-207;;048-126-638-295-633;;162-595-211-964-732;;102-525-305-026-982;;198-255-557-466-605;;126-276-304-096-248;;022-966-564-286-010;;066-381-518-491-227;;100-288-635-420-561;;109-085-153-426-589;;103-325-469-482-706;;064-721-648-858-758;;147-652-416-009-91X;;099-221-900-902-909;;126-935-028-965-262;;018-609-923-126-036;;139-502-549-753-757;;197-948-761-443-932;;110-274-738-579-44X;;035-351-979-744-686;;101-926-299-108-252;;081-908-115-341-912;;068-526-286-451-695;;085-089-981-235-306;;094-897-985-582-884;;058-186-123-296-466;;166-895-948-860-575;;004-439-995-645-84X;;083-426-711-091-981;;195-122-728-705-888;;048-936-281-468-195;;159-609-908-253-881;;049-009-974-166-949;;011-427-521-923-882;;170-230-393-513-403;;093-607-340-096-403;;152-200-807-437-149;;020-741-597-272-061;;037-422-327-750-077;;035-932-873-789-689;;046-085-360-321-735;;155-544-911-200-043;;104-850-048-352-972;;003-392-011-979-387;;066-237-412-858-59X;;074-284-194-392-577;;113-883-525-078-476;;166-029-725-963-402;;141-166-922-886-497;;165-251-100-716-808;;109-204-045-161-834;;189-683-554-136-955;;165-353-956-983-302;;063-803-839-644-974;;051-871-207-762-955;;138-247-784-496-090;;038-249-334-637-443;;046-370-067-481-310;;169-371-296-832-705;;153-729-739-593-970;;069-633-997-347-915;;160-807-285-904-31X;;047-156-743-684-869;;000-240-541-872-622;;035-068-177-056-247;;074-738-744-439-848;;138-787-884-951-764;;114-798-824-422-898;;078-455-648-882-140;;112-052-549-269-601;;096-849-705-427-06X;;078-047-648-538-080;;013-354-587-458-643;;128-872-146-288-255;;061-332-733-765-144;;109-434-075-785-246;;145-071-422-740-954;;162-800-428-141-77X;;002-063-645-914-688;;181-024-669-420-294;;187-926-803-643-861;;057-944-223-834-130;;146-767-809-560-706;;059-592-070-540-815;;097-448-851-425-096;;018-778-990-532-98X;;096-336-041-371-775;;090-436-225-800-626;;092-033-223-858-169;;032-684-217-856-979;;182-315-452-225-689;;040-798-052-639-620;;068-114-407-375-617;;106-592-285-731-726;;167-499-515-790-358;;070-050-216-615-632;;195-822-625-730-711;;189-216-861-876-440;;014-359-193-183-308;;194-186-690-532-630;;016-575-459-395-252;;087-928-277-129-46X;;111-133-476-723-938;;003-990-396-405-623;;163-151-058-351-997;;151-344-465-779-005;;072-777-892-227-002;;071-821-977-370-376;;041-432-544-920-283;;110-632-735-777-114;;058-379-831-072-333;;156-469-951-930-226;;187-876-404-940-989;;010-826-879-236-27X;;117-529-100-391-196;;002-845-782-767-254;;157-354-493-809-272;;181-468-200-745-144;;023-258-902-361-28X;;159-134-020-292-064;;043-898-253-760-643;;111-690-878-509-32X;;196-052-300-572-979;;120-385-246-339-073;;192-458-807-343-053;;083-333-063-696-022;;125-637-101-790-787;;172-394-782-704-741;;066-711-379-474-302;;079-298-994-401-696;;005-852-759-755-874;;072-508-048-394-184;;049-677-462-076-521;;191-850-084-024-787;;089-144-914-579-752;;109-649-091-909-809;;068-829-421-797-743;;188-594-080-232-783;;104-613-317-098-492;;023-376-288-646-230;;048-587-274-735-838;;150-006-224-965-685;;102-167-036-547-271;;000-516-057-093-541;;176-038-410-198-846;;068-843-132-911-766;;133-120-070-575-213;;136-085-248-942-323;;169-872-414-419-862;;051-256-698-482-143;;089-576-466-010-659;;130-052-604-227-782;;015-353-713-952-887;;002-515-389-754-797;;158-352-252-345-582;;136-538-193-286-021;;015-066-039-583-490;;011-437-655-743-317;;167-032-356-644-492;;145-860-956-427-913;;125-268-920-285-02X;;156-540-238-964-518;;191-290-970-363-369;;160-342-944-094-705;;095-677-340-734-432;;033-752-129-045-517;;124-770-287-497-103;;157-818-280-668-835;;003-796-530-027-67X;;094-382-473-866-987;;128-995-710-866-854;;095-605-518-469-419;;110-551-539-238-08X;;150-729-283-903-002;;168-781-551-840-389;;149-481-207-319-400;;096-711-022-446-040;;137-257-530-247-177;;060-987-755-984-891;;130-706-469-665-973;;014-808-684-667-797;;155-442-757-416-243;;092-260-127-842-984;;182-094-002-347-340;;176-054-933-221-515;;183-910-193-434-664;;121-949-433-895-46X;;074-479-581-652-025;;091-923-446-232-196;;055-142-957-939-794;;077-943-471-580-804;;064-364-740-323-286;;107-357-379-642-747;;177-378-422-307-242;;126-256-737-424-35X;;017-951-768-469-852;;128-536-803-171-899;;186-287-479-673-502;;165-067-046-620-513;;060-555-366-884-257;;120-990-272-765-856;;161-272-304-988-618;;059-208-201-706-354;;194-400-365-542-653;;079-764-122-943-696;;124-264-166-156-546;;045-150-361-235-291;;143-743-801-525-847;;009-341-098-772-124;;072-013-551-621-941;;197-113-887-652-195;;043-498-109-661-330;;078-485-955-676-029;;157-856-922-669-571;;058-614-807-785-680;;096-545-164-279-435;;139-551-348-910-067;;038-646-488-098-656;;093-870-466-408-861;;060-331-250-283-561;;199-486-248-430-443;;066-320-799-129-080;;128-449-854-423-712;;137-372-807-573-957;;189-605-123-609-235;;073-686-890-636-26X;;187-039-735-632-819;;012-207-372-151-349;;074-821-011-860-456;;043-521-615-638-46X;;006-332-501-354-35X;;127-671-133-475-716;;049-934-582-483-53X;;007-314-850-293-96X;;131-917-412-896-857;;002-261-341-505-911;;052-645-238-246-989;;092-934-619-305-737;;011-144-180-956-298;;156-231-830-847-741;;054-157-576-002-565;;183-345-161-055-003;;082-391-474-545-746;;084-099-115-293-537;;158-321-909-875-384;;136-887-999-923-195;;105-104-182-290-188;;007-793-271-768-642;;131-836-418-938-603;;001-588-295-217-190;;162-438-895-567-586;;063-587-782-806-173;;056-959-406-012-602;;093-446-251-597-260;;053-139-542-373-995;;097-472-593-898-973;;088-018-351-440-699;;083-503-605-557-334;;037-010-976-657-162;;140-773-900-406-323;;163-843-384-774-415;;050-455-453-607-070;;129-364-795-432-056;;031-203-589-974-515;;057-624-713-083-437;;038-526-290-148-64X;;186-193-068-823-10X;;116-384-542-586-248;;101-904-719-599-258;;110-451-388-267-415;;197-526-983-551-963;;198-574-169-434-589;;081-091-014-933-413;;064-191-894-051-401;;060-441-890-116-056;;188-128-084-247-132;;046-025-000-490-928;;040-676-419-056-849;;176-633-689-788-523;;043-661-218-786-543;;085-260-350-964-50X;;131-900-416-569-924;;011-347-347-981-912;;001-657-690-124-839;;014-968-405-303-37X;;179-390-344-069-027;;188-988-315-769-019;;173-614-178-106-233;;092-349-287-714-982;;016-302-522-378-09X;;160-549-900-489-295;;194-547-397-164-307;;091-611-593-100-73X;;007-029-110-529-305;;194-377-916-730-27X;;057-004-976-888-221;;111-456-617-844-415;;047-819-018-564-244;;049-193-777-157-261;;145-064-635-906-158;;199-522-820-507-399;;029-235-337-058-486;;111-488-094-654-271;;016-195-997-372-571;;146-925-638-609-835;;021-682-861-107-620;;125-123-976-068-318;;068-320-314-595-095;;139-838-154-402-10X;;036-010-290-305-107;;042-462-803-538-948;;164-404-241-494-645;;177-795-215-974-277;;009-573-898-261-763;;079-751-561-164-915;;057-736-257-885-773;;124-711-555-917-38X;;110-911-276-059-106;;093-268-188-748-767;;132-941-789-640-110;;109-500-624-975-169;;027-509-231-973-830;;084-929-873-482-361;;082-104-014-093-449;;053-398-351-688-827;;139-757-118-892-928;;199-030-962-175-464;;193-477-126-898-926;;151-966-184-974-097,US;;DE;;WO;;EP;;AU;;CN;;CA;;JP,0,G06F3/0604;;G06F3/061;;G06F3/0619;;G06F3/0631;;G06F3/0647;;G06F3/0653;;G06F3/0664;;G06F3/067;;G06F3/167;;G06F9/5072;;G06F9/5077;;G06F9/5083;;G06F2209/5019;;G06F3/0664;;G06F3/0653;;G06F9/5077;;G06F3/0619;;G06F3/067;;G06F3/0631,G06F3/06;;G06F9/50,,0,0,,,,PENDING
921,US,A1,US 2025/0166020 A1,156-372-219-554-214,5/22/2025,2025,US 202418445742 A,1/10/2024,US 202418445742 A;;US 202363629638 P,11/16/2023,Gamified Digital Commerce Marketplace,"A digital commerce networked (e.g., Protocols: TCP/IP, BECKN, . . . ) marketplace for buyer-consumer-Players and seller-merchant-players, particularly micro-small-medium enterprises, coordinated by interconnected regional-provider-auctioneers.Each seller-merchant-player in said marketplace has product-service-activity-attraction offerings, which are analytic-algorithm searched, by each buyer-consumer-players, on said network to select product-service-activity-attraction, based on each buyer-consumer-player's needs-wants and placed in said buyer-consumer-player's shopping bag of icons.Each buyer-consumer-player's icon game dashboard enables earning a discount coupon prize, thereby reducing the published list-price. Prior performance (sales, coupons, . . . ) dashboards, enable each seller-merchant-player to periodically wager on time-of-day slots, to place iconized multi-media up-cross sell advertisements of product-service-activity-attraction, bidding against other seller-merchant-players, who have related product-service-activity-attraction recommendations, which said buyer-consumer-player's analytic search could have discovered.Each regional-provider-auctioneer's dashboard enables coordination of: (1) buyer-consumer-player's conversion-to-purchase, including a “discount coupon” transaction and (2) accounting of (a) seller-merchant-player's product-service-activity-attraction inventory and bag of advertisements and (b) buyer-consumer-player's need-wants icon shopping bag(s) and earned prize coupon bag(s).",KARMARKAR JAYANT S,KARMARKAR JAYANT S,,https://lens.org/156-372-219-554-214,Patent Application,yes,5,0,2,196-579-121-157-367;;156-372-219-554-214,US;;WO,2,196-579-121-157-367;;156-372-219-554-214,US;;WO,0,G06Q30/02;;G06Q30/0207;;G06Q30/0212;;G06Q30/08;;G06Q30/0201;;G06Q30/0275,G06Q30/0273;;G06Q30/0201,,1,0,,,"“Gamification, the ultimate call to action?” (Aengeveld, Jordy; published September 6, 2019 at https://www.coupontools.com/en/blog/110/gamification-the-ultimate-call-to-action) (Year: 2019)",PENDING
922,US,B1,US 12299718 B1,164-640-818-726-450,5/13/2025,2025,US 202519039743 A,1/28/2025,US 202519039743 A;;US 202463733572 P;;US 202463718902 P;;US 202463548703 P,2/1/2024,Customizable voice messaging platform,"The present disclosure describes a customized voice messaging platform. The customized voice message placement can enhance engagement using personalized audio content. The platform can generate authentic-sounding voice messages using Al-driven processes, including text-to-speech (TTS) technology and audio concatenation, to create personalized audio content. The platform supports various delivery channels such as SMS, email, podcasts, and streaming services. The platform can incorporation visual elements like brand logos and animations into personalized messages. The platform can provide campaign creation functionality, enabling users to create campaigns deliver customized messages across multiple channels. The platform can provide message suggestions, automated testing, and other features. The platform can support rules for determining when to send messages and/or the content of messages.",ROBIN VOICE INC,JOHNSON ERIC;;WILLIAMSON PATRICK;;NICKELL CHAD,ROBIN VOICE INC (2025-01-28),https://lens.org/164-640-818-726-450,Granted Patent,yes,57,0,1,164-640-818-726-450,US,1,164-640-818-726-450,US,0,G06Q30/0276;;G06Q30/0269;;G06T11/00;;G06Q30/0276;;G06T11/00;;G10L25/18;;G06Q30/0269;;G10L15/1815;;G10L15/183;;G10L21/14,G06Q30/0241;;G06Q30/0251;;G06T11/00;;G10L15/18;;G10L15/183;;G10L21/14;;G10L25/18,,0,0,,,,ACTIVE
923,US,A1,US 2025/0086735 A1,023-697-257-388-82X,3/13/2025,2025,US 202418427275 A,1/30/2024,IN 202341061034 A,9/11/2023,MACHINE LEARNING FOR LEGAL CLAUSE EXTRACTION,"Methods, systems, apparatuses, devices, and computer program products are described. A system may support a machine learning model for legal clause extraction. The machine learning model may receive, as an input, at least a portion of a document and may output an indication of one or more legal clauses included in the document. To train the model, the system may receive a document and an indication of ground truths (e.g., legal clauses) for the document. The system may determine one-to-one mappings between the legal clauses indicated by the ground truths and the legal clauses indicated by the output of the machine learning model. The system may perform a longest common substring analysis on the one-to-one mappings to determine an accuracy of the machine learning model and may iteratively update the model based on the analysis.",SALESFORCE INC,VEDULA SUNDAR RAM;;DUA RAJDEEP;;SINGH AKASH;;DASH AMIT KUMAR;;GUPTA NIMESH;;SIPANI SOURAV;;SINGH AJAY;;GARG KHYATI;;SOMA SREE HARINI,SALESFORCE INC (2024-01-30),https://lens.org/023-697-257-388-82X,Patent Application,yes,0,0,1,023-697-257-388-82X,US,1,023-697-257-388-82X,US,0,G06Q50/18;;G06Q50/18,G06Q50/18,,0,0,,,,PENDING
924,US,A1,US 2024/0370432 A1,070-024-724-158-117,11/7/2024,2024,US 202418596801 A,3/6/2024,US 202418596801 A;;US 202363463146 P,5/1/2023,"SYSTEM, METHOD AND APPARATUS FOR NETWORK SEARCH INCLUDING A CHATBOT","The present specification provides, amongst other things, a novel system, method and apparatus for real time searches. A search engine is provided that generates search parameters based on a natural language conversation with a chatbot. The parameters are parsed into a plurality of portions according to a refinement protocol. At least one of the portions is sent to a first engine for a search, and the results of are transformed using the refinement protocol.",AMADEUS SAS,DEVAUX YANNICK;;VINCIGUERRA JEAN-PASCAL,,https://lens.org/070-024-724-158-117,Patent Application,yes,4,0,2,014-070-693-292-845;;070-024-724-158-117,US;;EP,6,061-943-546-938-946;;072-946-610-763-662;;035-193-511-202-661;;014-070-693-292-845;;118-629-492-668-186;;070-024-724-158-117,US;;EP,0,G06F16/3329;;G06F16/90332;;G06N20/00;;G06F16/953;;G06F16/24535;;G06F40/40;;G06F21/6245;;H04L51/02,G06F16/2453;;G06F16/953;;G06F21/62;;G06F40/40;;H04L51/02,,0,0,,,,PENDING
925,US,A1,US 2024/0411994 A1,173-766-386-967-882,12/12/2024,2024,US 202318457381 A,8/29/2023,US 202318457381 A;;US 202363471532 P,6/7/2023,EXTRACTING INFORMATION FROM REPORTS USING LARGE LANGUAGE MODELS,"A computer-implemented method for extracting and mapping structured information to a data model includes obtaining text data from one or more unstructured data sources. Rephrased text data is determined using a Large Language Model (LLM), a preprocessing prompt, and the text data. Extracted data is determined using the LLM, an extraction prompt, the data model, and the rephrased text data. The extracted data is mapped to the data model. The method can be applied, for example, to medical use cases or cyberthreat detection, among others, to improve the data models and support decision making.",NEC LABORATORIES EUROPE GMBH,SIRACUSANO GIUSEPPE;;SANVITO DAVIDE;;GONZALEZ SANCHEZ ROBERTO;;BIFULCO ROBERTO,NEC LABORATORIES EUROPE GMBH (2023-07-20),https://lens.org/173-766-386-967-882,Patent Application,yes,4,6,2,063-223-084-534-636;;173-766-386-967-882,US;;JP,2,063-223-084-534-636;;173-766-386-967-882,US;;JP,0,G06F40/295;;G06F40/205;;G06F40/205;;G06F40/295,G06F40/295;;G06F40/205,,0,0,,,,PENDING
926,US,A1,US 2025/0131129 A1,158-913-107-426-578,4/24/2025,2025,US 202418939928 A,11/7/2024,KR 20230143068 A;;KR 20230192711 A;;KR 2024016249 W,10/24/2023,"ELECTRONIC DEVICE, METHOD, AND RECORDING MEDIUM FOR SUPPORTING ARTIFICIAL INTELLIGENCE-BASED DATA SHARING","Various embodiments of the disclosure provide an electronic device, a method, and a recording medium configured to provide data sharing based on artificial intelligence (AI). The electronic device according to an embodiment may analyze shared data selected based on an input requesting to shared data of the electronic device. The electronic device may, based on the shared data including the personal information, generate hint information related to the personal information so that information corresponding to the personal information may be inferred by an external electronic device. The electronic device may replace the personal information with the hint information in the shared data and share the shared data including the hint information.",SAMSUNG ELECTRONICS CO LTD,SONG YOECHAN;;KIM DUKHYUN;;KIM SANGHEON;;KIM JUNSUNG;;SON DONGIL;;LIM YEUNWOOK,SAMSUNG ELECTRONICS CO. LTD (2024-10-21),https://lens.org/158-913-107-426-578,Patent Application,yes,0,0,1,158-913-107-426-578,US,3,135-663-958-661-396;;158-913-107-426-578;;141-936-011-575-071,US;;WO;;KR,0,G06F21/6254;;G06F21/6245;;G06F21/6254,G06F21/62,,0,0,,,,PENDING
927,US,A1,US 2025/0103602 A1,191-668-827-108-21X,3/27/2025,2025,US 202418826949 A,9/6/2024,US 202418826949 A;;US 202363539906 P;;US 202463568360 P,9/22/2023,System and Methods for Personalization and Customization of Search Results and Search Result Ranking in an Internet-Based Search Engine,"A computer server system and method are disclosed for personalization and customization of search results and search result rankings, such as for Internet searching. A representative server system comprises: a network interface to receive a primary query and transmit secondary queries and search results; and one or more processors configured to generate the secondary queries; to extract or transform responses into text variables; to use trained, supervised multi-class neural networks to classify the text variables to form initial classifications or categories and combine the initial classifications or categories to form resulting classifications or categories; to filter and rank the resulting classifications or categories; and to use the filtered and ranked resulting classifications or categories to generate and output the personalized search results and search result rankings, the personalized search results and search result rankings comprising one or more associated classifications or categories corresponding to the primary query.",RETAIL CAPITAL LLC,JHA SOURABH;;ZHAO ZHEN;;MANSUETI JACK;;SAMAL SATYAJIT;;YELLE DANNY M;;PENDER JEROME M,,https://lens.org/191-668-827-108-21X,Patent Application,yes,0,0,2,199-076-602-123-453;;191-668-827-108-21X,US,2,199-076-602-123-453;;191-668-827-108-21X,US,0,G06F16/24578;;G06F16/9535;;G06F16/9535;;G06F16/24578,G06F16/2457;;G06F16/9535,,1,1,128-324-338-127-280,10.1109/mspct.2011.6150476,"Ali et al., ""Metasearching using Supervised Rank Aggregation."" Proc. of the 2011 IEEE International Conference on Computational Intelligence and Computing Research (2011 IEEE ICCIC), Kanyakumari, India, IEEE press. 2011. (Year: 2011)",PENDING
928,US,A1,US 2025/0200114 A1,187-642-363-420-941,6/19/2025,2025,US 202418783424 A,7/25/2024,US 202418783424 A;;US 2024/0012269 W;;US 202318203524 A;;US 202318203534 A;;US 202318203530 A;;US 202318203537 A;;US 202463637254 P;;US 202363611006 P;;US 202463637258 P;;US 202463637266 P;;US 202463644385 P;;US 202463637275 P;;US 202463637277 P;;US 202363444162 P,2/8/2023,PERSONALIZED CONTENT GENERATION,"Methods, systems, and computer programs are presented for generating personalized content. One method includes an operation for identifying audience parameter values that indicate which users are members of an audience. The method further includes operations for determining attribute values for attributes used to generate items based on the audience parameter values, and generating items for the audience based on the attribute values. Generating each item comprises creating a prompt based on a type of the item, the attribute values, and the audience parameter values; selecting a generative artificial intelligence (GAI) tool to generate the item based on the type of item; and providing the created prompt to the selected GAI tool. The method further includes causing presentation of the generated items in a user interface (UI), receiving on the UI a selection of one of the items; and transmitting the selected item to one or more members of the audience.",TYPEFACE INC,PARASNIS ABHAY;;SHAH SAACHI;;MOREIRA JONATHAN;;BENDAPUDI PERRAJU;;POLA HEMA VISHNU;;SOOD VISHAL;;DAVE NIPUN;;PIMPLEY ANISH,TYPEFACE INC (2024-08-01),https://lens.org/187-642-363-420-941,Patent Application,yes,0,0,1,187-642-363-420-941,US,13,101-024-712-936-789;;055-185-359-749-43X;;140-719-340-018-551;;041-858-994-965-698;;038-024-101-354-760;;144-304-260-041-154;;170-700-138-228-895;;143-143-756-117-625;;040-754-353-577-107;;187-642-363-420-941;;147-907-512-157-164;;037-305-382-999-104;;124-442-286-055-183,US;;WO,0,G06Q30/0269;;G06F16/9035;;G06Q30/0244;;G06Q30/0276;;G06Q30/0271;;G06F16/9035;;G06Q30/0244;;G06Q30/0269;;G06F3/04842,G06F16/9035;;G06F3/04842;;G06Q30/0242;;G06Q30/0251,,0,0,,,,PENDING
929,WO,A1,WO 2024/238348 A1,180-548-859-594-536,11/21/2024,2024,US 2024/0028834 W,5/10/2024,US 202363466150 P,5/12/2023,DRILLING FRAMEWORK,"A method may include receiving, via an interface, a digital well plan for a well at a field site; automatically determining, based on a computational analysis of at least offset well data for offset wells at different field sites, a corresponding likelihood for each of a number of undesirable events for at least one section of the well specified by the digital well plan; automatically computing a potential risk metric for each of the number of undesirable events based at least in part on the corresponding likelihood for each of the number of undesirable events; and automatically generating a graphical user interface that includes a section identifier for each of the at least one section of the well, an undesirable event identifier for each of the number of undesirable events, and a potential risk identifier based on the potential risk metric for each of the number of undesirable events.",SCHLUMBERGER TECHNOLOGY CORP;;SCHLUMBERGER CA LTD;;SERVICES PETROLIERS SCHLUMBERGER;;GEOQUEST SYSTEMS BV,RUZHNIKOV ALEXEY;;GREGORY PETER;;SORIANO REMENTERIA AGUSTIN;;WILLIAMS MICHAEL JOHN,,https://lens.org/180-548-859-594-536,Patent Application,yes,3,0,3,174-166-935-346-905;;180-548-859-594-536;;124-654-712-192-530,US;;WO,3,174-166-935-346-905;;180-548-859-594-536;;124-654-712-192-530,US;;WO,0,E21B2200/20;;E21B41/00;;G06N5/00;;G06N5/022;;G06F30/20;;G06F30/12,E21B41/00;;G06N5/00,,2,1,051-977-834-864-753,10.1613/jair.1129,"FOXLONG: ""PDDL2.1: An Extension to PDDL for Expressing Temporal Planning Domains"", OURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH, vol. 20, 2003, pages 61 - 124;;JANGHORBANI ET AL.: ""Domain Authoring Assistant for Intelligent Virtual Agent, AAMAS"", 19: PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS, May 2019 (2019-05-01), pages 104 - 112",PENDING
930,US,A1,US 2025/0078091 A1,137-136-320-307-038,3/6/2025,2025,US 202318241078 A,8/31/2023,US 202318241078 A,8/31/2023,SYSTEMS AND METHODS FOR INTELLIGENT AND CONTINUOUS RESPONSIBLE AI COMPLIANCE AND GOVERNANCE MANAGEMENT IN AI PRODUCTS,"Systems and methods for responsible AI compliance and governance management in AI Products are disclosed. The system receives a request to assess an enterprise product associated with a specific application. Further, the system may determine a plurality of datasets associated with the AI model of the enterprise product. Furthermore, the system generates a training dataset and a test dataset for the determined plurality of datasets associated with the AI model. The system generates a ranked list of recommended metrics for the enterprise product based on the generated training dataset and the test dataset. The system further determines a mitigation strategy for the enterprise product based on the generated ranked list of recommended metrics. Furthermore, the system creates a feedback loop for continuous training and tuning the AI model and the plurality of datasets based on the determined mitigation strategy.",ACCENTURE GLOBAL SOLUTIONS LTD,MUNGUIA TAPIA EMMANUEL;;MUKHERJI ABHISHEK;;SATISH PADMANABHAN AISHWARYA;;SHASHI FNU;;BAJAJ YATIN;;CHO MOLLY CARRENE;;SUBRAHMONIA JAYASHREE;;ALAM NURE;;SAMBATH KUMAR SATHYAPRIYA,ACCENTURE GLOBAL SOLUTIONS LIMITED (2023-09-21),https://lens.org/137-136-320-307-038,Patent Application,yes,0,0,1,137-136-320-307-038,US,1,137-136-320-307-038,US,0,G06Q30/0203;;G06Q30/018;;G06N5/022;;G06N20/00;;G06Q30/018;;G06N5/022;;G06Q30/0203,G06Q30/018;;G06N5/022;;G06Q30/0203,,0,0,,,,PENDING
931,US,A1,US 2025/0041598 A1,156-154-395-443-841,2/6/2025,2025,US 202418926706 A,10/25/2024,US 202418926706 A;;US 202418583160 A;;US 202363447162 P;;US 202363535996 P,2/21/2023,ELECTRICAL STIMULATION METHODS AND DEVICES FOR IMPROVING BLOOD MANAGEMENT,"In an illustrative embodiment, methods and system for increasing coagulation potential and/or triggering a higher platelet activation rate in a subject via auricular neurostimulation include contacting skin of the subject with one or more therapeutic electrodes, each electrode positioned in a respective region of nerve structures of the auriculotemporal nerve (ATN), nerve structures connected to the ATN, nerve structures of the auricular branch of the vagus nerve (ABVN), or nerve structures connected to the ABVN, applying, to the electrodes, one or more stimulation patterns.",SPARK BIOMEDICAL INC,COVALIN ALEJANDRO;;CZURA CHRISTOPHER;;KHODAPARAST NAVID,,https://lens.org/156-154-395-443-841,Patent Application,yes,2,0,1,156-154-395-443-841,US,5,156-154-395-443-841;;101-026-482-241-429;;132-680-575-038-666;;166-891-782-224-166;;054-488-780-126-377,US;;WO,0,A61N1/0456;;A61N1/36034;;A61N1/36053;;A61N1/36025;;A61N1/0456;;A61N1/36034,A61N1/36;;A61N1/04,,0,0,,,,PENDING
932,US,A1,US 2025/0209481 A1,013-511-724-805-338,6/26/2025,2025,US 202418989725 A,12/20/2024,US 202418989725 A;;US 202463736746 P;;US 202363613860 P,12/22/2023,SYSTEMS AND METHODS FOR MACHINE LEARNING-BASED GENERATION OF INTERACTIVE VIRTUAL PERSONA COMMUNITIES,"A computer-implemented system, computer-implemented method, and computer-program product includes at a virtual persona service: identifying a respective set of permitted values or a respective distribution of values for each community persona variable of a set of community persona variables; constructing a virtual community persona template; generating a virtual community based on the virtual community persona template; receiving a user query and an indication of a virtual persona of the virtual persona community via an interactive user interface; constructing a persona-describing prompt based on a distinct set of community variables and associated variable values corresponding to the indicated virtual persona; providing, to one or more language learning models, the user query and the persona-describing prompt; and outputting, from the one or more language learning models, a response to the user query via the interactive user interface.",SOCIALTRAIT INC,JUDITH LUKAS;;SASIKUMAR SURAJ NARAYANAN,SOCIALTRAIT INC (2024-12-18),https://lens.org/013-511-724-805-338,Patent Application,yes,0,0,1,013-511-724-805-338,US,1,013-511-724-805-338,US,0,G06F40/40;;G06V20/49;;G06V20/46;;G06Q30/0203;;G06Q30/0203;;G06V20/46;;G06V20/49;;G06F40/40,G06Q30/0203;;G06F40/40;;G06V20/40,,0,0,,,,PENDING
933,US,A1,US 2024/0285944 A1,101-026-482-241-429,8/29/2024,2024,US 202418583160 A,2/21/2024,US 202418583160 A;;US 202363447162 P;;US 202363535996 P,2/21/2023,ELECTRICAL STIMULATION METHODS AND DEVICES FOR IMPROVING BLOOD MANAGEMENT,"In an illustrative embodiment, methods and system for increasing coagulation potential and/or triggering a higher platelet activation rate in a subject via auricular neurostimulation include contacting skin of the subject with one or more therapeutic electrodes, each electrode positioned in a respective region of nerve structures of the auriculotemporal nerve (ATN), nerve structures connected to the ATN, nerve structures of the auricular branch of the vagus nerve (ABVN), or nerve structures connected to the ABVN, applying, to the electrodes, one or more stimulation patterns.",SPARK BIOMEDICAL INC,COVALIN ALEJANDRO;;CZURA CHRISTOPHER;;KHODAPARAST NAVID,SPARK BIOMEDICAL INC (2024-02-23),https://lens.org/101-026-482-241-429,Patent Application,yes,0,0,3,166-891-782-224-166;;101-026-482-241-429;;054-488-780-126-377,US;;WO,5,156-154-395-443-841;;101-026-482-241-429;;132-680-575-038-666;;166-891-782-224-166;;054-488-780-126-377,US;;WO,0,A61N1/36017;;A61N1/3606;;A61N1/36171;;A61N1/0456;;A61N1/36034;;A61N1/36031;;A61N1/36053;;A61N1/36007;;A61N1/3606;;A61N1/36017;;A61N1/36171;;A61N1/0456,A61N1/36;;A61N1/04,,0,0,,,,PENDING
934,WO,A2,WO 2025/029976 A2,187-019-329-740-509,2/6/2025,2025,US 2024/0040468 W,7/31/2024,US 202363516891 P,8/1/2023,MULTIMODAL USER INTERFACES FOR INTERACTING WITH DIGITAL MODEL FILES,"Methods and systems enabling multimodal inputs for interacting with a live digital object are provided. The system receives the live digital object which includes a digital artifact extracted from a digital model file through a model representation. The system receives a user's security level and determines the user's access permission and modification permission to access and modify the digital artifact. The system accesses a multimodal interface configured to receive a conversational input and a spatial input, outputs the digital artifact to the multimodal interface based on tire access permission, receives from the multimodal interface a conversational input and a spatial input from tire user, and generates a modified digital artifact from the digital artifact via the digital model representation, based on the modification permission and on the conversational or spatial input. The multimodal interface may include conventional interfaces (GUIs/ APIs), conversational interfaces (text/voice), and spatial computing interfaces (VR/AR/MR/gestural).",ISTARI DIGITAL INC,ROPER WILLIAM;;BENSON CHRISTOPHER LEE;;KRISHNAN SRIRAM;;ABUNOJAIM BAHA ALDEEN E A;;KOTELLY CHRISTOPHER ALEXIS;;HAJ DAOUD RIDA JALAL RIDA;;DEGROFF DWIGHT EDWARD,,https://lens.org/187-019-329-740-509,Patent Application,yes,0,2,2,187-019-329-740-509;;188-084-798-471-433,WO,2,187-019-329-740-509;;188-084-798-471-433,WO,0,G06F21/577;;G06F21/6218,G06F21/62,,0,0,,,,PENDING
935,US,A1,US 2024/0067957 A1,027-416-621-281-650,2/29/2024,2024,US 202318339607 A,6/22/2023,US 202318339607 A;;US 202263399845 P;;US 202363481010 P,8/22/2022,AUTOCATALYTIC BASE EDITING FOR RNA-RESPONSIVE TRANSLATIONAL CONTROL,"Genetic circuits that control transgene expression in response to pre-defined transcriptional cues would enable the development of smart therapeutics. The present disclosure relates to engineered programmable single-transcript RNA sensors in which adenosine deaminases acting on RNA (ADARs) autocatalytically convert trigger hybridization into a translational output. This system amplifies the signal from editing by endogenous ADAR through a positive feedback loop. Amplification is mediated by the expression of a hyperactive, minimal ADAR variant and its recruitment to the edit site via an orthogonal RNA targeting mechanism. This topology confers high dynamic range, low background, minimal off-target effects, and a small genetic footprint. The circuits and systems disclosed herein leverage an ability to detect single nucleotide polymorphisms and modulate translation in response to endogenous transcript levels in mammalian cells.",MASSACHUSETTS INST TECHNOLOGY;;HARVARD COLLEGE,COLLINS JAMES J;;GAYET RAPHAEL;;IIIA KATHERINE;;RAZAVI SHIVA;;TIPPENS NATHANIEL;;ZHANG KEHAN;;CHEN JACK;;CHEN JONATHAN;;LALWANI MAKOTO,,https://lens.org/027-416-621-281-650,Patent Application,yes,0,0,2,027-416-621-281-650;;114-531-557-301-190,US;;WO,2,027-416-621-281-650;;114-531-557-301-190,US;;WO,0,C12N15/11;;C12N9/78;;C12N15/1086;;C12N15/1082;;C12Y305/04004;;C12N15/86;;C12N9/22;;C12N15/1082;;C12N15/1086;;C12N15/11;;C12N9/78;;C12N2750/14143;;C12N15/86;;C12N2310/20;;C12N2310/531;;C12Y305/04004,C12N15/10;;C12N9/78;;C12N15/11;;C12N15/86,,0,0,,,,PENDING
936,US,A1,US 2024/0399145 A1,132-680-575-038-666,12/5/2024,2024,US 202418807124 A,8/16/2024,US 202418807124 A;;US 202418583160 A;;US 202363447162 P;;US 202363535996 P,2/21/2023,ELECTRICAL STIMULATION METHODS AND DEVICES FOR IMPROVING BLOOD MANAGEMENT,"In an illustrative embodiment, methods and systems for increasing coagulation potential and/or triggering a higher platelet activation rate in a subject via auricular neurostimulation include contacting skin of the subject with one or more therapeutic electrodes, each electrode positioned in a respective region of nerve structures of the auriculotemporal nerve (ATN), nerve structures connected to the ATN, nerve structures of the auricular branch of the vagus nerve (ABVN), or nerve structures connected to the ABVN, applying, to the electrodes, one or more stimulation patterns.",SPARK BIOMEDICAL INC,COVALIN ALEJANDRO;;CZURA CHRISTOPHER;;KHODAPARAST NAVID,,https://lens.org/132-680-575-038-666,Patent Application,yes,0,0,1,132-680-575-038-666,US,5,156-154-395-443-841;;101-026-482-241-429;;132-680-575-038-666;;166-891-782-224-166;;054-488-780-126-377,US;;WO,0,A61N1/36034;;A61N1/0456;;A61N1/36014;;A61N1/326;;A61N1/36053;;A61N1/36114;;A61N1/0556;;A61N1/326;;A61N1/0456;;A61N1/36034;;A61N1/36014,A61N1/32;;A61N1/04;;A61N1/36,,0,0,,,,PENDING
937,WO,A1,WO 2025/122673 A1,036-357-953-798-153,6/12/2025,2025,US 2024/0058546 W,12/4/2024,US 202363606533 P,12/5/2023,METHODS AND SYSTEMS FOR GENERATING DATA FROM A SURGICAL PROCEDURE USING GENERATIVE ARTIFICIAL INTELLIGENCE,"A method for annotating data generated from a surgical procedure may include: providing image data of a surgical procedure; implementing a large language and vision assistant, wherein the large language and vision assistant comprises a large language model and an image processing model; and using the large language and vision assistant to generate a written description of anatomy, pathology, and/or physiology observed during the surgical procedure.",ACTIV SURGICAL INC;;HUVER SEAN D,HUVER SEAN D;;CALEF THOMAS J;;MCCULLOH CHRISTOPHER J;;SKINNER GARRETT;;JENTIS GABRIEL;;IYER SANTOSH;;OBERLIN JOHN;;MAROIS MIKAEL;;KIM PETER C W,,https://lens.org/036-357-953-798-153,Patent Application,yes,0,0,1,036-357-953-798-153,WO,1,036-357-953-798-153,WO,0,G16H50/20;;G16H30/40;;G16H80/00;;G16H15/00;;G16H70/20,G16H80/00;;G16H30/20;;G16H30/40;;G16H50/20,,0,0,,,,PENDING
938,US,A1,US 2025/0209297 A1,011-468-910-252-956,6/26/2025,2025,US 202418990937 A,12/20/2024,US 202418990937 A;;US 202463564879 P;;US 202363613969 P;;US 202463705435 P,12/22/2023,CHATBOT PLATFORM,"Technology is disclosed for programmatically implementing a chatbot that utilizes a language model to determine answers from a knowledge base or external resource. In one implementation, a conversation with a user is accessed. A representation summarizing the conversation is generated based on applying the conversation to a language model. An embedding corresponding to the representation is generated. A response is determined based on computing similarity of the embedding corresponding to the representation to embeddings corresponding to sentences of documents in a knowledge base. A corresponding representation of the response is communicated to the user. In one implementation, in response to a user input received in the conversation, an external resource, such as a third-party website or application is accessed and chatbot output is generated in response to a user input in a chat session.",INTERCOM INC,REID FERGAL CHARLES;;KOSTELAC MARIO;;BRODIGAN DAVID;;MAHAR MOLLY,,https://lens.org/011-468-910-252-956,Patent Application,yes,0,0,1,011-468-910-252-956,US,1,011-468-910-252-956,US,0,G06N3/006;;G06N3/042;;G06N3/042;;G06N3/006,G06N3/006;;G06N3/042,,0,0,,,,PENDING
939,US,A1,US 2025/0104290 A1,152-794-526-902-236,3/27/2025,2025,US 202418429251 A,1/31/2024,US 202418429251 A;;US 202363585902 P,9/27/2023,AUTOMATIC IMAGE GENERATION USING LATENT STRUCTURAL DIFFUSION,Examples described herein relate to automatic image generation. A plurality of inputs is accessed. The inputs include first input data and second input data. The first input data includes a text prompt describing a desired image and the second input data is indicative of one or more structural features of the desired image. One or more intermediate outputs are generated via a first generative machine learning model that uses the plurality of inputs as first control signals. An output image is generated via a second generative machine learning model that uses at least a subset of the plurality of inputs and at least a subset of the one or more intermediate outputs as second control signals. The output image is presented at a user device of a user.,DING ERLI;;ELES COLIN;;FRUCHTMAN AMIR;;GULER RIZA ALP;;LI YANYU;;LIU XIAN;;MUCA ERGETA;;RAMI KOUJAN MOHAMMAD;;REN JIAN;;SAGAR DHRITIMAN;;SIAROHIN ALIAKSANDR;;SKOROKHODOV IVAN;;TULYAKOV SERGEY,DING ERLI;;ELES COLIN;;FRUCHTMAN AMIR;;GULER RIZA ALP;;LI YANYU;;LIU XIAN;;MUCA ERGETA;;RAMI KOUJAN MOHAMMAD;;REN JIAN;;SAGAR DHRITIMAN;;SIAROHIN ALIAKSANDR;;SKOROKHODOV IVAN;;TULYAKOV SERGEY,SNAP INC (2024-02-02);;SNAP GROUP LIMITED (2024-02-05),https://lens.org/152-794-526-902-236,Patent Application,yes,0,0,1,152-794-526-902-236,US,2,152-794-526-902-236;;174-341-717-688-777,US;;WO,0,G06V10/44;;G06T11/00;;G06V10/44;;G06T11/00,G06T11/00;;G06V10/44,,0,0,,,,PENDING
940,WO,A2,WO 2024/259032 A2,006-479-027-687-304,12/19/2024,2024,US 2024/0033710 W,6/13/2024,US 202363507973 P;;US 202463571398 P,6/13/2023,SYSTEMS AND METHODS FOR PREDICTING MENTAL HEALTH CONDITIONS BASED ON PROCESSING OF CONVERSATIONAL SPEECH/TEXT AND LANGUAGE,"Described herein are systems and methods for identifying the severity of a mental health condition or symptoms of same by listening to a human-to-human conversation by receiving conversation data, processing the conversation data to generate a language model output and/or an acoustic model output using one or more language models and/or acoustic models. Further described herein are systems and methods for automatically tracking and providing analytics on self-report questionnaires administered during the conversation.",ELLIPSIS HEALTH INC,SHRIBERG ELIZABETH;;CHLEBEK PIOTR;;RUTOWSKI TOMEK;;HARATI AMIR;;ARATOW MICHAEL;;MONDAL MAINUL;;MCCOOL MELISSA;;NARAYANAN VAISHNAVI;;TAGORE ISHANI;;LU YANG;;GOULART TULIO;;ROZANSKI ROBERT,,https://lens.org/006-479-027-687-304,Patent Application,yes,0,0,2,006-479-027-687-304;;160-848-724-931-127,WO,2,006-479-027-687-304;;160-848-724-931-127,WO,0,G06F40/30;;G16H50/20;;G16H10/20;;G16H15/00;;G16H10/60;;G16H20/70,,,0,0,,,,PENDING
941,WO,A1,WO 2025/072369 A1,145-214-898-586-265,4/3/2025,2025,US 2024/0048463 W,9/25/2024,US 202363585108 P;;US 202363596365 P;;US 202463558534 P,9/25/2023,SYSTEMS AND METHODS FOR GENERATING CUSTOMIZED AI MODELS,"While AI models, like large language models, are powerful tools with multiple applications, they can be complex to use and can require a lot of resources to operate. The disclosed systems and methods provide tools to generate customized models (or AI agents) that are configured with features like tailored knowledge, capabilities, and instructions that make them faster, more efficient, and using less computational resources. Custom models may offer several technical advantages of improved efficiency, resource use, and connectivity. This disclosure describes systems and methods to configure, evaluate, generate, and deploy the custom models that can more efficiently run specific tasks. Disclosed systems and methods are configured to, for example, receive a query to generate a custom model, generate the custom model with the information in the query, and then resolve user queries more efficiently using the custom model.",OPENAI OPCO LLC,TURLEY NICHOLAS;;DIMSON THOMAS;;GODEMENT OLIVIER;;POKRASS MICHELLE,,https://lens.org/145-214-898-586-265,Patent Application,yes,4,0,3,145-214-898-586-265;;047-153-711-406-465;;026-002-614-958-233,US;;WO,3,145-214-898-586-265;;047-153-711-406-465;;026-002-614-958-233,US;;WO,0,G06N20/00;;G06N5/022;;G06N20/00;;G06N5/022;;G06F16/3344;;G06N5/02,G06N5/022;;G06N20/00,,2,0,,,"YOUYANG NG ET AL: ""SimplyRetrieve: A Private and Lightweight Retrieval-Centric Generative AI Tool"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 8 August 2023 (2023-08-08), XP091589061;;SHIZHE DIAO ET AL: ""LMFlow: An Extensible Toolkit for Finetuning and Inference of Large Foundation Models"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 21 June 2023 (2023-06-21), XP091544275",PENDING
942,WO,A2,WO 2024/220444 A2,181-413-368-104-289,10/24/2024,2024,US 2024/0024827 W,4/16/2024,US 202363459656 P,4/16/2023,GENERATIVE AI FOR CONTROL AND MANAGEMENT OF MANUFACTURING PROCESSES,"By converting various data sources and control systems for a manufacturing process into natural language (or near natural language) intermediate representations, a large language model trained on a large corpus of text can be used to generate analysis, recommendations, and solutions based on the full range of domain expertise embodied in the supporting corpus.",TULIP INTERFACES INC,LINDER NATAN;;KUBAT RONY;;SHILKROT ROY;;GLIDDEN MASON,,https://lens.org/181-413-368-104-289,Patent Application,yes,0,2,2,012-035-198-290-23X;;181-413-368-104-289,WO,2,012-035-198-290-23X;;181-413-368-104-289,WO,0,G06N20/00;;G06Q50/04;;G06Q10/0639;;G06F40/56;;G06F16/345;;G06V20/52;;G06V10/82;;G06V2201/06,,,0,0,,,,PENDING
943,US,A1,US 2025/0205489 A1,042-027-301-736-542,6/26/2025,2025,US 202318394982 A,12/22/2023,US 202318394982 A,12/22/2023,DEVICES AND METHODS FOR RECOVERING FROM BRAIN TRAUMA USING ELECTRICAL STIMULATION,"Systems and methods for providing rehabilitative neurostimulation therapy after neurological trauma include a head-wearable neurostimulation device including at least two electrodes, and sensor(s) i) integrated into the wearable device, and/or ii) in communication with a controller of the device. The controller is configured to, after a stroke or a traumatic brain injury (TBI) experienced by a wearer of the device, deliver stimulation therapy coordinated with a training regimen for supporting the wearer in regaining abilities. The stimulation therapy may include collecting, from the sensor(s), a time sequence of signals, analyzing the signals to identify evidence of participation in the training regimen, and, responsive to identifying the evidence, directing non-invasive stimulation pulses via the electrodes to i) the ABVN and/or ii) the ATN to induce neuronal plasticity, thereby promoting creation of new neural pathways corresponding to the training regimen.",SPARK BIOMEDICAL INC,COVALIN ALEJANDRO;;KHODAPARAST NAVID,SPARK BIOMEDICAL INC (2023-12-23),https://lens.org/042-027-301-736-542,Patent Application,yes,0,0,1,042-027-301-736-542,US,1,042-027-301-736-542,US,0,A61N1/3603;;G16H20/30;;A61N1/36036;;G16H40/67;;A61N1/0484;;A61N1/36031;;A61N1/0456;;A61N1/36034;;A61N1/36025;;A61N1/0476;;A61N1/36003;;A61N1/36036;;G16H40/67;;G16H20/30;;A61N1/3603,A61N1/36;;G16H20/30;;G16H40/67,,0,0,,,,PENDING
944,WO,A1,WO 2025/072344 A1,174-341-717-688-777,4/3/2025,2025,US 2024/0048430 W,9/25/2024,US 202363585902 P;;US 202418429251 A,9/27/2023,AUTOMATIC IMAGE GENERATION USING LATENT STRUCTURAL DIFFUSION,Examples described herein relate to automatic image generation. A plurality of inputs is accessed. The inputs include first input data and second input data. The first input data includes a text prompt describing a desired image and the second input data is indicative of one or more structural features of the desired image. One or more intermediate outputs are generated via a first generative machine learning model that uses the plurality of inputs as first control signals. An output image is generated via a second generative machine learning model that uses at least a subset of the plurality of inputs and at least a subset of the one or more intermediate outputs as second control signals. The output image is presented at a user device of a user.,SNAP INC,DING ERLI;;ELES COLIN;;FRUCHTMAN AMIR;;GULER RIZA ALP;;LI YANYU;;LIU XIAN;;MUCA ERGETA;;RAMI KOUJAN MOHAMMAD;;REN JIAN;;SAGAR DHRITIMAN;;SIAROHIN ALIAKSANDR;;SKOROKHODOV IVAN;;TULYAKOV SERGEY,,https://lens.org/174-341-717-688-777,Patent Application,yes,2,0,1,174-341-717-688-777,WO,2,152-794-526-902-236;;174-341-717-688-777,US;;WO,0,G06T2207/20081;;G06T2207/20084;;G06T2207/30196;;G06T2207/10024;;G06T2207/10028;;G06T2207/20092;;G06T2207/30201;;G06T11/00,G06T11/00,,2,0,,,"SOON YAU CHEONG ET AL: ""KPE: Keypoint Pose Encoding for Transformer-based Image Generation"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 6 October 2022 (2022-10-06), XP091335235;;RAMESH ADITYA ET AL: ""Hierarchical text-conditional image generation with CLIP latents"", ARXIV (CORNELL UNIVERSITY), 12 April 2022 (2022-04-12), Ithaca, XP093129668, Retrieved from the Internet <URL:https://arxiv.org/pdf/2204.06125.pdf> [retrieved on 20240209], DOI: 10.48550/arXiv.2204.06125",PENDING
945,US,B1,US 12292811 B1,150-084-174-776-205,5/6/2025,2025,US 202418954389 A,11/20/2024,US 202418954389 A;;US 202418812913 A;;US 202418661532 A;;US 202418661519 A;;US 202418633293 A,4/11/2024,Dynamic system resource-sensitive model software and hardware selection,"The systems and methods disclosed herein enable the dynamic selection of one or more AI models to generate an output in response to an input. The system receives, from a computing device, an output generation request including an input for the generation of an output using one or more models from a plurality of models. The system generates expected values for a set of output attributes of the output generation request. For each particular model in the plurality of models, the system determines the capabilities of the particular model, and dynamically select a subset of models from the plurality of models. The system dynamically selects a subset of available system resources to process the input included in the output generation request. The system generates the output by processing the input included in the output generation request using the selected subset of available system resources.",CITIBANK NA,DEB SOURABH;;ENGELBRECHT JASON;;WANG ZHEYU;;JIN HAOLIN,CITIBANK N.A (2024-08-26),https://lens.org/150-084-174-776-205,Granted Patent,yes,26,0,1,150-084-174-776-205,US,36,166-860-055-274-237;;192-529-172-020-159;;117-165-481-521-817;;062-084-390-952-648;;009-332-012-767-769;;130-711-467-813-772;;150-084-174-776-205;;134-859-487-724-028;;136-076-696-451-742;;174-498-778-674-614;;135-411-020-650-37X;;082-042-370-293-809;;081-164-654-051-886;;126-999-415-386-749;;101-393-155-626-043;;028-517-317-595-400;;183-393-311-078-435;;120-491-497-842-713;;071-444-314-653-665;;151-710-271-944-022;;169-310-367-816-659;;114-332-483-825-36X;;176-222-606-932-299;;109-693-731-347-460;;187-959-165-043-749;;165-235-788-605-427;;184-797-936-150-334;;129-627-428-962-735;;132-864-126-338-301;;147-316-129-152-657;;087-574-341-939-358;;052-233-397-211-176;;154-552-332-382-958;;158-104-528-887-831;;122-629-432-281-208;;053-045-267-490-224,US;;WO;;EP,0,G06F8/41;;G06N3/0455;;G06N3/084;;G06F11/3419;;G06F9/5055,G06F11/34;;G06F9/50,,1,0,,,"Generative machine learning models; IPCCOM000272835D, Aug. 17, 2023. (Year: 2023).",ACTIVE
946,WO,A2,WO 2024/178222 A2,189-834-120-717-045,8/29/2024,2024,US 2024/0016899 W,2/22/2024,US 202363486350 P,2/22/2023,APPARATUS AND METHOD FOR TREATING SLEEP APNEA,"Apparatus for treating sleep apnea and methods for use include a wearable housing having a contact surface configured to removably engage a wearer's chin, a stimulator enclosed in the housing and configured to produce a magnetic field directed through the contact surface, and a control unit in communication with the stimulator and sensor(s), each sensor configured to produce signals indicative of i) biometric measurements of the wearer or ii) environmental measurements corresponding to an environment of the wearer. The control unit may be configured to analyze the sensor signals to detect an apneic event or a hypoxic condition of the wearer, and, responsive to the detecting, activate the stimulator to produce a magnetic field configured to deliver stimulation to targeted tissues(s) and/or nerve(s), thereby causing contraction of the wearer's pharyngeal tissue, tongue, and/or other dilator muscle.",TEXAS MEDICAL CENTER,GLICK AARON RUSH;;VELAZQUEZ CARLOS FRANCISCO BERNAL,,https://lens.org/189-834-120-717-045,Patent Application,yes,0,0,2,189-834-120-717-045;;033-097-662-407-872,WO,2,189-834-120-717-045;;033-097-662-407-872,WO,0,A61N2/02;;A61N1/3601;;A61F5/566;;A61N2/006;;A61N2/004;;A61N1/3611,,,0,0,,,,PENDING
947,US,A1,US 2025/0005288 A1,177-877-178-510-156,1/2/2025,2025,US 202318217335 A,6/30/2023,US 202318217335 A,6/30/2023,DIRECTIVE GENERATIVE THREAD-BASED USER ASSISTANCE SYSTEM,"Embodiments of the disclosed technologies include generating a first thread classification prompt based on a first thread portion of an online dialog involving a user of a computing device, sending the first thread classification prompt to a first large language model, receiving a first thread classification generated and output by the first large language model based on the first thread classification prompt, formulating a plan execution prompt based on the first thread classification, sending the plan execution prompt to a second large language model, receiving a second thread portion generated and output by the second large language model based on the plan execution prompt and the online dialog, and generating a label for a third thread portion of the online dialog.",MICROSOFT TECHNOLOGY LICENSING LLC,AMATRIAIN-RUBIO XAVIER;;BREMER CHRISTOPHER M;;LOPEZ CARLOS H;;MONESTIE PIERRE Y;;TECLEMARIAM LAURA;;KASERA YAMINI;;KAZI MICHAEEL;;FU ZHOUTONG;;WU MUCHEN;;NARANG WINNIE;;TU YIYUAN;;MUNOZ ALCALDE JAIME;;PASUMARTHY NITIN;;BACH THAO;;WILLIAMS DAVID;;GARIBA PRIYANKA,MICROSOFT TECHNOLOGY LICENSING LLC (2023-07-12),https://lens.org/177-877-178-510-156,Patent Application,yes,0,2,2,061-147-580-666-254;;177-877-178-510-156,US;;WO,2,061-147-580-666-254;;177-877-178-510-156,US;;WO,0,G06F40/35;;G06F40/30;;G06F40/216;;G06F40/35;;G06F9/445,G06F40/35;;G06F9/445,,0,0,,,,PENDING
948,US,A1,US 2025/0094735 A1,038-820-171-081-558,3/20/2025,2025,US 202418885507 A,9/13/2024,US 202418885507 A;;US 202363583159 P;;US 202363583160 P;;US 202363583164 P,9/15/2023,DETECTION AND HANDLING OF ERRORS IN INPUT AND OUTPUT TO AND FROM A LARGE LANGUAGE MODEL,"Techniques for enhanced chatbot interaction using various large language model providers are provided. In one aspect, a method may include generating a request payload having a common request body specification based on an utterance such that the common request body specification may be a standardized data input format used by a generative artificial intelligence (GenAI) interface for interacting with GenAI model providers. In various embodiments, the method may include converting the common request body specification into a custom request body specification having a data input format associated with a GenAI model provider selected from the plurality of GenAI model providers, communicating, by the GenAI interface, the request payload with the custom request body specification to the GenAI provider for processing by a GenAI model, receiving, at the GenAI interface from the GenAI model provider, a response payload associated with: (i) an error, (ii) processing the request payload, or (iii) both.",ORACLE INT CORP,SAIKIA AMITABH;;DAVELAAR STEVEN MARTIJN,ORACLE INTERNATIONAL CORPORATION (2024-09-18),https://lens.org/038-820-171-081-558,Patent Application,yes,0,1,1,038-820-171-081-558,US,2,134-031-581-433-542;;038-820-171-081-558,US,0,G06F40/40;;G06F40/40,G06F40/40,,0,0,,,,PENDING
949,US,A1,US 2024/0403634 A1,178-505-872-766-791,12/5/2024,2024,US 202418676339 A,5/28/2024,US 202418676339 A;;US 202363505227 P;;US 202363583484 P;;US 202363505218 P;;US 202363579898 P,5/31/2023,SAVING PRODUCTION RUNS OF A FUNCTION AS UNIT TEST AND AUTOMATIC OUTPUT REGENERATION,"An artificial intelligence system can be used to respond to natural language inputs. The AI System may, for example, receive a first user input for a LLM, generate a first prompt based on the first user input, transmit the first prompt to an LLM, receive an output from the LLM, and evaluate the output from the LLM with reference to one or more validation tests. Responsive to determining that the output from the LLM is not validated, generate a second prompt for the LLM, where the second prompt indicates at least an aspect of the output that caused the output to not be evaluated (e.g., a portion of the output that may need to be updated or corrected), transmit the second prompt to the LLM, and receive an updated output from the LLM. The AI system can include an application for testing functions that utilize interactions with language models.",PALANTIR TECHNOLOGIES INC,HAWES MATTHEW;;SHANKAR ANKIT;;TELLING MORTEN;;MAJID ADIL;;DOBSON JACK,PALANTIR TECHNOLOGIES INC (2024-09-10),https://lens.org/178-505-872-766-791,Patent Application,yes,0,5,1,178-505-872-766-791,US,1,178-505-872-766-791,US,0,G06N3/08;;G06N3/08,G06N3/08,,0,0,,,,PENDING
950,US,A1,US 2024/0386347 A1,004-983-701-435-273,11/21/2024,2024,US 202418655675 A,5/6/2024,US 202418655675 A;;US 202363502822 P;;US 202363509508 P;;US 202363584448 P;;US 202463558000 P,5/17/2023,OBJECT-BASED PROCESS MANAGEMENT,"A system may receive a representation of a process, wherein the representation of the process includes: a plurality of states, and one or more transitions among states of the plurality of states. A system may receive a plurality of data objects, wherein each of the data objects is associated with a respective set of properties. A system may determine for each of the plurality of data objects, respective state information associated with the data objects. A system may cause generation of an interactive graphical user interface including: a graph-based visualization of at least a portion of the plurality of states and the one or more transitions, wherein the graph-based visualization is generated based at least in part on at least a portion of the plurality of data objects and associated properties and state information.",PALANTIR TECHNOLOGIES INC,DHILLON ALEX;;SCHNEIDER ALEC;;PATTON CASEY;;TAM KA-WING COURTNEY;;MATTOO HARSHIL;;MADINE OLIVER,PALANTIR TECHNOLOGIES INC (2024-05-20),https://lens.org/004-983-701-435-273,Patent Application,yes,0,0,1,004-983-701-435-273,US,3,196-013-110-803-033;;118-203-793-271-256;;004-983-701-435-273,US;;EP,0,G06Q10/0633;;G06Q10/0633,G06Q10/0633,,0,0,,,,PENDING
951,EP,A1,EP 4465217 A1,118-203-793-271-256,11/20/2024,2024,EP 24176168 A,5/16/2024,US 202363502822 P;;US 202363509508 P;;US 202363584448 P;;US 202463558000 P;;US 202418665675 A;;US 202418655680 A,5/17/2023,OBJECT-BASED PROCESS MANAGEMENT,"A system may receive a representation of a process, wherein the representation of the process includes: a plurality of states, and one or more transitions among states of the plurality of states. A system may receive a plurality of data objects, wherein each of the data objects is associated with a respective set of properties. A system may determine for each of the plurality of data objects, respective state information associated with the data objects. A system may cause generation of an interactive graphical user interface including: a graph-based visualization of at least a portion of the plurality of states and the one or more transitions, wherein the graph-based visualization is generated based at least in part on at least a portion of the plurality of data objects and associated properties and state information.",PALANTIR TECHNOLOGIES INC,DHILLON ALEX;;SCHNEIDER ALEC;;PATTON CASEY;;TAM KA-WING COURTNEY;;MATTOO HARSHIL;;MADINE OLIVER,,https://lens.org/118-203-793-271-256,Patent Application,yes,10,0,1,118-203-793-271-256,EP,3,196-013-110-803-033;;118-203-793-271-256;;004-983-701-435-273,US;;EP,0,G06Q10/06316;;G06N20/00;;G06F40/30;;G06F16/289;;G06F16/26,G06Q10/0631;;G06F16/248,,3,2,097-301-495-641-182;;125-545-780-046-731,10.1145/3543873.3587309;;10.1145/3491102.3517582,"WIKIPEDIA: ""Large language model"", INTERNET ARTICLE, 15 May 2023 (2023-05-15), XP093209602, Retrieved from the Internet <URL:https://en.wikipedia.org/w/index.php?title=Large_language_model&oldid=1154967861> [retrieved on 20240927];;XU CANWEN ET AL: ""Mirror: A Natural Language Interface for Data Querying, Summarization, and Visualization"", ARCHITECTUAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, IEEE COMPUTER SOCIETY PRESS, 10662 LOS VAQUEROS CIRCLE PO BOX 3014 LOS ALAMITOS, CA 90720-1264 USA, 30 April 2023 (2023-04-30), pages 49 - 52, XP059077142, ISBN: 978-0-8186-0805-6, DOI: 10.1145/3543873.3587309;;TONGSHUANG WU ET AL: ""AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 4 October 2021 (2021-10-04), XP091069877",PENDING
952,US,A1,US 2024/0385885 A1,196-013-110-803-033,11/21/2024,2024,US 202418655680 A,5/6/2024,US 202418655680 A;;US 202363502822 P;;US 202363509508 P;;US 202363584448 P;;US 202463558000 P,5/17/2023,OBJECT-BASED PROCESS MANAGEMENT,"A system may receive a representation of a process, wherein the representation of the process includes: a plurality of states, and one or more transitions among states of the plurality of states. A system may receive a plurality of data objects, wherein each of the data objects is associated with a respective set of properties. A system may determine for each of the plurality of data objects, respective state information associated with the data objects. A system may cause generation of an interactive graphical user interface including: a graph-based visualization of at least a portion of the plurality of states and the one or more transitions, wherein the graph-based visualization is generated based at least in part on at least a portion of the plurality of data objects and associated properties and state information.",PALANTIR TECHNOLOGIES INC,DHILLON ALEX;;SCHNEIDER ALEC;;PATTON CASEY;;TAM KA-WING COURTNEY;;MATTOO HARSHIL;;MADINE OLIVER,PALANTIR TECHNOLOGIES INC (2024-05-20),https://lens.org/196-013-110-803-033,Patent Application,yes,0,1,1,196-013-110-803-033,US,3,196-013-110-803-033;;118-203-793-271-256;;004-983-701-435-273,US;;EP,0,G06F9/451;;G06F9/5027,G06F9/50,,0,0,,,,PENDING
953,US,A1,US 2024/0354503 A1,081-601-941-326-785,10/24/2024,2024,US 202318341681 A,6/26/2023,FR 2304014 A,4/21/2023,GENERATIVE THOUGHT STARTERS,"Embodiments of the described technologies determine input signals, where the input signals are specific to a user of the user network. The input signals are input to a set of artificial intelligence (AI) models. In response to the input signals, the first set of AI models output a first set of AI-derived signals relating to the input signals. At least one prompt template is applied to the first set of AI-derived signals to create at least one prompt. The at least one prompt is input to at least one generative AI model. In response to the at least one prompt, the at least one generative AI model outputs at least one thought starter machine-generated by the at least one generative AI model. The at least one thought starter includes digital content configured to be distributed via the user network.",MICROSOFT TECHNOLOGY LICENSING LLC,BARUCH KEREN KOCHAVA;;ARCARA KEVIN MICHAEL;;KAPLAN ADAM JASON;;DE LONGUEAU SAINT MICHEL EMILIE MARIE ANDRÉA;;CHARANIA FAIZAAN SHAFIQ,MICROSOFT TECHNOLOGY LICENSING LLC (2023-07-13),https://lens.org/081-601-941-326-785,Patent Application,yes,0,3,1,081-601-941-326-785,US,2,081-601-941-326-785;;172-430-752-378-354,US;;WO,0,G06F16/345;;G06F40/253;;G06F16/345;;G06F40/253,G06F40/253;;G06F16/34,,0,0,,,,PENDING
954,US,A1,US 2024/0346342 A1,162-689-677-152-311,10/17/2024,2024,US 202418635988 A,4/15/2024,US 202418635988 A;;US 202463633774 P;;US 202363582192 P;;US 202363459194 P,4/13/2023,GENERATIVE MACHINE LEARNING MODELS FOR GENEALOGY,"Disclosed herein are methods, systems, and non-transitory computer readable mediums for generating a shareable genealogical summary for a target individual. An example method includes receiving a request from a user to generate a shareable genealogical summary about a target user. The method generates the shareable genealogical summary comprising a genealogical history of the target user. The method provides genealogical information for the target user to a machine-learning language model. The genealogical information includes a family tree. The method receives a response generated by executing the machine-learning language model from a model serving system. The method provides the shareable genealogical summary for display to the user.",ANCESTRY COM OPERATIONS INC,LEWIS GLEN BREWER;;LISS ALEXANDER;;SHELLEY DANIEL VAL;;MANGUM GARY LEE;;SANTHANAM PRASHANTH;;SELLECK CAITY;;MOLLOY LIAM,ANCESTRY.COM OPERATIONS INC (2024-07-03),https://lens.org/162-689-677-152-311,Patent Application,yes,0,6,1,162-689-677-152-311,US,1,162-689-677-152-311,US,0,G06N5/022;;G06F40/284;;G06F40/106;;G06F40/30;;G06N5/01;;G06N3/045;;G06N3/044;;G06F40/56;;G06N7/01;;G06N5/022;;G06F40/106;;G06F40/284,G06N5/022;;G06F40/106;;G06F40/284,,0,0,,,,PENDING
955,WO,A1,WO 2025/037311 A1,080-893-419-542-929,2/20/2025,2025,IL 2024050820 W,8/14/2024,US 202363519519 P;;US 202363548339 P;;US 202463645998 P,8/14/2023,METHODS FOR IMPLEMENTING ARTIFICIAL INTELLIGENCE CAPABILITIES IN SOFTWARE APPLICATIONS,"The invention relates to methods and systems for integrating generative artificial intelligence (Al) capabilities into Software as a Service (SaaS) platforms. It comprises maintaining Al agents with varying credentials, enabling their interaction with alphanumeric data in table structures, and implementing a hierarchical access control scheme. The system displays table structures, provides interfaces for user inputs, and allows Al agents to be added as platform users. The generative Al agents can analyze data, identify actions, and perform tasks autonomously. The invention also includes methods for proactive information gathering, interactive analysis of Al outputs, and management of Al resources as limited assets. This approach enhances SaaS functionality by enabling Al-driven task completion, data analysis, and decision-making while maintaining data security and user-specific access controls.",MONDAY COM LTD,MYSTETSKYI VLAD;;FRIDMAN OR;;BESOR TZVIKA;;VERTMAN DANIELLE;;BEN YEOSHOA ODED;;BARDUGO AMIR;;HAI DANIEL,,https://lens.org/080-893-419-542-929,Patent Application,yes,3,0,3,115-508-893-488-661;;120-168-781-175-049;;080-893-419-542-929,WO,9,168-638-516-851-013;;086-697-142-734-230;;120-168-781-175-049;;016-206-116-962-776;;191-758-934-878-008;;080-893-419-542-929;;179-988-086-794-125;;115-508-893-488-661;;186-063-869-477-272,US;;WO,0,G06N5/043;;G06N3/02;;G06F40/18;;G06F16/2428;;G06F8/65;;G06F8/71;;G06F40/35;;G06Q10/06;;G06Q10/04;;G06Q10/103;;G06Q10/20;;G06Q50/50;;G06N20/00,G06F8/30;;G06N3/02;;G06N5/043,,0,0,,,,PENDING
956,US,A1,US 2025/0244964 A1,197-517-064-570-579,7/31/2025,2025,US 19179061,4/15/2025,,,METHODS FOR IMPLEMENTING ARTIFICIAL INTELLIGENCE CAPABILITIES IN SOFTWARE APPLICATIONS,"The invention relates to methods and systems for integrating generative artificial intelligence (AI) capabilities into Software as a Service (SaaS) platforms. It comprises maintaining AI agents with varying credentials, enabling their interaction with alphanumeric data in table structures, and implementing a hierarchical access control scheme. The system displays table structures, provides interfaces for user inputs, and allows AI agents to be added as platform users. The generative AI agents can analyze data, identify actions, and perform tasks autonomously. The invention also includes methods for proactive information gathering, interactive analysis of AI outputs, and management of AI resources as limited assets. This approach enhances SaaS functionality by enabling AI-driven task completion, data analysis, and decision-making while maintaining data security and user-specific access controls.",monday.com Ltd.,Vlad MYSTETSKYI;;Or FRIDMAN;;Tzvika BESOR;;Danielle VERTMAN;;Oded BEN YEOSHOA;;Amir BARDUGO;;Daniel HAI,,https://lens.org/197-517-064-570-579,Patent Application,yes,0,0,1,197-517-064-570-579,US,1,197-517-064-570-579,US,0,G06F8/34,G06F8/34,,0,0,,,,UNKNOWN
957,WO,A1,WO 2024/220308 A1,172-430-752-378-354,10/24/2024,2024,US 2024/0024168 W,4/12/2024,FR 2304014 A;;US 202318341681 A,4/21/2023,GENERATIVE THOUGHT STARTERS,"Embodiments of the described technologies determine input signals, where the input signals are specific to a user of the user network. The input signals are input to a set of artificial intelligence (AI) models. In response to the input signals, the first set of AI models output a first set of AI-derived signals relating to the input signals. At least one prompt template is applied to the first set of AI-derived signals to create at least one prompt. The at least one prompt is input to at least one generative AI model. In response to the at least one prompt, the at least one generative AI model outputs at least one thought starter machine-generated by the at least one generative AI model. The at least one thought starter includes digital content configured to be distributed via the user network.",MICROSOFT TECHNOLOGY LICENSING LLC,BARUCH KEREN KOCHAVA;;ARCARA KEVIN MICHAEL;;KAPLAN ADAM JASON;;ANDRÉA DE LONGUEAU SAINT MICHEL EMILIE MARIE;;CHARANIA FAIZAAN SHAFIQ,,https://lens.org/172-430-752-378-354,Patent Application,yes,2,0,1,172-430-752-378-354,WO,2,081-601-941-326-785;;172-430-752-378-354,US;;WO,0,G06N3/0475,G06N3/0475,,0,0,,,,PENDING
958,US,A1,US 2025/0238811 A1,076-199-236-991-989,7/24/2025,2025,US 202418953799 A,11/20/2024,US 202418953799 A;;US 202463624463 P,1/24/2024,AUTOMATED COMPLIANCE VERIFICATION OF REGULATED CONTENT ITEMS IN A CONTENT PAGE,"Computer-implemented systems and methods are disclosed, including systems and methods for performing compliance testing using language models or other machine learning models. A computer-implemented method may include, for example, accessing a content item; accessing a compliance ruleset; executing a compliance checker that utilizes a set of machine learning models; generating a prompt that includes the content item and the compliance ruleset; processing the prompt using the compliance checker; responsive to receiving a compliance determination dataset that indicates whether the content item satisfies one or more criteria within the compliance ruleset from the compliance checker; and generating an output based at least in part on the compliance determination dataset.",COMPLYAUTO IP LLC,CLEVELAND CHRISTOPHER JAMES;;GRAFF CASEY ANDREW,,https://lens.org/076-199-236-991-989,Patent Application,yes,0,0,3,076-199-236-991-989;;016-379-561-977-111;;008-384-016-086-723,US,3,008-384-016-086-723;;016-379-561-977-111;;076-199-236-991-989,US,0,G06Q30/018;;G06Q30/0277;;G06N20/00;;G06N3/0475;;G05B2219/31396;;G06N5/025;;H04L67/146;;G06N3/045,G06Q30/018,,0,0,,,,PENDING
959,US,A1,US 2025/0165717 A1,001-043-232-756-138,5/22/2025,2025,US 202519032030 A,1/18/2025,US 202519032030 A;;US 202418650042 A;;US 202363499489 P,5/1/2023,Multilevel Data Analysis,"A graphical, hierarchical document stream browser and environment for semantic (e.g. framing) and performance data analysis and interactive visualization integrates three scales: entities (competitive), entity (diachronic), and document (linguistic). The document level includes annotation and computational linguistics facilities; the entity level has calendrical and time-series focus. All levels emphasize deep linkage and network (i.e. connective/relational space) view of objects, with user-configurable connectivity. Large language model (LLM) integrations provide synthetic advisories, public opinions, reports, plot insights, comparisons; traditional natural language processing techniques and neural models are also employed. A smart plot system includes a “plot cart” and interpreter with an analysis snippet library. Graph structure may arise via adjustable blending or perceptual optimization of canned attribute-related distance functions or via link-induction query language with deep “semantic stored procedure” subexpressions, or feed into graph neural network-style inference for predictions. Most non-LLM ongoing computational load is client-side, using precomputed hierarchical summary files.",PONTIMYX CORP,BURTON ANDREW JOHN,,https://lens.org/001-043-232-756-138,Patent Application,yes,11,0,2,001-043-232-756-138;;154-438-023-580-150,US,2,001-043-232-756-138;;154-438-023-580-150,US,0,G06T2200/24;;G06F40/30;;G06T11/206;;G06F16/3344;;G06F40/30;;G06T2200/24;;G06T11/206;;G06F16/3344,G06F40/30;;G06F16/334;;G06T11/20,,0,0,,,,PENDING
960,US,A1,US 2024/0371510 A1,170-514-791-623-856,11/7/2024,2024,US 202418644278 A,4/24/2024,US 202418644278 A;;US 202363530986 P;;US 202363498341 P,4/26/2023,DIGITAL CONTENT LABELING BASED ON CORRELATED PERSON BEHAVIORS,"A system and method for determining and labeling any one or more components of digital content forming a session work product determined during the session of operation of a computing system by a person/operator. The person provides one or more informational contributions during the session of operation as sensed or determined by one or more input devices in communication with the computing system. The labeling is based at least in part upon correlating any of the informational contributions with any one or more minimal content objects comprising a component of digital content. Informational contributions comprise any one of or any combination of the person's authenticated identity, presence, liveness, and/or behaviors made substantially congruent or concurrent with the receiving of digital information comprising either of minimal content objects or application commands by the computing system.",AMAN JAMES ANDREW,AMAN JAMES ANDREW,,https://lens.org/170-514-791-623-856,Patent Application,yes,0,2,1,170-514-791-623-856,US,1,170-514-791-623-856,US,0,G16H40/63;;G16H40/63,G16H40/63,,0,0,,,,PENDING
961,US,A1,US 2025/0190688 A1,073-193-584-282-349,6/12/2025,2025,US 202418947774 A,11/14/2024,US 202418947774 A;;US 202318169808 A,2/15/2023,GENERATIVE COLLABORATIVE PUBLISHING SYSTEM,"Examples identify a user of a network as a possible contributor of digital content to a document, and identify different channels that are each capable of sending, to the user, an invitation for the user to contribute to the document. Respective channel usage data is determined, which includes historical data relating to use of the channel by the user to interact with content. Respective channel affinity scores are computed based on the respective channel usage data, where a channel affinity score includes an estimate of a likelihood of the user contributing to the document through the channel. Based on the respective channel affinity scores, an optimal channel is selected, and the invitation is sent to the user to contribute to the document through the optimal channel.",MICROSOFT TECHNOLOGY LICENSING LLC,MURALIDHARAN AJITH;;JAIN AASTHA;;LIU ZHANGLONG,MICROSOFT TECHNOLOGY LICENSING LLC (2023-03-20),https://lens.org/073-193-584-282-349,Patent Application,yes,0,0,2,023-759-557-167-149;;073-193-584-282-349,US,6,180-408-464-257-442;;029-499-748-945-396;;053-783-597-052-74X;;180-201-969-969-105;;023-759-557-167-149;;073-193-584-282-349,US;;WO,0,G06F40/30;;G06F40/166;;G06F40/30;;G06F40/166,G06F40/166;;G06F40/30,,0,0,,,,PENDING
962,US,A1,US 2024/0273306 A1,053-783-597-052-74X,8/15/2024,2024,US 202318169793 A,2/15/2023,US 202318169793 A,2/15/2023,GENERATIVE COLLABORATIVE PUBLISHING SYSTEM,"Embodiments of the disclosed technologies include creating a first set of title prompts by applying a first set of title prompt templates to a seed, where the seed includes a topic descriptor, applying a first generative language model to the first set of title prompts, outputting, by the first generative language model, based on the first set of title prompts, a first set of document titles, creating a first set of document prompts by applying a first set of document prompt templates different from the first set of title prompt templates to the first set of document titles, applying a second generative language model to the first set of document prompts, and outputting, by the second generative language model, based on the first set of document prompts, a first set of documents.",MICROSOFT TECHNOLOGY LICENSING LLC,SOMAIYA MANAS;;SOMASUNDARAM LAKSHMAN;;LORENZETTI SOPER LAURA;;PAN YAO;;PEZARRO NICHOLAS,MICROSOFT TECHNOLOGY LICENSING LLC (2023-03-15),https://lens.org/053-783-597-052-74X,Patent Application,yes,5,6,1,053-783-597-052-74X,US,6,180-408-464-257-442;;029-499-748-945-396;;053-783-597-052-74X;;180-201-969-969-105;;023-759-557-167-149;;073-193-584-282-349,US;;WO,0,G06F40/186;;G06F16/957;;G06N3/08;;G06F40/40;;G06N3/0475;;G06F40/40;;G06F40/186;;G06N3/08;;G06N3/0475;;G06F16/957,G06F40/40;;G06F16/957;;G06F40/186;;G06N3/0475;;G06N3/08,,0,0,,,,PENDING
963,US,A1,US 2024/0273291 A1,180-408-464-257-442,8/15/2024,2024,US 202318169786 A,2/15/2023,US 202318169786 A,2/15/2023,GENERATIVE COLLABORATIVE PUBLISHING SYSTEM,"Embodiments of the disclosed technologies include, in response to input of a first prompt to a generative language model, outputting, by the generative language model, a first document including a first piece of writing, where the first piece of writing is based on the first prompt. Feedback is received for the first document, where the feedback includes a rating for the first piece of writing. Using the generative language model, a second prompt different from the first prompt is generated, where the second prompt is based on the feedback. In response to input of the second prompt to the generative language model, the generative language model outputs a second document different from the first document, where the second document includes a second piece of writing based on the second prompt. The second document is published to a network.",MICROSOFT TECHNOLOGY LICENSING LLC,SMITH ALANA M;;SOMASUNDARAM LAKSHMAN;;SHAH SAARTH;;LORENZETTI SOPER LAURA;;KAPLAN ADAM;;SOMAIYA MANAS;;PAN YAO,MICROSOFT TECHNOLOGY LICENSING LLC (2023-03-15),https://lens.org/180-408-464-257-442,Patent Application,yes,13,10,1,180-408-464-257-442,US,6,180-408-464-257-442;;029-499-748-945-396;;053-783-597-052-74X;;180-201-969-969-105;;023-759-557-167-149;;073-193-584-282-349,US;;WO,0,G06F40/279;;G06F16/383;;G06F40/56;;G06F16/383;;G06F40/279,G06F40/279;;G06F16/383,,0,0,,,,PENDING
964,US,A1,US 2023/0245654 A1,032-790-847-350-496,8/3/2023,2023,US 202318157413 A,1/20/2023,US 202318157413 A;;US 202263305061 P;;US 202263379961 P;;US 202263382044 P;;US 202263383579 P;;US 202263477524 P,1/31/2022,Systems and Methods for Implementing Smart Assistant Systems,"In one embodiment, a system includes an automatic speech recognition (ASR) module, a natural-language understanding (NLU) module, a dialog manager, one or more agents, an arbitrator, a delivery system, one or more processors, and a non-transitory memory coupled to the processors comprising instructions executable by the processors, the processors operable when executing the instructions to receive a user input, process the user input using the ASR module, the NLU module, the dialog manager, one or more of the agents, the arbitrator, and the delivery system, and provide a response to the user input.",META PLATFORMS INC,SHRIVASTAVA AKSHAT;;DESAI SHREY;;GUPTA ANCHIT;;ELKAHKY ALI;;LIVSHITS ALEKSANDR;;KOLMYKOV-ZOTOV ALEXANDER;;ALY AHMED;;YU JINSONG;;NAIK MANALI ANAND;;YANG SHUHUI;;LIU BAIYANG;;APPINI SURYA TEJA;;SINGH TARUN VIR;;SU HANG;;ZHU JIEDAN;;PENG FUCHUN;;BHATTACHARYA SHOUBHIK;;MALIK KSHITIZ;;BAKSHI SHREYAN;;BHARADWAJ AKASH;;SRINIVAS HARISH;;YANG XIAO;;HUANG ZHUANGQUN;;KEREN GIL;;LE DUC HOANG;;MOHAMED AHMED KAMAL ATWA;;LIU ZHE;;MOHANTY PRANAB,,https://lens.org/032-790-847-350-496,Patent Application,yes,0,15,1,032-790-847-350-496,US,1,032-790-847-350-496,US,0,H04L63/0428;;G06N3/0442;;G06N3/0455;;G06N3/0895;;G06N3/096;;G06N3/098;;G06N5/027;;G06N5/04;;G10L15/063;;G10L15/1822;;G10L15/183;;G10L15/22;;G10L15/30;;G10L25/87;;G10L2015/223;;G10L15/22;;G10L15/063;;G10L15/1815;;G10L15/197;;G10L15/30;;G10L2015/086;;G10L2015/223;;H04L63/0428,G10L15/22;;G10L15/06;;G10L15/18;;G10L15/197;;G10L15/30;;H04L9/40,,0,0,,,,DISCONTINUED
965,WO,A1,WO 2024/173728 A1,180-201-969-969-105,8/22/2024,2024,US 2024/0016049 W,2/15/2024,US 202318169786 A;;US 202318169793 A;;US 202318169802 A;;US 202318169808 A,2/15/2023,GENERATIVE COLLABORATIVE PUBLISHING SYSTEM,"Embodiments of the disclosed technologies include using a generative language model to generate digital content for a first version of a first document. A second version of the first document is generated by dividing the first version of the first document into segments. A first segment includes a subset of the digital content. Embodiments enable user contributions to one or more of the segments. A first contribution to the second version of the first document is received. A first segment-contribution pair is created by linking the first contribution with the first segment. A second contribution to the second version of the first document is used to create a second segment-contribution pair by linking the second contribution with the second segment. At least one of the first segment-contribution pair or the second segment-contribution pair is capable of being used to generate, by the generative language model, a second document.",MICROSOFT TECHNOLOGY LICENSING LLC,SOMAIYA MANAS;;FIELDS SARA;;IU MARIA;;JAIN AASTHA;;KAPLAN ADAM;;LI YILIN;;LIU ZHANGLONG;;LORENZETTI SOPER LAURA;;MURALIDHARAN AJITH;;PAN YAO;;PATIRA SHWETA;;PEZARRO NICHOLAS;;SHAH SAARTH;;SMITH ALANA;;SOMASUNDARAM LAKSHMAN,,https://lens.org/180-201-969-969-105,Patent Application,yes,5,0,1,180-201-969-969-105,WO,6,180-408-464-257-442;;029-499-748-945-396;;053-783-597-052-74X;;180-201-969-969-105;;023-759-557-167-149;;073-193-584-282-349,US;;WO,0,G06F40/56;;G06N20/00;;G06Q10/101;;G06F40/30;;G06N3/045;;G06F40/186;;G06F16/93,G06F40/186;;G06F16/93;;G06F40/30;;G06F40/56;;G06N3/045;;G06N20/00;;G06Q10/101,,2,1,125-545-780-046-731,10.1145/3491102.3517582,"ANONYMOUS: ""GitHub - adieyal/dynamicprompts: Templating language for generating prompts for text to image generators such as Stable Diffusion"", 4 February 2023 (2023-02-04), XP093169614, Retrieved from the Internet <URL:https://web.archive.org/web/20230204003550/https://github.com/adieyal/dynamicprompts> [retrieved on 20240603];;WU TONGSHUANG ET AL: ""AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts"", CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, ACM, NEW YORK, NY, USA, 29 April 2022 (2022-04-29), pages 1 - 22, XP059454410, ISBN: 978-1-4503-9157-3, DOI: 10.1145/3491102.3517582",PENDING
966,US,A1,US 2024/0273286 A1,029-499-748-945-396,8/15/2024,2024,US 202318169802 A,2/15/2023,US 202318169802 A,2/15/2023,GENERATIVE COLLABORATIVE PUBLISHING SYSTEM,"Embodiments of the disclosed technologies include generating, by a generative language model, a first version of a first document, generating a second version of the first document by dividing the first version of the first document into a plurality of segments, where a first segment of the plurality of segments includes a subset of the digital content generated by the generative language model; enabling contributions to the first segment; enabling contributions to a second segment of the plurality of segments; receiving a first contribution to the second version of the first document, where the first contribution includes digital content generated by a first user of the network; creating a first segment-contribution pair by linking the first contribution with the first segment; receiving a second contribution to the second version of the first document; and creating a second segment-contribution pair by linking the second contribution with the second segment, where at least one of the first segment-contribution pair or the second segment-contribution pair is capable of being used to generate, by the generative language model, a second document.",MICROSOFT TECHNOLOGY LICENSING LLC,IU MARIA;;SOMASUNDARAM LAKSHMAN;;LI YILIN;;PATIRA SHWETA;;KAPLAN ADAM;;FIELDS SARA REMI,MICROSOFT TECHNOLOGY LICENSING LLC (2022-03-20),https://lens.org/029-499-748-945-396,Patent Application,yes,76,5,1,029-499-748-945-396,US,6,180-408-464-257-442;;029-499-748-945-396;;053-783-597-052-74X;;180-201-969-969-105;;023-759-557-167-149;;073-193-584-282-349,US;;WO,0,G06F40/258;;G06N3/0475;;G06F40/197;;G06F40/117;;H04L67/06;;G06N3/08;;G06F40/166;;G06F40/197;;G06F40/166;;G06F40/258;;H04L67/06;;G06N3/08;;G06N3/0475;;G06F40/117;;G06F8/33;;G06Q10/101,G06F40/197;;G06F40/117;;G06F40/166;;G06F40/258;;G06N3/0475;;G06N3/08,,2,2,183-047-952-975-521;;136-778-293-232-98X,10.1145/3491102.3502030;;10.1145/3490099.3511105,"Mina Lee et al.; CoAuthor: Designing a Human-AI Collaborative Writing Dataset for Exploring Language Model Capabilities. In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems (CHI '22). Association for Computing Machinery, Pg. 1–19. https://doi.org/10.1145/3491102.3502030 (Year: 2022);;Ann Yuan et. al.; Wordcraft: Story Writing With Large Language Models. In Proceedings of the 27th International Conference on Intelligent User Interfaces (IUI '22). Association for Computing Machinery, New York, NY, USA, 841–852. https://doi.org/10.1145/3490099.3511105 (Year: 2022)",PENDING
967,US,A1,US 2024/0296352 A1,095-686-929-567-889,9/5/2024,2024,US 202318477817 A,9/29/2023,US 202318477817 A;;US 202318116176 A;;US 202363468192 P,3/1/2023,ARTIFICIAL INTELLIGENCE ENHANCED KNOWLEDGE FRAMEWORK,"A computer-implemented system, a method, and computer products for development and use of a knowledge framework are provided. The system comprises one or more processors and a memory including computer program code. The computer program code is configured to, when executed, cause the one or more processors to perform various tasks. These tasks include receive session data related to responses received from a participant in a session, receive machine learning data, create or enhance the knowledge framework based on the machine learning data and the session data, and create additional machine learning data using the knowledge framework as a source of information. The method performs these tasks, and the computer readable medium contains similar computer program code. The method can perform these tasks with computer synergistic generative artificial intelligence, machine learning, and knowledge framework subsystems.",KPMG LLP,YANOSY JR JOHN A;;PUVVADA ANU;;KIM STEPHANIE;;URBAN ANDREW;;SISSELMAN MICHAEL,KPMG LLP (2023-10-03),https://lens.org/095-686-929-567-889,Patent Application,yes,0,12,1,095-686-929-567-889,US,2,095-686-929-567-889;;125-794-570-731-666,US,0,G06N5/02;;G06N5/046;;G06N5/022;;G06N5/022,G06N5/022,,0,0,,,,PENDING
968,WO,A2,WO 2025/032373 A2,154-900-404-647-731,2/13/2025,2025,IB 2024000589 W,7/3/2024,US 202363524745 P,7/3/2023,"AUTOMATED TRANSFORMATION OF INFORMATION FROM IMAGES TO TEXTUAL REPRESENTATIONS, AND APPLICATIONS THEREFOR","Recent developments in machine learning (commonly coined ""artificial intelligence"" or ""AI"") have vastly expanded applications for this technology, such as myriad ""chat"" agents adept at understanding natural human language. While state of the art generative models can parse text queries from a user and provide comprehensive, accurate responses (including generating images depicting desired content), current implementations struggle with understanding all information present in images of documents, especially images of business documents. In particular, generative models fail to understand structured and semi-structured information, e.g., as indicated by graphical information such as lines, geometric relationships (e.g., indicated by tables, graphs, figures, etc.), formatting, and other contextual information that human readers easily and implicitly understand. The disclosed inventive concepts transform structured and semi-structured information along with textual content into a textual representation that allows generative models to better understand textual content and non-textual structured information present in document images.",TUNGSTEN AUTOMATION CORP,THOMPSON STEVE;;LEVDIK VERONIKA;;VYMENETS IURII;;LEE DONGHAN,,https://lens.org/154-900-404-647-731,Patent Application,yes,0,1,2,154-900-404-647-731;;139-672-418-788-88X,WO,12,161-392-054-894-534;;139-672-418-788-88X;;128-486-187-215-567;;074-231-448-232-049;;163-455-560-818-006;;103-156-078-574-254;;146-847-435-291-213;;183-889-087-923-997;;183-261-492-385-607;;154-900-404-647-731;;020-667-497-087-384;;063-813-580-987-730,US;;WO,0,G06V30/414;;G06F40/137;;G06F18/231;;G06V30/1448;;G06F40/56;;G06F40/131;;G06F40/30;;G06V10/82,,,0,0,,,,PENDING
969,US,A1,US 2024/0362197 A1,163-455-560-818-006,10/31/2024,2024,US 202418763909 A,7/3/2024,US 202418763909 A;;US 202218080627 A;;US 202217571327 A;;US 202363524745 P;;US 202163170268 P,4/2/2021,"AUTOMATED TRANSFORMATION OF INFORMATION FROM IMAGES TO TEXTUAL REPRESENTATIONS, AND APPLICATIONS THEREFOR","Recent developments in machine learning (commonly coined “artificial intelligence” or “AI”) have vastly expanded applications for this technology, such as myriad “chat” agents adept at understanding natural human language. While state of the art generative models can parse text queries from a user and provide comprehensive, accurate responses (including generating images depicting desired content), current implementations struggle with understanding all information present in images of documents, especially images of business documents. In particular, generative models fail to understand structured and semi-structured information, e.g., as indicated by graphical information such as lines, geometric relationships (e.g., indicated by tables, graphs, figures, etc.), formatting, and other contextual information that human readers easily and implicitly understand. The disclosed inventive concepts transform structured and semi-structured information along with textual content into a textual representation that allows generative models to better understand textual content and non-textual structured information present in document images.",TUNGSTEN AUTOMATION CORP,THOMPSON STEVE;;LEVDIK VERONIKA;;VYMENETS IURII;;LEE DONGHAN,TUNGSTEN AUTOMATION CORPORATION (2024-06-26),https://lens.org/163-455-560-818-006,Patent Application,yes,4,4,3,161-392-054-894-534;;183-261-492-385-607;;163-455-560-818-006,US,12,161-392-054-894-534;;139-672-418-788-88X;;128-486-187-215-567;;074-231-448-232-049;;163-455-560-818-006;;103-156-078-574-254;;146-847-435-291-213;;183-889-087-923-997;;183-261-492-385-607;;154-900-404-647-731;;020-667-497-087-384;;063-813-580-987-730,US;;WO,0,G06V30/414;;G06V10/70;;G06F16/2282;;G06V30/413;;G06V30/412;;G06F16/2282;;G06V30/413;;G06V10/70;;G06V30/412;;G06V30/414,G06F16/22;;G06V10/70;;G06V30/412;;G06V30/413;;G06V30/414,,0,0,,,,ACTIVE
970,WO,A1,WO 2025/141559 A1,042-641-653-700-738,7/3/2025,2025,IL 2024051195 W,12/17/2024,US 202363614588 P;;US 202463555115 P,12/24/2023,DETECTING AND USING NON-TEXTUAL INFORMATION IN HUMAN SPEECH,"Automatic recognition of non-verbal messages in speech, and in particular to detection or analysis of prosodic multilayered analysis of intonation units such as prosodic unit prototypes and their multi-labeled variations, may form a hierarchical classification for the analysis of non¬ verbal information or cues in speech. A speech captured by a microphone is fed to a weakly- supervised deep learning acoustic model for speech recognition and transcription, that may be based on encoder-decoder Transformer architecture, such as Whisper by OpenAI. The model is trained to output multiple words form the text in the captured speech, to identify Intonation Units (IUs) that include one or more words, and associate non-verbal labels to each of the IUs. The labels may indicate a prototype, a discourse function (such as a conversation action), an emotion, an emphasis, or an attitude, as well as a genre of a part of, or whole of, the entire captured speech.",YEDA RES & DEV,HAREL DAVID;;BIRON TIRZA;;BEN ARTZI ERAN;;BARBOY MOSHE,,https://lens.org/042-641-653-700-738,Patent Application,yes,0,0,1,042-641-653-700-738,WO,1,042-641-653-700-738,WO,0,G10L15/16;;G10L15/18;;G06N20/00;;G10L25/90;;G06N3/09;;G10L15/02;;G06N3/08,G10L15/18;;G06N3/09;;G06N20/00;;G10L15/02;;G10L15/16;;G10L25/90,,0,0,,,,PENDING
971,WO,A1,WO 2024/158853 A1,182-939-572-853-706,8/2/2024,2024,US 2024/0012671 W,1/24/2024,US 202363481697 P;;US 202363468145 P;;US 202363529563 P;;US 202363537671 P,1/26/2023,TRAINING DYNAMIC HYBRID AI NETWORKS,"Computer-implemented methods and systems train, dynamically, a machine-learning network from a base system. Computing learned parameters for the network comprises, for at least a first portion of the machine-learning network, a back-propagation pass through the machine-learning network. The back-propagation pass comprises, for the first portion of the machine-learning network, computation of derivatives, with respect to a loss function, for the learned parameters. The method further comprises making a sensibility level assessment that comprises a determination of whether the machine-learning network produces an insensible result according to a criteria of sensibility. The method further comprises making one or more sensibility-improving modifications in response to a determination, in the sensibility level assessment of the machine-learning network, that the machine-learning network produces an insensible result, such that the one or one or more sensibility-improving modifications make the machine-learning network less vulnerable to producing insensible results.",D5AI LLC,BAKER JAMES K,,https://lens.org/182-939-572-853-706,Patent Application,yes,5,8,1,182-939-572-853-706,WO,5,093-969-708-687-446;;132-319-596-751-519;;079-721-858-331-537;;122-363-903-699-761;;182-939-572-853-706,WO,0,G06N3/082;;G06N3/02;;G06N3/08;;G06N3/084;;G06N3/045,G06N3/084;;G06N3/02;;G06N3/045;;G06N3/08;;G06N3/082,,0,0,,,,PENDING
972,WO,A2,WO 2024/243183 A2,093-969-708-687-446,11/28/2024,2024,US 2024/0030324 W,5/21/2024,US 202363468145 P;;US 202363529563 P;;US 202363537671 P,5/22/2023,TRAINING HUMAN-GUIDED AI NETWORKS,"Computer-implemented methods and systems train, dynamically, a machine-learning network from a base system. Computing learned parameters for the network comprises, for at least a first portion of the machine-learning network, a backpropagation pass through the machine-learning network. The back-propagation pass comprises, for the first portion of the machine-learning network, computation of derivatives, with respect to a loss function, for the learned parameters. The method further comprises making a sensibility level assessment that comprises a determination of whether the machine-learning network produces an insensible result according to a criterion of sensibility. The method further comprises making one or more sensibility-improving modifications in response to a determination, in the sensibility level assessment of the machine-learning network, that the machine-learning network produces an insensible result, such that the one or one or more sensibility-improving modifications make the machine-learning network less vulnerable to producing insensible results.",D5AI LLC,BAKER JAMES K;;BAKER NIELSEN HEATHER,,https://lens.org/093-969-708-687-446,Patent Application,yes,0,5,2,093-969-708-687-446;;132-319-596-751-519,WO,5,093-969-708-687-446;;132-319-596-751-519;;079-721-858-331-537;;122-363-903-699-761;;182-939-572-853-706,WO,0,G06N20/00;;G06F40/56;;G06F40/30;;G06T11/60;;G06F40/166,,,0,0,,,,PENDING
973,WO,A2,WO 2025/029526 A2,122-363-903-699-761,2/6/2025,2025,US 2024/0039132 W,7/23/2024,US 202363529563 P;;US 202363537671 P,7/28/2023,EXPLAINABLE ADAPTABLE ARTIFICIAL INTELLIGENCE NETWORKS,"Computer-implemented methods and systems make a generative AI system more explainable. A programmed computer system grows a generative AI system by adding one or more explainable network elements to the generative AI system. Each explainable network element can be trained to discriminate two or more explainable sets of training data items for the generative AI system. After adding the one or more explainable network elements, training of the generative AI system can be updated with the one or more explainable network elements added. Then the programmed computer system can determined whether continued growth of the generative AI system is required.",D5AI LLC,BAKER JAMES K;;BAKER NIELSEN HEATHER,,https://lens.org/122-363-903-699-761,Patent Application,yes,0,2,2,122-363-903-699-761;;079-721-858-331-537,WO,5,093-969-708-687-446;;132-319-596-751-519;;079-721-858-331-537;;122-363-903-699-761;;182-939-572-853-706,WO,0,G06N3/0475;;G06N3/045;;G06N3/047;;G06N3/044;;G06N3/08,G06N3/0475,,0,0,,,,PENDING
974,WO,A1,WO 2025/120371 A1,142-108-441-841-133,6/12/2025,2025,IB 2024000711 W,12/5/2024,US 202318533158 A,12/7/2023,"DIGITAL MUSIC COMPOSITION, PERFORMANCE AND PRODUCTION STUDIO SYSTEM NETWORK AND METHODS","A collaborative cloud-based digital music composition, performance and production studio system network employing machine-intelligent digital audio workstation (DAW) systems that are supported by cloud-based automated music composition, performance, production and publishing services. Such services enable improved workflows and enhanced productivity, while ensuring that the music IP rights of all parties involved in the Al-assisted music creation process are respected and responsibly managed in the best economic interests of individual artists, performers, producers, publishers and consumers alike. The digital music studio system network can be realized in various ways supporting the DAW systems in ways suited to different user preferences and application environments.",BANDLAB SINGAPORE PTE LTD,SILVERSTEIN ANDREW,,https://lens.org/142-108-441-841-133,Patent Application,yes,14,0,3,142-108-441-841-133;;155-926-326-846-04X;;127-831-092-245-235,US;;WO,3,142-108-441-841-133;;155-926-326-846-04X;;127-831-092-245-235,US;;WO,0,G10H1/0025;;G10H2250/311;;G10H2240/181;;G10H2240/131;;G10H2240/075;;G10H2210/036;;G10H2210/131;;G10H2210/105;;G10H2240/175;;G10H1/0058;;H04H60/04;;G06Q50/184;;G10H1/0025;;G10H1/0066;;G10H1/0091;;G10H2210/036;;G10H2210/056;;G10H2210/105;;G10H2210/111;;G10H2220/116;;G10H2220/126;;G10H2240/135;;G10H2240/145;;G10H2240/311;;G10H2250/311,G10H1/00;;H04H60/05,,3,0,,,"CURTIS HAWTHORNEANDRLY STASYUKADAM ROBERTSIAN SIMONCHENG-ZHI ANNA HUANGSANDER DIEIEMANERICH ELSENJESSE ENGELDOUGLAS ECKGOOGLE BRAI, ENABLING FACTORIZED PIANO MUSIC MODELING AND GENERATION WITH THE MAESTRO DATASET, January 2019 (2019-01-01);;PRAFULLA DHARIWAIHEEWOO JUNCHRISTINE PAYNEJONG WOOK KIMALEC REDFORDILYA SUTKEVER, JUKEBOX: A GENERATIVE MODEL FOR MUSIC, 30 April 2020 (2020-04-30);;SAKYA BASAK ET AL.: ""Learning and Extraction of Acoustic Patterns (LEAP) Lab that proposes an End-to-End (E2E) Lyrics Recognition System with Voice to Singing Style Transfer"", 17 February 2021, INDIAN INSTITUTE OF SCIENCE",PENDING
975,US,B2,US 10934555 B2,138-483-426-497-020,3/2/2021,2021,US 201916268155 A,2/5/2019,US 201916268155 A;;US 201414403491 A;;IL 2013050447 W;;US 201361814890 P;;US 201361814888 P;;US 201361814899 P;;US 201361814892 P;;US 201261651131 P,5/24/2012,Compositions and methods for silencing gene expression,"A method of introducing naked dsRNA into a seed is provided. The method comprising contacting the seed with the naked dsRNA under conditions which allow penetration of the dsRNA into the seed, thereby introducing the dsRNA into the seed.",A B SEEDS LTD;;MONSANTO TECHNOLOGY LLC,AVNIEL AMIR;;LIDOR-NILI EFRAT;;MAOR RUDY;;MEIR OFIR;;NOIVIRT-BRIK ORLY;;YANAI-AZULAY OSNAT,A.B. SEEDS LTD (2015-05-26);;MONSANTO TECHNOLOGY LLC (2018-08-07),https://lens.org/138-483-426-497-020,Granted Patent,yes,701,0,25,047-839-439-346-905;;165-255-257-393-048;;160-623-860-388-141;;033-786-322-681-924;;157-538-483-865-293;;022-984-635-252-352;;039-256-239-705-243;;046-388-120-940-48X;;149-930-986-438-898;;001-185-454-427-747;;086-816-927-237-540;;005-349-484-722-310;;101-519-381-887-47X;;036-568-876-583-959;;158-659-516-302-671;;077-507-943-509-678;;109-984-531-427-36X;;156-704-667-269-036;;068-863-079-055-996;;138-483-426-497-020;;065-554-112-494-651;;028-902-362-546-086;;098-824-491-528-413;;062-336-189-166-176;;071-167-420-297-26X,IN;;AU;;CL;;CN;;AR;;UY;;CA;;US;;GT;;MX;;WO;;EP;;ZA,60,165-255-257-393-048;;047-839-439-346-905;;033-786-322-681-924;;157-538-483-865-293;;039-256-239-705-243;;168-516-192-821-612;;105-042-716-517-682;;022-984-635-252-352;;149-738-666-092-904;;046-388-120-940-48X;;086-816-927-237-540;;001-185-454-427-747;;068-592-159-211-555;;129-105-620-017-401;;101-519-381-887-47X;;189-397-033-050-905;;137-278-923-051-477;;069-545-481-887-785;;156-986-111-896-593;;158-659-516-302-671;;037-907-677-095-557;;062-668-423-448-931;;109-984-531-427-36X;;075-310-310-783-384;;068-863-079-055-996;;138-483-426-497-020;;156-704-667-269-036;;001-176-293-834-194;;001-788-459-110-346;;098-824-491-528-413;;071-167-420-297-26X;;062-336-189-166-176;;072-470-214-325-256;;160-623-860-388-141;;082-063-046-106-875;;016-034-925-256-072;;093-867-071-225-676;;019-490-708-908-124;;123-886-197-664-586;;149-930-986-438-898;;047-957-751-545-834;;118-214-392-868-848;;125-760-167-105-897;;005-349-484-722-310;;065-805-786-066-681;;012-052-842-444-020;;036-568-876-583-959;;130-751-389-723-187;;077-507-943-509-678;;130-410-151-809-663;;065-554-112-494-651;;028-902-362-546-086;;168-167-769-800-873;;103-000-424-765-539;;113-513-426-799-050;;117-241-159-255-276;;163-761-199-824-178;;058-071-719-071-233;;162-946-832-807-053;;060-352-484-265-713,IN;;UA;;EA;;BR;;AU;;CN;;CL;;AR;;UY;;CA;;US;;GT;;IL;;MX;;WO;;EP;;ZA,197,C12N15/8218;;C12N15/8201;;C12N15/8206;;C12N15/8216;;C12N15/825;;C12N15/8261;;C12N15/8266;;C12N15/8267;;C12N15/8271;;C12N15/8279;;C12N15/8282;;C12N15/8283;;Y02A40/146;;C12N15/8218;;C12N15/8201;;C12N15/8216;;C12N15/8279;;Y02A40/146,C12N15/82,,719,398,036-123-124-415-053;;069-001-144-687-381;;023-552-029-167-825;;048-009-207-299-701;;038-402-616-027-940;;028-797-991-602-114;;102-187-300-811-077;;104-035-667-492-172;;086-166-721-877-284;;052-510-880-891-311;;053-613-937-215-188;;043-331-741-993-537;;002-087-743-613-340;;003-875-770-454-430;;032-274-261-990-671;;047-521-700-308-567;;029-230-790-723-285;;047-081-462-662-061;;008-302-254-594-772;;136-126-337-057-906;;031-527-014-493-527;;070-787-320-484-966;;039-911-172-986-236;;072-715-870-403-26X;;041-041-058-895-723;;069-342-939-917-772;;062-888-249-166-545;;012-796-970-570-146;;031-726-933-606-432;;028-879-364-813-800;;040-212-644-912-781;;037-436-935-246-322;;040-724-945-810-77X;;006-747-397-728-941;;050-760-907-643-836;;025-826-673-610-398;;103-789-998-878-066;;177-774-432-250-854;;004-138-829-854-030;;064-370-104-798-951;;142-601-351-255-48X;;027-212-987-940-871;;024-419-471-968-012;;011-667-144-347-922;;097-237-657-880-394;;049-427-391-860-033;;119-467-092-439-795;;059-011-946-503-122;;077-173-282-557-404;;080-894-535-175-374;;016-065-299-590-306;;044-555-862-064-75X;;023-504-101-075-882;;089-109-321-301-671;;126-811-902-964-190;;058-784-568-630-359;;084-860-209-235-626;;104-360-448-140-176;;055-701-183-726-645;;009-071-232-779-208;;061-425-939-476-666;;012-774-820-541-393;;012-473-488-674-864;;032-731-813-181-575;;030-862-429-192-074;;059-316-611-312-014;;143-642-463-512-599;;037-071-523-057-649;;007-223-730-630-593;;050-831-791-646-757;;039-357-550-809-62X;;018-020-177-526-297;;078-939-408-414-293;;002-925-419-791-188;;034-169-422-977-098;;052-117-185-220-953;;016-462-696-960-736;;097-856-627-615-322;;012-434-847-446-766;;074-171-815-422-660;;001-559-933-242-09X;;057-485-435-858-492;;062-096-601-946-458;;164-534-958-750-672;;021-278-973-988-966;;059-118-573-990-713;;002-453-979-745-62X;;020-327-117-600-49X;;070-807-024-887-811;;021-193-222-699-394;;013-277-654-553-151;;096-447-656-174-50X;;079-645-151-303-880;;019-412-872-362-879;;082-100-684-857-809;;104-777-503-225-855;;024-884-129-371-660;;008-524-108-435-574;;078-709-384-851-929;;027-405-529-761-455;;154-846-142-703-726;;099-536-497-326-345;;094-705-431-740-888;;124-455-081-069-533;;060-665-575-093-301;;008-351-417-349-749;;031-358-248-495-432;;014-795-456-316-610;;006-229-209-064-800;;021-396-697-877-588;;132-241-266-225-922;;007-719-389-115-270;;104-808-502-597-47X;;024-818-007-486-659;;012-647-513-004-289;;004-642-128-907-307;;037-057-743-189-175;;071-196-756-713-514;;005-650-379-718-988;;075-456-952-742-308;;035-761-349-403-491;;020-555-087-143-252;;072-681-849-776-261;;070-154-514-954-76X;;091-884-183-467-452;;085-343-327-749-776;;043-775-594-554-805;;180-614-076-892-759;;006-181-967-002-57X;;018-386-508-939-042;;078-811-478-526-888;;007-937-419-405-38X;;123-462-091-533-888;;047-085-065-007-520;;006-277-819-385-309;;148-645-222-736-650;;025-123-548-557-830;;051-886-241-972-798;;067-718-908-191-016;;073-464-134-517-608;;125-337-916-664-488;;004-382-742-906-891;;049-182-874-631-208;;005-827-830-138-963;;032-985-977-611-121;;090-639-623-438-845;;045-314-324-344-657;;050-062-029-955-490;;020-739-123-523-153;;075-451-577-269-826;;017-782-072-702-842;;057-418-628-274-637;;000-933-083-257-092;;000-061-233-286-329;;109-425-033-892-84X;;099-540-925-262-395;;018-206-371-614-130;;109-316-086-583-730;;034-320-019-212-73X;;080-116-623-771-28X;;077-461-215-793-067;;027-202-576-111-439;;007-024-337-046-110;;010-719-964-194-146;;014-479-583-662-888;;075-577-203-978-058;;067-448-031-020-634;;065-015-185-372-96X;;072-703-877-540-584;;048-995-377-244-137;;005-371-109-791-382;;016-138-197-744-92X;;005-445-861-594-474;;021-682-869-898-922;;000-362-844-900-809;;064-399-104-388-935;;067-430-644-063-48X;;003-958-262-957-30X;;098-616-108-643-894;;000-940-429-848-793;;081-031-110-296-317;;019-861-404-615-066;;173-629-984-343-120;;079-002-396-735-332;;035-919-317-191-305;;021-005-488-851-524;;063-320-015-259-516;;020-628-402-049-798;;120-078-034-329-308;;046-716-780-139-807;;010-213-808-238-946;;034-066-527-320-55X;;027-211-496-625-08X;;058-032-369-859-095;;015-464-397-066-243;;056-454-460-773-011;;006-921-276-070-451;;010-990-186-783-718;;047-954-884-863-20X;;016-476-351-988-028;;074-621-106-099-069;;002-015-816-730-810;;023-334-319-228-512;;095-097-457-771-746;;142-355-597-257-513;;004-626-109-620-298;;000-901-861-214-915;;004-896-057-372-340;;023-806-244-141-502;;116-335-966-752-384;;065-722-456-697-049;;008-718-632-073-878;;034-810-165-352-185;;000-080-317-597-347;;017-702-696-688-484;;099-207-961-389-677;;089-816-873-060-813;;006-645-594-256-747;;075-338-777-113-75X;;102-250-946-144-989;;137-135-861-552-672;;010-863-400-557-550;;116-276-213-964-553;;011-050-520-672-455;;072-760-697-434-777;;072-521-483-239-791;;017-862-183-447-725;;176-849-888-077-559;;056-329-508-959-016;;000-863-018-787-408;;130-635-805-653-07X;;079-375-792-388-32X;;014-874-061-205-698;;029-029-798-477-598;;005-423-688-406-136;;075-542-282-473-380;;000-047-739-257-25X;;039-676-361-532-623;;028-592-439-902-966;;000-940-350-207-192;;004-965-775-595-916;;006-907-043-649-058;;028-454-456-551-197;;084-871-281-182-85X;;110-804-785-489-047;;147-592-827-721-723;;032-472-341-405-10X;;046-368-589-968-81X;;007-674-204-331-246;;046-650-479-211-102;;036-123-124-415-053;;026-099-766-250-748;;081-955-958-049-081;;049-425-115-015-360;;006-212-893-997-904;;003-307-199-216-170;;040-648-271-878-492;;011-020-980-421-334;;084-075-973-536-762;;060-895-951-227-873;;052-917-415-312-171;;052-838-356-282-404;;110-095-968-579-249;;013-540-309-530-165;;060-649-142-637-051;;083-929-657-924-341;;026-260-818-721-539;;048-601-845-272-864;;105-110-952-350-513;;121-434-653-544-239;;000-243-811-205-541;;014-513-749-213-529;;067-653-596-364-613;;017-020-742-350-380;;088-692-701-638-772;;025-974-255-763-441;;023-734-074-303-707;;140-140-024-006-433;;093-068-451-758-174;;044-909-132-117-552;;010-928-111-712-862;;080-467-355-442-678;;081-030-863-022-949;;006-341-445-617-542;;040-212-644-912-781;;129-972-302-044-717;;091-546-627-046-05X;;082-835-678-745-138;;102-886-095-169-611;;034-529-757-762-220;;058-464-585-357-355;;034-099-384-372-782;;080-754-192-715-396;;014-923-224-809-153;;117-762-770-369-597;;032-731-813-181-575;;037-753-351-287-744;;164-172-033-840-996;;042-485-854-715-117;;168-201-082-641-681;;008-102-284-918-620;;042-222-123-978-795;;010-447-902-215-144;;053-355-245-478-017;;007-503-489-891-338;;079-621-633-485-211;;030-906-456-072-037;;137-014-294-135-686;;053-613-937-215-188;;043-331-741-993-537;;064-794-445-352-076;;086-516-035-965-986;;123-891-669-693-147;;140-589-484-007-98X;;043-198-819-314-048;;072-715-870-403-26X;;034-986-092-405-387;;124-708-903-199-218;;177-774-432-250-854;;142-601-351-255-48X;;008-948-434-489-34X;;027-655-204-543-179;;004-129-323-096-645;;125-980-003-853-48X;;044-861-616-927-64X;;102-288-135-328-606;;048-959-281-822-221;;084-860-209-235-626;;023-645-752-394-966;;009-071-232-779-208;;032-731-813-181-575;;030-862-429-192-074;;081-328-436-274-959;;021-154-927-361-543;;104-783-012-422-740;;058-718-028-696-802;;039-830-375-301-546;;009-664-598-436-203;;074-171-815-422-660;;056-450-266-168-506;;002-453-979-745-62X;;040-894-614-487-64X;;170-433-181-339-108;;069-826-503-554-932;;056-562-923-114-265;;031-358-248-495-432;;010-063-169-073-776;;007-994-282-764-197;;018-136-323-012-492;;029-521-832-204-417;;007-719-389-115-270;;122-110-367-955-825;;070-305-850-157-458;;014-614-002-632-728;;036-803-768-033-228;;058-530-882-985-844;;010-118-268-389-261;;097-653-613-472-893;;049-182-874-631-208;;003-271-630-414-480;;052-775-908-000-730;;099-030-961-773-336;;064-765-208-934-280;;067-448-031-020-634;;033-011-307-248-758;;051-336-143-861-879;;028-872-733-118-394;;014-923-224-809-153;;002-346-239-287-615;;137-797-449-455-419;;012-407-507-322-042;;057-835-974-217-907;;006-817-563-567-890;;004-626-109-620-298;;019-471-897-548-426;;151-287-735-366-086;;142-824-895-726-516;;138-885-282-908-143;;025-114-034-775-377;;014-874-061-205-698;;075-155-723-735-21X;;004-965-775-595-916;;037-200-232-563-806;;072-742-092-699-386;;004-810-398-522-757;;089-199-953-298-716;;011-537-175-124-478;;036-324-322-252-540;;163-834-643-843-100;;010-286-051-468-148;;015-644-377-568-009;;021-190-674-610-000;;066-439-043-684-357;;023-734-074-303-707;;072-915-591-646-994;;085-787-646-385-76X;;059-024-569-473-302;;005-611-282-283-314,15147914;;10.1016/s0014-5793(04)00474-0;;10.1016/j.febslet.2004.04.018;;19226841;;10.1038/79501;;10973223;;10.1016/j.bbrc.2004.02.157;;15044091;;pmc3016640;;19823018;;10.4161/cc.8.21.9887;;10.1271/bbb.69.415;;15725671;;17950838;;10.1016/j.biomaterials.2007.10.003;;14586551;;10.1007/s00299-003-0684-8;;9070840;;10.1006/bbrc.1996.5762;;10.1007/s001220050567;;10.5772/15721;;17337069;;10.1016/j.jviromet.2007.01.031;;17081978;;10.1016/j.cell.2006.09.032;;10.1007/s11248-013-9716-5;;23748931;;pmc3835954;;10.1104/pp.001560;;pmc166520;;12114580;;18052880;;10.1094/mpmi-21-1-0030;;pmc423215;;10.1105/tpc.018929;;15100396;;10.1016/j.plantsci.2005.11.007;;pmc1524957;;10.1186/1746-4811-2-13;;16808845;;15358270;;10.1016/j.tplants.2004.06.003;;15723047;;10.1038/nbt1069;;10.1126/science.2003222;;2003222;;8148881;;10.1046/j.1365-313x.1994.05020299.x;;17117799;;10.1021/jf0618022;;15171994;;10.1016/j.brainresprot.2004.03.003;;pmc3469495;;10.1371/journal.pone.0047534;;23071820;;16413549;;10.1016/j.febslet.2005.12.098;;10.4141/p96-174;;9383471;;10.1016/1074-5521(95)90028-4;;10.1016/j.tig.2006.03.003;;16567016;;10.2307/3871093;;pmc144111;;10.1105/tpc.11.10.1995;;10521528;;10.1614/ws-d-12-00032.1;;10.1093/aob/mcp059;;pmc2685324;;19304995;;10.1073/pnas.84.15.5345;;pmc298852;;16593862;;pmc2933685;;20712880;;10.1186/1756-3305-3-73;;11722770;;10.1046/j.1365-313x.2001.01159.x;;10.1007/bf02986242;;10.1007/s10059-009-0093-0;;19533030;;15695452;;10.1093/pcp/pci046;;10.1104/pp.91.3.1212;;pmc1062142;;16667134;;pmc4139310;;10.1371/journal.pone.0104956;;25141304;;11910011;;10.1105/tpc.010336;;pmc150586;;17433309;;10.1016/j.febslet.2007.03.076;;24178604;;10.1007/s002990050092;;10.1007/bf00231918;;22170977;;10.1104/pp.111.186775;;pmc3271760;;10.1046/j.1365-313x.1998.00343.x;;10069079;;10.1126/science.1197761;;21292972;;pmc3529199;;9349273;;10.1023/a:1005821801228;;10.1126/science.3293213;;3293213;;10.1007/s10549-008-0097-z;;18587642;;pmc3736740;;10.3389/fpls.2016.01327;;pmc5003833;;27625678;;10850496;;10.1016/s0092-8674(00)80864-8;;10.1016/j.tibtech.2005.01.006;;15734551;;10.1073/pnas.83.6.1832;;16593669;;pmc323178;;10.1038/nbt0583-262;;10.1002/j.1460-2075.1988.tb02944.x;;16453841;;pmc458408;;11997974;;10.1002/ps.485;;22690671;;10.1111/j.1365-2583.2012.01150.x;;10948264;;10.2307/3871144;;10.1105/tpc.12.8.1477;;pmc149117;;pmc2919395;;10.1371/journal.pone.0012064;;20706585;;15000829;;10.1089/154545703322617069;;10.3896/ibra.1.51.1.15;;10.1071/ap06064;;10.1614/ws-d-10-00150.1;;10.1007/pl00001697;;pmc1069010;;15781493;;10.1093/nar/gki312;;20413458;;10.1126/science.1185880;;7630949;;pmc157489;;10.1104/pp.108.3.1299;;10.1038/346818a0;;1697402;;14561401;;10.1016/j.cub.2003.09.035;;10.1016/j.tplants.2010.10.005;;21081278;;10.1038/35888;;9486653;;pmc346080;;10.1073/pnas.79.6.1859;;16593170;;8490131;;10.1007/bf00023608;;7629126;;10.1074/jbc.270.30.18147;;10.1007/s00705-005-0688-5;;16341944;;19165150;;pmc2657584;;10.1038/emboj.2009.2;;20018685;;10.1073/pnas.0906649107;;pmc2824275;;pmc334194;;1408765;;10.1093/nar/20.17.4631;;20734050;;10.1007/s00299-010-0911-z;;8592746;;10.1126/science.270.5244.1986;;10.1186/1471-2229-14-32;;pmc3898995;;24438198;;pmc2692493;;19115957;;10.1021/mp800134q;;10.1371/journal.ppat.1003035;;pmc3534371;;23308063;;3346248;;10.1016/s0021-9258(18)68922-7;;pmc3080097;;10.1002/ps.1911;;20063320;;pmc1832224;;10.1371/journal.pone.0000360;;17426809;;21472969;;10.1002/ps.2086;;10.1002/ps.1754;;19367567;;10.1016/s0014-5793(97)00361-x;;9175862;;10998188;;10.1046/j.1365-313x.2000.00849.x;;10.1093/jexbot/51.suppl_1.439;;10938852;;10.1093/emboj/cdf464;;pmc125409;;12198169;;16751099;;10.1016/j.cell.2006.03.043;;12110901;;10.1038/418244a;;10.2307/4003015;;10.1104/pp.102.016766;;12970491;;pmc196602;;pmc3055837;;10.1186/2041-9139-2-7;;21362165;;10.1074/jbc.m500597200;;15855162;;10.1111/j.1467-7652.2004.00103.x;;17168901;;10.1006/pest.1997.2265;;10.1093/emboj/cdg431;;pmc202373;;12941703;;17773338;;10.1126/science.222.4630.1346;;10.1038/303179a0;;pmc157149;;10.1104/pp.107.2.469;;12228373;;10.1093/nar/gkh238;;14769947;;pmc373385;;10.1016/j.plaphy.2010.04.001;;20451401;;16025102;;10.1038/nbt1118;;pmc2094068;;10.1093/nar/gkm699;;17884914;;10.1038/nature03895;;16100779;;10.1038/nbt986;;15208640;;23301879;;10.1111/nph.12117;;22410795;;10.1038/cr.2012.36;;pmc3317568;;19574437;;pmc2729613;;10.1105/tpc.108.063719;;10.1007/s002990050332;;30727591;;10.1146/annurev.arplant.57.032905.105218;;16669754;;21478445;;pmc3101537;;10.1105/tpc.110.082594;;10.1614/wt-08-187.1;;15174838;;10.1021/ja0486059;;10.1111/j.1745-4514.2010.00483.x;;17259216;;10.1093/nar/gkl1120;;pmc1851635;;12044032;;10.1021/nn900887m;;19772305;;19484242;;10.1007/s00299-009-0717-z;;15619617;;10.1038/nbt1051;;10.1080/03746609308684806;;10.1002/ps.2780380205;;10.1002/ps.2780550112;;12181491;;pmc129380;;10.1073/pnas.182204199;;10.1093/bioinformatics/15.5.356;;10366655;;10.1182/blood.v91.3.852;;9446645;;pmc3900453;;24465841;;10.1371/journal.pone.0086012;;12782736;;10.1105/tpc.011452;;pmc156379;;15081052;;10.1016/j.copbio.2004.02.004;;9299405;;10.1006/bbrc.1997.7191;;10.1093/nar/gkh094;;15003224;;10.1016/j.pbi.2004.01.001;;10.2135/cssaspecpub14.c4;;17059408;;10.1111/j.1365-313x.2006.02894.x;;11522828;;10.1093/nar/29.17.3583;;pmc55870;;12789523;;10.1007/s00299-003-0581-1;;pmc2693113;;19457242;;10.1186/1746-4811-5-6;;10.1111/jen.12224;;19191500;;10.1021/nl803083u;;10.1016/j.bioelechem.2006.03.041;;16733098;;10.1186/1472-6750-10-85;;pmc3019158;;21134283;;10.1104/pp.110.157123;;pmc2899913;;20439547;;10.1105/tpc.003210;;12119378;;pmc150710;;18490376;;10.1093/nar/gkn250;;pmc2447759;;15576678;;pmc535699;;10.1093/nar/gnh170;;19748270;;10.1016/j.tcb.2009.07.003;;9500671;;10.1007/s001090050193;;10.1006/abbi.1995.1183;;7893158;;24233091;;10.1007/bf00716828;;10.1099/0022-1317-71-9-2167;;2212996;;10.1126/science.2549631;;2549631;;22682174;;10.1016/b978-0-12-394314-9.00011-7;;10.1038/nsmb710;;14718920;;10.1038/nrm1403;;15173824;;10.1089/108729002760070849;;12074364;;10.1111/j.1365-2583.2009.00847.x;;19196347;;10.1038/4362;;9853623;;18684657;;10.1016/j.tplants.2008.06.003;;16212497;;10.1146/annurev.cellbio.21.122303.114706;;21878996;;10.1038/emboj.2011.274;;pmc3181474;;10717316;;10.1016/s0168-9452(99)00232-0;;10.1046/j.1365-313x.1994.6040481.x;;17416734;;10.1105/tpc.106.049270;;pmc1913758;;10230064;;10.1046/j.1365-313x.1999.00420.x;;10.1128/jvi.79.12.7812-7818.2005;;15919934;;pmc1143663;;20413459;;10.1126/science.1187959;;pmc3160336;;21886479;;10.1371/journal.pbio.1001127;;7565598;;10.1007/bf02191603;;8806402;;10.1007/bf00019459;;16041363;;10.1038/nbt1122;;3118463;;10.1126/science.3118463;;10.1104/pp.108.133967;;pmc2649409;;19144766;;10.1007/s00299-009-0754-7;;19655146;;19614744;;10.1111/j.1742-4658.2009.07145.x;;10.1046/j.1365-313x.1992.t01-31-00999.x;;1303798;;10.1111/j.1365-313x.1992.00321.x;;11818553;;pmc122210;;10.1073/pnas.032652399;;10.1016/s0960-9822(99)80016-5;;10021363;;pmc2879792;;20388669;;10.1104/pp.110.154963;;pmc3115079;;21490419;;10.4161/psb.5.9.12477;;16929310;;10.1038/nmeth911;;17905866;;pmc2151717;;10.1104/pp.107.108217;;10.1002/ps.1671;;19097025;;10.2307/3088718;;10.1016/j.pestbp.2005.07.007;;10.1021/bc970172u;;9404669;;18298069;;10.1021/jf072954f;;12323077;;pmc128820;;10.1186/1471-2091-3-27;;10.3390/v4091753;;23170182;;pmc3499829;;10.1038/nbt936;;14758366;;20680963;;10.1002/ps.2006;;10.1186/1746-4811-1-12;;16356171;;pmc1325021;;10.1046/j.1467-7652.2004.00054.x;;17147603;;12508062;;10.1093/jxb/erg050;;15564128;;10.1016/j.tplants.2004.10.009;;10.1093/nar/gki732;;16049023;;pmc1180746;;pmc152341;;10.1105/tpc.010108;;12671090;;10.1128/jvi.78.6.3149-3154.2004;;14990735;;pmc353744;;10.1177/014107680409701202;;pmc1079666;;10.1258/jrsm.97.12.560;;15574851;;pmc20710;;10.1073/pnas.94.9.4262;;9113977;;10.1093/nar/18.8.2188;;2336405;;pmc330714;;10.1007/s00425-004-1239-0;;15024648;;24430686;;10.1007/bf00390312;;20709960;;pmc2930571;;10.1073/pnas.1009416107;;11135122;;10.1046/j.1365-313x.2000.00941.x;;14635182;;10.1002/arch.10118;;12925687;;10.1172/jci200319552;;pmc171401;;10.1172/jci19552;;17997764;;10.1111/j.1469-8137.2007.02225.x;;19805904;;10.1007/s12038-009-0049-8;;10.1104/pp.114.3.881;;9232874;;pmc158375;;pmc160246;;10.1105/tpc.5.1.9;;8439747;;10.2307/3869424;;10.1016/s0092-8674(01)00576-1;;11719187;;10.1111/j.1445-6664.2008.00282.x;;23620279;;pmc3695504;;10.1093/nar/gkt200;;10.1071/fp06130;;32689310;;10.1002/ps.2780380206;;10.1002/ps.2780380211;;10.1093/nar/gkl532;;16916791;;pmc1540741;;10.1261/rna.5090103;;12756322;;pmc1370431;;10.1093/pcp/pci251;;16381658;;16167901;;10.3410/f.1027810.334800;;10.1111/j.1365-313x.2005.02515.x;;10.1111/j.1365-313x.2007.03287.x;;17922813;;10.1002/ps.554;;12233193;;10.4161/cc.3.6.892;;22980207;;10.1016/j.plantsci.2006.04.005;;7698484;;10.1042/bst0220915;;9617820;;10.1023/a:1006099512706;;10.1038/nbt0797-647;;9219267;;12659646;;10.1186/1472-6750-3-3;;pmc153545;;10.1128/jvi.75.24.12288-12297.2001;;pmc116125;;11711619;;15068884;;10.1016/j.virusres.2004.01.019;;12147768;;10.1146/annurev.phyto.40.120301.093728;;10.1046/j.1365-313x.2001.00976.x;;11260498;;pmc308517;;10.1093/nar/22.22.4673;;7984417;;9804418;;10.1038/27579;;10.1101/gad.1284105;;15741316;;15361535;;10.1093/jxb/erh251;;pmc159744;;2562504;;10.1105/tpc.1.1.133;;10.2307/3869069;;10.1038/nbt0988-1072;;10.1016/j.febslet.2004.07.075;;15327987;;10.1614/0043-1745(2002)050[0700:rrowta]2.0.co;2;;10.1007/s001220050986;;22682175;;10.1016/b978-0-12-394314-9.00012-9;;10.1038/nbt0502-446;;11981553;;10.1002/1439-7633(20010401)2:4<239::aid-cbic239>3.0.co;2-r;;11828450;;10.1002/1439-7633(20010401)2:4<239::aid-cbic239>3.3.co;2-i;;10.1093/nar/gkh247;;pmc373388;;14769950;;15147914;;10.1016/s0014-5793(04)00474-0;;10.1016/j.febslet.2004.04.018;;11551936;;10.1074/jbc.m106252200;;pmc100295;;11809879;;10.1093/nar/30.3.675;;19933266;;10.1093/pcp/pcp167;;12776180;;10.1038/sj.embor.embor865;;pmc1319205;;10.1038/nbt0692-667;;10.1101/gad.1410506;;16600909;;10.5772/12984;;10.1146/annurev.biochem.67.1.99;;9759484;;pmc1370754;;15811921;;10.1261/rna.7272305;;17137497;;10.1186/1471-2105-7-520;;pmc1698581;;10.1016/s0092-8674(00)81749-3;;9790525;;10.1111/j.1365-3180.2006.00527.x;;10440665;;10.1002/(sici)1097-0290(19991005)65:1<1::aid-bit1>3.0.co;2-f;;10.1002/(sici)1097-0290(19991005)65:1<1::aid-bit1>3.3.co;2-6;;pmc159160;;10.1104/pp.104.1.37;;12232059;;10.1016/j.pestbp.2006.04.004;;10.1104/pp.60.6.885;;pmc542740;;16660207;;9811908;;10.1073/pnas.95.23.13959;;pmc24986;;9821277;;10.1016/s0958-1669(98)80034-7;;10.1034/j.1399-3054.2001.1120411.x;;11473714;;10.1016/j.jbiotec.2007.01.040;;17442442;;pmc41053;;7568019;;10.1073/pnas.92.19.8793;;10.1038/nature01145;;12410317;;19330324;;10.1007/s00253-009-1967-y;;10.1046/j.1365-3180.2000.00172.x;;11381131;;pmc34402;;10.1073/pnas.121172798;;17093204;;10.1093/toxsci/kfl161;;10.1093/mp/ssr066;;21859960;;17406292;;10.1038/nprot.2006.97;;10.1016/j.jconrel.2007.07.016;;17716771;;10.1093/nar/gkh024;;10.1007/bf00269517;;24240249;;10.14411/eje.2008.108;;10.1002/ps.2048;;21061270;;10.2307/3871093;;pmc144111;;10.1105/tpc.11.10.1995;;10521528;;27136078;;10.1038/nbt.3547;;10.1126/science.223.4635.496;;17781445;;10.1038/nbt.2647;;23873081;;pmc3969858;;10.1038/sj.gene.6364190;;15815687;;10.1007/s10681-007-9621-1;;10.1614/ws-08-020.1;;pmc3237934;;10.1016/j.ijpharm.2011.08.014;;21864664;;18269576;;10.1111/j.1365-313x.2007.03328.x;;10.1614/ws-03-098r;;16169961;;10.1104/pp.105.066134;;pmc1256002;;10.1614/ws-d-10-00150.1;;12771197;;pmc156720;;10.1093/nar/gkg385;;10.1007/978-3-540-77587-4_248;;25925567;;10.1093/nar/gkv415;;pmc4446448;;24531762;;10.1038/nature12971;;pmc4697943;;pmc2743854;;19404258;;10.1038/nature07845;;10.1007/bf00017727;;2103446;;10.1002/ps.2286;;21953884;;10.1104/pp.104.4.1113;;12232152;;pmc159271;;10.1016/j.febslet.2005.08.014;;16139270;;10.1111/j.1601-5223.1993.00273.x;;10.1111/j.1365-313x.2010.04220.x;;20374530;;10.1016/1049-9644(92)90034-b;;10.5772/15721;;17337069;;10.1016/j.jviromet.2007.01.031;;10.1146/annurev.arplant.59.032607.092759;;18444897;;10646606;;10.1038/35003214;;15372043;;10.1038/nature02874;;10.1016/b978-0-12-800197-4.00005-1;;15660154;;pmc539327;;10.1371/journal.pbio.0030013;;17117799;;10.1021/jf0618022;;10.1016/s0168-9452(00)00460-x;;11297786;;10.1016/j.agee.2011.06.012;;10.1007/s10059-009-0093-0;;19533030;;pmc4139310;;10.1371/journal.pone.0104956;;25141304;;19255730;;10.1007/s12010-009-8554-7;;19734715;;32846663;;10.1016/j.cois.2014.09.012;;pmc3795411;;10.1126/science.1231143;;23287718;;10.1111/j.1365-313x.2004.02024.x;;15053763;;10.1093/jee/88.3.584;;pmc553667;;10.1002/j.1460-2075.1987.tb02537.x;;16453789;;11997974;;10.1002/ps.485;;10.1111/j.1365-3180.2009.00700.x;;pmc2919395;;10.1371/journal.pone.0012064;;20706585;;10.1614/ws-d-10-00150.1;;10.1007/pl00001697;;pmc3656029;;23696834;;10.1371/journal.pone.0063576;;pmc2409047;;10.1104/pp.108.117275;;18524877;;10.4161/psb.3.8.5696;;pmc2634491;;19704463;;10.1080/07352680902743069;;10.1093/bib/bbl004;;16772267;;16916934;;pmc1559744;;10.1073/pnas.0603638103;;20734050;;10.1007/s00299-010-0911-z;;10.3724/sp.j.1206.2011.00129;;pmc1832224;;10.1371/journal.pone.0000360;;17426809;;12472699;;10.1046/j.1365-313x.2002.01471.x;;10.1017/s0043174500058288;;10.1007/978-4-431-09427-2_25;;10.1074/jbc.m402817200;;15180984;;10.1016/j.plaphy.2010.04.001;;20451401;;21757633;;10.1104/pp.111.181891;;pmc3165866;;15829604;;10.1105/tpc.105.030700;;pmc1091769;;10.1091/mbc.e03-12-0923;;pmc452591;;15090618;;10.1038/nature00896;;pmc9524216;;12087358;;23301879;;10.1111/nph.12117;;9756470;;10.1126/science.282.5386.100;;10.1385/1-59259-827-7:061;;15310913;;10.1016/s0168-9452(02)00274-1;;10.1111/j.1365-3180.1994.tb01990.x;;10.1111/j.1365-313x.2007.03060.x;;17376159;;10.1111/j.1365-313x.2004.02307.x;;15659100;;10.1016/s1671-2927(08)60261-8;;10.1111/jen.12224;;10.1104/pp.112.193508;;22474216;;pmc3406889;;14731289;;10.1111/j.1365-2818.2004.01285.x;;pmc27236;;10.1073/pnas.230334397;;11078509;;10.1093/bfgp/elp052;;20053816;;10.1046/j.1365-313x.1994.6040481.x;;10.1517/17425247.2013.840286;;24090239;;10.1002/ps.1732;;19255973;;10.1146/annurev-arplant-042809-112119;;20192743;;10.1614/ws-03-098r;;22983090;;10.1038/nbt.2355;;12378268;;10069834;;10.1104/pp.119.3.961;;pmc32110;;10.3389/fpls.2014.00269;;pmc4052903;;24966864;;7817872;;10.1016/s0065-3527(08)60327-9;;10.1007/s00425-004-1239-0;;15024648;;10.1002/(sici)1526-4998(200004)56:4<320::aid-ps125>3.0.co;2-b;;10.1002/ps.2780380217;;17287115;;10.1016/j.copbio.2007.01.012;;9841401;;10.1126/science.282.5388.430;;pmc1560916;;10.1105/tpc.106.044305;;16891400;;12659646;;10.1186/1472-6750-3-3;;pmc153545;;11455629;;10.1002/1526-4998(200101)57:1<3::aid-ps269>3.0.co;2-6;;15361535;;10.1093/jxb/erh251;;10.1093/med/9780198791607.003.0014;;10.1038/sj.hdy.6800563;;15316559;;pmc4559001;;26334912;;10.1186/s12864-015-1880-y;;10.1016/j.cell.2009.01.046;;19239888;;10.1104/pp.57.6.855;;16659585;;pmc542135;;10.1038/35081168;;11459066;;8722009;;10.1139/o95-101;;10.1371/journal.pone.0029713;;22242141;;pmc3248448;;22905193;;pmc3419704;;10.1371/journal.pone.0042975;;17720757;;10.1104/pp.107.105262;;pmc2048730;;10.1007/s00425-006-0364-3;;16906433;;17093204;;10.1093/toxsci/kfl161;;10.1007/s00425-014-2054-x;;24643516;;10.1111/j.1365-2583.2010.01049.x;;20854479;;10.1046/j.1365-313x.2003.01772.x;;12795700;;10.1007/s13744-015-0291-8;;26013264,"Unnannalai et al, 2006, FEBS Letters, 566:307-310.;;Hwa et al (2008, Euphytica, 160:287-293).;;Agricultural Chemical Usage 2006 Vegetables Summary, Agricultural Statistics Board, NASS, USDA, pp. 1-372 (2007).;;Agrios, Plant Pathology (Second Edition), 2:466-470 (1978).;;Alarcón-Reverte et al., “Resistance to ACCase-inhibiting herbicides in the weed Lolium multiforum,” Comm. Appl. Biol. Sci., 73(4):899-902 (2008).;;Al-Kaff et al., “Plants rendered herbicide-susceptible by cauliflower mosaic virus—elicited suppression of a 35S promoter-regulated transgene,” Nature Biotechnology, 18:995-999 (2000).;;Amarzguioui et al., “An algorithm for selection of functional siRNA sequences,” Biochemical and Biophysical Research Communications, 316:1050-1058 (2004).;;Ambrus et al., “The Diverse Roles of RNA Helicases in RNAi,” Cell Cycle, 8(21):3500-3505 (2009).;;An et al., “Transient RNAi Induction against Endogenous Genes in Arabidopsis Protoplasts Using in Vitro-Prepared Double-Stranded RNA,” Biosci Biotechnol Biochem, 69(2):415-418 (2005).;;Andersen et al., “Delivery of siRNA from lyophilized polymeric surfaces,”Biomaterials, 29:506-512 (2008).;;Andersson et al., “A novel selection system for potato transformation using a mutated AHAS gene,” Plant Cell Reports, 22(4):261-267 (2003).;;Anonymous, “A handbook for high-level expression and purification of 6xHis-tagged proteins,” The QiaExpressionist, (2003).;;Anonymous, “Agronomy Facts 37: Adjuvants for enhancing herbicide performance,” n.p., 1-8, (Jan. 26, 2000), Web, (Jan. 21, 2014).;;Anonymous, “Devgen, The mini-Monsanto,” KBC Securities (2006).;;Anonymous, “Do Monsanto have the next big thing?,” Austalian Herbicide Resistance Initiative (AHRI), (Apr. 23, 2013) Web. (Jan. 19, 2015).;;Aoki et al., “In Vivo Transfer Efficiency of Antisense Oligonucleotides into the Myocardium Using HVJ—Liposome Method,” Biochem Biophys Res Commun, 231:540-545 (1997).;;Arpaia et al., “Production of transgenic eggplant (Solanum melongena L.) resistant to Colorado Potato Beetle (Leptinotarsa decemlineata Say),” (1997) Theor. Appl. Genet., 95:329-334 (1997).;;Artymovich, “Using RNA interference to increase crop yield and decrease pest damage,” MMG 445 Basic Biotech., 5(1):7-12 (2009).;;Asad et al., “Silicon Carbide Whisker-mediated Plant Transformation,” Properties and Applicants of Silicon Carbide, pp. 345-358 (2011).;;Ascencio-Ibanez et al., “DNA abrasion onto plants is an effective method for geminivirus infection and virus-induced gene silencing,” J. of Virol Meth., 142:198-203 (2007).;;Axtell et al., “A Two-Hit Trigger for siRNA Biogenesis in Plants,” Cell, 127:565-577 (2006).;;Bachman et al., “Characterization of the spectrum of insecticidal activity of a double-stranded RNA with targeted activity against Western Corn Rootworm (Diabrotica virgifera virgifera LeConte),” Transgenic Res., pp. 1-16 (2013).;;Baerson et al., “Glyphosate-Resistant Goosegrass. Identification of a Mutation in the Target Enzyme 5-Enolpyruvylshikimate-3-Phosphate Synthase,” Plant Physiol., 129(3):1265-1275 (2002).;;Bai et al., “Naturally Occurring Broad-Spectrum Powdery Mildew Resistance in a Central American Tomato Accession Is Caused by Loss of Mlo Function,” MPMI, 21(1):30-39 (2008).;;Balibrea et al., “Extracellular Invertase is an Essential Component of Cytokinin-Mediated Delay of Senescence,” The Plant Cell, 16(5):1276-1287.;;Bannerjee et al., “Efficient production of transgenic potato (S. tuberosum L. ssp. andigena) plants via Agrobacterium tumefaciens-mediated transformation,” Plant Sci., 170:732 738 (2006).;;Bart et al., “A novel system for gene silencing using siRNAs in rice leaf and stem-derived protoplasts,” Plant Methods, 2(13):1-9 (2006).;;Basu et al., “Weed genomics: new tools to understand weed biology,” Trends in Plant Science, 9(8):391-398 (2004).;;Baulcombe, “RNA silencing and heritable epigenetic effects in tomato and Arabidopsis,” Abstract 13th Animal Fall Symposium, Plant Genomes to Phenomes, Donald Danforth Plant Science Center, 28-30 (2011).;;Bayer et al., “Programmable ligand-controlled riboregulators of eukaryotic gene expression,” Nature Biotechnol., 23(3):337-343 (2005).;;Beal, et al., “Second Structural Motif for Recognition of DNA by Oligonucleotide-Directed Triple-Helix Formation,” Science, 251:1360-1363 (1992).;;Becker et al., “Fertile transgenic wheat from microprojectile bombardment of scutellar tissue,” The Plant Journal, 5(2):299-307 (1994).;;Belhadj et al., “Methyl Jasmonate Induces Defense Responses in Grapevine and Triggers Protection against Erysiphe necator,” J. Agric Food Chem., 54:9119-9125 (2006).;;Bhargava et al., “Long double-stranded RNA-mediated RNA interference as a tool to achieve site-specific silencing of hypothalamic neuropeptides,” Brain Research Protocols, 13:115-125 (2004).;;Boletta et al., “High Efficient Non-Viral Gene Delivery to the Rat Kidney by Novel Polycationic Vectors,” J. Am Soc. Nephrol., 7:1728 (1996).;;Bolognesi et al., “Characterizing the Mechanism of Action of Double-Stranded RNA Activity against Western Corn Rootworm(Diabrotica virgifera virgifera LeConte),” PLoS ONE 7(10):e47534 (2012).;;Bolter et al., “A chloroplastic inner envelope membrane protease is essential for plant development,” FEBS Letters, 580:789-794 (2006).;;Bourgeois et al., “Field and producer survey of ACCase resistant wild oat in Manitoba,” Canadian Journal of Plant Science, 709-715 (1997).;;Breaker et al., “A DNA enzyme with Mg2+-dependent RNA phosphoesterase activity,” Chemistry and Biology, 2:655-660 (1995).;;Brodersen et al., “The diversity of RNA silencing pathways in plants,” Trends in Genetics, 22(5):268-280 (2006).;;Brugière et al., “Glutamine Synthetase in the Phloem Plays a Major Role in Controlling Proline Production,” The Plant Cell, 11:1995-2011 (1999).;;Burgos et al., “Review: Confirmation of Resistance to Herbicides and Evaluation of Resistance Levels,” Weed Science, 61 (1):4-20 (2013).;;Busch et al., “RNAi for discovery of novel crop protection products,” Pflanzenschutz-Nachrichten Bayer, 58(1):34-50 (2005).;;Butler et al., “Priming and re-drying improve the survival of mature seeds of Digitalis purpurea during storage,” Annals of Botany, 103:1261-1270 (2009).;;Bytebier et al., “T-DNA organization in tumor cultures and transgenic plants of the monocotyledon Asparagus officinalis,” Proc. Natl. Acad. Sci. U.S.A., 84:5345-5349 (1987).;;Campbell et al., “Gene-knockdown in the honey bee mite Varroa destructor by a non-invasive approach: studies on a glutathione S-transferase,” Parasites & Vectors, 3(1):73, pp. 1-10 (2010).;;Chabannes et al., “In situ analysis of lignins in transgenic tobacco reveals a differential impact of individual transformations on the spatial patterns of lignm deposition at the cellular and subcellular levels,” The Plant Journal, 28(3):271-282 (2001).;;Chabbouh et al., “Cucumber mosaic virus in artichoke,” FAO Plant Protection Bulletin, 38:52-53 (1990).;;Chakravarty et al., “Genetic Transformation in Potato: Approaches and Strategies,” Amer J Potato Res, 84:301 311 (2007).;;Chang et al., “Dual-target gene silencing by using long, sythetic siRNA duplexes without triggering antiviral responses,” Molecules and Cells, 27(6) 689-695 (2009).;;Chang et al., “Cellular Internalization of Fluorescent Proteins via Arginine-rich Intracellular Delivery Peptide in Plant Cells,” Plant Cell Physiol., 46(3):482-488 (2005).;;Chee et al., “Transformation of Soybean (Glycine max) by Infecting Germinating Seeds with Agrobacterium tumefaciens,” Plant Physiol., 91:1212-1218 (1989).;;Chen et al., “Exploring MicroRNA-Like Small RNAs in the Filamentous Fungus Fusarium oxysporum,” PLOS One, 9(8):e104956:1-10 (2014).;;Chen et al., “In Vivo Analysis of the Role of atTic20 in Protein Import into Chloroplasts,” The Plant Cell, 14:641-654 (2002).;;Chen et al., “Transfection and Expression of Plasmid DNA in Plant Cells by an Arginine-Rich Intracellular Delivery Peptide without Protoplast Preparation,” FEBS Letters 581, pp. 1891-1897 (2007).;;Cheng et al., “Production of fertile transgenic peanut (Arachis hypogaea L.) plants using Agrobacterium tumefaciens,” Plant Cell Reports, 15:653-657 (1996).;;Chi et al., “The Function of RH22, a DEAD RNA Helicase, in the Biogenesis of the 505 Ribosomal Subunits of Arabidopsis Chloroplasts,” Plant Physiology, 158:693-707 (2012).;;Chupp et al., “Chapter 8: White Rust,” Vegetable Diseases and Their Control, The Ronald Press Company, New York, pp. 267-269 (1960).;;Clough et al., “Floral dip: a simplified method for Agrobacterium-mediated transformation of Arabidopsis thaliana,” The Plant Journal, 16(6):735-743 (1998).;;CN101914540 Patent Disclosure, “Introduction of RNA into plant by interference,” (2010).;;Colbourne et al., “The Ecoresponsive Genome of Daphnia pulex,” Science, 331(6017):555-561 (2011).;;Colliver et al., “Differential modification of flavonoid and isoflavonoid biosynthesis with an antisense chalcone synthase construct in transgenic Lotus corniculatus,” Plant Molecular Biology, 35:509-522 (1997).;;Communication pursuant to Article 94(3) EPC dated Jan. 14, 2016, in European Patent Application No. 12 832 415.9.;;Communication pursuant to Article 94(3) EPC dated Jun. 26, 2015, in European Patent Application No. 11 753 916.3.;;Communication pursuant to Article 94(3) EPC dated Mar. 18, 2016, in European Patent Application No. 12 832 160.1.;;Communication pursuant to Article 94(3) EPC dated Mar. 24, 2016, in European Patent Application No. 12 831 684.1.;;Communication pursuant to Article 94(3) EPC dated Mar. 4, 2016, in European Patent Application No. 12 830 932.5.;;Communication pursuant to Article 94(3) EPC dated Mar. 9, 2016, in European Patent Application No. 12 831 166.9.;;Communication pursuant to Article 94(3) EPC dated Oct. 23, 2015, in European Patent Application No. 12 831 945.6.;;Communication pursuant to Article 94(3) EPC dated Sep. 5, 2018, in European Patent Application No. 17152830.0.;;Concise Descriptions of Relevance filed by a third party on Nov. 29, 2012, in U.S. Appl. No. 13/042,856.;;Cooney et al., “Site-Specific Oligonucleotide Binding Represses Transcription of the Human c-myc Gene in Vitro,” Science ,241:456-459 (1988).;;Cost Action FA0806 progress report “Plant virus control employing RNA-based vaccines: A novel non-transgenic strategy” (2010).;;Coticchia et al., “Calmodulin modulates Akt activity in human breast cancer cell lines,” Breast Cancer Res. Treat, 115:545-560 (2009).;;Dalakouras et al., “Induction of Silencing in Plants by High-Pressure Spraying of in vitro-Synthesized Small RNAs,” Frontiers in Plant Science, 7(1327):1-5 (2016).;;Dalmay et al., “An RNA-Depenedent RNA Polymerase Gene in Arabidopsis Is Required for Posttransciptional Gene Silencing Mediated by a Transgene but Not by a Virus,” Cell, 101:543-553 (2000).;;DATABASE EMBL [online] 20 March 2001 (2001-03-20), ""GA__Ea0017G05f Gossypium arboreum 7-10 dpa fiber library Gossypium arboreum cDNA clone GA__Ea0017G05f, mRNA sequence."", XP002781749, retrieved from EBI;;Davidson et al., “Engineering regulatory RNAs,” TRENDS in Biotechnology, 23(3):109-112 (2005).;;Dawson et al., “cDNA cloning of the complete genome of tobacco mosaic virus and production of infectious transcripts,” Proc. Natl. Acad. Sci. USA, 83:1832-1836 (1986).;;Declaration of Jerzy Zabkiewicz executed Nov. 28, 2017, as filed by Opponent in Australian Patent Application No. 2014262189, pp. 1-73.;;Declaration of Jerzy Zabkiewicz executed Nov. 28, 2017, as filed by Opponent in Australian Patent Application No. 2014262189, pp. 1-4.;;Declaration of Neena Mitter executed Nov. 30, 2017, as filed by Opponent in Australian Patent Application No. 2014262189, pp. 1-114.;;Declaration of Neena Mitter executed Nov. 30, 2017, as filed by Opponent in Australian Patent Application No. 2014262189, pp. 1-25.;;De Framond, “MINI-Ti: A New Vector Strategy for Plant Genetic Engineering,” Nature Biotechnology, 1:262-269 (1983).;;Della-Cioppa et al., “Import of a precursor protein into chloroplasts is inhibited by the herbicide glyphosate,” The EMBO Journal, 7(5):1299-1305 (1988).;;Delye et al., “PCR-based detection of resistance to acetyl-CoA carboxylase-inhibiting herbicides in black-grass (Alopecurus myosuroides Huds) and ryegrass (Lolium rigidum Gaud),” Pest Management Science, 58:474-478 (2002).;;Desai et al., “Reduction in deformed wing virus infection in larval and adult honey bees (Apis mellifera L.) by double-stranded RNA ingestion,” Insect Molecular Biology, 21(4):446-455 (2012).;;Desveaux et al., “PBF-2 Is a Novel Single-Stranded DNA Binding Factor Implicated in PR-10a Gene Activation in Potato,” The Plant Cell, 12:1477-1489 (2000).;;Di Stilio et al., “Virus-Induced Gene Silencing as a Tool for Comparative Functional Studies in Thalictrum,” PLoS One, 5(8):e12064 (2010).;;Diallo et al., “Long Endogenous dsRNAs Can Induce Complete Gene Silencing in Mammalian Cells and Primary Cultures,” Oligonucleotides, 13:381-392 (2003).;;Dietemann et al., “Varroa destructor: research avenues towards sustainable control,” Journal of Apicultural Research, 51(1):125-132 (2012).;;Dietzgen et al., “Transgenic gene silencing strategies for virus control,” Australasian Plant Pathology, 35:605-618 (2006).;;Dilpreet et al., “Glyphosate Resistance in a Johnsongrass (Sorghum halepense) Biotype from Arkansas,” Weed Science, 59(3):299-304 (2011).;;Downey et al., “Single and dual parasitic mite infestations on the honey bee, Apis mellifera L.,” Insectes Sociaux, 47(2):171-176 (2000).;;Du et al., “A systematic analysis of the silencing effects of an active siRNA at all single-nucleotide mismatched target sites,” Nucleic Acids Research, 33(5):1671-1677 (2005).;;Dunoyer et al., “Small RNA Duplexes Function as Mobile Silencing Signals Between Plant Cells,” Science, 328:912-916 (2010).;;Egli et al., “A Maize Acetyl-Coenzyme A Carboxylase cDNA Sequence,” Plant Physiol., 108: 1299-1300 (1995).;;Ellington et al., “In vitro selection of RNA molecules that bind specific ligands,” Nature, 346:818-822 (1990).;;Emery et al., “Radial Patterning of Arabidopsis Shoots by Class III HD-ZIP and KANADI Genes,” Current Biology, 13:1768-1774 (2003).;;European Cooperation in the field of Scientific and Technical Research—Memorandum of Understanding for COST Action FA0806 (2008).;;European Search Report dated Sep. 7, 2017, in European Patent Application No. 17152830.0.;;Examination Report dated Mar. 1, 2018, in Australian Patent Application No. 2013264742.;;Extended European Search Report dated Dec. 19, 2018, in European Patent Application No. 16804395.8.;;Extended European Search Report dated Feb. 2, 2015, in European Patent Application No. 12 830 932.5.;;Extended European Search Report dated Feb. 27, 2015, in European Patent Application No. 12 832 160.1.;;Extended European Search Report dated Feb. 3, 2015, in European Patent Application No. 12 831 945.6.;;Extended European Search Report dated Jan. 20, 2016, in European Patent Application No. 13 794 339.5.;;Extended European Search Report dated Jan. 21, 2015, in European Patent Application No. 12 832 415.9.;;Extended European Search Report dated Jan. 29, 2015, in European Patent Application No. 12 831 567.8.;;Extended European Search Report dated Jun. 29, 2015, in European Patent Application No. 12 831 494.5.;;Extended European Search Report dated Mar. 17, 2015, in European Patent Application No. 12 831 684.1.;;Extended European Search Report dated Mar. 3, 2015, in European Patent Application No. 12 831 166.9.;;Extended European Search Report dated Nov. 16, 2018, in European Patent Application No. 18182238.8.;;Extended European Search Report dated Nov. 21, 2018, in European Patent Application No. 18175809.5.;;Extended European Search Report dated Nov. 7, 2017, in European Patent Application No. 15811092.4.;;Extended European Search Report dated Nov. 8, 2017, in European Patent Application No. 15737282.2.;;Extended European Search Report dated Oct. 8, 2013, in European Patent Application No. 11753916.3.;;Extended European Search Report dated Sep. 28, 2018, in European Patent Application No. 16740770.9.;;Extended European Search Report dated Sep. 29, 2016, in European Patent Application No. 14778840.0.;;Extended European Search Report dated Apr. 13, 2018, in European Patent Application No. 15812530.0.;;Extended European Search Report dated Mar. 15, 2018, in European Patent Application No. 17181861.0.;;Farooq et al., “Rice seed priming,” IPRN, 30(2):45-48 (2005).;;Fassler, BLAST Glossary, National Center for Biotechnology Information (2011).;;Feuillet et al., “Crop genome sequencing: lessons and rationales,” Trends Plant Sci., 16:77-88 (2011).;;Final Office Action dated Apr. 7, 2016, in U.S. Appl. No. 13/619,980.;;Final Office Action dated Dec. 17, 2015, in U.S. Appl. No. 14/335,135.;;Final Office Action dated Feb. 17, 2016, in U.S. Appl. No. 13/612,929.;;Final Office Action dated Feb. 4, 2016, in U.S. Appl. No. 13/612,936.;;Final Office Action dated Jun. 30, 2016, in U.S. Appl. No. 13/901,326.;;Final Office Action dated Mar. 2, 2016, in U.S. Appl. No. 13/612,995.;;Final Office Action dated Mar. 21, 2016, in U.S. Appl. No. 13/612,925.;;Final Office Action dated May 26, 2016, in U.S. Appl. No. 14/532,596.;;Final Office Action dated Nov. 10, 2015, in U.S. Appl. No. 13/612,985.;;Final Office Action dated Nov. 10, 2016, in U.S. Appl. No. 13/583,302.;;Final Office Action dated Nov. 19, 2015, in U.S. Appl. No. 13/612,941.;;Final Office Action dated Nov. 30, 2015, in U.S. Appl. No. 13/612,948.;;Final Office Action dated Nov. 7, 2013, in U.S. Appl. No. 13/042,856.;;Final Office Action dated Oct. 20, 2016, in U.S. Appl. No. 14/480,199.;;Final Office Action dated Oct. 22, 2015, in U.S. Appl. No. 14/608,951.;;Final Office Action dated Sep. 9, 2016, in U.S. Appl. No. 13/612,954.;;Final Office Action dated Sep. 9, 2016, in U.S. Appl. No. 14/608,951.;;Final Office Action dated Sep. 9, 2016, in U.S. Appl. No. 14/603,347.;;Fire et al., “Potent and specific genetic interference by double-stranded RNA in Caenorhabditis elegans,” Nature, 391:806-811 (1998).;;First Examination Report dated Apr. 23, 2013, in New Zealand Patent Application No. 601784.;;First Examination Report dated Jul. 28, 2014, in New Zealand Patent Application No. 627060.;;First Office Action dated Aug. 31, 2015, in Chinese Patent Application No. 201280053985.3.;;First Office Action dated Feb. 2, 2016, in Chinese Patent Application No. 201380039346.6.;;First Office Action dated Jul. 7, 2015, in Chinese Patent Application No. 201280054820.8.;;First Office Action dated Mar. 12, 2015, in Chinese Patent Application No. 201280053984.9.;;First Office Action dated Mar. 2, 2015, in Chinese Patent Application No. 201280054819.5.;;First Office Action dated May 27, 2015, in Chinese Patent Application No. 201280054179.8.;;First Office Action dated Sep. 9, 2015, in Chinese Patent Application No. 201280055409.2.;;Fraley et al., “Liposome-mediated delivery of tobacco mosaic virus RNA into tobacco protoplasts: A sensitive assay for monitoring liposome-protoplast interactions,” Proc Natl Acad Sci U S A., 79(6):1859-1863 (1982).;;Fukuhara et al., “Enigmatic Double-Stranded RNA in Japonica Rice,” Plant Molecular Biology, 21:1121-1130 (1993).;;Fukuhara et al., “The Unusual Structure of a Novel RNA Replicon in Rice,” The Journal of Biological Chemistry, 270(30):18147-18149 (1995).;;Fukuhara et al., “The wide distribution of endornaviruses, large double-stranded RNA replicons with plasmid-like properties,” Archives of Virology, 151:995-1002 (2006).;;Fukunaga et al., “dsRNA with 5′ overhangs v contributes to endogenous and antiviral RNA silencing pathways in plants,” The EMBO Journal, 28(5):545-555 (2009).;;Further Examination Report dated May 16, 2014, in New Zealand Patent Application No. 601784.;;Gaines et al., “Gene amplification confers glyphosate resistance in Amaranthus palmeri,” Proc. Natl. Acad. Sci. USA, 107(3):1029-1034 (2010).;;Gallic et al., “Identification of the motifs within the tobacco mosaic virus 5′-leader responsible for enhancing translation,” Nucleic Acids Res., 20(17):4631-4638 (1992).;;Gan et al., “Bacterially expressed dsRNA protects maize against SCMV infection,” Plant Cell Rep, 29:1261-1268 (2010).;;Gan et al., “Inhibition of Leaf Senescence by Autoregulated Production of Cytokinin,” Science, 270:1986-1988 (1995).;;Gao et al., “Down-regulation of acetolactate synthase compromises 01-1-mediated resistance to powdery mildew in tomato,” BMC Plant Biology, 14 (2014).;;Gao et al., “Nonviral Methods for siRNA Delivery,” Molecular Pharmaceutics, 6(3):651-658 (2008).;;Garbian et al., “Bidirectional Transfer of RNAi between Honey Bee and Varroa destructor: Varroa Gene Silencing Reduces Varroa Population,” 8(12):1-9:e1003035 (2012).;;Gasser et al., “Structure, Expression, and Evolution of the 5-Enolpyruvylshikimate-3-phosphate Synthase Genes of Petunia and Tomato,” J. Biol. Chem., 263: 4280-4287 (1988).;;Ge et al., “Rapid vacuolar sequestration: the horseweed glyphosate resistance mechanism,” Pest Management Sci., 66:345-348 (2010).;;GenBank Accession No. AY545657.1 (2004).;;GenBank Accession No. CB377464, “CmaE1_37_J02_T3 Cowpea weevil larvae Lambda Zap Express Library Callosobruchus maculatus cDNA, mRNA sequence,” (2007).;;GenBank Accession No. DY640489, “PU2_plate27_F03 PU2 Prunus persica cDNA similar to expressed mRNA inferred from Prunus persica hypothetical domain/motif cont aining IPR011005:Dihydropteroate synthase-like, MRNA sequence” (2006).;;GenBank Accession No. EF143582 (2007).;;GenBank Accession No. EU024568, “Amaranthus hypochondriacus acetolactate synthase (ALS) gene” (2007).;;GenBank Accession No. EW765249, “ST020010B10C12 Normalized and subtracted western corn rootworm female head cDNA library Diabrotica virgifera virgifera cDNA clone ST020010B10C12 5-, mRNA sequence,” (2007).;;GenBank Accession No. EW771198, “ST020010B10C12 Normalized and subtracted western corn rootworm female head cDNA library Diabrotica virgifera virgifera cDNA clone ST020010B10C12 5-, mRNA sequence,” (2007).;;GenBank Accession No. FE348695, “CBIB7954.fwd CBIB_Daphnia_pulex_Chosen_One_Library_2Daphnia pulex cDNA clone CBIB7954 5′, mRNA sequence” (2011).;;GenBank Accession No. FJ972198, “Solanum lycopersicum cultivar Ailsa Craig dihydropterin pyrophosphokinase-dihydropteroate synthase (HPPK-DHPS) gene, complete cds” (2010).;;GenBank Accession No. GI:186478573 (2014).;;GenBank Accession No. GU120406, “Chrysomela tremulae ribosomal protein L7 (RpL7) mRNA, complete cds” (2009).;;GenBank Accession No. HD315444, “Sequence 192160 from Patent EP2213738” (2010).;;GenBank Accession No. Q4GXM3_BIPLU, “Ribosomal protein L7e” (2006).;;GenBank Accession No. U87257.1, “Daucus carota 4-hydroxyphenylpyruvate dioxygenase mRNA, complete cds” (1997).;;GenBank Accession No. XM_014456745.1, Predicted: Myotis lucifugus ribonucleoprotein, PTB-binding 2 (RAVER2), transcript variant X3, mRNA,: (2015).;;GenBank Accession No. Y08611.1, “P.sativum mRNA for dihydropterin pyrophosphokinase/dihydropteroate synthase.” (2006).;;GenEmbl Accession No. FJ861243 (2010).;;Gomez-Zurita et al., “Recalibrated Tree of Leaf Beetles (Chrysomelidae) Indicates Independent Diversification of Angiosperms and Their Insect Herbivores,” PLoS One, 4(e360):1-8 (2007).;;Gong et al., “Silencing of Rieske iron-sulfur protein using chemically synthesised siRNA as a potential biopesticide against Plutella xylostella,” Pest Manag Sci, 67:514-520 (2011).;;Gossamer Threads, Compendium of Herbicide Adjuvants: Organo-Silicone Surfactant, p. 1-4 (1998).;;Gressel et al., “A strategy to provide long-term control of weedy rice while mitigating herbicide resistance transgene flow, and its potential use for other crops with related weeds,” Pest Manag Sci, 65(7):723-731 (2009).;;Gudkov, “Minireview: The L7/L12 ribosomal domain of the ribosome: structural and functional studies,” FEBS Letters, 407:253-256 (1997).;;Gutensohn et al., “Functional analysis of the two Arabidopsis homologues of Toc34, a component of the chloroplast protein import apparatus,” The Plant Journal, 23(6):771-783 (2000).;;Haigh, “The Priming of Seeds: Investigation into a method of priming large quantities of seeds using salt solutions,” Thesis submitted to Macquarie University (1983).;;Hajirezaei et al., “Impact of elevated cytosolic and apoplastic invertase activity on carbon metabolism during potato tuber development,” Journal of Experimental Botany, 51:439-445 (2000).;;Hamilton et al., “Guidelines for the Identification and Characterization of Plant Viruses,” J. gen. Virol., 54:223-241 (1981).;;Hamilton et al., “Two classes of short interfering RNA in RNA silencing,” EMBO J., 21(17):4671-4679 (2002).;;Han et al., “Molecular Basis for the Recognition of Primary microRNAs by the Drosha-DGCR8 Complex,” Cell, 125(5):887-901 (2006).;;Hannon, “RNA interference,” Nature,481:244-251 (2002).;;Hardegree, “Drying and storage effects on germination of primed grass seeds,” Journal of Range Management, 47(3):196-199 (1994).;;Harrison et al., “Does Lowering Glutamine Synthetase Activity in Nodules Modigy Nitrogen Metabolism and Growth of Lotus japonicus?,” Plant Physiology, 133:253-262 (2003).;;Heffer et al., “Rapid isolation of gene homologs across taxa: Efficient identification and isolation of gene orthologs from non-model organism genomes, a technical report,” EvoDevo Journal, 2(7):1-5 (2011).;;Herman et al., “A three-component dicamba O-demethylase from Pseudomonas maltophilia, strain DI-6: gene isolation, characterization, and heterologous expression,” J. Biol. Chem., 280: 24759-24767 (2005).;;Hewezi et al., “Local infiltration of high- and low-molecular-weight RNA from silenced sunflower (Helianthus annuus L.) plants triggers post-transcriptional gene silencing in non-silenced plants,” Plant Biotechnology Journal, 3:81-89 (2005).;;Hidayat et al., “Enhanced Metabolism of Fluazifop Acid in a Biotype of Digitaria sanguinalis Resistant to the Herbicide Fluazifop-P-Butyl,” Pesticide Biochem. Physiol., 57:137-146 (1997).;;Himber et al., “Transitivity-dependant and -independent cell-to-cell movement of RNA silencing,” The EMBO Journal, 22(17):4523-4533 (2003).;;Hirschberg et al., “Molecular Basis of Herbicide Resistance in Amaranthus hybridus,” Science, 222:1346-1349 (1983).;;Hoekema et al., “A binary plant vector strategy based on separation of vir- and T-region of the Agrobacterium tumefaciens Ti-plasmid,” Nature, 303:179-180 (1983).;;Hofgen et al., “Repression of Acetolactate Synthase Activity through Antisense Inhibition: Molecular and Biochemical Analysis of Transgenic Potato (Solanum tuberosum L. cv Desiree) Plants,” Plant Physiol., 107(2):469-477 (1995).;;Holtra et al., “Assessment of the Physiological Condition of Salvinia natans L. Exposed to Copper(II) Ions,” Environ. Protect. Eng., 41:147-158 (2015).;;Hsieh et al., “A library of siRNA duplexes targeting the phosphoinositide 3-kinase pathway: determinants of gene silencing for use in cell-based screens,” Nucleic Acids res., 32(3):893-901 (2004).;;Hu et al., “High efficiency transport of quantum dots into plant roots with the aid of silwet L-77,” Plant Physiology and Biochemistry, 48:703-709 (2010).;;Huesken et al., “Design of a genome-wide siRNA library using an artificial neural network,” Nature Biotechnology, 23(8): 995-1001 (2005).;;Hunter et al., “RNA Interference Strategy to suppress Psyllids & Leafhoppers,” International Plant and Animal Genome XIX, 15-19 (2011).;;Ichihara et al., “Thermodynamic instability of siRNA duplex is a prerequisite for dependable prediction of siRNA activities,” Nucleic Acids Res., 35(18):e123 (2007).;;International Preliminary Report on Patentability (Chapter II) dated Jul. 24, 2015, in International Application No. PCT/US2014/047204.;;International Preliminary Report on Patentability dated Sep. 11, 2012, in International Application No. PCT/US2011/027528.;;International Preliminary Report on Patentability dated Sep. 11, 2014, in International Application No. PCT/IL2013/050447.;;International Rice Genome Sequencing Project, The map-based sequence of the rice genome, Nature, 436(11):793-800 (2005).;;International Search Report and the Written Opinion dated Feb. 25, 2013, in International Application No. PCT/US2012/054883.;;International Search Report and the Written Opinion dated Feb. 27, 2013, in International Application No. PCT/US2012/054814.;;International Search Report and the Written Opinion dated Feb. 27, 2013, in International Application No. PCT/US2012/054842.;;International Search Report and the Written Opinion dated Feb. 27, 2013, in International Application No. PCT/US2012/054862.;;International Search Report and the Written Opinion dated Feb. 27, 2013, in International Application No. PCT/US2012/054894.;;International Search Report and the Written Opinion dated Feb. 27, 2013, in International Application No. PCT/US2012/054974.;;International Search Report and the Written Opinion dated Feb. 27, 2013, in International Application No. PCT/US2012/054980.;;International Search Report and the Written Opinion dated Jul. 15, 2014, in International Application No. PCT/US2014/025305.;;International Search Report and the Written Opinion dated Jul. 22, 2014, in International Application No. PCT/IL2013/051083.;;International Search Report and the Written Opinion dated Jul. 22, 2014, in International Application No. PCT/IL2013/051085.;;International Search Report and the Written Opinion dated Jul. 24, 2014, in International Application No. PCT/US2014/026036.;;International Search Report and the Written Opinion dated May 10, 2011, in International Application No. PCT/US2011/027528.;;International Search Report and the Written Opinion dated Oct. 1, 2013, in International Application No. PCT/IL2013/050447.;;International Search Report and Written Opinion dated Aug. 25, 2014, in International Application No. PCT/US2014/023503.;;International Search Report and Written Opinion dated Aug. 27, 2014, in International Application No. PCT/US2014/023409.;;International Search Report and Written Opinion dated Feb. 23, 2015, in International Application No. PCT/US2014/063832.;;International Search Report and Written Opinion dated Jul. 8, 2015, in International Application No. PCT/US2015/011408.;;International Search Report and Written Opinion dated Mar. 26, 2015, in International Application No. PCT/US2014/069353.;;International Search Report and Written Opinion dated May 26, 2016, in International Application No. PCT/US2016/014344.;;International Search Report and Written Opinion dated Nov. 24, 2015, in International Application No. PCT/US2015/037522.;;International Search Report and Written Opinion dated Nov. 27, 2015, in International Application No. PCT/US2015/037015.;;International Search Report dated Mar. 12, 2013, in International Application No. PCT/US2012/054789.;;Invitation to Pay Additional Fees dated May 6, 2014, in International Application No. PCT/IL2013/051083.;;Invitation to Pay Additional Fees dated May 6, 2014, in International Application No. PCT/IL2013/051085.;;Invitation to Pay Additional Fees dated Nov. 25, 2014, in International Application No. PCT/US2014/047204.;;Invitation to Pay Additional Fees dated Sep. 8, 2015, in International Application No. PCT/US2015/037015.;;Invitation to Pay Additional Fees dated Sep. 9, 2015, in International Application No. PCT/US2015/037522.;;Isaacs et al., “Engineered riboregulators enable post-transcriptional control of gene expression,” Nature Biotechnology, 22(7):841-847 (2004).;;Jang et al., “Resistance to herbicides caused by single amino acid mutations in acetyl-CoA carboxylase in resistant populations of grassy weeds,” New Phytologist, 197(4):1110-1116 (2013).;;Ji et al., “Regulation of small RNA stability: methylation and beyond,” Cell Research, 22:624-636 (2012).;;Jiang et al., Chapter III Seeds and Seedlings, Botany, Northwest A&F University Press, pp. 87-92 (2009). et al.",INACTIVE
